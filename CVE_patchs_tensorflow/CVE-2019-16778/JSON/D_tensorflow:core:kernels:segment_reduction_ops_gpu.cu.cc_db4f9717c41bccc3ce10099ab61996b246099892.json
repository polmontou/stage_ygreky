"diff --git a/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc b/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc\nindex 0623df166f8..490c3d2de82 100644\n--- a/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc\n+++ b/tensorflow/core/kernels/segment_reduction_ops_gpu.cu.cc\n@@ -106,21 +106,21 @@ __global__ void SortedSegmentSumCustomKernel(const Index input_outer_dim_size,\n // Each element is mapped from input to output by a combination of its\n // 'segment_ids' mapping and 'inner_dim_size'.\n template <typename T, typename Index, typename KernelReductionFunctor>\n-__global__ void UnsortedSegmentCustomKernel(const Index input_outer_dim_size,\n-                                            const Index inner_dim_size,\n-                                            const Index output_outer_dim_size,\n+__global__ void UnsortedSegmentCustomKernel(const int64 input_outer_dim_size,\n+                                            const int64 inner_dim_size,\n+                                            const int64 output_outer_dim_size,\n                                             const Index* segment_ids,\n                                             const T* input, T* output) {\n-  const Index input_total_size = input_outer_dim_size * inner_dim_size;\n-  const Index output_total_size = output_outer_dim_size * inner_dim_size;\n-  for (int input_index : GpuGridRangeX(input_total_size)) {\n-    const Index input_segment_index = input_index / inner_dim_size;\n-    const Index segment_offset = input_index % inner_dim_size;\n+  const int64 input_total_size = input_outer_dim_size * inner_dim_size;\n+  for (int64 input_index : GpuGridRangeX(input_total_size)) {\n+    const int64 input_segment_index = input_index / inner_dim_size;\n+    const int64 segment_offset = input_index % inner_dim_size;\n     const Index output_segment_index = segment_ids[input_segment_index];\n-    if (output_segment_index < 0 || output_segment_index >= output_total_size) {\n+    if (output_segment_index < 0 ||\n+        output_segment_index >= output_outer_dim_size) {\n       continue;\n     }\n-    const Index output_index =\n+    const int64 output_index =\n         output_segment_index * inner_dim_size + segment_offset;\n     KernelReductionFunctor()(output + output_index, ldg(input + input_index));\n   }\n@@ -174,10 +174,9 @@ void SegmentSumFunctor<T, Index>::operator()(\n template <typename T, typename Index, typename InitialValueF,\n           typename ReductionF>\n struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n-  void operator()(OpKernelContext* ctx, const Index num_segments,\n-                  const TensorShape& segment_ids_shape,\n+  void operator()(OpKernelContext* ctx, const TensorShape& segment_ids_shape,\n                   typename TTypes<Index>::ConstFlat segment_ids,\n-                  const Index data_size, const T* data,\n+                  typename TTypes<T, 2>::ConstTensor data,\n                   typename TTypes<T, 2>::Tensor output) {\n     if (output.size() == 0) {\n       return;\n@@ -188,6 +187,7 @@ struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n     TF_CHECK_OK(GpuLaunchKernel(\n         SetToValue<T>, config.block_count, config.thread_per_block, 0,\n         d.stream(), output.size(), output.data(), InitialValueF()()));\n+    const int64 data_size = data.size();\n     if (data_size == 0 || segment_ids_shape.num_elements() == 0) {\n       return;\n     }\n@@ -196,15 +196,16 @@ struct UnsortedSegmentFunctor<GPUDevice, T, Index, InitialValueF, ReductionF> {\n     // *) 'data_size' is the total number of elements to process.\n     // *) 'segment_ids.shape' is a prefix of data's shape.\n     // *) 'input_outer_dim_size' is the total number of segments to process.\n-    const Index input_outer_dim_size = segment_ids.dimension(0);\n-    const Index input_inner_dim_size = data_size / input_outer_dim_size;\n+    const int64 input_outer_dim_size = segment_ids.dimension(0);\n+    const int64 input_inner_dim_size = data.dimension(1);\n+    const int64 output_outer_dim_size = output.dimension(0);\n     config = GetGpuLaunchConfig(data_size, d);\n \n-    TF_CHECK_OK(\n-        GpuLaunchKernel(UnsortedSegmentCustomKernel<T, Index, ReductionF>,\n-                        config.block_count, config.thread_per_block, 0,\n-                        d.stream(), input_outer_dim_size, input_inner_dim_size,\n-                        num_segments, segment_ids.data(), data, output.data()));\n+    TF_CHECK_OK(GpuLaunchKernel(\n+        UnsortedSegmentCustomKernel<T, Index, ReductionF>, config.block_count,\n+        config.thread_per_block, 0, d.stream(), input_outer_dim_size,\n+        input_inner_dim_size, output_outer_dim_size, segment_ids.data(),\n+        data.data(), output.data()));\n   }\n };\n "