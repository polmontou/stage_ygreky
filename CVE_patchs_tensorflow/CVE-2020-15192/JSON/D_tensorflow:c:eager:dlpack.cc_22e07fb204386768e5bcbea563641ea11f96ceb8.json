"diff --git a/tensorflow/c/eager/dlpack.cc b/tensorflow/c/eager/dlpack.cc\nindex 30d2009dc6a..df8e9ace997 100644\n--- a/tensorflow/c/eager/dlpack.cc\n+++ b/tensorflow/c/eager/dlpack.cc\n@@ -249,21 +249,36 @@ void TFE_CallDLManagedTensorDeleter(void* dlm_ptr) {\n }\n \n void* TFE_HandleToDLPack(TFE_TensorHandle* h, TF_Status* status) {\n+  auto tf_dlm_context = GetDlContext(h, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n+  auto* tf_dlm_data = TFE_TensorHandleDevicePointer(h, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n   const Tensor* tensor = GetTensorFromHandle(h, status);\n   TF_DataType data_type = static_cast<TF_DataType>(tensor->dtype());\n-  TensorReference tensor_ref(*tensor);  // This will call buf_->Ref()\n \n+  auto tf_dlm_type = GetDlDataType(data_type, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n+  TensorReference tensor_ref(*tensor);  // This will call buf_->Ref()\n   auto* tf_dlm_tensor_ctx = new TfDlManagedTensorCtx(tensor_ref);\n   tf_dlm_tensor_ctx->reference = tensor_ref;\n \n   DLManagedTensor* dlm_tensor = &tf_dlm_tensor_ctx->tensor;\n   dlm_tensor->manager_ctx = tf_dlm_tensor_ctx;\n   dlm_tensor->deleter = &DLManagedTensorDeleter;\n-  dlm_tensor->dl_tensor.ctx = GetDlContext(h, status);\n+  dlm_tensor->dl_tensor.ctx = tf_dlm_context;\n   int ndim = tensor->dims();\n   dlm_tensor->dl_tensor.ndim = ndim;\n-  dlm_tensor->dl_tensor.data = TFE_TensorHandleDevicePointer(h, status);\n-  dlm_tensor->dl_tensor.dtype = GetDlDataType(data_type, status);\n+  dlm_tensor->dl_tensor.data = tf_dlm_data;\n+  dlm_tensor->dl_tensor.dtype = tf_dlm_type;\n \n   std::vector<int64_t>* shape_arr = &tf_dlm_tensor_ctx->shape;\n   std::vector<int64_t>* stride_arr = &tf_dlm_tensor_ctx->strides;\n@@ -276,13 +291,14 @@ void* TFE_HandleToDLPack(TFE_TensorHandle* h, TF_Status* status) {\n     (*stride_arr)[i] = (*shape_arr)[i + 1] * (*stride_arr)[i + 1];\n   }\n \n-  dlm_tensor->dl_tensor.shape = &(*shape_arr)[0];\n+  dlm_tensor->dl_tensor.shape = shape_arr->data();\n   // There are two ways to represent compact row-major data\n   // 1) nullptr indicates tensor is compact and row-majored.\n   // 2) fill in the strides array as the real case for compact row-major data.\n   // Here we choose option 2, since some frameworks didn't handle the strides\n   // argument properly.\n-  dlm_tensor->dl_tensor.strides = &(*stride_arr)[0];\n+  dlm_tensor->dl_tensor.strides = stride_arr->data();\n+\n   dlm_tensor->dl_tensor.byte_offset =\n       0;  // TF doesn't handle the strides and byte_offsets here\n   return static_cast<void*>(dlm_tensor);"