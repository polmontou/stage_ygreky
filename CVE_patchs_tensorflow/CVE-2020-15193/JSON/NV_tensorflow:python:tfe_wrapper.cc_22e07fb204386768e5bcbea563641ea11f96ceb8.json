"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");;\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <memory>\n\n#include \"Python.h\"\n#include \"absl/strings/str_format.h\"\n#include \"pybind11/chrono.h\"\n#include \"pybind11/complex.h\"\n#include \"pybind11/functional.h\"\n#include \"pybind11/pybind11.h\"\n#include \"pybind11/stl.h\"\n#include \"tensorflow/c/c_api.h\"\n#include \"tensorflow/c/c_api_experimental.h\"\n#include \"tensorflow/c/eager/c_api.h\"\n#include \"tensorflow/c/eager/c_api_experimental.h\"\n#include \"tensorflow/c/eager/c_api_internal.h\"\n#include \"tensorflow/c/eager/dlpack.h\"\n#include \"tensorflow/c/eager/tfe_tensorhandle_internal.h\"\n#include \"tensorflow/c/tf_status.h\"\n#include \"tensorflow/c/tf_status_helper.h\"\n#include \"tensorflow/compiler/jit/flags.h\"\n#include \"tensorflow/compiler/jit/get_compiler_ir.h\"\n#include \"tensorflow/python/eager/pywrap_tensor_conversion.h\"\n#include \"tensorflow/python/eager/pywrap_tfe.h\"\n#include \"tensorflow/python/lib/core/py_exception_registry.h\"\n#include \"tensorflow/python/lib/core/pybind11_lib.h\"\n#include \"tensorflow/python/lib/core/pybind11_status.h\"\n#include \"tensorflow/python/lib/core/safe_ptr.h\"\n#include \"tensorflow/python/lib/core/safe_pyobject_ptr.h\"\n#include \"tensorflow/python/util/util.h\"\n\nnamespace py = pybind11;\n\nPYBIND11_MAKE_OPAQUE(TFE_Executor);\nPYBIND11_MAKE_OPAQUE(TFE_ContextOptions);\nPYBIND11_MAKE_OPAQUE(TFE_CancellationManager);\n\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringCounter0);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringCounter1);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringCounter2);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringStringGauge0);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringStringGauge1);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringStringGauge2);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringIntGauge0);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringIntGauge1);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringIntGauge2);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringBoolGauge0);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringBoolGauge1);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringBoolGauge2);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringSampler0);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringSampler1);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringSampler2);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringCounterCell);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringIntGaugeCell);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringStringGaugeCell);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringBoolGaugeCell);\nPYBIND11_MAKE_OPAQUE(TFE_MonitoringSamplerCell);\n\nPYBIND11_MAKE_OPAQUE(TF_DeviceList);\nPYBIND11_MAKE_OPAQUE(TF_Function);\nPYBIND11_MAKE_OPAQUE(TF_Buffer);\n\n// Eager helper functions migrated from pywrap_tfe.i.\n\nnamespace tensorflow {\n\n// We cannot use Context as an opaque type. SWIG also had\n// difficult directly passing the pointer around. These\n// typemaps are migrated over from pywrap_tfe.i. I tried\n// using a custom type caster, but we get segfaults periodically.\n\n// TODO(amitpatankar): Move input and output logic of Context into a\n// pybind11 custom type caster.\n\nTFE_Context* InputTFE_Context(const py::handle& ctx) {\n  return static_cast<TFE_Context*>(PyCapsule_GetPointer(ctx.ptr(), nullptr));\n}\n\nPyObject* OutputTFE_Context(TFE_Context* context) {\n  return PyCapsule_New(context, nullptr, TFE_DeleteContextCapsule);\n}\n\nTF_Buffer* ProtoStringToTFBuffer(PyObject* input) {\n  // Convert a Python string object to TF_Buffer.\n  char* c_string;\n  Py_ssize_t py_size;\n  // PyBytes_AsStringAndSize() does not copy but simply interprets the input\n  if (PyBytes_AsStringAndSize(input, &c_string, &py_size) == -1) {\n    // Python has raised an error (likely TypeError or UnicodeEncodeError).\n    throw py::error_already_set();\n  }\n  return TF_NewBufferFromString(static_cast<void*>(c_string),\n                                static_cast<size_t>(py_size));\n}\n\n// These functions are typemaps from the Python side. I did not use\n// a custom type caster since the logic is slightly harder to follow. This\n// converter is also only used once in `TFE_Py_ExecuteCancelable_wrapper`.\nTFE_InputTensorHandles InputTFE_InputTensorHandles(\n    const py::handle& input_tensors) {\n  TFE_InputTensorHandles input_tensor_handles;\n  if (input_tensors.ptr() != Py_None) {\n    if (!PyList_Check(input_tensors.ptr())) {\n      tensorflow::ThrowTypeError(\"must provide a list of Tensors as inputs\");\n    }\n    Py_ssize_t len = PyList_Size(input_tensors.ptr());\n    input_tensor_handles.resize(len);\n    for (Py_ssize_t i = 0; i < len; ++i) {\n      PyObject* elem = PyList_GetItem(input_tensors.ptr(), i);\n      if (!elem) {\n        tensorflow::ThrowTypeError(\"Input Tensor does not exist.\");\n      }\n      if (EagerTensor_CheckExact(elem)) {\n        (input_tensor_handles)[i] = EagerTensor_Handle(elem);\n      } else if (tensorflow::swig::IsEagerTensorSlow(elem)) {\n        // Use equivalent of object.__getattribute__ to get the underlying\n        // tf wrapped EagerTensor (if there is one).\n        tensorflow::Safe_PyObjectPtr tf_should_use_attr(\n#if PY_MAJOR_VERSION < 3\n            PyString_InternFromString(\"_tf_should_use_wrapped_value\")\n#else\n            PyUnicode_InternFromString(\"_tf_should_use_wrapped_value\")\n#endif\n        );\n        tensorflow::Safe_PyObjectPtr value_attr(\n            PyObject_GenericGetAttr(elem, tf_should_use_attr.get()));\n        if (value_attr) {\n          // This is an EagerTensor wrapped inside a TFShouldUse wrapped object.\n          (input_tensor_handles)[i] = EagerTensor_Handle(value_attr.get());\n        } else {\n          // This is a subclass of EagerTensor that we don't support.\n          PyErr_Clear();\n          tensorflow::ThrowTypeError(\n              tensorflow::strings::StrCat(\n                  \"Saw an object that is an instance of a strict subclass of \"\n                  \"EagerTensor, which is not supported.  Item \",\n                  i, \" is type: \", elem->ob_type->tp_name)\n                  .c_str());\n        }\n      } else if (tensorflow::swig::IsTensor(elem)) {\n        // If it isnt an EagerTensor, but is still a Tensor, it must be a graph\n        // tensor.\n        tensorflow::Safe_PyObjectPtr name_attr(\n            PyObject_GetAttrString(elem, \"name\"));\n        tensorflow::ThrowTypeError(\n            tensorflow::strings::StrCat(\n                \"An op outside of the function building code is being passed\\n\"\n                \"a \\\"Graph\\\" tensor. It is possible to have Graph tensors\\n\"\n                \"leak out of the function building context by including a\\n\"\n                \"tf.init_scope in your function building code.\\n\"\n                \"For example, the following function will fail:\\n\",\n                \"  @tf.function\\n\", \"  def has_init_scope():\\n\",\n                \"    my_constant = tf.constant(1.)\\n\",\n                \"    with tf.init_scope():\\n\",\n                \"      added = my_constant * 2\\n\",\n                \"The graph tensor has name: \",\n                name_attr ? TFE_GetPythonString(name_attr.get()) : \"<unknown>\")\n                .c_str());\n      } else {\n        tensorflow::ThrowTypeError(\n            tensorflow::strings::StrCat(\n                \"provided list of inputs contains objects other \"\n                \"than 'EagerTensor'. Item \",\n                i, \" is type: \", elem->ob_type->tp_name)\n                .c_str());\n      }\n    }\n  }\n  return input_tensor_handles;\n}\n\n// These functions are typemaps from the Python side. I did not use\n// a custom type caster since the logic is slightly harder to follow. This\n// converter is also only used once in `TFE_Py_ExecuteCancelable_wrapper`.\n// This function actually takes a number rather than an output Tensor holder.\nTFE_OutputTensorHandles InputTFE_OutputTensorHandles(\n    const py::handle& num_outputs) {\n  TFE_OutputTensorHandles output_tensor_handles;\n#if PY_MAJOR_VERSION < 3\n  if (!PyInt_Check(num_outputs.ptr())) {\n#else\n  if (!PyLong_Check(num_outputs.ptr())) {\n#endif\n    PyErr_SetString(PyExc_TypeError,\n                    \"expected an integer value (size of the number of \"\n                    \"outputs of the operation)\");\n    throw py::error_already_set();\n  }\n#if PY_MAJOR_VERSION < 3\n  long sz = PyInt_AsLong(num_outputs.ptr());  // NOLINT\n#else\n  long sz = PyLong_AsLong(num_outputs.ptr());  // NOLINT\n#endif\n  if (sz > 0) {\n#if PY_MAJOR_VERSION < 3\n    output_tensor_handles.resize(PyInt_AsLong(num_outputs.ptr()), nullptr);\n#else\n    output_tensor_handles.resize(PyLong_AsLong(num_outputs.ptr()), nullptr);\n#endif\n  }\n  return output_tensor_handles;\n}\n\n// Packs multiple `EagerTensor`s of the same dtype and shape into one\n// `EagerTensor`.\npy::object TFE_Py_PackEagerTensors_wrapper(const py::handle& context,\n                                           const py::handle& tensors) {\n  TFE_Context* ctx = tensorflow::InputTFE_Context(context);\n  TFE_InputTensorHandles handles = InputTFE_InputTensorHandles(tensors);\n  tensorflow::Safe_TF_StatusPtr status = tensorflow::make_safe(TF_NewStatus());\n  int size = handles.size();\n  TFE_TensorHandle* packed_handle =\n      TFE_CreatePackedTensorHandle(ctx, handles.data(), &size, status.get());\n  tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  PyObject* packed_tensor =\n      EagerTensorFromHandle(packed_handle, /*is_packed=*/true);\n  return tensorflow::PyoOrThrow(packed_tensor);\n}\n\n// This function was created from fusing the typemap logic in platform/base.i.\npy::object TFE_Py_ExecuteCancelable_wrapper(\n    const py::handle& context, const char* device_name, const char* op_name,\n    const py::handle& inputs, const py::handle& attrs,\n    TFE_CancellationManager* cancellation_manager,\n    const py::handle& num_outputs) {\n  TFE_Context* ctx = tensorflow::InputTFE_Context(context);\n  TFE_InputTensorHandles input_tensor_handles =\n      InputTFE_InputTensorHandles(inputs);\n  TFE_OutputTensorHandles output_tensor_handles =\n      InputTFE_OutputTensorHandles(num_outputs);\n  tensorflow::Safe_TF_StatusPtr status = tensorflow::make_safe(TF_NewStatus());\n  TFE_Py_ExecuteCancelable(ctx, device_name, op_name, &input_tensor_handles,\n                           attrs.ptr(), cancellation_manager,\n                           &output_tensor_handles, status.get());\n\n  int output_len = output_tensor_handles.size();\n  PyObject* output_list = PyList_New(output_len);\n  for (int i = 0; i < output_len; ++i) {\n    PyObject* output;\n    output = EagerTensorFromHandle(output_tensor_handles.at(i));\n    PyList_SetItem(output_list, i, output);\n  }\n  tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  return tensorflow::PyoOrThrow(output_list);\n}\n\nstatic py::object TF_ListPhysicalDevices() {\n  std::vector<string> devices;\n  tensorflow::Status s =\n      tensorflow::DeviceFactory::ListAllPhysicalDevices(&devices);\n  MaybeRaiseRegisteredFromStatus(s);\n  PyObject* result = PyList_New(devices.size());\n  int i = 0;\n  for (auto& dev : devices) {\n    PyObject* dev_obj = PyBytes_FromStringAndSize(dev.data(), dev.size());\n    PyList_SetItem(result, i, dev_obj);\n    ++i;\n  }\n  return tensorflow::PyoOrThrow(result);\n}\n\nstatic std::unordered_map<string, string> TF_GetDeviceDetails(int index) {\n  tensorflow::Safe_TF_StatusPtr status = tensorflow::make_safe(TF_NewStatus());\n  std::unordered_map<string, string> device_details;\n  tensorflow::Status s =\n      tensorflow::DeviceFactory::GetAnyDeviceDetails(index, &device_details);\n  tensorflow::Set_TF_Status_from_Status(status.get(), s);\n  MaybeRaiseRegisteredFromTFStatus(status.get());\n  return device_details;\n}\n\nstatic py::object TFE_ClearScalarCache() {\n  tensorflow::TFE_TensorHandleCache::Get()->Clear();\n  return py::none();\n}\n\n// Returns compiler IR for a given function.\nstatic std::string TFE_GetCompilerIr(py::handle& ctx,\n                                     const char* concrete_function_name,\n                                     const char* stage, const char* device_name,\n                                     py::handle& inputs) {\n  EagerContext* context = ContextFromInterface(\n      reinterpret_cast<ImmediateExecutionContext*>(InputTFE_Context(ctx)));\n\n  std::string s_stage(stage);\n  IrExportStage selected_stage = [&] {\n    if (s_stage == \"hlo\") {\n      return IrExportStage::HLO;\n    } else if (s_stage == \"optimized_hlo\") {\n      return IrExportStage::OPTIMIZED_HLO;\n    } else {\n      ThrowValueError(\n          absl::StrFormat(\"Invalid stage selected: '%s'. Valid values are: \"\n                          \"'hlo', 'optimized_hlo'\",\n                          s_stage)\n              .c_str());\n    }\n  }();\n\n  TFE_InputTensorHandles handles = InputTFE_InputTensorHandles(inputs);\n\n  std::vector<const Tensor*> input_tensors;\n  for (TFE_TensorHandle* tensor_handle : handles) {\n    AbstractTensorHandle* abstract_tensor_handle = unwrap(tensor_handle);\n    TensorHandle* th = TensorHandleFromInterface(abstract_tensor_handle);\n\n    const Tensor* t;\n    Status st = th->Tensor(&t);\n    if (!st.ok()) {\n      ThrowValueError(\n          absl::StrFormat(\"Could not resolve tensor: '%s'\", st.error_message())\n              .c_str());\n    }\n    input_tensors.push_back(t);\n  }\n\n  DeviceNameUtils::ParsedName input_device_name;\n  if (!DeviceNameUtils::ParseFullOrLocalName(device_name, &input_device_name)) {\n    ThrowValueError(\n        absl::StrFormat(\"Failed parsing device name: '%s'\", device_name)\n            .c_str());\n  }\n\n  std::vector<Device*> devices = context->local_device_mgr()->ListDevices();\n  auto selected_device = absl::c_find_if(devices, [&](const Device* d) {\n    return DeviceNameUtils::AreCompatibleDevNames(input_device_name,\n                                                  d->parsed_name());\n  });\n  if (selected_device == devices.end()) {\n    ThrowValueError(\"No matching device found\");\n  }\n\n  xla::StatusOr<std::string> hlo_text =\n      GetCompilerIr(selected_stage, context->pflr(), concrete_function_name,\n                    *selected_device, input_tensors);\n\n  if (!hlo_text.ok()) {\n    ThrowValueError(absl::StrFormat(\"Failed getting HLO text: '%s'\",\n                                    hlo_text.status().error_message())\n                        .c_str());\n  }\n  return *hlo_text;\n}\n\n}  // namespace tensorflow\n\nnamespace {\n\n// Wrapper around the EagerContextThreadLocalData struct (defined in\n// pywrap_tfe.h), so it can be accessed from Python.\n//\n// For PyObject* fields, the get_*() methods return a new reference; and the\n// set_*() methods create a new reference (i.e., they do not steal a reference).\nclass EagerContextThreadLocalDataWrapper {\n public:\n  explicit EagerContextThreadLocalDataWrapper(py::handle py_eager_context,\n                                              py::handle is_eager,\n                                              py::handle device_spec)\n      : py_eager_context_(py_eager_context.ptr()) {\n    tensorflow::MakeEagerContextThreadLocalData(\n        py_eager_context.ptr(), is_eager.ptr(), device_spec.ptr());\n  }\n\n  ~EagerContextThreadLocalDataWrapper() {\n    tensorflow::DestroyEagerContextThreadLocalData(py_eager_context_);\n  }\n\n  bool get_is_eager() const { return GetData()->is_eager; }\n  void set_is_eager(bool v) { GetData()->is_eager = v; }\n\n  bool get_invoking_op_callbacks() const {\n    return GetData()->invoking_op_callbacks;\n  }\n  void set_invoking_op_callbacks(bool v) {\n    GetData()->invoking_op_callbacks = v;\n  }\n\n  py::handle get_device_name() const {\n    return GetPyObject(&GetData()->device_name);\n  }\n  void set_device_name(py::handle v) {\n    SetPyObject(v, &GetData()->device_name);\n  }\n\n  py::handle get_scope_name() const {\n    return GetPyObject(&GetData()->scope_name);\n  }\n  void set_scope_name(py::handle v) { SetPyObject(v, &GetData()->scope_name); }\n\n  py::handle get_device_spec() const {\n    return GetPyObject(&GetData()->device_spec);\n  }\n  void set_device_spec(py::handle v) {\n    SetPyObject(v, &GetData()->device_spec);\n  }\n\n  py::handle get_function_call_options() const {\n    return GetPyObject(&GetData()->function_call_options);\n  }\n  void set_function_call_options(py::handle v) {\n    SetPyObject(v, &GetData()->function_call_options);\n  }\n\n  py::handle get_executor() const { return GetPyObject(&GetData()->executor); }\n  void set_executor(py::handle v) { SetPyObject(v, &GetData()->executor); }\n\n  py::handle get_op_callbacks() const {\n    return GetPyObject(&GetData()->op_callbacks);\n  }\n  void set_op_callbacks(py::handle v) {\n    SetPyObject(v, &GetData()->op_callbacks);\n  }\n\n private:\n  tensorflow::EagerContextThreadLocalData* GetData() const {\n    auto* result =\n        tensorflow::GetEagerContextThreadLocalData(py_eager_context_);\n    if (!result) {\n      throw py::error_already_set();\n    }\n    return result;\n  }\n\n  py::handle GetPyObject(tensorflow::Safe_PyObjectPtr* obj) const {\n    Py_INCREF(obj->get());\n    return obj->get();\n  }\n\n  void SetPyObject(py::handle value, tensorflow::Safe_PyObjectPtr* ptr) {\n    Py_INCREF(value.ptr());\n    ptr->reset(value.ptr());\n  }\n\n  PyObject* py_eager_context_;  // not owned (borrowed reference).\n};\n\n}  // namespace\n\n// py::return_value_policy::reference is defined as specified by the\n// pybind11 documents listed here.\n// https://pybind11.readthedocs.io/en/stable/advanced/functions.html#return-value-policies\n// This means that C++ maintains ownership of the object. We\n// are only assigning this to functions that return opaque types.\n\nPYBIND11_MODULE(_pywrap_tfe, m) {\n  py::class_<TFE_Executor> TFE_Executor_class(m, \"TFE_Executor\");\n  py::class_<TFE_ContextOptions> TFE_ContextOptions_class(m,\n                                                          \"TFE_ContextOptions\");\n  py::class_<TFE_MonitoringCounter0> TFE_MonitoringCounter0_class(\n      m, \"TFE_MonitoringCounter0\");\n  py::class_<TFE_MonitoringCounter1> TFE_MonitoringCounter1_class(\n      m, \"TFE_MonitoringCounter1\");\n  py::class_<TFE_MonitoringCounter2> TFE_MonitoringCounter2_class(\n      m, \"TFE_MonitoringCounter2\");\n  py::class_<TFE_MonitoringStringGauge0> TFE_MonitoringStringGauge0_class(\n      m, \"TFE_MonitoringStringGauge0\");\n  py::class_<TFE_MonitoringStringGauge1> TFE_MonitoringStringGauge1_class(\n      m, \"TFE_MonitoringStringGauge1\");\n  py::class_<TFE_MonitoringStringGauge2> TFE_MonitoringStringGauge2_class(\n      m, \"TFE_MonitoringStringGauge2\");\n  py::class_<TFE_MonitoringIntGauge0> TFE_MonitoringIntGauge0_class(\n      m, \"TFE_MonitoringIntGauge0\");\n  py::class_<TFE_MonitoringIntGauge1> TFE_MonitoringIntGauge1_class(\n      m, \"TFE_MonitoringIntGauge1\");\n  py::class_<TFE_MonitoringIntGauge2> TFE_MonitoringIntGauge2_class(\n      m, \"TFE_MonitoringIntGauge2\");\n  py::class_<TFE_MonitoringBoolGauge0> TFE_MonitoringBoolGauge0_class(\n      m, \"TFE_MonitoringBoolGauge0\");\n  py::class_<TFE_MonitoringBoolGauge1> TFE_MonitoringBoolGauge1_class(\n      m, \"TFE_MonitoringBoolGauge1\");\n  py::class_<TFE_MonitoringBoolGauge2> TFE_MonitoringBoolGauge2_class(\n      m, \"TFE_MonitoringBoolGauge2\");\n  py::class_<TFE_MonitoringCounterCell> TFE_MonitoringCounterCell_class(\n      m, \"TFE_MonitoringCounterCell\");\n  py::class_<TFE_MonitoringIntGaugeCell> TFE_MonitoringIntGaugeCell_class(\n      m, \"TFE_MonitoringIntGaugeCell\");\n  py::class_<TFE_MonitoringStringGaugeCell> TFE_MonitoringStringGaugeCell_class(\n      m, \"TFE_MonitoringStringGaugeCell\");\n  py::class_<TFE_MonitoringBoolGaugeCell> TFE_MonitoringBoolGaugeCell_class(\n      m, \"TFE_MonitoringBoolGaugeCell\");\n  py::class_<TFE_MonitoringSamplerCell> TFE_MonitoringSamplerCell_class(\n      m, \"TFE_MonitoringSamplerCell\");\n  py::class_<TFE_MonitoringBuckets> TFE_MonitoringBuckets_class(\n      m, \"TFE_MonitoringBuckets\");\n  py::class_<TFE_MonitoringSampler0> TFE_MonitoringSampler0_class(\n      m, \"TFE_MonitoringSampler0\");\n  py::class_<TFE_MonitoringSampler1> TFE_MonitoringSampler1_class(\n      m, \"TFE_MonitoringSampler1\");\n  py::class_<TFE_MonitoringSampler2> TFE_MonitoringSampler2_class(\n      m, \"TFE_MonitoringSampler2\");\n  py::class_<TFE_CancellationManager> TFE_CancellationManager_class(\n      m, \"TFE_CancellationManager\");\n\n  py::class_<TF_DeviceList> TF_DeviceList_class(m, \"TF_DeviceList\");\n  py::class_<TF_Function> TF_Function_class(m, \"TF_Function\");\n\n  m.def(\"TFE_Py_RegisterExceptionClass\", [](const py::handle& e) {\n    return tensorflow::PyoOrThrow(TFE_Py_RegisterExceptionClass(e.ptr()));\n  });\n  m.def(\"TFE_Py_RegisterFallbackExceptionClass\", [](const py::handle& e) {\n    return tensorflow::PyoOrThrow(\n        TFE_Py_RegisterFallbackExceptionClass(e.ptr()));\n  });\n\n  m.def(\n      \"TFE_GetTotalMemoryUsage\", [](py::handle& ctx, const char* device_name) {\n        tensorflow::EagerContext* context = tensorflow::ContextFromInterface(\n            reinterpret_cast<tensorflow::ImmediateExecutionContext*>(\n                tensorflow::InputTFE_Context(ctx)));\n\n        tensorflow::DeviceNameUtils::ParsedName input_device_name;\n        if (!tensorflow::DeviceNameUtils::ParseFullOrLocalName(\n                device_name, &input_device_name)) {\n          tensorflow::ThrowValueError(\n              absl::StrFormat(\"Failed parsing device name: '%s'\", device_name)\n                  .c_str());\n        }\n\n        std::vector<tensorflow::Device*> devices =\n            context->local_device_mgr()->ListDevices();\n\n        tensorflow::Device* matched_device = nullptr;\n        for (int device_idx = 0; device_idx < devices.size(); device_idx++) {\n          tensorflow::Device* device = devices[device_idx];\n\n          if (tensorflow::DeviceNameUtils::AreCompatibleDevNames(\n                  input_device_name, device->parsed_name())) {\n            if (device->device_type() == tensorflow::DEVICE_CPU) {\n              tensorflow::ThrowValueError(\n                  \"CPU does not support getting allocator information\");\n            }\n\n            if (matched_device != nullptr) {\n              tensorflow::ThrowValueError(\n                  absl::StrFormat(\n                      \"Multiple devices matching the provided string \"\n                      \"'%s': '%s' and \"\n                      \"'%s' \",\n                      device_name, matched_device->name(), device->name())\n                      .c_str());\n            }\n            matched_device = device;\n          }\n        }\n\n        if (matched_device == nullptr) {\n          tensorflow::ThrowValueError(\n              absl::StrFormat(\"No matching devices found for '%s'\", device_name)\n                  .c_str());\n        }\n\n        tensorflow::AllocatorAttributes attrs;\n        tensorflow::Allocator* allocator = matched_device->GetAllocator(attrs);\n\n        if (absl::optional<tensorflow::AllocatorStats> stats =\n                allocator->GetStats()) {\n          return stats->bytes_in_use;\n        }\n\n        tensorflow::ThrowTypeError(\n            absl::StrFormat(\"Allocator stats not available for device '%s'\",\n                            matched_device->name())\n                .c_str());\n      });\n\n  // XLA Eager Logic\n  m.def(\"TF_SetXlaEnableLazyCompilation\", &TF_SetXlaEnableLazyCompilation);\n  m.def(\"TF_SetTfXlaCpuGlobalJit\", &TF_SetTfXlaCpuGlobalJit);\n  m.def(\"TF_SetXlaAutoJitMode\", &TF_SetXlaAutoJitMode);\n  m.def(\"TF_SetXlaConstantFoldingDisabled\", &TF_SetXlaConstantFoldingDisabled);\n  m.def(\"TF_GetXlaConstantFoldingDisabled\", &TF_GetXlaConstantFoldingDisabled);\n  m.def(\"TF_SetXlaMinClusterSize\", &TF_SetXlaMinClusterSize);\n  m.def(\"TF_GetCompilerIr\", &tensorflow::TFE_GetCompilerIr);\n\n  // MLIR Logic\n  m.def(\"TF_IsMlirBridgeEnabled\", [] {\n    return tensorflow::GetMlirCommonFlags()->tf_mlir_enable_mlir_bridge;\n  });\n  m.def(\"TF_EnableMlirBridge\", [](bool enabled) {\n    tensorflow::GetMlirCommonFlags()->tf_mlir_enable_mlir_bridge = enabled;\n  });\n  m.def(\"TF_EnableXlaDevices\", [] {\n    tensorflow::GetXlaDeviceFlags()->tf_xla_enable_xla_devices = true;\n  });\n\n  // // TFE_Context Logic\n  m.def(\n      \"TFE_NewContext\",\n      [](const TFE_ContextOptions* opts) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        TFE_Context* context = TFE_NewContext(opts, status.get());\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return tensorflow::PyoOrThrow(tensorflow::OutputTFE_Context(context));\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_DeleteContext\", [](py::handle& o) {\n    TFE_DeleteContext(tensorflow::InputTFE_Context(o));\n  });\n  m.def(\n      \"TFE_ContextListDevices\",\n      [](py::handle& o) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_ContextListDevices(tensorflow::InputTFE_Context(o),\n                                             status.get());\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_HostAddressSpace\", [](py::handle& o, TF_Buffer& buf) {\n    TFE_HostAddressSpace(tensorflow::InputTFE_Context(o), &buf);\n  });\n  m.def(\"TFE_ContextAddFunction\", [](py::handle& ctx, TF_Function* func) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextAddFunction(tensorflow::InputTFE_Context(ctx), func,\n                           status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextAddFunctionDef\",\n        [](py::handle& ctx, const char* serialized_function_def, size_t size) {\n          tensorflow::Safe_TF_StatusPtr status =\n              tensorflow::make_safe(TF_NewStatus());\n          TFE_ContextAddFunctionDef(tensorflow::InputTFE_Context(ctx),\n                                    serialized_function_def, size,\n                                    status.get());\n          tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        });\n  m.def(\"TFE_ContextGetFunctionDef\",\n        [](py::handle& ctx, const char* function_name, TF_Buffer& buf) {\n          tensorflow::Safe_TF_StatusPtr status =\n              tensorflow::make_safe(TF_NewStatus());\n          TFE_ContextGetFunctionDef(tensorflow::InputTFE_Context(ctx),\n                                    function_name, &buf, status.get());\n          tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        });\n  m.def(\"TFE_ContextRemoveFunction\", [](py::handle& ctx, const char* name) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextRemoveFunction(tensorflow::InputTFE_Context(ctx), name,\n                              status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextHasFunction\", [](py::handle& ctx, const char* name) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    auto output =\n        TFE_ContextHasFunction(tensorflow::InputTFE_Context(ctx), name);\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    return output;\n  });\n  m.def(\"TFE_ContextEnableRunMetadata\", [](py::handle& ctx) {\n    TFE_ContextEnableRunMetadata(tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextDisableRunMetadata\", [](py::handle& ctx) {\n    TFE_ContextEnableRunMetadata(tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextEnableGraphCollection\", [](py::handle& ctx) {\n    TFE_ContextEnableGraphCollection(tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextDisableGraphCollection\", [](py::handle& ctx) {\n    TFE_ContextDisableGraphCollection(tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextExportRunMetadata\", [](py::handle& ctx, TF_Buffer& buf) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextExportRunMetadata(tensorflow::InputTFE_Context(ctx), &buf,\n                                 status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextClearCaches\", [](py::handle& o) {\n    TFE_ContextClearCaches(tensorflow::InputTFE_Context(o));\n  });\n  m.def(\"TFE_GetContextId\", [](py::handle& ctx) {\n    return TFE_GetContextId(tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextGetDevicePlacementPolicy\", [](py::handle& ctx) {\n    return TFE_ContextGetDevicePlacementPolicy(\n        tensorflow::InputTFE_Context(ctx));\n  });\n  m.def(\"TFE_ContextSetThreadLocalDevicePlacementPolicy\",\n        [](py::handle& ctx, TFE_ContextDevicePlacementPolicy policy) {\n          TFE_ContextSetThreadLocalDevicePlacementPolicy(\n              tensorflow::InputTFE_Context(ctx), policy);\n        });\n  m.def(\"TFE_ContextSetServerDef\", [](py::handle& ctx, int keep_alive_secs,\n                                      py::bytes proto) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    tensorflow::Safe_TF_BufferPtr buf =\n        tensorflow::make_safe(tensorflow::ProtoStringToTFBuffer(proto.ptr()));\n    TFE_ContextSetServerDef(tensorflow::InputTFE_Context(ctx), keep_alive_secs,\n                            buf.get()->data, buf.get()->length, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextUpdateServerDef\", [](py::handle& ctx, int keep_alive_secs,\n                                         py::bytes proto) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    tensorflow::Safe_TF_BufferPtr buf =\n        tensorflow::make_safe(tensorflow::ProtoStringToTFBuffer(proto.ptr()));\n    Py_BEGIN_ALLOW_THREADS;\n    TFE_ContextUpdateServerDef(tensorflow::InputTFE_Context(ctx),\n                               keep_alive_secs, buf.get()->data,\n                               buf.get()->length, status.get());\n    Py_END_ALLOW_THREADS;\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextCheckAlive\", [](py::handle& ctx, const char* worker_name) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    bool output = TFE_ContextCheckAlive(tensorflow::InputTFE_Context(ctx),\n                                        worker_name, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    return output;\n  });\n  m.def(\"TFE_ContextSyncExecutors\", [](py::handle& ctx) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextAsyncWait(tensorflow::InputTFE_Context(ctx), status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextClearExecutors\", [](py::handle& ctx) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextAsyncWait(tensorflow::InputTFE_Context(ctx), status.get());\n    // NOTE: different from TFE_ContextSyncExecutors that raises potential\n    // errors, deliberately ignore executor statuses in cleanup.\n  });\n  m.def(\"TFE_ContextSetSoftDevicePlacement\", [](py::handle& ctx, bool enable) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextSetSoftDevicePlacement(tensorflow::InputTFE_Context(ctx), enable,\n                                      status.get());\n  });\n  m.def(\"TFE_ContextSetLogDevicePlacement\", [](py::handle& ctx, bool enable) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TFE_ContextSetSoftDevicePlacement(tensorflow::InputTFE_Context(ctx), enable,\n                                      status.get());\n  });\n\n  // TFE_Executor logic\n  m.def(\n      \"TFE_NewExecutor\",\n      [](const bool is_async) {\n        TFE_Executor* exc = TFE_NewExecutor(is_async);\n        return exc;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_DeleteExecutor\", &TFE_DeleteExecutor);\n  m.def(\"TFE_ExecutorIsAsync\", &TFE_ExecutorIsAsync);\n  m.def(\"TFE_ExecutorWaitForAllPendingNodes\", [](TFE_Executor& exc) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    // NOTE: release Python GIL for pending PyFunc ops to be executed properly.\n    Py_BEGIN_ALLOW_THREADS;\n    TFE_ExecutorWaitForAllPendingNodes(&exc, status.get());\n    Py_END_ALLOW_THREADS;\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ExecutorClearError\", &TFE_ExecutorClearError);\n  m.def(\"TFE_ContextSetExecutorForThread\", [](py::handle& ctx,\n                                              TFE_Executor& exc) {\n    TFE_ContextSetExecutorForThread(tensorflow::InputTFE_Context(ctx), &exc);\n  });\n  m.def(\n      \"TFE_ContextGetExecutorForThread\",\n      [](py::handle& o) {\n        return TFE_ContextGetExecutorForThread(tensorflow::InputTFE_Context(o));\n      },\n      py::return_value_policy::reference);\n\n  m.def(\"TFE_OpNameGetAttrType\",\n        [](py::handle& ctx, const char* op_or_function_name,\n           const char* attr_name) {\n          int temp = 0;\n          unsigned char* is_list = reinterpret_cast<unsigned char*>(&temp);\n          tensorflow::Safe_TF_StatusPtr status =\n              tensorflow::make_safe(TF_NewStatus());\n          auto output = TFE_OpNameGetAttrType(tensorflow::InputTFE_Context(ctx),\n                                              op_or_function_name, attr_name,\n                                              is_list, status.get());\n          tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n#if PY_MAJOR_VERSION < 3\n          PyObject* output_pyo = PyInt_FromLong(output);\n#else\n          PyObject* output_pyo = PyLong_FromLong(output);\n#endif\n          if (*is_list == 1) {\n            PyObject* list = PyList_New(1);\n            PyList_SetItem(list, 0, output_pyo);\n            return tensorflow::PyoOrThrow(list);\n          }\n          return tensorflow::PyoOrThrow(output_pyo);\n        });\n  m.def(\"TFE_Py_InitEagerTensor\", [](const py::handle& o) {\n    return tensorflow::PyoOrThrow(TFE_Py_InitEagerTensor(o.ptr()));\n  });\n  m.def(\"TFE_Py_PackEagerTensors\",\n        [](const py::handle& context, const py::handle& handles) {\n          return tensorflow::TFE_Py_PackEagerTensors_wrapper(context, handles);\n        });\n  m.def(\"TFE_Py_SetEagerTensorProfiler\", &TFE_Py_SetEagerTensorProfiler);\n  m.def(\"TFE_Py_RegisterJVPFunction\", [](const py::handle& o) {\n    return tensorflow::PyoOrThrow(TFE_Py_RegisterJVPFunction(o.ptr()));\n  });\n  m.def(\"TFE_Py_RegisterGradientFunction\", [](const py::handle& o) {\n    return tensorflow::PyoOrThrow(TFE_Py_RegisterGradientFunction(o.ptr()));\n  });\n  m.def(\"TFE_Py_Execute\",\n        [](const py::handle& context, const char* device_name,\n           const char* op_name, const py::handle& inputs,\n           const py::handle& attrs, const py::handle& num_outputs) {\n          return tensorflow::TFE_Py_ExecuteCancelable_wrapper(\n              context, device_name, op_name, inputs, attrs.ptr(), nullptr,\n              num_outputs);\n        });\n  m.def(\n      \"TFE_Py_ExecuteCancelable\",\n      [](const py::handle& context, const char* device_name,\n         const char* op_name, const py::handle& inputs, const py::handle& attrs,\n         TFE_CancellationManager& cancellation_manager,\n         const py::handle& num_outputs) {\n        return tensorflow::TFE_Py_ExecuteCancelable_wrapper(\n            context, device_name, op_name, inputs, attrs.ptr(),\n            &cancellation_manager, num_outputs);\n      });\n  m.def(\"TFE_Py_FastPathExecute\", [](const py::args args) {\n    // TFE_Py_FastPathExecute requires error checking prior to returning.\n    return tensorflow::PyoOrThrow(TFE_Py_FastPathExecute_C(args.ptr()));\n  });\n  m.def(\"TFE_Py_RecordGradient\",\n        [](const py::handle& op_name, const py::handle& inputs,\n           const py::handle& attrs, const py::handle& results,\n           const py::handle& forward_pass_name_scope) {\n          return tensorflow::PyoOrThrow(TFE_Py_RecordGradient(\n              op_name.ptr(), inputs.ptr(), attrs.ptr(), results.ptr(),\n              forward_pass_name_scope.ptr()));\n        });\n  m.def(\"TFE_Py_UID\", []() { return tensorflow::PyoOrThrow(TFE_Py_UID()); });\n\n  // TFE_Py_Tape Logic\n  m.def(\"TFE_Py_TapeSetNew\", [](const py::handle& persistent,\n                                const py::handle& watch_accessed_variables) {\n    return tensorflow::PyoOrThrow(\n        TFE_Py_TapeSetNew(persistent.ptr(), watch_accessed_variables.ptr()));\n  });\n  m.def(\"TFE_Py_TapeSetAdd\",\n        [](const py::handle& tape) { TFE_Py_TapeSetAdd(tape.ptr()); });\n  m.def(\"TFE_Py_TapeSetRemove\",\n        [](const py::handle& tape) { TFE_Py_TapeSetRemove(tape.ptr()); });\n  m.def(\"TFE_Py_TapeSetStopOnThread\", &TFE_Py_TapeSetStopOnThread);\n  m.def(\"TFE_Py_TapeSetRestartOnThread\", &TFE_Py_TapeSetRestartOnThread);\n  m.def(\"TFE_Py_TapeSetIsStopped\",\n        []() { return tensorflow::PyoOrThrow(TFE_Py_TapeSetIsStopped()); });\n  m.def(\"TFE_Py_TapeSetIsEmpty\",\n        []() { return tensorflow::PyoOrThrow(TFE_Py_TapeSetIsEmpty()); });\n  m.def(\"TFE_Py_TapeSetShouldRecordBackprop\", [](const py::handle& tensors) {\n    return tensorflow::PyoOrThrow(\n        TFE_Py_TapeSetShouldRecordBackprop(tensors.ptr()));\n  });\n  m.def(\"TFE_Py_TapeSetPossibleGradientTypes\", [](const py::handle& tensors) {\n    return tensorflow::PyoOrThrow(\n        TFE_Py_TapeSetPossibleGradientTypes(tensors.ptr()));\n  });\n  m.def(\"TFE_Py_TapeSetDeleteTrace\", &TFE_Py_TapeSetDeleteTrace);\n  m.def(\"TFE_Py_TapeSetRecordOperation\",\n        [](const py::handle& op_type, const py::handle& output_tensors,\n           const py::handle& input_tensors, const py::handle& backward_function,\n           const py::handle& forward_function) {\n          return tensorflow::PyoOrThrow(TFE_Py_TapeSetRecordOperation(\n              op_type.ptr(), output_tensors.ptr(), input_tensors.ptr(),\n              backward_function.ptr(), forward_function.ptr()));\n        });\n  m.def(\n      \"TFE_Py_TapeSetRecordOperationBackprop\",\n      [](const py::handle& op_type, const py::handle& output_tensors,\n         const py::handle& input_tensors, const py::handle& backward_function) {\n        return tensorflow::PyoOrThrow(TFE_Py_TapeSetRecordOperationBackprop(\n            op_type.ptr(), output_tensors.ptr(), input_tensors.ptr(),\n            backward_function.ptr()));\n      });\n  m.def(\n      \"TFE_Py_TapeSetRecordOperationForwardprop\",\n      [](const py::handle& op_type, const py::handle& output_tensors,\n         const py::handle& input_tensors, const py::handle& backward_function,\n         const py::handle& forwardprop_output_indices) {\n        return tensorflow::PyoOrThrow(TFE_Py_TapeSetRecordOperationForwardprop(\n            op_type.ptr(), output_tensors.ptr(), input_tensors.ptr(),\n            backward_function.ptr(), forwardprop_output_indices.ptr()));\n      });\n  m.def(\"TFE_Py_TapeGradient\",\n        [](const py::handle& tape, const py::handle& target,\n           const py::handle& sources, const py::handle& output_gradients,\n           const py::handle& sources_raw,\n           const py::handle& unconnected_gradients) {\n          tensorflow::Safe_TF_StatusPtr status =\n              tensorflow::make_safe(TF_NewStatus());\n          PyObject* output = TFE_Py_TapeGradient(\n              tape.ptr(), target.ptr(), sources.ptr(), output_gradients.ptr(),\n              sources_raw.ptr(), unconnected_gradients.ptr(), status.get());\n          tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n          return tensorflow::PyoOrThrow(output);\n        });\n\n  m.def(\"TFE_Py_TapeVariableAccessed\", [](const py::handle& variable) {\n    TFE_Py_TapeVariableAccessed(variable.ptr());\n  });\n  m.def(\"TFE_Py_TapeWatch\",\n        [](const py::handle& tape, const py::handle& tensor) {\n          TFE_Py_TapeWatch(tape.ptr(), tensor.ptr());\n        });\n  m.def(\"TFE_Py_TapeWatchVariable\",\n        [](const py::handle& tape, const py::handle& variable) {\n          TFE_Py_TapeWatchVariable(tape.ptr(), variable.ptr());\n        });\n  m.def(\"TFE_Py_TapeWatchedVariables\", [](const py::handle& tape) {\n    return tensorflow::PyoOrThrow(TFE_Py_TapeWatchedVariables(tape.ptr()));\n  });\n\n  // TFE_Py_VariableWatcher logic.\n  m.def(\"TFE_Py_VariableWatcherNew\",\n        []() { return tensorflow::PyoOrThrow(TFE_Py_VariableWatcherNew()); });\n  m.def(\"TFE_Py_VariableWatcherRemove\", [](const py::handle& variable_watcher) {\n    TFE_Py_VariableWatcherRemove(variable_watcher.ptr());\n  });\n  m.def(\"TFE_Py_VariableWatcherVariableAccessed\",\n        [](const py::handle& variable) {\n          TFE_Py_VariableWatcherVariableAccessed(variable.ptr());\n        });\n  m.def(\"TFE_Py_VariableWatcherWatchedVariables\",\n        [](const py::handle& variable_watcher) {\n          return tensorflow::PyoOrThrow(\n              TFE_Py_VariableWatcherWatchedVariables(variable_watcher.ptr()));\n        });\n\n  // TFE_Py_ForwardAccumulator logic.\n  m.def(\"TFE_Py_ForwardAccumulatorNew\", [](bool use_batch) {\n    return tensorflow::PyoOrThrow(TFE_Py_ForwardAccumulatorNew(use_batch));\n  });\n\n  m.def(\"TFE_Py_ForwardAccumulatorSetAdd\", [](const py::handle& accumulator) {\n    return tensorflow::PyoOrThrow(\n        TFE_Py_ForwardAccumulatorSetAdd(accumulator.ptr()));\n  });\n  m.def(\"TFE_Py_ForwardAccumulatorSetRemove\",\n        [](const py::handle& accumulator) {\n          TFE_Py_ForwardAccumulatorSetRemove(accumulator.ptr());\n        });\n\n  m.def(\"TFE_Py_ForwardAccumulatorWatch\",\n        [](const py::handle& accumulator, const py::handle& tensor,\n           const py::handle& tangent) {\n          TFE_Py_ForwardAccumulatorWatch(accumulator.ptr(), tensor.ptr(),\n                                         tangent.ptr());\n        });\n  m.def(\"TFE_Py_ForwardAccumulatorJVP\",\n        [](const py::handle& accumulator, const py::handle& tensor) {\n          return tensorflow::PyoOrThrow(\n              TFE_Py_ForwardAccumulatorJVP(accumulator.ptr(), tensor.ptr()));\n        });\n  m.def(\"TFE_Py_ForwardAccumulatorPushState\", []() {\n    return tensorflow::PyoOrThrow(TFE_Py_ForwardAccumulatorPushState());\n  });\n  m.def(\"TFE_Py_ForwardAccumulatorPopState\", []() {\n    return tensorflow::PyoOrThrow(TFE_Py_ForwardAccumulatorPopState());\n  });\n  m.def(\"TFE_Py_PackJVPs\", [](const py::handle& tensors) {\n    return tensorflow::PyoOrThrow(TFE_Py_PackJVPs(tensors.ptr()));\n  });\n\n  // TFE_ContextOptions Logic\n  m.def(\"TFE_NewContextOptions\", &TFE_NewContextOptions,\n        py::return_value_policy::reference);\n  m.def(\"TFE_ContextOptionsSetConfig\", [](TFE_ContextOptions* options,\n                                          py::bytes proto) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    tensorflow::Safe_TF_BufferPtr buf =\n        tensorflow::make_safe(tensorflow::ProtoStringToTFBuffer(proto.ptr()));\n    TFE_ContextOptionsSetConfig(options, buf.get()->data, buf.get()->length,\n                                status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_ContextOptionsSetDevicePlacementPolicy\",\n        &TFE_ContextOptionsSetDevicePlacementPolicy);\n  m.def(\"TFE_ContextOptionsSetLazyRemoteInputsCopy\",\n        &TFE_ContextOptionsSetLazyRemoteInputsCopy);\n  m.def(\"TFE_ContextOptionsSetTfrt\", &TFE_ContextOptionsSetTfrt);\n  m.def(\"TFE_ContextOptionsSetAsync\", &TFE_ContextOptionsSetAsync);\n  m.def(\"TFE_DeleteContextOptions\", &TFE_DeleteContextOptions,\n        py::return_value_policy::reference);\n\n  // TFE_Py_TensorShape Logic\n  m.def(\"TFE_Py_TensorShapeSlice\",\n        [](const py::handle& tensors, int slice_dim) {\n          return tensorflow::PyoOrThrow(\n              TFE_Py_TensorShapeSlice(tensors.ptr(), slice_dim));\n        });\n  m.def(\"TFE_Py_TensorShapeOnDevice\", [](const py::handle& tensors,\n                                         int slice_dim) {\n    return tensorflow::PyoOrThrow(TFE_Py_TensorShapeOnDevice(tensors.ptr()));\n  });\n  m.def(\"TFE_Py_EnableInteractivePythonLogging\",\n        &TFE_Py_EnableInteractivePythonLogging);\n\n  // Additional Context Logic\n  m.def(\"TFE_Py_SetEagerContext\", [](const py::handle& o) {\n    return tensorflow::PyoOrThrow(TFE_Py_SetEagerContext(o.ptr()));\n  });\n  m.def(\"TFE_ContextStartStep\", [](py::handle& o) {\n    TFE_ContextStartStep(tensorflow::InputTFE_Context(o.ptr()));\n  });\n  m.def(\"TFE_ContextEndStep\", [](py::handle& o) {\n    TFE_ContextEndStep(tensorflow::InputTFE_Context(o.ptr()));\n  });\n  m.def(\"TFE_Py_RegisterVSpace\", [](const py::handle& o) {\n    return tensorflow::PyoOrThrow(TFE_Py_RegisterVSpace(o.ptr()));\n  });\n  m.def(\"TFE_Py_EncodeArg\",\n        [](const py::handle& o, bool include_tensor_ranks_only) {\n          return tensorflow::PyoOrThrow(\n              TFE_Py_EncodeArg(o.ptr(), include_tensor_ranks_only));\n        });\n  m.def(\"TFE_EnableCollectiveOps\", [](const py::handle& ctx, py::bytes proto) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    tensorflow::Safe_TF_BufferPtr buf =\n        tensorflow::make_safe(tensorflow::ProtoStringToTFBuffer(proto.ptr()));\n    TFE_EnableCollectiveOps(tensorflow::InputTFE_Context(ctx), buf.get()->data,\n                            buf.get()->length, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n  m.def(\"TFE_AbortCollectiveOps\", [](const py::handle& ctx, int code,\n                                     const char* message) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    TF_SetStatus(status.get(), static_cast<TF_Code>(code), message);\n    TFE_AbortCollectiveOps(tensorflow::InputTFE_Context(ctx), status.get());\n  });\n  m.def(\"TFE_CollectiveOpsCheckPeerHealth\",\n        [](const py::handle& ctx, const char* task) {\n          tensorflow::Safe_TF_StatusPtr status =\n              tensorflow::make_safe(TF_NewStatus());\n          TFE_CollectiveOpsCheckPeerHealth(tensorflow::InputTFE_Context(ctx),\n                                           task, status.get());\n          tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        });\n  m.def(\"TF_ListPhysicalDevices\", &tensorflow::TF_ListPhysicalDevices);\n  m.def(\"TF_GetDeviceDetails\", &tensorflow::TF_GetDeviceDetails);\n  m.def(\"TF_DeleteDeviceList\", &TF_DeleteDeviceList,\n        py::return_value_policy::reference);\n  m.def(\"TF_DeviceListCount\", &TF_DeviceListCount);\n  m.def(\"TF_DeviceListName\", [](const TF_DeviceList* list, int index) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    auto output = TF_DeviceListName(list, index, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    return output;\n  });\n  m.def(\"TF_DeviceListType\", [](const TF_DeviceList* list, int index) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    auto output = TF_DeviceListType(list, index, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    return output;\n  });\n\n  m.def(\"TF_PickUnusedPortOrDie\", &TF_PickUnusedPortOrDie);\n\n  // TFE_MonitoringCounter Logic\n  m.def(\"TFE_MonitoringCounterCellIncrementBy\",\n        &TFE_MonitoringCounterCellIncrementBy);\n  m.def(\"TFE_MonitoringCounterCellValue\", &TFE_MonitoringCounterCellValue);\n  m.def(\n      \"TFE_MonitoringNewCounter0\",\n      [](const char* name, const char* description) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewCounter0(name, status.get(), description);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteCounter0\", &TFE_MonitoringDeleteCounter0,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellCounter0\", &TFE_MonitoringGetCellCounter0,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewCounter1\",\n      [](const char* name, const char* description, const char* label1) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewCounter1(name, status.get(), description, label1);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteCounter1\", &TFE_MonitoringDeleteCounter1,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellCounter1\", &TFE_MonitoringGetCellCounter1,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewCounter2\",\n      [](const char* name, const char* description, const char* label1,\n         const char* label2) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewCounter2(name, status.get(), description,\n                                                label1, label2);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteCounter2\", &TFE_MonitoringDeleteCounter2,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellCounter2\", &TFE_MonitoringGetCellCounter2,\n        py::return_value_policy::reference);\n\n  // TFE_MonitoringIntGauge Logic\n  m.def(\"TFE_MonitoringIntGaugeCellSet\", &TFE_MonitoringIntGaugeCellSet);\n  m.def(\"TFE_MonitoringIntGaugeCellValue\", &TFE_MonitoringIntGaugeCellValue);\n  m.def(\n      \"TFE_MonitoringNewIntGauge0\",\n      [](const char* name, const char* description) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewIntGauge0(name, status.get(), description);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteIntGauge0\", &TFE_MonitoringDeleteIntGauge0,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellIntGauge0\", &TFE_MonitoringGetCellIntGauge0,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewIntGauge1\",\n      [](const char* name, const char* description, const char* label1) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewIntGauge1(name, status.get(), description, label1);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteIntGauge1\", &TFE_MonitoringDeleteIntGauge1,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellIntGauge1\", &TFE_MonitoringGetCellIntGauge1,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewIntGauge2\",\n      [](const char* name, const char* description, const char* label1,\n         const char* label2) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewIntGauge2(name, status.get(),\n                                                 description, label1, label2);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteIntGauge2\", &TFE_MonitoringDeleteIntGauge2,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellIntGauge2\", &TFE_MonitoringGetCellIntGauge2,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringStringGaugeCellSet\", &TFE_MonitoringStringGaugeCellSet);\n  m.def(\"TFE_MonitoringStringGaugeCellValue\",\n        &TFE_MonitoringStringGaugeCellValue);\n  m.def(\n      \"TFE_MonitoringNewStringGauge0\",\n      [](const char* name, const char* description) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewStringGauge0(name, status.get(), description);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n\n  // TFE_MonitoringStringGauge Logic\n  m.def(\"TFE_MonitoringDeleteStringGauge0\", &TFE_MonitoringDeleteStringGauge0);\n  m.def(\"TFE_MonitoringGetCellStringGauge0\", &TFE_MonitoringGetCellStringGauge0,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewStringGauge1\",\n      [](const char* name, const char* description, const char* label1) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewStringGauge1(name, status.get(),\n                                                    description, label1);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteStringGauge1\", &TFE_MonitoringDeleteStringGauge1);\n  m.def(\"TFE_MonitoringGetCellStringGauge1\", &TFE_MonitoringGetCellStringGauge1,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewStringGauge2\",\n      [](const char* name, const char* description, const char* label1,\n         const char* label2) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewStringGauge2(\n            name, status.get(), description, label1, label2);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteStringGauge2\", &TFE_MonitoringDeleteStringGauge2);\n  m.def(\"TFE_MonitoringGetCellStringGauge2\", &TFE_MonitoringGetCellStringGauge2,\n        py::return_value_policy::reference);\n\n  // TFE_MonitoringBoolGauge Logic\n  m.def(\"TFE_MonitoringBoolGaugeCellSet\", &TFE_MonitoringBoolGaugeCellSet);\n  m.def(\"TFE_MonitoringBoolGaugeCellValue\", &TFE_MonitoringBoolGaugeCellValue);\n  m.def(\n      \"TFE_MonitoringNewBoolGauge0\",\n      [](const char* name, const char* description) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewBoolGauge0(name, status.get(), description);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteBoolGauge0\", &TFE_MonitoringDeleteBoolGauge0,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellBoolGauge0\", &TFE_MonitoringGetCellBoolGauge0,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewBoolGauge1\",\n      [](const char* name, const char* description, const char* label1) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewBoolGauge1(name, status.get(),\n                                                  description, label1);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteBoolGauge1\", &TFE_MonitoringDeleteBoolGauge1,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellBoolGauge1\", &TFE_MonitoringGetCellBoolGauge1,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewBoolGauge2\",\n      [](const char* name, const char* description, const char* label1,\n         const char* label2) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewBoolGauge2(name, status.get(),\n                                                  description, label1, label2);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteBoolGauge2\", &TFE_MonitoringDeleteBoolGauge2,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellBoolGauge2\", &TFE_MonitoringGetCellBoolGauge2,\n        py::return_value_policy::reference);\n\n  // TFE_MonitoringSampler Logic\n  m.def(\"TFE_MonitoringSamplerCellAdd\", &TFE_MonitoringSamplerCellAdd);\n  m.def(\"TFE_MonitoringSamplerCellValue\", &TFE_MonitoringSamplerCellValue);\n  m.def(\"TFE_MonitoringNewExponentialBuckets\",\n        &TFE_MonitoringNewExponentialBuckets,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteBuckets\", &TFE_MonitoringDeleteBuckets,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewSampler0\",\n      [](const char* name, TFE_MonitoringBuckets* buckets,\n         const char* description) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output =\n            TFE_MonitoringNewSampler0(name, buckets, status.get(), description);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteSampler0\", &TFE_MonitoringDeleteSampler0,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellSampler0\", &TFE_MonitoringGetCellSampler0,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewSampler1\",\n      [](const char* name, TFE_MonitoringBuckets* buckets,\n         const char* description, const char* label1) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewSampler1(name, buckets, status.get(),\n                                                description, label1);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteSampler1\", &TFE_MonitoringDeleteSampler1,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellSampler1\", &TFE_MonitoringGetCellSampler1,\n        py::return_value_policy::reference);\n  m.def(\n      \"TFE_MonitoringNewSampler2\",\n      [](const char* name, TFE_MonitoringBuckets* buckets,\n         const char* description, const char* label1, const char* label2) {\n        tensorflow::Safe_TF_StatusPtr status =\n            tensorflow::make_safe(TF_NewStatus());\n        auto output = TFE_MonitoringNewSampler2(name, buckets, status.get(),\n                                                description, label1, label2);\n        tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n        return output;\n      },\n      py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringDeleteSampler2\", &TFE_MonitoringDeleteSampler2,\n        py::return_value_policy::reference);\n  m.def(\"TFE_MonitoringGetCellSampler2\", &TFE_MonitoringGetCellSampler2,\n        py::return_value_policy::reference);\n\n  // TFE_CancellationManager Logic\n  m.def(\"TFE_NewCancellationManager\", &TFE_NewCancellationManager,\n        py::return_value_policy::reference);\n  m.def(\"TFE_CancellationManagerIsCancelled\",\n        &TFE_CancellationManagerIsCancelled);\n  m.def(\"TFE_CancellationManagerStartCancel\",\n        &TFE_CancellationManagerStartCancel);\n  m.def(\"TFE_DeleteCancellationManager\", &TFE_DeleteCancellationManager,\n        py::return_value_policy::reference);\n\n  m.def(\"TFE_ClearScalarCache\", &tensorflow::TFE_ClearScalarCache);\n\n  // Util buffer helper functions\n  m.def(\"TF_NewBufferFromString\", &TF_NewBufferFromString,\n        py::return_value_policy::reference);\n\n  // DLPack functions\n  m.def(\"TFE_ToDlpackCapsule\", [](py::handle& o) {\n    PyObject* eager_tensor_pyobject_ptr = o.ptr();\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n\n    if (!EagerTensor_CheckExact(eager_tensor_pyobject_ptr)) {\n      status->status = tensorflow::errors::InvalidArgument(\n          \"The argument to `to_dlpack` must be a TF tensor, not Python object\");\n      tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    }\n\n    TFE_TensorHandle* thandle = EagerTensor_Handle(eager_tensor_pyobject_ptr);\n    void* dlm_ptr = tensorflow::TFE_HandleToDLPack(thandle, status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n\n    py::capsule capsule(\n        dlm_ptr, tensorflow::kDlTensorCapsuleName, [](PyObject* capsule) {\n          if (PyCapsule_IsValid(capsule, tensorflow::kDlTensorCapsuleName)) {\n            void* dlm_rptr =\n                PyCapsule_GetPointer(capsule, tensorflow::kDlTensorCapsuleName);\n            if (dlm_rptr) {\n              tensorflow::TFE_CallDLManagedTensorDeleter(dlm_rptr);\n              PyCapsule_SetDestructor(capsule, nullptr);\n            }\n          }\n        });\n    return capsule;\n  });\n\n  m.def(\"TFE_FromDlpackCapsule\", [](const py::capsule& pycapsule,\n                                    const py::handle& context) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    if (absl::string_view(pycapsule.name()) !=\n        tensorflow::kDlTensorCapsuleName) {\n      status->status = tensorflow::errors::InvalidArgument(\n          \"DLPack tensor must be a capsule with name \\\"dltensor\\\", got \\\"%s\\\". \"\n          \"Note that a DLPack tensor may be consumed at most once.\",\n          absl::string_view(pycapsule.name()));\n      tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    }\n\n    TFE_TensorHandle* thandle = tensorflow::TFE_HandleFromDLPack(\n        pycapsule, status.get(), tensorflow::InputTFE_Context(context));\n\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n\n    PyCapsule_SetName(pycapsule.ptr(), \"used_dltensor\");\n    PyCapsule_SetDestructor(pycapsule.ptr(), nullptr);\n\n    PyObject* pyhandle = EagerTensorFromHandle(thandle);\n    return tensorflow::PyoOrThrow(pyhandle);\n  });\n\n  m.def(\"TFE_Py_RegisterCustomDevice\", [](const py::handle& context,\n                                          const py::capsule& device,\n                                          const char* device_name,\n                                          const py::capsule& device_info) {\n    tensorflow::Safe_TF_StatusPtr status =\n        tensorflow::make_safe(TF_NewStatus());\n    if (absl::string_view(device.name()) != \"TFE_CustomDevice\") {\n      status->status = tensorflow::errors::InvalidArgument(\n          \"Expected a capsule named 'TFE_CustomDevice' for the `device` \"\n          \"argument, got \",\n          absl::string_view(device.name()));\n      tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    }\n    if (absl::string_view(device_info.name()) !=\n        \"TFE_CustomDevice_DeviceInfo\") {\n      status->status = tensorflow::errors::InvalidArgument(\n          \"Expected a capsule named 'TFE_CustomDevice_DeviceInfo' for \"\n          \"the `device_info` argument, got \",\n          absl::string_view(device_info.name()));\n      tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n    }\n    // TFE_RegisterCustomDevice takes ownership\n    PyCapsule_SetDestructor(device_info.ptr(), nullptr);\n    TFE_RegisterCustomDevice(\n        tensorflow::InputTFE_Context(context),\n        *reinterpret_cast<TFE_CustomDevice*>(\n            PyCapsule_GetPointer(device.ptr(), \"TFE_CustomDevice\")),\n        device_name,\n        PyCapsule_GetPointer(device_info.ptr(), \"TFE_CustomDevice_DeviceInfo\"),\n        status.get());\n    tensorflow::MaybeRaiseRegisteredFromTFStatus(status.get());\n  });\n\n  py::class_<EagerContextThreadLocalDataWrapper>(m,\n                                                 \"EagerContextThreadLocalData\")\n      .def(py::init<py::handle, py::handle, py::handle>(),\n           py::arg(\"py_eager_context\"), py::arg(\"is_eager\"),\n           py::arg(\"device_spec\"))\n      .def_property(\"is_eager\",\n                    &EagerContextThreadLocalDataWrapper::get_is_eager,\n                    &EagerContextThreadLocalDataWrapper::set_is_eager)\n      .def_property(\n          \"invoking_op_callbacks\",\n          &EagerContextThreadLocalDataWrapper::get_invoking_op_callbacks,\n          &EagerContextThreadLocalDataWrapper::set_invoking_op_callbacks)\n      .def_property(\"device_name\",\n                    &EagerContextThreadLocalDataWrapper::get_device_name,\n                    &EagerContextThreadLocalDataWrapper::set_device_name)\n      .def_property(\"scope_name\",\n                    &EagerContextThreadLocalDataWrapper::get_scope_name,\n                    &EagerContextThreadLocalDataWrapper::set_scope_name)\n      .def_property(\"device_spec\",\n                    &EagerContextThreadLocalDataWrapper::get_device_spec,\n                    &EagerContextThreadLocalDataWrapper::set_device_spec)\n      .def_property(\n          \"function_call_options\",\n          &EagerContextThreadLocalDataWrapper::get_function_call_options,\n          &EagerContextThreadLocalDataWrapper::set_function_call_options)\n      .def_property(\"executor\",\n                    &EagerContextThreadLocalDataWrapper::get_executor,\n                    &EagerContextThreadLocalDataWrapper::set_executor)\n      .def_property(\"op_callbacks\",\n                    &EagerContextThreadLocalDataWrapper::get_op_callbacks,\n                    &EagerContextThreadLocalDataWrapper::set_op_callbacks);\n\n  // C API Enum\n\n  py::enum_<TFE_ContextDevicePlacementPolicy>(\n      m, \"TFE_ContextDevicePlacementPolicy\")\n      .value(\"TFE_DEVICE_PLACEMENT_EXPLICIT\", TFE_DEVICE_PLACEMENT_EXPLICIT)\n      .value(\"TFE_DEVICE_PLACEMENT_WARN\", TFE_DEVICE_PLACEMENT_WARN)\n      .value(\"TFE_DEVICE_PLACEMENT_SILENT\", TFE_DEVICE_PLACEMENT_SILENT)\n      .value(\"TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32\",\n             TFE_DEVICE_PLACEMENT_SILENT_FOR_INT32)\n      .export_values();\n\n  py::enum_<TF_AttrType>(m, \"TF_AttrType\")\n      .value(\"TF_ATTR_STRING\", TF_ATTR_STRING)\n      .value(\"TF_ATTR_INT\", TF_ATTR_INT)\n      .value(\"TF_ATTR_FLOAT\", TF_ATTR_FLOAT)\n      .value(\"TF_ATTR_BOOL\", TF_ATTR_BOOL)\n      .value(\"TF_ATTR_TYPE\", TF_ATTR_TYPE)\n      .value(\"TF_ATTR_SHAPE\", TF_ATTR_SHAPE)\n      .value(\"TF_ATTR_TENSOR\", TF_ATTR_TENSOR)\n      .value(\"TF_ATTR_PLACEHOLDER\", TF_ATTR_PLACEHOLDER)\n      .value(\"TF_ATTR_FUNC\", TF_ATTR_FUNC)\n      .export_values();\n};"