"diff --git a/tensorflow/lite/model_test.cc b/tensorflow/lite/model_test.cc\nindex 6993e350a48..110c54aa571 100644\n--- a/tensorflow/lite/model_test.cc\n+++ b/tensorflow/lite/model_test.cc\n@@ -438,24 +438,48 @@ TEST(BasicFlatBufferModel, TestParseModelWithSparseTensor) {\n }\n \n // TODO(b/150072943): Add malformed model with sparse tensor tests.\n-TEST(BasicFlatBufferModel, TestHandleMalformedModel) {\n-  const auto model_paths = {\n-      // These models use the same tensor as both input and ouput of a node\n-      \"tensorflow/lite/testdata/add_shared_tensors.bin\",\n-  };\n-\n-  for (const auto& model_path : model_paths) {\n-    std::unique_ptr<tflite::FlatBufferModel> model =\n-        FlatBufferModel::BuildFromFile(model_path);\n-    ASSERT_NE(model, nullptr);\n-\n-    tflite::ops::builtin::BuiltinOpResolver resolver;\n-    InterpreterBuilder builder(*model, resolver);\n-    std::unique_ptr<Interpreter> interpreter;\n-    ASSERT_EQ(builder(&interpreter), kTfLiteOk);\n-    ASSERT_NE(interpreter, nullptr);\n-    ASSERT_NE(interpreter->AllocateTensors(), kTfLiteOk);\n-  }\n+\n+// The models here have at least a node that uses the same tensor as input and\n+// output. This causes segfaults when trying to eval the operator, hence we try\n+// to prevent this scenario. The earliest place we can check this is in\n+// `AllocateTensors`, hence the test checks that `interpreter->AllocateTensors`\n+// detects these bad models.\n+TEST(BasicFlatBufferModel, TestHandleMalformedModelReuseTensor) {\n+  const auto model_path =\n+      \"tensorflow/lite/testdata/add_shared_tensors.bin\";\n+\n+  std::unique_ptr<tflite::FlatBufferModel> model =\n+      FlatBufferModel::BuildFromFile(model_path);\n+  ASSERT_NE(model, nullptr);\n+\n+  tflite::ops::builtin::BuiltinOpResolver resolver;\n+  InterpreterBuilder builder(*model, resolver);\n+  std::unique_ptr<Interpreter> interpreter;\n+  ASSERT_EQ(builder(&interpreter), kTfLiteOk);\n+  ASSERT_NE(interpreter, nullptr);\n+  ASSERT_NE(interpreter->AllocateTensors(), kTfLiteOk);\n+}\n+\n+// The models here have a buffer index for a tensor pointing to a null buffer.\n+// This results in the tensor being interpreted as read-write, but the model\n+// assumes the tensor is read-only. As such, `interpreter->Invoke()` would\n+// segfault if no precondition check is added. The test checks that the\n+// precondition check exists.\n+TEST(BasicFlatBufferModel, TestHandleMalformedModelInvalidBuffer) {\n+  const auto model_path =\n+      \"tensorflow/lite/testdata/segment_sum_invalid_buffer.bin\";\n+\n+  std::unique_ptr<tflite::FlatBufferModel> model =\n+      FlatBufferModel::BuildFromFile(model_path);\n+  ASSERT_NE(model, nullptr);\n+\n+  tflite::ops::builtin::BuiltinOpResolver resolver;\n+  InterpreterBuilder builder(*model, resolver);\n+  std::unique_ptr<Interpreter> interpreter;\n+  ASSERT_EQ(builder(&interpreter), kTfLiteOk);\n+  ASSERT_NE(interpreter, nullptr);\n+  ASSERT_EQ(interpreter->AllocateTensors(), kTfLiteOk);\n+  ASSERT_NE(interpreter->Invoke(), kTfLiteOk);\n }\n \n // TODO(aselle): Add tests for serialization of builtin op data types."