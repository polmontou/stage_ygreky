"/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/lite/model.h\"\n\n#include <fcntl.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <fstream>\n#include <iostream>\n\n#include <gtest/gtest.h>\n#include \"tensorflow/lite/core/api/error_reporter.h\"\n#include \"tensorflow/lite/kernels/register.h\"\n#include \"tensorflow/lite/testing/util.h\"\n\n// Comparison for TfLiteRegistration. Since TfLiteRegistration is a C object,\n// we must declare this in global namespace, so argument-dependent operator\n// lookup works.\ninline bool operator==(const TfLiteRegistration& a,\n                       const TfLiteRegistration& b) {\n  return a.invoke == b.invoke && a.init == b.init && a.prepare == b.prepare &&\n         a.free == b.free;\n}\n\nnamespace tflite {\n\n// Provide a dummy operation that does nothing.\nnamespace {\nvoid* dummy_init(TfLiteContext*, const char*, size_t) { return nullptr; }\nvoid dummy_free(TfLiteContext*, void*) {}\nTfLiteStatus dummy_resize(TfLiteContext*, TfLiteNode*) { return kTfLiteOk; }\nTfLiteStatus dummy_invoke(TfLiteContext*, TfLiteNode*) { return kTfLiteOk; }\nTfLiteRegistration dummy_reg = {dummy_init, dummy_free, dummy_resize,\n                                dummy_invoke};\n}  // namespace\n\n// Provide a trivial resolver that returns a constant value no matter what\n// op is asked for.\nclass TrivialResolver : public OpResolver {\n public:\n  explicit TrivialResolver(TfLiteRegistration* constant_return = nullptr)\n      : constant_return_(constant_return) {}\n  // Find the op registration of a custom operator by op name.\n  const TfLiteRegistration* FindOp(tflite::BuiltinOperator op,\n                                   int version) const override {\n    return constant_return_;\n  }\n  // Find the op registration of a custom operator by op name.\n  const TfLiteRegistration* FindOp(const char* op, int version) const override {\n    return constant_return_;\n  }\n\n private:\n  TfLiteRegistration* constant_return_;\n};\n\nTEST(BasicFlatBufferModel, TestNonExistentFiles) {\n  ASSERT_TRUE(!FlatBufferModel::BuildFromFile(\"/tmp/tflite_model_1234\"));\n}\n\nTEST(BasicFlatBufferModel, TestBufferAlignment) {\n  // On 32-bit ARM buffers are required to be 4-bytes aligned, on other\n  // platforms there is no alignment requirement.\n  const uintptr_t kAlignment = 4;\n  const uintptr_t kAlignmentBits = kAlignment - 1;\n\n  // Use real model data so that we can be sure error is only from the\n  // alignment requirement and not from bad data.\n  std::ifstream fp(\"tensorflow/lite/testdata/empty_model.bin\");\n  ASSERT_TRUE(fp.good());\n  std::string empty_model_data((std::istreambuf_iterator<char>(fp)),\n                               std::istreambuf_iterator<char>());\n  auto free_chars = [](char* p) { free(p); };\n  std::unique_ptr<char, decltype(free_chars)> buffer(\n      reinterpret_cast<char*>(malloc(empty_model_data.size() + kAlignment)),\n      free_chars);\n\n  // Check that aligned buffer works (no other errors in the test).\n  char* aligned = reinterpret_cast<char*>(\n      (reinterpret_cast<uintptr_t>(buffer.get()) + kAlignment) &\n      ~kAlignmentBits);\n  memcpy(aligned, empty_model_data.c_str(), empty_model_data.size());\n  EXPECT_TRUE(\n      FlatBufferModel::BuildFromBuffer(aligned, empty_model_data.size()));\n\n  // Check unaligned buffer handling.\n  char* unaligned =\n      reinterpret_cast<char*>(reinterpret_cast<uintptr_t>(buffer.get()) | 0x1);\n  memcpy(unaligned, empty_model_data.c_str(), empty_model_data.size());\n#ifdef __arm__\n  EXPECT_FALSE(\n      FlatBufferModel::BuildFromBuffer(unaligned, empty_model_data.size()));\n#else   // !__arm__\n  EXPECT_TRUE(\n      FlatBufferModel::BuildFromBuffer(unaligned, empty_model_data.size()));\n#endif  // __arm__\n}\n\n// Make sure a model with nothing in it loads properly.\nTEST(BasicFlatBufferModel, TestEmptyModelsAndNullDestination) {\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/empty_model.bin\");\n  ASSERT_TRUE(model);\n  // Now try to build it into a model.\n  std::unique_ptr<Interpreter> interpreter;\n  ASSERT_EQ(InterpreterBuilder(*model, TrivialResolver())(&interpreter),\n            kTfLiteOk);\n  ASSERT_NE(interpreter, nullptr);\n  ASSERT_NE(InterpreterBuilder(*model, TrivialResolver())(nullptr), kTfLiteOk);\n}\n\n// Make sure currently unsupported # of subgraphs are checked\n// TODO(aselle): Replace this test when multiple subgraphs are supported.\nTEST(BasicFlatBufferModel, TestZeroSubgraphs) {\n  auto m = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/0_subgraphs.bin\");\n  ASSERT_TRUE(m);\n  std::unique_ptr<Interpreter> interpreter;\n  ASSERT_NE(InterpreterBuilder(*m, TrivialResolver())(&interpreter), kTfLiteOk);\n}\n\nTEST(BasicFlatBufferModel, TestMultipleSubgraphs) {\n  auto m = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/2_subgraphs.bin\");\n  ASSERT_TRUE(m);\n  std::unique_ptr<Interpreter> interpreter;\n  ASSERT_EQ(InterpreterBuilder(*m, TrivialResolver())(&interpreter), kTfLiteOk);\n  EXPECT_EQ(interpreter->subgraphs_size(), 2);\n}\n\n// Test what happens if we cannot bind any of the ops.\nTEST(BasicFlatBufferModel, TestModelWithoutNullRegistrations) {\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\");\n  ASSERT_TRUE(model);\n  // Check that we get an error code and interpreter pointer is reset.\n  std::unique_ptr<Interpreter> interpreter(new Interpreter);\n  ASSERT_NE(InterpreterBuilder(*model, TrivialResolver(nullptr))(&interpreter),\n            kTfLiteOk);\n  ASSERT_EQ(interpreter, nullptr);\n}\n\n// Make sure model is read to interpreter properly\nTEST(BasicFlatBufferModel, TestModelInInterpreter) {\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\");\n  ASSERT_TRUE(model);\n  // Check that we get an error code and interpreter pointer is reset.\n  std::unique_ptr<Interpreter> interpreter(new Interpreter);\n  ASSERT_EQ(\n      InterpreterBuilder(*model, TrivialResolver(&dummy_reg))(&interpreter),\n      kTfLiteOk);\n  ASSERT_NE(interpreter, nullptr);\n  ASSERT_EQ(interpreter->tensors_size(), 4);\n  ASSERT_EQ(interpreter->nodes_size(), 2);\n  std::vector<int> inputs = {0, 1};\n  std::vector<int> outputs = {2, 3};\n  ASSERT_EQ(interpreter->inputs(), inputs);\n  ASSERT_EQ(interpreter->outputs(), outputs);\n\n  EXPECT_EQ(std::string(interpreter->GetInputName(0)), \"input0\");\n  EXPECT_EQ(std::string(interpreter->GetInputName(1)), \"input1\");\n  EXPECT_EQ(std::string(interpreter->GetOutputName(0)), \"out1\");\n  EXPECT_EQ(std::string(interpreter->GetOutputName(1)), \"out2\");\n\n  // Make sure all input tensors are correct\n  TfLiteTensor* i0 = interpreter->tensor(0);\n  ASSERT_EQ(i0->type, kTfLiteFloat32);\n  ASSERT_NE(i0->data.raw, nullptr);  // mmapped\n  ASSERT_EQ(i0->allocation_type, kTfLiteMmapRo);\n  TfLiteTensor* i1 = interpreter->tensor(1);\n  ASSERT_EQ(i1->type, kTfLiteFloat32);\n  ASSERT_EQ(i1->data.raw, nullptr);\n  ASSERT_EQ(i1->allocation_type, kTfLiteArenaRw);\n  TfLiteTensor* o0 = interpreter->tensor(2);\n  ASSERT_EQ(o0->type, kTfLiteFloat32);\n  ASSERT_EQ(o0->data.raw, nullptr);\n  ASSERT_EQ(o0->allocation_type, kTfLiteArenaRw);\n  TfLiteTensor* o1 = interpreter->tensor(3);\n  ASSERT_EQ(o1->type, kTfLiteFloat32);\n  ASSERT_EQ(o1->data.raw, nullptr);\n  ASSERT_EQ(o1->allocation_type, kTfLiteArenaRw);\n\n  // Check op 0 which has inputs {0, 1} outputs {2}.\n  {\n    const std::pair<TfLiteNode, TfLiteRegistration>* node_and_reg0 =\n        interpreter->node_and_registration(0);\n    ASSERT_NE(node_and_reg0, nullptr);\n    const TfLiteNode& node0 = node_and_reg0->first;\n    const TfLiteRegistration& reg0 = node_and_reg0->second;\n    TfLiteIntArray* desired_inputs = TfLiteIntArrayCreate(2);\n    desired_inputs->data[0] = 0;\n    desired_inputs->data[1] = 1;\n    TfLiteIntArray* desired_outputs = TfLiteIntArrayCreate(1);\n    desired_outputs->data[0] = 2;\n    ASSERT_TRUE(TfLiteIntArrayEqual(node0.inputs, desired_inputs));\n    ASSERT_TRUE(TfLiteIntArrayEqual(node0.outputs, desired_outputs));\n    TfLiteIntArrayFree(desired_inputs);\n    TfLiteIntArrayFree(desired_outputs);\n    ASSERT_EQ(reg0, dummy_reg);\n  }\n\n  // Check op 1 which has inputs {2} outputs {3}.\n  {\n    const std::pair<TfLiteNode, TfLiteRegistration>* node_and_reg1 =\n        interpreter->node_and_registration(1);\n    ASSERT_NE(node_and_reg1, nullptr);\n    const TfLiteNode& node1 = node_and_reg1->first;\n    const TfLiteRegistration& reg1 = node_and_reg1->second;\n    TfLiteIntArray* desired_inputs = TfLiteIntArrayCreate(1);\n    TfLiteIntArray* desired_outputs = TfLiteIntArrayCreate(1);\n    desired_inputs->data[0] = 2;\n    desired_outputs->data[0] = 3;\n    ASSERT_TRUE(TfLiteIntArrayEqual(node1.inputs, desired_inputs));\n    ASSERT_TRUE(TfLiteIntArrayEqual(node1.outputs, desired_outputs));\n    TfLiteIntArrayFree(desired_inputs);\n    TfLiteIntArrayFree(desired_outputs);\n    ASSERT_EQ(reg1, dummy_reg);\n  }\n}\n\n// Test that loading a model with TensorFlow ops fails when the flex delegate is\n// not linked into the target.\nTEST(FlexModel, FailureWithoutFlexDelegate) {\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/multi_add_flex.bin\");\n  ASSERT_TRUE(model);\n\n  // Note that creation will succeed when using the BuiltinOpResolver, but\n  // unless the appropriate delegate is linked into the target or the client\n  // explicitly installs the delegate, execution will fail.\n  std::unique_ptr<Interpreter> interpreter;\n  ASSERT_EQ(InterpreterBuilder(*model,\n                               ops::builtin::BuiltinOpResolver{})(&interpreter),\n            kTfLiteOk);\n  ASSERT_TRUE(interpreter);\n\n  // As the flex ops weren't resolved implicitly by the flex delegate, runtime\n  // allocation and execution will fail.\n  ASSERT_EQ(interpreter->AllocateTensors(), kTfLiteError);\n}\n\n// This tests on a flatbuffer that defines a shape of 2 to be a memory mapped\n// buffer. But the buffer is provided to be only 1 element.\nTEST(BasicFlatBufferModel, TestBrokenMmap) {\n  ASSERT_FALSE(FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/test_model_broken.bin\"));\n}\n\nTEST(BasicFlatBufferModel, TestNullModel) {\n  // Check that we get an error code and interpreter pointer is reset.\n  std::unique_ptr<Interpreter> interpreter(new Interpreter);\n  ASSERT_NE(\n      InterpreterBuilder(nullptr, TrivialResolver(&dummy_reg))(&interpreter),\n      kTfLiteOk);\n  ASSERT_EQ(interpreter.get(), nullptr);\n}\n\n// Mocks the verifier by setting the result in ctor.\nclass FakeVerifier : public tflite::TfLiteVerifier {\n public:\n  explicit FakeVerifier(bool result) : result_(result) {}\n  bool Verify(const char* data, int length,\n              tflite::ErrorReporter* reporter) override {\n    return result_;\n  }\n\n private:\n  bool result_;\n};\n\nTEST(BasicFlatBufferModel, TestWithTrueVerifier) {\n  FakeVerifier verifier(true);\n  ASSERT_TRUE(FlatBufferModel::VerifyAndBuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\", &verifier));\n}\n\nTEST(BasicFlatBufferModel, TestWithFalseVerifier) {\n  FakeVerifier verifier(false);\n  ASSERT_FALSE(FlatBufferModel::VerifyAndBuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\", &verifier));\n}\n\nTEST(BasicFlatBufferModel, TestWithNullVerifier) {\n  ASSERT_TRUE(FlatBufferModel::VerifyAndBuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\", nullptr));\n}\n\n// This makes sure the ErrorReporter is marshalled from FlatBufferModel to\n// the Interpreter.\nTEST(BasicFlatBufferModel, TestCustomErrorReporter) {\n  TestErrorReporter reporter;\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/empty_model.bin\", &reporter);\n  ASSERT_TRUE(model);\n\n  std::unique_ptr<Interpreter> interpreter;\n  TrivialResolver resolver;\n  InterpreterBuilder(*model, resolver)(&interpreter);\n  ASSERT_NE(interpreter->Invoke(), kTfLiteOk);\n  ASSERT_EQ(reporter.num_calls(), 1);\n}\n\n// This makes sure the ErrorReporter is marshalled from FlatBufferModel to\n// the Interpreter.\nTEST(BasicFlatBufferModel, TestNullErrorReporter) {\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/empty_model.bin\", nullptr);\n  ASSERT_TRUE(model);\n\n  std::unique_ptr<Interpreter> interpreter;\n  TrivialResolver resolver;\n  InterpreterBuilder(*model, resolver)(&interpreter);\n  ASSERT_NE(interpreter->Invoke(), kTfLiteOk);\n}\n\n// Test that loading model directly from a Model flatbuffer works.\nTEST(BasicFlatBufferModel, TestBuildFromModel) {\n  TestErrorReporter reporter;\n  FileCopyAllocation model_allocation(\n      \"tensorflow/lite/testdata/test_model.bin\", &reporter);\n  ASSERT_TRUE(model_allocation.valid());\n  ::flatbuffers::Verifier verifier(\n      reinterpret_cast<const uint8_t*>(model_allocation.base()),\n      model_allocation.bytes());\n  ASSERT_TRUE(VerifyModelBuffer(verifier));\n  const Model* model_fb = ::tflite::GetModel(model_allocation.base());\n\n  auto model = FlatBufferModel::BuildFromModel(model_fb);\n  ASSERT_TRUE(model);\n\n  std::unique_ptr<Interpreter> interpreter;\n  ASSERT_EQ(\n      InterpreterBuilder(*model, TrivialResolver(&dummy_reg))(&interpreter),\n      kTfLiteOk);\n  ASSERT_NE(interpreter, nullptr);\n}\n\n// Test reading the minimum runtime string from metadata in a Model flatbuffer.\nTEST(BasicFlatBufferModel, TestReadRuntimeVersionFromModel) {\n  // First read a model that doesn't have the runtime string.\n  auto model1 = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/test_model.bin\");\n  ASSERT_TRUE(model1);\n  ASSERT_EQ(model1->GetMinimumRuntime(), \"\");\n\n  // Read a model that has minimum runtime string populated.\n  auto model2 = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/test_min_runtime.bin\");\n  ASSERT_TRUE(model2);\n  // Check that we have read the runtime string correctly.\n  ASSERT_EQ(model2->GetMinimumRuntime(), \"1.5.0\");\n}\n\n// The test model has the following tensor encoded in the TACO format:\n// [[1, 0, 2, 3],\n//  [0, 4, 0, 0],\n//  [0, 0, 5, 0],\n//  [0, 0, 0, 6]].\n// TACO supports multiple encodings like CSR, CSC, etc. We chose to use the one\n// similar to the blocked-CSR format with 2x2 row-major dense blocks.\nTEST(BasicFlatBufferModel, TestParseModelWithSparseTensor) {\n  // The model only has 1 sparse constant tensor.\n  auto model = FlatBufferModel::BuildFromFile(\n      \"tensorflow/lite/testdata/sparse_tensor.bin\");\n  ASSERT_TRUE(model);\n\n  std::unique_ptr<Interpreter> interpreter(new Interpreter);\n  ASSERT_EQ(InterpreterBuilder(*model, TrivialResolver())(&interpreter),\n            kTfLiteOk);\n  ASSERT_NE(interpreter, nullptr);\n  ASSERT_EQ(interpreter->tensors_size(), 2);\n  TfLiteTensor* t1 = interpreter->tensor(0);\n  ASSERT_EQ(t1->allocation_type, kTfLiteMmapRo);\n\n  TfLiteIntArray* traversal_order = TfLiteIntArrayCreate(4);\n  traversal_order->data[0] = 0;\n  traversal_order->data[1] = 1;\n  traversal_order->data[2] = 2;\n  traversal_order->data[3] = 3;\n  ASSERT_TRUE(\n      TfLiteIntArrayEqual(t1->sparsity->traversal_order, traversal_order));\n  TfLiteIntArrayFree(traversal_order);\n\n  TfLiteIntArray* block_map = TfLiteIntArrayCreate(2);\n  block_map->data[0] = 0;\n  block_map->data[1] = 1;\n  ASSERT_TRUE(TfLiteIntArrayEqual(t1->sparsity->block_map, block_map));\n  TfLiteIntArrayFree(block_map);\n\n  ASSERT_EQ(t1->sparsity->dim_metadata_size, 4);\n\n  ASSERT_EQ(t1->sparsity->dim_metadata[0].format, kTfLiteDimDense);\n  ASSERT_EQ(t1->sparsity->dim_metadata[0].dense_size, 2);\n  ASSERT_EQ(t1->sparsity->dim_metadata[0].array_segments, nullptr);\n  ASSERT_EQ(t1->sparsity->dim_metadata[0].array_indices, nullptr);\n\n  ASSERT_EQ(t1->sparsity->dim_metadata[1].format, kTfLiteDimSparseCSR);\n  ASSERT_EQ(t1->sparsity->dim_metadata[1].dense_size, 0);\n  TfLiteIntArray* array_segments = TfLiteIntArrayCreate(3);\n  array_segments->data[0] = 0;\n  array_segments->data[1] = 2;\n  array_segments->data[2] = 3;\n  ASSERT_TRUE(TfLiteIntArrayEqual(t1->sparsity->dim_metadata[1].array_segments,\n                                  array_segments));\n  TfLiteIntArrayFree(array_segments);\n\n  TfLiteIntArray* array_indices = TfLiteIntArrayCreate(3);\n  array_indices->data[0] = 0;\n  array_indices->data[1] = 1;\n  array_indices->data[2] = 1;\n  ASSERT_TRUE(TfLiteIntArrayEqual(t1->sparsity->dim_metadata[1].array_indices,\n                                  array_indices));\n  TfLiteIntArrayFree(array_indices);\n\n  ASSERT_EQ(t1->sparsity->dim_metadata[2].format, kTfLiteDimDense);\n  ASSERT_EQ(t1->sparsity->dim_metadata[2].dense_size, 2);\n  ASSERT_EQ(t1->sparsity->dim_metadata[2].array_segments, nullptr);\n  ASSERT_EQ(t1->sparsity->dim_metadata[2].array_indices, nullptr);\n\n  ASSERT_EQ(t1->sparsity->dim_metadata[3].format, kTfLiteDimDense);\n  ASSERT_EQ(t1->sparsity->dim_metadata[3].dense_size, 2);\n  ASSERT_EQ(t1->sparsity->dim_metadata[3].array_segments, nullptr);\n  ASSERT_EQ(t1->sparsity->dim_metadata[3].array_indices, nullptr);\n}\n\n// TODO(b/150072943): Add malformed model with sparse tensor tests.\nTEST(BasicFlatBufferModel, TestHandleMalformedModel) {\n  const auto model_paths = {\n      // These models use the same tensor as both input and ouput of a node\n      \"tensorflow/lite/testdata/add_shared_tensors.bin\",\n  };\n\n  for (const auto& model_path : model_paths) {\n    std::unique_ptr<tflite::FlatBufferModel> model =\n        FlatBufferModel::BuildFromFile(model_path);\n    ASSERT_NE(model, nullptr);\n\n    tflite::ops::builtin::BuiltinOpResolver resolver;\n    InterpreterBuilder builder(*model, resolver);\n    std::unique_ptr<Interpreter> interpreter;\n    ASSERT_EQ(builder(&interpreter), kTfLiteOk);\n    ASSERT_NE(interpreter, nullptr);\n    ASSERT_NE(interpreter->AllocateTensors(), kTfLiteOk);\n  }\n}\n\n// TODO(aselle): Add tests for serialization of builtin op data types.\n// These tests will occur with the evaluation tests of individual operators,\n// not here.\n\n}  // namespace tflite\n\nint main(int argc, char** argv) {\n  ::tflite::LogToStderr();\n  ::testing::InitGoogleTest(&argc, argv);\n  return RUN_ALL_TESTS();\n}"