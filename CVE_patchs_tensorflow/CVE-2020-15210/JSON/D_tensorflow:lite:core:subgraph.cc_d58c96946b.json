"diff --git a/tensorflow/lite/core/subgraph.cc b/tensorflow/lite/core/subgraph.cc\nindex 2fe8099d372..47d0fddb12b 100644\n--- a/tensorflow/lite/core/subgraph.cc\n+++ b/tensorflow/lite/core/subgraph.cc\n@@ -581,6 +581,33 @@ TfLiteStatus Subgraph::CheckTensorIndices(const char* label, const int* indices,\n   return kTfLiteOk;\n }\n \n+// We have two arrays and we need to check that elements from one array don't\n+// show up in the other. We could sort both arrays and then iterate with two\n+// pointers from start to finish always increasing the smaller one but since\n+// these arrays are usually short (<25 elements for inputs, usually <3 for\n+// outputs), this might be slower than the naive approach (if arrays have size n\n+// and m, with n >> m ~ O(1), first approach is O(nlogn) whereas the other is\n+// O(n)). Plus, sorting the input and output arrays might not be something we\n+// want as it destroys ordering of elements.\n+//\n+// If it turns out that this is an issue, we can switch to the other algorithm.\n+TfLiteStatus Subgraph::CheckInputAndOutputForOverlap(const int* input_indices,\n+                                                     int num_inputs,\n+                                                     const int* output_indices,\n+                                                     int num_outputs) {\n+  for (int i = 0; i < num_inputs; i++) {\n+    for (int j = 0; j < num_outputs; j++) {\n+      if (input_indices[i] == output_indices[j]) {\n+        ReportError(\"Tensor %d is both input %d and output %d\\n\",\n+                    input_indices[i], i, j);\n+        consistent_ = false;\n+        return kTfLiteError;\n+      }\n+    }\n+  }\n+  return kTfLiteOk;\n+}\n+\n namespace {\n // Multiply two sizes and return true if overflow occurred;\n // This is based off tensorflow/overflow.h but is simpler as we already\n@@ -707,6 +734,16 @@ TfLiteStatus Subgraph::AddNodeWithParameters(\n       &context_,\n       CheckTensorIndices(\"node outputs\", outputs.data(), outputs.size()));\n \n+  // For builtin ops, inputs and outputs must not overlap. Custom ops must do\n+  // this check by themselves if they don't support overlapping tensors. This\n+  // distinction is to allow custom ops to just forward a tensor, reusing it as\n+  // both input and output.\n+  if (builtin_data != nullptr) {\n+    TF_LITE_ENSURE_OK(&context_, CheckInputAndOutputForOverlap(\n+                                     inputs.data(), inputs.size(),\n+                                     outputs.data(), outputs.size()));\n+  }\n+\n   int new_node_index = nodes_and_registration_.size();\n   if (node_index) *node_index = new_node_index;\n   nodes_and_registration_.resize(nodes_and_registration_.size() + 1);"