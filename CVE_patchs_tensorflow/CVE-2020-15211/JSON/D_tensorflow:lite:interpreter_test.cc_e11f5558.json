"diff --git a/tensorflow/lite/interpreter_test.cc b/tensorflow/lite/interpreter_test.cc\nindex bd0f724a7bf..66728ea89e9 100644\n--- a/tensorflow/lite/interpreter_test.cc\n+++ b/tensorflow/lite/interpreter_test.cc\n@@ -621,8 +621,10 @@ TfLiteRegistration GetPassthroughOpRegistration() {\n   reg.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n     auto* first_new_tensor = static_cast<int*>(node->user_data);\n \n-    const TfLiteTensor* tensor0 = GetInput(context, node, 0);\n-    TfLiteTensor* tensor1 = GetOutput(context, node, 0);\n+    const TfLiteTensor* tensor0;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &tensor0));\n+    TfLiteTensor* tensor1;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &tensor1));\n \n     TfLiteIntArray* newSize = TfLiteIntArrayCopy(tensor0->dims);\n     TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, tensor1, newSize));\n@@ -646,7 +648,8 @@ TfLiteRegistration GetPassthroughOpRegistration() {\n     return kTfLiteOk;\n   };\n   reg.invoke = [](TfLiteContext* context, TfLiteNode* node) {\n-    const TfLiteTensor* a0 = GetInput(context, node, 0);\n+    const TfLiteTensor* a0;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &a0));\n \n     auto populate = [&](int id) {\n       TfLiteTensor* t = &context->tensors[id];\n@@ -780,8 +783,10 @@ TEST(BasicInterpreter, ThreeStepAllocate) {\n   // String-in String-out node.\n   TfLiteRegistration reg_copy = {nullptr, nullptr, nullptr, nullptr};\n   reg_copy.invoke = [](TfLiteContext* context, TfLiteNode* node) {\n-    const TfLiteTensor* input = GetInput(context, node, 0);\n-    TfLiteTensor* output = GetOutput(context, node, 0);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n     DynamicBuffer buf;\n     StringRef str_ref = GetString(input, 0);\n     buf.AddString(str_ref);\n@@ -792,14 +797,17 @@ TEST(BasicInterpreter, ThreeStepAllocate) {\n   // String-in Int-out node.\n   TfLiteRegistration reg_len = {nullptr, nullptr, nullptr, nullptr};\n   reg_len.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n-    TfLiteTensor* output = GetOutput(context, node, 0);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n     TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n     outputSize->data[0] = 1;\n     return context->ResizeTensor(context, output, outputSize);\n   };\n   reg_len.invoke = [](TfLiteContext* context, TfLiteNode* node) {\n-    const TfLiteTensor* a0 = GetInput(context, node, 0);\n-    TfLiteTensor* a1 = GetOutput(context, node, 0);\n+    const TfLiteTensor* a0;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &a0));\n+    TfLiteTensor* a1;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &a1));\n     a1->data.i32[0] = a0->bytes;\n     return kTfLiteOk;\n   };\n@@ -848,14 +856,18 @@ TEST(BasicInterpreter, AllocateTwice) {\n \n   TfLiteRegistration reg = {nullptr, nullptr, nullptr, nullptr};\n   reg.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n-    const TfLiteTensor* tensor0 = GetInput(context, node, 0);\n-    TfLiteTensor* tensor1 = GetOutput(context, node, 0);\n+    const TfLiteTensor* tensor0;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &tensor0));\n+    TfLiteTensor* tensor1;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &tensor1));\n     TfLiteIntArray* newSize = TfLiteIntArrayCopy(tensor0->dims);\n     return context->ResizeTensor(context, tensor1, newSize);\n   };\n   reg.invoke = [](TfLiteContext* context, TfLiteNode* node) {\n-    const TfLiteTensor* a0 = GetInput(context, node, 0);\n-    TfLiteTensor* a1 = GetOutput(context, node, 0);\n+    const TfLiteTensor* a0;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &a0));\n+    TfLiteTensor* a1;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &a1));\n     int num = a0->dims->data[0];\n     for (int i = 0; i < num; i++) {\n       a1->data.f[i] = a0->data.f[i];\n@@ -1205,8 +1217,10 @@ class TestExecutionPlan : public ::testing::Test {\n \n     reg.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n       // Set output size to input size\n-      const TfLiteTensor* tensor0 = GetInput(context, node, 0);\n-      TfLiteTensor* tensor1 = GetOutput(context, node, 0);\n+      const TfLiteTensor* tensor0;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &tensor0));\n+      TfLiteTensor* tensor1;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &tensor1));\n       TfLiteIntArray* newSize = TfLiteIntArrayCopy(tensor0->dims);\n       return context->ResizeTensor(context, tensor1, newSize);\n     };\n@@ -1215,8 +1229,10 @@ class TestExecutionPlan : public ::testing::Test {\n       CallReporting* call_reporting =\n           static_cast<CallReporting*>(node->builtin_data);\n       // Copy input data to output data.\n-      const TfLiteTensor* a0 = GetInput(context, node, 0);\n-      TfLiteTensor* a1 = GetOutput(context, node, 0);\n+      const TfLiteTensor* a0;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &a0));\n+      TfLiteTensor* a1;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &a1));\n       int num = a0->dims->data[0];\n       for (int i = 0; i < num; i++) {\n         a1->data.f[i] = a0->data.f[i];\n@@ -1403,8 +1419,10 @@ class CancellationTest : public ::testing::Test {\n     // Set output size to the input size in CancelOp::Prepare(). Code exists to\n     // have a framework in Prepare. The input and output tensors are not used.\n     reg.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n-      const TfLiteTensor* in_tensor = GetInput(context, node, 0);\n-      TfLiteTensor* out_tensor = GetOutput(context, node, 0);\n+      const TfLiteTensor* in_tensor;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &in_tensor));\n+      TfLiteTensor* out_tensor;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &out_tensor));\n       TfLiteIntArray* new_size = TfLiteIntArrayCopy(in_tensor->dims);\n       return context->ResizeTensor(context, out_tensor, new_size);\n     };\n@@ -1423,8 +1441,10 @@ class CancellationTest : public ::testing::Test {\n     // Set output size to the input size in OkOp::Prepare(). Code exists to have\n     // a framework in Prepare. The input and output tensors are not used.\n     reg.prepare = [](TfLiteContext* context, TfLiteNode* node) {\n-      const TfLiteTensor* in_tensor = GetInput(context, node, 0);\n-      TfLiteTensor* out_tensor = GetOutput(context, node, 0);\n+      const TfLiteTensor* in_tensor;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &in_tensor));\n+      TfLiteTensor* out_tensor;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &out_tensor));\n       TfLiteIntArray* new_size = TfLiteIntArrayCopy(in_tensor->dims);\n       return context->ResizeTensor(context, out_tensor, new_size);\n     };"