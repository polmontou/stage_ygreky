"diff --git a/tensorflow/lite/kernels/add_n.cc b/tensorflow/lite/kernels/add_n.cc\nindex e933c5bbd66..d8fb2160833 100644\n--- a/tensorflow/lite/kernels/add_n.cc\n+++ b/tensorflow/lite/kernels/add_n.cc\n@@ -33,13 +33,18 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, num_inputs >= 2);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   output->type = input1->type;\n \n   // Check that all input tensors have the same shape and type.\n   for (int i = kInputTensor1 + 1; i < num_inputs; ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE(context, HaveSameShapes(input1, input));\n     TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input->type);\n   }\n@@ -55,15 +60,22 @@ template <typename T>\n void EvalAddN(TfLiteContext* context, TfLiteNode* node) {\n   // TODO(haoliang): Initialize all_inputs only once during init.\n   VectorOfTensors<T> all_inputs(*context, *node->inputs);\n+  // Safe to use unchecked since caller checks that tensor is valid\n   TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n   int num_inputs = NumInputs(node);\n+  // Safe to use unchecked since caller checks that tensor is valid\n   const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n   reference_ops::AddN<T>(GetTensorShape(input1), num_inputs, all_inputs.data(),\n                          GetTensorData<T>(output));\n }\n \n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* input1;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kInputTensor1, &input1));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   if (output->type == kTfLiteFloat32) {\n     EvalAddN<float>(context, node);\n   } else if (output->type == kTfLiteInt32) {"