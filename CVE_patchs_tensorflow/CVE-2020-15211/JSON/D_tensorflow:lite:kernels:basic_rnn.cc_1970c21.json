"diff --git a/tensorflow/lite/kernels/basic_rnn.cc b/tensorflow/lite/kernels/basic_rnn.cc\nindex c2e503d6462..715ae5cb671 100644\n--- a/tensorflow/lite/kernels/basic_rnn.cc\n+++ b/tensorflow/lite/kernels/basic_rnn.cc\n@@ -60,13 +60,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n-  const TfLiteTensor* hidden_state =\n-      GetInput(context, node, kHiddenStateTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n+  const TfLiteTensor* hidden_state;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kHiddenStateTensor, &hidden_state));\n \n   // Check all the parameters of tensor match within themselves and match the\n   // input configuration.\n@@ -86,7 +93,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[0], batch_size);\n   TF_LITE_ENSURE_EQ(context, hidden_state->dims->data[1], num_units);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Resize output.\n   TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n@@ -105,7 +114,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     TfLiteIntArrayFree(node->temporaries);\n     node->temporaries = TfLiteIntArrayCreate(6);\n     node->temporaries->data[0] = op_data->scratch_tensor_index;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/0);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n+                                                &input_quantized));\n     input_quantized->type = input_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -114,8 +125,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        input_quantized_size));\n     }\n     node->temporaries->data[1] = op_data->scratch_tensor_index + 1;\n-    TfLiteTensor* hidden_state_quantized =\n-        GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &hidden_state_quantized));\n     hidden_state_quantized->type = input_weights->type;\n     hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(hidden_state_quantized->dims,\n@@ -127,7 +139,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                               hidden_state_quantized_size));\n     }\n     node->temporaries->data[2] = op_data->scratch_tensor_index + 2;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -138,7 +152,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        scaling_factors_size));\n     }\n     node->temporaries->data[3] = op_data->scratch_tensor_index + 3;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/3, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {num_units, batch_size};\n@@ -151,7 +167,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        accum_scratch_size));\n     }\n     node->temporaries->data[4] = op_data->scratch_tensor_index + 4;\n-    TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n     zero_points->type = kTfLiteInt32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -162,7 +180,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        zero_points_size));\n     }\n     node->temporaries->data[5] = op_data->scratch_tensor_index + 5;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[2] = {2, num_units};\n@@ -260,14 +280,23 @@ TfLiteStatus EvalHybrid(const TfLiteTensor* input,\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteRNNParams*>(node->builtin_data);\n   auto* op_data = reinterpret_cast<OpData*>(node->user_data);\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* input_weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* recurrent_weights =\n-      GetInput(context, node, kRecurrentWeightsTensor);\n-  const TfLiteTensor* bias = GetInput(context, node, kBiasTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* input_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTensor, &input_weights));\n+  const TfLiteTensor* recurrent_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, kRecurrentWeightsTensor, &recurrent_weights));\n+  const TfLiteTensor* bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n   TfLiteTensor* hidden_state =\n-      &context->tensors[node->inputs->data[kHiddenStateTensor]];\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+      GetVariableInput(context, node, kHiddenStateTensor);\n+  TF_LITE_ENSURE(context, hidden_state != nullptr);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // We already checked that weight types are consistent, so branch on one.\n   switch (input_weights->type) {\n@@ -277,12 +306,23 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       // TODO(mirkov): implement eval with quantized inputs as well.\n-      TfLiteTensor* input_quantized = GetTemporary(context, node, 0);\n-      TfLiteTensor* hidden_state_quantized = GetTemporary(context, node, 1);\n-      TfLiteTensor* scaling_factors = GetTemporary(context, node, 2);\n-      TfLiteTensor* accum_scratch = GetTemporary(context, node, 3);\n-      TfLiteTensor* zero_points = GetTemporary(context, node, 4);\n-      TfLiteTensor* row_sums = GetTemporary(context, node, 5);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 0, &input_quantized));\n+      TfLiteTensor* hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, 1, &hidden_state_quantized));\n+      TfLiteTensor* scaling_factors;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 2, &scaling_factors));\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 3, &accum_scratch));\n+      TfLiteTensor* zero_points;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, 4, &zero_points));\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, 5, &row_sums));\n       return EvalHybrid(input, input_weights, recurrent_weights, bias, params,\n                         input_quantized, hidden_state_quantized,\n                         scaling_factors, hidden_state, output, zero_points,"