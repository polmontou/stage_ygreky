"diff --git a/tensorflow/lite/kernels/bidirectional_sequence_lstm.cc b/tensorflow/lite/kernels/bidirectional_sequence_lstm.cc\nindex 45d973d1d98..7ccc67c79f6 100644\n--- a/tensorflow/lite/kernels/bidirectional_sequence_lstm.cc\n+++ b/tensorflow/lite/kernels/bidirectional_sequence_lstm.cc\n@@ -21,6 +21,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/kernels/cpu_backend_context.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/internal/kernel_utils.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n@@ -192,8 +193,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n   TF_LITE_ENSURE(context, params->cell_clip >= 0);\n   TF_LITE_ENSURE(context, params->proj_clip >= 0);\n \n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, input_to_forget_weights_tensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_forget_weights_tensor,\n+                                 &input_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[1], n_input);\n@@ -211,16 +214,20 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, input_to_cell_weights_tensor);\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_cell_weights_tensor,\n+                                 &input_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[1], n_input);\n   TF_LITE_ENSURE_TYPES_EQ(context, input_to_cell_weights->type,\n                           input_to_forget_weights->type);\n \n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, input_to_output_weights_tensor);\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, input_to_output_weights_tensor,\n+                                 &input_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[1], n_input);\n@@ -239,8 +246,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n                             input_to_forget_weights->type);\n   }\n \n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, recurrent_to_forget_weights_tensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, recurrent_to_forget_weights_tensor,\n+                            &recurrent_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[0],\n                     n_cell);\n@@ -249,8 +258,10 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n   TF_LITE_ENSURE_TYPES_EQ(context, recurrent_to_forget_weights->type,\n                           input_to_forget_weights->type);\n \n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, recurrent_to_cell_weights_tensor);\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, recurrent_to_cell_weights_tensor,\n+                            &recurrent_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[1],\n@@ -316,20 +327,25 @@ TfLiteStatus CheckLstmTensorDimensionsAndTypes(\n     TF_LITE_ENSURE_TYPES_EQ(context, input_gate_bias->type, kTfLiteFloat32);\n   }\n \n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, forget_gate_bias_tensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, forget_gate_bias_tensor, &forget_gate_bias));\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_TYPES_EQ(context, forget_gate_bias->type, kTfLiteFloat32);\n \n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, cell_gate_bias_tensor);\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, cell_gate_bias_tensor,\n+                                          &cell_gate_bias));\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->type, kTfLiteFloat32);\n \n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, output_gate_bias_tensor);\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, output_gate_bias_tensor, &output_gate_bias));\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->data[0], n_cell);\n   TF_LITE_ENSURE_TYPES_EQ(context, output_gate_bias->type, kTfLiteFloat32);\n@@ -413,7 +429,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Inferring batch size, number of outputs and sequence length and\n   // number of cells from the input tensors.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n   TF_LITE_ENSURE_EQ(context, input->dims->size, 3);\n   const bool time_major = params->time_major;\n@@ -421,15 +438,19 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   const int n_batch = time_major ? input->dims->data[1] : input->dims->data[0];\n   const int n_input = input->dims->data[2];\n \n-  const TfLiteTensor* fw_input_to_output_weights =\n-      GetInput(context, node, kFwInputToOutputWeightsTensor);\n+  const TfLiteTensor* fw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToOutputWeightsTensor,\n+                                 &fw_input_to_output_weights));\n   const int n_fw_cell = fw_input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, fw_input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, fw_input_to_output_weights->dims->data[1],\n                     n_input);\n \n-  const TfLiteTensor* bw_input_to_output_weights =\n-      GetInput(context, node, kBwInputToOutputWeightsTensor);\n+  const TfLiteTensor* bw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToOutputWeightsTensor,\n+                                 &bw_input_to_output_weights));\n   const int n_bw_cell = bw_input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->dims->data[1],\n@@ -437,8 +458,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, bw_input_to_output_weights->type,\n                     fw_input_to_output_weights->type);\n \n-  const TfLiteTensor* fw_recurrent_to_output_weights =\n-      GetInput(context, node, kFwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* fw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToOutputWeightsTensor,\n+                            &fw_recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, fw_recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, fw_recurrent_to_output_weights->dims->data[0],\n                     n_fw_cell);\n@@ -446,8 +469,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                     fw_input_to_output_weights->type);\n   const int n_fw_output = fw_recurrent_to_output_weights->dims->data[1];\n \n-  const TfLiteTensor* bw_recurrent_to_output_weights =\n-      GetInput(context, node, kBwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* bw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToOutputWeightsTensor,\n+                            &bw_recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, bw_recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, bw_recurrent_to_output_weights->dims->data[0],\n                     n_bw_cell);\n@@ -504,7 +529,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Get the pointer to output, activation_state and cell_state buffer tensors.\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteTensor* fw_activation_state =\n       GetVariableInput(context, node, kFwInputActivationStateTensor);\n   TF_LITE_ENSURE(context, fw_activation_state != nullptr);\n@@ -541,8 +568,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Create a scratch buffer tensor.\n   node->temporaries->data[kFwScratchBuffer] =\n       op_data->scratch_tensor_index + kFwScratchBuffer;\n-  TfLiteTensor* fw_scratch_buffer =\n-      GetTemporary(context, node, kFwScratchBuffer);\n+  TfLiteTensor* fw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kFwScratchBuffer,\n+                                              &fw_scratch_buffer));\n   fw_scratch_buffer->type = input->type;\n   fw_scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -581,7 +609,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Resize the output tensors.\n   if (!params->merge_outputs) {\n-    TfLiteTensor* bw_output = GetOutput(context, node, kBwOutputTensor);\n+    TfLiteTensor* bw_output;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kBwOutputTensor, &bw_output));\n     TfLiteIntArray* bw_output_size = TfLiteIntArrayCreate(3);\n     bw_output_size->data[0] = time_major ? max_time : n_batch;\n     bw_output_size->data[1] = time_major ? n_batch : max_time;\n@@ -600,8 +630,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // Create a scratch buffer tensor.\n   node->temporaries->data[kBwScratchBuffer] =\n       op_data->scratch_tensor_index + kBwScratchBuffer;\n-  TfLiteTensor* bw_scratch_buffer =\n-      GetTemporary(context, node, kBwScratchBuffer);\n+  TfLiteTensor* bw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kBwScratchBuffer,\n+                                              &bw_scratch_buffer));\n   bw_scratch_buffer->type = input->type;\n   bw_scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -631,8 +662,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // (if present), activation_state and cell_state tensors.\n     node->temporaries->data[kInputQuantized] =\n         op_data->scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = fw_input_to_output_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -643,8 +675,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kFwActivationStateQuantized] =\n         op_data->scratch_tensor_index + kFwActivationStateQuantized;\n-    TfLiteTensor* fw_activation_state_quantized =\n-        GetTemporary(context, node, kFwActivationStateQuantized);\n+    TfLiteTensor* fw_activation_state_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFwActivationStateQuantized,\n+                                  &fw_activation_state_quantized));\n     fw_activation_state_quantized->type = fw_input_to_output_weights->type;\n     fw_activation_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_activation_state_quantized->dims,\n@@ -657,8 +691,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwActivationStateQuantized] =\n         op_data->scratch_tensor_index + kBwActivationStateQuantized;\n-    TfLiteTensor* bw_activation_state_quantized =\n-        GetTemporary(context, node, kBwActivationStateQuantized);\n+    TfLiteTensor* bw_activation_state_quantized;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kBwActivationStateQuantized,\n+                                  &bw_activation_state_quantized));\n     bw_activation_state_quantized->type = fw_input_to_output_weights->type;\n     bw_activation_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_activation_state_quantized->dims,\n@@ -671,8 +707,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kFwCellStateQuantized] =\n         op_data->scratch_tensor_index + kFwCellStateQuantized;\n-    TfLiteTensor* fw_cell_state_quantized =\n-        GetTemporary(context, node, kFwCellStateQuantized);\n+    TfLiteTensor* fw_cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kFwCellStateQuantized,\n+                                       &fw_cell_state_quantized));\n     fw_cell_state_quantized->type = fw_input_to_output_weights->type;\n     fw_cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_cell_state_quantized->dims,\n@@ -685,8 +723,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwCellStateQuantized] =\n         op_data->scratch_tensor_index + kBwCellStateQuantized;\n-    TfLiteTensor* bw_cell_state_quantized =\n-        GetTemporary(context, node, kBwCellStateQuantized);\n+    TfLiteTensor* bw_cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kBwCellStateQuantized,\n+                                       &bw_cell_state_quantized));\n     bw_cell_state_quantized->type = fw_input_to_output_weights->type;\n     bw_cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_cell_state_quantized->dims,\n@@ -705,7 +745,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // the scaling factor of the matrix).\n     node->temporaries->data[kInputScalingFactors] =\n         op_data->scratch_tensor_index + kInputScalingFactors;\n-    TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);\n+    TfLiteTensor* input_sf;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kInputScalingFactors, &input_sf));\n     input_sf->type = kTfLiteFloat32;\n     input_sf->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {n_batch};\n@@ -717,8 +760,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAuxInputScalingFactors] =\n         op_data->scratch_tensor_index + kAuxInputScalingFactors;\n-    TfLiteTensor* aux_input_sf =\n-        GetTemporary(context, node, kAuxInputScalingFactors);\n+    TfLiteTensor* aux_input_sf;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kAuxInputScalingFactors,\n+                                       &aux_input_sf));\n     aux_input_sf->type = kTfLiteFloat32;\n     aux_input_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(aux_input_sf->dims, 1, scaling_dims)) {\n@@ -729,8 +774,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateScalingFactors] =\n         op_data->scratch_tensor_index + kOutputStateScalingFactors;\n-    TfLiteTensor* output_state_sf =\n-        GetTemporary(context, node, kOutputStateScalingFactors);\n+    TfLiteTensor* output_state_sf;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kOutputStateScalingFactors,\n+                                  &output_state_sf));\n     output_state_sf->type = kTfLiteFloat32;\n     output_state_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_sf->dims, 1, scaling_dims)) {\n@@ -741,8 +788,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kProductScalingFactors] =\n         op_data->scratch_tensor_index + kProductScalingFactors;\n-    TfLiteTensor* prod_scaling_factors =\n-        GetTemporary(context, node, kProductScalingFactors);\n+    TfLiteTensor* prod_scaling_factors;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kProductScalingFactors,\n+                                       &prod_scaling_factors));\n     prod_scaling_factors->type = kTfLiteFloat32;\n     prod_scaling_factors->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(prod_scaling_factors->dims, 1,\n@@ -758,8 +807,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // this is used for diagonal matrices, only need to store n_cell values.\n     node->temporaries->data[kRecoveredCellWeights] =\n         op_data->scratch_tensor_index + kRecoveredCellWeights;\n-    TfLiteTensor* recovered_cell_weights =\n-        GetTemporary(context, node, kRecoveredCellWeights);\n+    TfLiteTensor* recovered_cell_weights;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                       &recovered_cell_weights));\n     recovered_cell_weights->type = kTfLiteFloat32;\n     recovered_cell_weights->allocation_type = kTfLiteArenaRw;\n     int recovered_cell_dims[1] = {n_fw_cell};\n@@ -775,8 +826,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate a temporary tensor to store the accumulated int32 values.\n     node->temporaries->data[kAccumScratchBuffer] =\n         op_data->scratch_tensor_index + kAccumScratchBuffer;\n-    TfLiteTensor* accum_scratch =\n-        GetTemporary(context, node, kAccumScratchBuffer);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kAccumScratchBuffer, &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int n_cell = std::max(n_fw_cell, n_bw_cell);\n@@ -797,7 +850,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate temporary tensors for storing zero-points.\n     node->temporaries->data[kInputZeroPoints] =\n         op_data->scratch_tensor_index + kInputZeroPoints;\n-    TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);\n+    TfLiteTensor* input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kInputZeroPoints, &input_zp));\n     input_zp->type = kTfLiteFloat32;\n     input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_zp->dims, 1, scaling_dims)) {\n@@ -808,8 +863,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAuxInputZeroPoints] =\n         op_data->scratch_tensor_index + kAuxInputZeroPoints;\n-    TfLiteTensor* aux_input_zp =\n-        GetTemporary(context, node, kAuxInputZeroPoints);\n+    TfLiteTensor* aux_input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kAuxInputZeroPoints, &aux_input_zp));\n     aux_input_zp->type = kTfLiteFloat32;\n     aux_input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(aux_input_zp->dims, 1, scaling_dims)) {\n@@ -820,8 +877,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateZeroPoints] =\n         op_data->scratch_tensor_index + kOutputStateZeroPoints;\n-    TfLiteTensor* output_state_zp =\n-        GetTemporary(context, node, kOutputStateZeroPoints);\n+    TfLiteTensor* output_state_zp;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateZeroPoints,\n+                                       &output_state_zp));\n     output_state_zp->type = kTfLiteFloat32;\n     output_state_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_zp->dims, 1, scaling_dims)) {\n@@ -844,7 +903,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kFwRowSums] =\n         op_data->scratch_tensor_index + kFwRowSums;\n-    TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n+    TfLiteTensor* fw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n     fw_row_sums->type = kTfLiteInt32;\n     fw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int fw_row_sums_dims[2] = {fw_row_sums_rows, n_fw_cell};\n@@ -867,7 +928,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwRowSums] =\n         op_data->scratch_tensor_index + kBwRowSums;\n-    TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+    TfLiteTensor* bw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n     bw_row_sums->type = kTfLiteInt32;\n     bw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int bw_row_sums_dims[2] = {bw_row_sums_rows, n_bw_cell};\n@@ -884,8 +947,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     if (has_aux_input) {\n       node->temporaries->data[kAuxInputQuantized] =\n           op_data->scratch_tensor_index + kAuxInputQuantized;\n-      TfLiteTensor* aux_input_quantized =\n-          GetTemporary(context, node, kAuxInputQuantized);\n+      TfLiteTensor* aux_input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kAuxInputQuantized,\n+                                         &aux_input_quantized));\n       aux_input_quantized->type = fw_input_to_output_weights->type;\n       aux_input_quantized->allocation_type = kTfLiteArenaRw;\n       if (!TfLiteIntArrayEqual(aux_input_quantized->dims, aux_input->dims)) {\n@@ -906,26 +971,39 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       node->builtin_data);\n   auto* op_data = reinterpret_cast<OpData*>(node->user_data);\n   // Input tensor.\n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n \n   // Tensors for the forward cell.\n   const TfLiteTensor* fw_input_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwInputToInputWeightsTensor);\n-  const TfLiteTensor* fw_input_to_forget_weights =\n-      GetInput(context, node, kFwInputToForgetWeightsTensor);\n-  const TfLiteTensor* fw_input_to_cell_weights =\n-      GetInput(context, node, kFwInputToCellWeightsTensor);\n-  const TfLiteTensor* fw_input_to_output_weights =\n-      GetInput(context, node, kFwInputToOutputWeightsTensor);\n+  const TfLiteTensor* fw_input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToForgetWeightsTensor,\n+                                 &fw_input_to_forget_weights));\n+  const TfLiteTensor* fw_input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToCellWeightsTensor,\n+                                 &fw_input_to_cell_weights));\n+  const TfLiteTensor* fw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwInputToOutputWeightsTensor,\n+                                 &fw_input_to_output_weights));\n \n   const TfLiteTensor* fw_recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_forget_weights =\n-      GetInput(context, node, kFwRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_cell_weights =\n-      GetInput(context, node, kFwRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_to_output_weights =\n-      GetInput(context, node, kFwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* fw_recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToForgetWeightsTensor,\n+                            &fw_recurrent_to_forget_weights));\n+  const TfLiteTensor* fw_recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentToCellWeightsTensor,\n+                                 &fw_recurrent_to_cell_weights));\n+  const TfLiteTensor* fw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kFwRecurrentToOutputWeightsTensor,\n+                            &fw_recurrent_to_output_weights));\n \n   const TfLiteTensor* fw_cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kFwCellToInputWeightsTensor);\n@@ -936,12 +1014,17 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* fw_input_gate_bias =\n       GetOptionalInputTensor(context, node, kFwInputGateBiasTensor);\n-  const TfLiteTensor* fw_forget_gate_bias =\n-      GetInput(context, node, kFwForgetGateBiasTensor);\n-  const TfLiteTensor* fw_cell_gate_bias =\n-      GetInput(context, node, kFwCellGateBiasTensor);\n-  const TfLiteTensor* fw_output_gate_bias =\n-      GetInput(context, node, kFwOutputGateBiasTensor);\n+  const TfLiteTensor* fw_forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwForgetGateBiasTensor,\n+                                 &fw_forget_gate_bias));\n+  const TfLiteTensor* fw_cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwCellGateBiasTensor,\n+                                          &fw_cell_gate_bias));\n+  const TfLiteTensor* fw_output_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwOutputGateBiasTensor,\n+                                 &fw_output_gate_bias));\n \n   const TfLiteTensor* fw_projection_weights =\n       GetOptionalInputTensor(context, node, kFwProjectionWeightsTensor);\n@@ -950,30 +1033,44 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   TfLiteTensor* fw_activation_state =\n       GetVariableInput(context, node, kFwInputActivationStateTensor);\n-  TF_LITE_ENSURE(context, fw_activation_state != nullptr);\n+  TFLITE_DCHECK(fw_activation_state != nullptr);\n   TfLiteTensor* fw_cell_state =\n       GetVariableInput(context, node, kFwInputCellStateTensor);\n-  TF_LITE_ENSURE(context, fw_cell_state != nullptr);\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TFLITE_DCHECK(fw_cell_state != nullptr);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n \n   // Tensors for the backward cell.\n   const TfLiteTensor* bw_input_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwInputToInputWeightsTensor);\n-  const TfLiteTensor* bw_input_to_forget_weights =\n-      GetInput(context, node, kBwInputToForgetWeightsTensor);\n-  const TfLiteTensor* bw_input_to_cell_weights =\n-      GetInput(context, node, kBwInputToCellWeightsTensor);\n-  const TfLiteTensor* bw_input_to_output_weights =\n-      GetInput(context, node, kBwInputToOutputWeightsTensor);\n+  const TfLiteTensor* bw_input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToForgetWeightsTensor,\n+                                 &bw_input_to_forget_weights));\n+  const TfLiteTensor* bw_input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToCellWeightsTensor,\n+                                 &bw_input_to_cell_weights));\n+  const TfLiteTensor* bw_input_to_output_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwInputToOutputWeightsTensor,\n+                                 &bw_input_to_output_weights));\n \n   const TfLiteTensor* bw_recurrent_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_forget_weights =\n-      GetInput(context, node, kBwRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_cell_weights =\n-      GetInput(context, node, kBwRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_to_output_weights =\n-      GetInput(context, node, kBwRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* bw_recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToForgetWeightsTensor,\n+                            &bw_recurrent_to_forget_weights));\n+  const TfLiteTensor* bw_recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentToCellWeightsTensor,\n+                                 &bw_recurrent_to_cell_weights));\n+  const TfLiteTensor* bw_recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kBwRecurrentToOutputWeightsTensor,\n+                            &bw_recurrent_to_output_weights));\n \n   const TfLiteTensor* bw_cell_to_input_weights =\n       GetOptionalInputTensor(context, node, kBwCellToInputWeightsTensor);\n@@ -984,12 +1081,17 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* bw_input_gate_bias =\n       GetOptionalInputTensor(context, node, kBwInputGateBiasTensor);\n-  const TfLiteTensor* bw_forget_gate_bias =\n-      GetInput(context, node, kBwForgetGateBiasTensor);\n-  const TfLiteTensor* bw_cell_gate_bias =\n-      GetInput(context, node, kBwCellGateBiasTensor);\n-  const TfLiteTensor* bw_output_gate_bias =\n-      GetInput(context, node, kBwOutputGateBiasTensor);\n+  const TfLiteTensor* bw_forget_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwForgetGateBiasTensor,\n+                                 &bw_forget_gate_bias));\n+  const TfLiteTensor* bw_cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwCellGateBiasTensor,\n+                                          &bw_cell_gate_bias));\n+  const TfLiteTensor* bw_output_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwOutputGateBiasTensor,\n+                                 &bw_output_gate_bias));\n \n   const TfLiteTensor* bw_projection_weights =\n       GetOptionalInputTensor(context, node, kBwProjectionWeightsTensor);\n@@ -999,19 +1101,21 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // State tensors.\n   TfLiteTensor* bw_activation_state =\n       GetVariableInput(context, node, kBwInputActivationStateTensor);\n-  TF_LITE_ENSURE(context, bw_activation_state != nullptr);\n+  TFLITE_DCHECK(bw_activation_state != nullptr);\n   TfLiteTensor* bw_cell_state =\n       GetVariableInput(context, node, kBwInputCellStateTensor);\n-  TF_LITE_ENSURE(context, bw_cell_state != nullptr);\n+  TFLITE_DCHECK(bw_cell_state != nullptr);\n   TfLiteTensor* bw_output = params->merge_outputs\n                                 ? nullptr\n                                 : GetOutput(context, node, kBwOutputTensor);\n \n   // Temporary tensors.\n-  TfLiteTensor* fw_scratch_buffer =\n-      GetTemporary(context, node, kFwScratchBuffer);\n-  TfLiteTensor* bw_scratch_buffer =\n-      GetTemporary(context, node, kBwScratchBuffer);\n+  TfLiteTensor* fw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kFwScratchBuffer,\n+                                              &fw_scratch_buffer));\n+  TfLiteTensor* bw_scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kBwScratchBuffer,\n+                                              &bw_scratch_buffer));\n \n   // (Optional) auxiliary inputs.\n   const TfLiteTensor* aux_input =\n@@ -1112,27 +1216,47 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     }\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n-      TfLiteTensor* input_quantized =\n-          GetTemporary(context, node, kInputQuantized);\n-      TfLiteTensor* fw_activation_state_quantized =\n-          GetTemporary(context, node, kFwActivationStateQuantized);\n-      TfLiteTensor* bw_activation_state_quantized =\n-          GetTemporary(context, node, kBwActivationStateQuantized);\n-      TfLiteTensor* fw_cell_state_quantized =\n-          GetTemporary(context, node, kFwCellStateQuantized);\n-      TfLiteTensor* bw_cell_state_quantized =\n-          GetTemporary(context, node, kBwCellStateQuantized);\n-      TfLiteTensor* prod_scaling_factors =\n-          GetTemporary(context, node, kProductScalingFactors);\n-      TfLiteTensor* recovered_cell_weights =\n-          GetTemporary(context, node, kRecoveredCellWeights);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kInputQuantized, &input_quantized));\n+      TfLiteTensor* fw_activation_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwActivationStateQuantized,\n+                                    &fw_activation_state_quantized));\n+      TfLiteTensor* bw_activation_state_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwActivationStateQuantized,\n+                                    &bw_activation_state_quantized));\n+      TfLiteTensor* fw_cell_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kFwCellStateQuantized,\n+                                         &fw_cell_state_quantized));\n+      TfLiteTensor* bw_cell_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kBwCellStateQuantized,\n+                                         &bw_cell_state_quantized));\n+      TfLiteTensor* prod_scaling_factors;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kProductScalingFactors,\n+                                         &prod_scaling_factors));\n+      TfLiteTensor* recovered_cell_weights;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                         &recovered_cell_weights));\n       TfLiteTensor* aux_input_quantized =\n           use_aux_input ? GetTemporary(context, node, kAuxInputQuantized)\n                         : nullptr;\n-      TfLiteTensor* accum_scratch =\n-          GetTemporary(context, node, kAccumScratchBuffer);\n-      TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n-      TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kAccumScratchBuffer, &accum_scratch));\n+      TfLiteTensor* fw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n+      TfLiteTensor* bw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n       const int fw_row_sums_size = fw_row_sums->dims->data[0];\n       const int bw_row_sums_size = bw_row_sums->dims->data[0];\n       TfLiteStatus fw_pass_status = lstm_eval::EvalHybrid("