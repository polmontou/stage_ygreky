"diff --git a/tensorflow/lite/kernels/bidirectional_sequence_rnn.cc b/tensorflow/lite/kernels/bidirectional_sequence_rnn.cc\nindex bc88740b6ed..8ce19e5fb99 100644\n--- a/tensorflow/lite/kernels/bidirectional_sequence_rnn.cc\n+++ b/tensorflow/lite/kernels/bidirectional_sequence_rnn.cc\n@@ -97,21 +97,34 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->outputs->size,\n                     params->merge_outputs ? 1 : 2);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* fw_input_weights =\n-      GetInput(context, node, kFwWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_weights =\n-      GetInput(context, node, kFwRecurrentWeightsTensor);\n-  const TfLiteTensor* fw_bias = GetInput(context, node, kFwBiasTensor);\n-  const TfLiteTensor* fw_hidden_state =\n-      GetInput(context, node, kFwHiddenStateTensor);\n-  const TfLiteTensor* bw_input_weights =\n-      GetInput(context, node, kBwWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_weights =\n-      GetInput(context, node, kBwRecurrentWeightsTensor);\n-  const TfLiteTensor* bw_bias = GetInput(context, node, kBwBiasTensor);\n-  const TfLiteTensor* bw_hidden_state =\n-      GetInput(context, node, kBwHiddenStateTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* fw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwWeightsTensor,\n+                                          &fw_input_weights));\n+  const TfLiteTensor* fw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentWeightsTensor,\n+                                 &fw_recurrent_weights));\n+  const TfLiteTensor* fw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwBiasTensor, &fw_bias));\n+  const TfLiteTensor* fw_hidden_state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwHiddenStateTensor,\n+                                          &fw_hidden_state));\n+  const TfLiteTensor* bw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwWeightsTensor,\n+                                          &bw_input_weights));\n+  const TfLiteTensor* bw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentWeightsTensor,\n+                                 &bw_recurrent_weights));\n+  const TfLiteTensor* bw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwBiasTensor, &bw_bias));\n+  const TfLiteTensor* bw_hidden_state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwHiddenStateTensor,\n+                                          &bw_hidden_state));\n \n   const TfLiteTensor* aux_input =\n       GetOptionalInputTensor(context, node, kAuxInputTensor);\n@@ -186,8 +199,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kInputQuantized] =\n         op_data->scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = fw_input_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -198,8 +212,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kFwHiddenStateQuantized] =\n         op_data->scratch_tensor_index + kFwHiddenStateQuantized;\n-    TfLiteTensor* fw_hidden_state_quantized =\n-        GetTemporary(context, node, kFwHiddenStateQuantized);\n+    TfLiteTensor* fw_hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kFwHiddenStateQuantized,\n+                                       &fw_hidden_state_quantized));\n     fw_hidden_state_quantized->type = fw_input_weights->type;\n     fw_hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(fw_hidden_state_quantized->dims,\n@@ -213,8 +229,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     node->temporaries->data[kBwHiddenStateQuantized] =\n         op_data->scratch_tensor_index + kBwHiddenStateQuantized;\n-    TfLiteTensor* bw_hidden_state_quantized =\n-        GetTemporary(context, node, kBwHiddenStateQuantized);\n+    TfLiteTensor* bw_hidden_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kBwHiddenStateQuantized,\n+                                       &bw_hidden_state_quantized));\n     bw_hidden_state_quantized->type = fw_input_weights->type;\n     bw_hidden_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(bw_hidden_state_quantized->dims,\n@@ -229,8 +247,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate temporary tensors to store scaling factors of quantization.\n     node->temporaries->data[kScalingFactors] =\n         op_data->scratch_tensor_index + kScalingFactors;\n-    TfLiteTensor* scaling_factors =\n-        GetTemporary(context, node, kScalingFactors);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScalingFactors,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -242,7 +261,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kAccumScratch] =\n         op_data->scratch_tensor_index + kAccumScratch;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {std::max(fw_num_units, bw_num_units),\n@@ -257,8 +278,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kZeroPoints] =\n         op_data->scratch_tensor_index + kZeroPoints;\n-    TfLiteTensor* zero_points =\n-        GetTemporary(context, node, /*index=*/kZeroPoints);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kZeroPoints, &zero_points));\n     zero_points->type = kTfLiteInt32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -271,8 +294,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     const int num_row_sums = has_aux_input ? 3 : 2;\n     node->temporaries->data[kFwRowSums] =\n         op_data->scratch_tensor_index + kFwRowSums;\n-    TfLiteTensor* fw_row_sums =\n-        GetTemporary(context, node, /*index=*/kFwRowSums);\n+    TfLiteTensor* fw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kFwRowSums, &fw_row_sums));\n     fw_row_sums->type = kTfLiteInt32;\n     fw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int fw_row_sums_dims[2] = {num_row_sums, fw_num_units};\n@@ -285,8 +310,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kBwRowSums] =\n         op_data->scratch_tensor_index + kBwRowSums;\n-    TfLiteTensor* bw_row_sums = GetTemporary(context, node,\n-                                             /*index=*/kBwRowSums);\n+    TfLiteTensor* bw_row_sums;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, /*index=*/kBwRowSums, &bw_row_sums));\n     bw_row_sums->type = kTfLiteInt32;\n     bw_row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int bw_row_sums_dims[2] = {num_row_sums, bw_num_units};\n@@ -300,8 +327,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     if (has_aux_input) {\n       node->temporaries->data[kAuxInputQuantized] =\n           op_data->scratch_tensor_index + kAuxInputQuantized;\n-      TfLiteTensor* aux_input_quantized =\n-          GetTemporary(context, node, kAuxInputQuantized);\n+      TfLiteTensor* aux_input_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kAuxInputQuantized,\n+                                         &aux_input_quantized));\n       aux_input_quantized->type = fw_input_weights->type;\n       aux_input_quantized->allocation_type = kTfLiteArenaRw;\n       if (!TfLiteIntArrayEqual(aux_input_quantized->dims, aux_input->dims)) {\n@@ -315,7 +344,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   // Resize outputs.\n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteIntArray* fw_output_size_array = TfLiteIntArrayCreate(3);\n   fw_output_size_array->data[0] = (time_major) ? max_time : batch_size;\n   fw_output_size_array->data[1] = (time_major) ? batch_size : max_time;\n@@ -324,7 +355,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(\n       context, context->ResizeTensor(context, fw_output, fw_output_size_array));\n   if (!params->merge_outputs) {\n-    TfLiteTensor* bw_output = GetOutput(context, node, kBwOutputTensor);\n+    TfLiteTensor* bw_output;\n+    TF_LITE_ENSURE_OK(\n+        context, GetOutputSafe(context, node, kBwOutputTensor, &bw_output));\n     TfLiteIntArray* bw_output_size_array = TfLiteIntArrayCreate(3);\n     bw_output_size_array->data[0] = batch_size;\n     bw_output_size_array->data[1] = max_time;\n@@ -678,17 +711,28 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const auto* params = reinterpret_cast<TfLiteBidirectionalSequenceRNNParams*>(\n       node->builtin_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* fw_input_weights =\n-      GetInput(context, node, kFwWeightsTensor);\n-  const TfLiteTensor* fw_recurrent_weights =\n-      GetInput(context, node, kFwRecurrentWeightsTensor);\n-  const TfLiteTensor* fw_bias = GetInput(context, node, kFwBiasTensor);\n-  const TfLiteTensor* bw_input_weights =\n-      GetInput(context, node, kBwWeightsTensor);\n-  const TfLiteTensor* bw_recurrent_weights =\n-      GetInput(context, node, kBwRecurrentWeightsTensor);\n-  const TfLiteTensor* bw_bias = GetInput(context, node, kBwBiasTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* fw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kFwWeightsTensor,\n+                                          &fw_input_weights));\n+  const TfLiteTensor* fw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwRecurrentWeightsTensor,\n+                                 &fw_recurrent_weights));\n+  const TfLiteTensor* fw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kFwBiasTensor, &fw_bias));\n+  const TfLiteTensor* bw_input_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBwWeightsTensor,\n+                                          &bw_input_weights));\n+  const TfLiteTensor* bw_recurrent_weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwRecurrentWeightsTensor,\n+                                 &bw_recurrent_weights));\n+  const TfLiteTensor* bw_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kBwBiasTensor, &bw_bias));\n \n   // Get auxiliary inputs.\n   const TfLiteTensor* aux_input =\n@@ -700,12 +744,14 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   TfLiteTensor* fw_hidden_state =\n       GetVariableInput(context, node, kFwHiddenStateTensor);\n-  TF_LITE_ENSURE(context, fw_hidden_state != nullptr);\n+  TFLITE_DCHECK(fw_hidden_state != nullptr);\n   TfLiteTensor* bw_hidden_state =\n       GetVariableInput(context, node, kBwHiddenStateTensor);\n-  TF_LITE_ENSURE(context, bw_hidden_state != nullptr);\n+  TFLITE_DCHECK(bw_hidden_state != nullptr);\n \n-  TfLiteTensor* fw_output = GetOutput(context, node, kFwOutputTensor);\n+  TfLiteTensor* fw_output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kFwOutputTensor, &fw_output));\n   TfLiteTensor* bw_output = params->merge_outputs\n                                 ? nullptr\n                                 : GetOutput(context, node, kBwOutputTensor);\n@@ -741,18 +787,34 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                        bw_hidden_state, bw_output);\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n-      TfLiteTensor* input_quantized =\n-          GetTemporary(context, node, kInputQuantized);\n-      TfLiteTensor* fw_hidden_state_quantized =\n-          GetTemporary(context, node, kFwHiddenStateQuantized);\n-      TfLiteTensor* bw_hidden_state_quantized =\n-          GetTemporary(context, node, kBwHiddenStateQuantized);\n-      TfLiteTensor* scaling_factors =\n-          GetTemporary(context, node, kScalingFactors);\n-      TfLiteTensor* zero_points = GetTemporary(context, node, kZeroPoints);\n-      TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n-      TfLiteTensor* fw_row_sums = GetTemporary(context, node, kFwRowSums);\n-      TfLiteTensor* bw_row_sums = GetTemporary(context, node, kBwRowSums);\n+      TfLiteTensor* input_quantized;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kInputQuantized, &input_quantized));\n+      TfLiteTensor* fw_hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kFwHiddenStateQuantized,\n+                                         &fw_hidden_state_quantized));\n+      TfLiteTensor* bw_hidden_state_quantized;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kBwHiddenStateQuantized,\n+                                         &bw_hidden_state_quantized));\n+      TfLiteTensor* scaling_factors;\n+      TF_LITE_ENSURE_OK(\n+          context,\n+          GetTemporarySafe(context, node, kScalingFactors, &scaling_factors));\n+      TfLiteTensor* zero_points;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kZeroPoints, &zero_points));\n+      TfLiteTensor* accum_scratch;\n+      TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                  &accum_scratch));\n+      TfLiteTensor* fw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kFwRowSums, &fw_row_sums));\n+      TfLiteTensor* bw_row_sums;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, kBwRowSums, &bw_row_sums));\n       TfLiteTensor* aux_input_quantized =\n           use_aux_input ? GetTemporary(context, node, kAuxInputQuantized)\n                         : nullptr;"