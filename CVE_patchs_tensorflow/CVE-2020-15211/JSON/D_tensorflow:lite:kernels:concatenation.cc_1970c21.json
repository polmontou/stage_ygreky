"diff --git a/tensorflow/lite/kernels/concatenation.cc b/tensorflow/lite/kernels/concatenation.cc\nindex 5d5f06ba013..3f759228e04 100644\n--- a/tensorflow/lite/kernels/concatenation.cc\n+++ b/tensorflow/lite/kernels/concatenation.cc\n@@ -45,7 +45,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // The number of dimensions of the input tensors must match, and all\n   // dimensions except 'axis' must be equal.\n-  const TfLiteTensor* t0 = GetInput(context, node, 0);\n+  const TfLiteTensor* t0;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &t0));\n   TfLiteType input_type = t0->type;\n   if (axis < 0) axis += t0->dims->size;\n   TF_LITE_ENSURE(context, axis >= 0);\n@@ -63,7 +64,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   // will be the sum of inputs\n   int sum_axis = t0->dims->data[axis];\n   for (int i = 1; i < num_inputs; ++i) {\n-    const TfLiteTensor* t = GetInput(context, node, i);\n+    const TfLiteTensor* t;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &t));\n     TF_LITE_ENSURE_EQ(context, t->dims->size, t0->dims->size);\n     TF_LITE_ENSURE_EQ(context, t->type, input_type);\n     for (int d = 0; d < t0->dims->size; ++d) {\n@@ -80,7 +82,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     output_size->data[d] = (d == axis) ? sum_axis : t0->dims->data[d];\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);\n \n   if (input_type == kTfLiteInt8) {\n@@ -88,7 +91,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // is a restriction we introduced to Int8 kernels.\n     VectorOfTensors<int8_t> all_inputs(*context, *node->inputs);\n     for (int i = 0; i < node->inputs->size; ++i) {\n-      const TfLiteTensor* t = GetInput(context, node, i);\n+      const TfLiteTensor* t;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &t));\n       TF_LITE_ENSURE_EQ(context, t->params.scale, output->params.scale);\n       TF_LITE_ENSURE_EQ(context, t->params.zero_point,\n                         output->params.zero_point);\n@@ -103,7 +107,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params =\n       reinterpret_cast<TfLiteConcatenationParams*>(node->builtin_data);\n   int axis = params->axis;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   if (axis < 0) axis += output->dims->size;\n \n // TODO(ahentz): Creating 'all_inputs' below is not very efficient. We should"