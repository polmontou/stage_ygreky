"diff --git a/tensorflow/lite/kernels/hashtable/hashtable_size.cc b/tensorflow/lite/kernels/hashtable/hashtable_size.cc\nindex 48029795ae0..34a8031a3c0 100644\n--- a/tensorflow/lite/kernels/hashtable/hashtable_size.cc\n+++ b/tensorflow/lite/kernels/hashtable/hashtable_size.cc\n@@ -32,14 +32,16 @@ TfLiteStatus PrepareHashtableSize(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputResourceIdTensor);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputResourceIdTensor,\n+                                          &input_resource_id_tensor));\n   TF_LITE_ENSURE_EQ(context, input_resource_id_tensor->type, kTfLiteInt32);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(input_resource_id_tensor), 1);\n   TF_LITE_ENSURE_EQ(context, SizeOfDimension(input_resource_id_tensor, 0), 1);\n \n-  TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);\n-  TF_LITE_ENSURE(context, output_tensor != nullptr);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputTensor, &output_tensor));\n   TF_LITE_ENSURE_EQ(context, output_tensor->type, kTfLiteInt64);\n   TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n   outputSize->data[0] = 1;\n@@ -47,11 +49,14 @@ TfLiteStatus PrepareHashtableSize(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus EvalHashtableSize(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input_resource_id_tensor =\n-      GetInput(context, node, kInputResourceIdTensor);\n+  const TfLiteTensor* input_resource_id_tensor;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputResourceIdTensor,\n+                                          &input_resource_id_tensor));\n   int resource_id = input_resource_id_tensor->data.i32[0];\n \n-  TfLiteTensor* output_tensor = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node, kOutputTensor, &output_tensor));\n   auto* output_data = GetTensorData<std::int64_t>(output_tensor);\n \n   Subgraph* subgraph = reinterpret_cast<Subgraph*>(context->impl_);"