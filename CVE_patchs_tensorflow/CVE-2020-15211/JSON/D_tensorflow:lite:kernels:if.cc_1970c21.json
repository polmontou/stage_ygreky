"diff --git a/tensorflow/lite/kernels/if.cc b/tensorflow/lite/kernels/if.cc\nindex 4c39a07bf8b..7099442ced7 100644\n--- a/tensorflow/lite/kernels/if.cc\n+++ b/tensorflow/lite/kernels/if.cc\n@@ -22,6 +22,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/core/subgraph.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n \n namespace tflite {\n@@ -52,7 +53,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE(context, node->inputs->size > 0);\n \n   // The first input is the condition.\n-  const TfLiteTensor* cond = GetInput(context, node, 0);\n+  const TfLiteTensor* cond;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &cond));\n   // Currently only bool is supported.\n   // TODO(ycling): Support other types since TensorFlow also support\n   // non-bool types as condition.\n@@ -83,7 +85,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     for (int i = 0; i < num_inputs; ++i) {\n       // The first input of the node is the condition. The indices of the inputs\n       // passed to the subgraphs are offset by 1.\n-      const TfLiteTensor* input = GetInput(context, node, i + 1);\n+      const TfLiteTensor* input;\n+      TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i + 1, &input));\n       std::vector<int> dims(input->dims->data,\n                             input->dims->data + input->dims->size);\n       subgraph->ResizeInputTensor(i, dims);\n@@ -113,7 +116,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   for (int i = 0; i < num_outputs; ++i) {\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     if (has_dynamic_output_tensors) {\n       SetTensorToDynamic(output);\n     } else {\n@@ -133,7 +137,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* cond = GetInput(context, node, 0);\n+  const TfLiteTensor* cond;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &cond));\n   bool cond_value = cond->data.b[0];\n \n   Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n@@ -147,7 +152,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   Subgraph& active_branch_subgraph =\n       *(*subgraphs)[active_branch_subgraph_index];\n   for (int i = 0; i < active_branch_subgraph.inputs().size(); ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i + 1);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i + 1, &input));\n     TfLiteTensor* subgraph_input =\n         active_branch_subgraph.tensor(active_branch_subgraph.inputs()[i]);\n     TF_LITE_ENSURE_EQ(context, input->bytes, subgraph_input->bytes);\n@@ -164,7 +170,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   bool has_dynamic_output_tensors = false;\n   for (int i = 0; i < node->outputs->size; ++i) {\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     if (IsDynamicTensor(output)) {\n       has_dynamic_output_tensors = true;\n       break;\n@@ -173,7 +180,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   if (has_dynamic_output_tensors) {\n     for (int i = 0; i < node->outputs->size; ++i) {\n-      TfLiteTensor* output = GetOutput(context, node, i);\n+      TfLiteTensor* output;\n+      TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n       TfLiteTensor* subgraph_output =\n           active_branch_subgraph.tensor(active_branch_subgraph.outputs()[i]);\n       TfLiteIntArray* output_size = TfLiteIntArrayCopy(subgraph_output->dims);\n@@ -185,7 +193,8 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   for (int i = 0; i < active_branch_subgraph.outputs().size(); ++i) {\n     const TfLiteTensor* subgraph_output =\n         active_branch_subgraph.tensor(active_branch_subgraph.outputs()[i]);\n-    TfLiteTensor* output = GetOutput(context, node, i);\n+    TfLiteTensor* output;\n+    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n     TF_LITE_ENSURE_EQ(context, output->bytes, subgraph_output->bytes);\n     memcpy(output->data.raw, subgraph_output->data.raw, output->bytes);\n   }"