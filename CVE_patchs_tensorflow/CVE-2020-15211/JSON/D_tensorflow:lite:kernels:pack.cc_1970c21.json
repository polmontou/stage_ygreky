"diff --git a/tensorflow/lite/kernels/pack.cc b/tensorflow/lite/kernels/pack.cc\nindex 90a87b0c8c7..16ea01b6dca 100644\n--- a/tensorflow/lite/kernels/pack.cc\n+++ b/tensorflow/lite/kernels/pack.cc\n@@ -38,7 +38,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumInputs(node), data->values_count);\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n-  const TfLiteTensor* input0 = GetInput(context, node, 0);\n+  const TfLiteTensor* input0;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input0));\n   const int dimension_size = NumDimensions(input0) + 1;\n   if (data->axis < 0) {\n     data->axis += dimension_size;\n@@ -55,7 +56,8 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n   // Make sure all inputs have the same shape and type.\n   for (int i = 1; i < data->values_count; ++i) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE(context, HaveSameShapes(input0, input));\n     TF_LITE_ENSURE_TYPES_EQ(context, input0->type, input->type);\n   }\n@@ -72,13 +74,16 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n   }\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   TF_LITE_ENSURE_TYPES_EQ(context, output->type, input0->type);\n \n   // Guarantee input/output quantization params match as we do not support\n   // packing quantized tensors.\n   for (int i = 0; i < data->values_count; i++) {\n-    const TfLiteTensor* input = GetInput(context, node, i);\n+    const TfLiteTensor* input;\n+    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, i, &input));\n     TF_LITE_ENSURE_EQ(context, input->params.zero_point,\n                       output->params.zero_point);\n     TF_LITE_ENSURE_EQ(context, input->params.scale, output->params.scale);\n@@ -106,7 +111,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const TfLitePackParams* data =\n       reinterpret_cast<TfLitePackParams*>(node->builtin_data);\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   switch (output->type) {\n     case kTfLiteFloat32: {\n       return PackImpl<float>(context, node, output, data->values_count,"