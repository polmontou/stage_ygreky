"diff --git a/tensorflow/lite/kernels/svdf.cc b/tensorflow/lite/kernels/svdf.cc\nindex 1b8bf904b8a..f3a17e1d3b5 100644\n--- a/tensorflow/lite/kernels/svdf.cc\n+++ b/tensorflow/lite/kernels/svdf.cc\n@@ -82,11 +82,14 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n   TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* weights_feature =\n-      GetInput(context, node, kWeightsFeatureTensor);\n-  const TfLiteTensor* weights_time =\n-      GetInput(context, node, kWeightsTimeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* weights_feature;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n+                                          &weights_feature));\n+  const TfLiteTensor* weights_time;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n \n   TF_LITE_ENSURE(context,\n                  input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n@@ -108,8 +111,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n   }\n \n-  const TfLiteTensor* state = GetInput(context, node, kStateTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  const TfLiteTensor* state;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Check the shape of input state tensors.\n   TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n@@ -143,7 +149,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   scratch_size_array->data[0] = batch_size;\n   scratch_size_array->data[1] = num_filters;\n \n-  TfLiteTensor* scratch_tensor = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch_tensor;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n \n   // The scratch buffer is of type int32 for full integer svdf and it's of type\n   // float32 for hybrid and float case.\n@@ -161,7 +169,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Tell interpreter to allocate temporary tensors to store quantized values\n     // of input tensors.\n     node->temporaries->data[1] = scratch_tensor_index + 1;\n-    TfLiteTensor* input_quantized = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                &input_quantized));\n     input_quantized->type = weights_feature->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -172,7 +182,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n     // Tell interpreter to allocate temporary tensors to store scaling factors.\n     node->temporaries->data[2] = scratch_tensor_index + 2;\n-    TfLiteTensor* scaling_factors = GetTemporary(context, node, /*index=*/2);\n+    TfLiteTensor* scaling_factors;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                &scaling_factors));\n     scaling_factors->type = kTfLiteFloat32;\n     scaling_factors->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {batch_size};\n@@ -186,7 +198,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Used to store dequantized weights_time matrix for hybrid computation of\n     // matmul(state, weights_time), which occurs in floating point.\n     node->temporaries->data[3] = scratch_tensor_index + 3;\n-    TfLiteTensor* float_weights_time = GetTemporary(context, node, /*index=*/3);\n+    TfLiteTensor* float_weights_time;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                &float_weights_time));\n     float_weights_time->type = kTfLiteFloat32;\n     // Persistent so that we can compute the dequantized weights only once.\n     float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n@@ -199,7 +213,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[4] = scratch_tensor_index + 4;\n-    TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n+    TfLiteTensor* zero_points;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n     zero_points->type = kTfLiteFloat32;\n     zero_points->allocation_type = kTfLiteArenaRw;\n     int zero_points_dims[1] = {batch_size};\n@@ -211,7 +227,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n \n     node->temporaries->data[5] = scratch_tensor_index + 5;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n     row_sums->type = kTfLiteFloat32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_dims[1] = {num_filters};\n@@ -228,7 +246,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     output_temp_size_array->data[0] = num_units;\n     output_temp_size_array->data[1] = batch_size;\n     node->temporaries->data[1] = scratch_tensor_index + 1;\n-    TfLiteTensor* output_temp = GetTemporary(context, node, /*index=*/1);\n+    TfLiteTensor* output_temp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n     output_temp->type = kTfLiteInt32;\n     output_temp->allocation_type = kTfLiteArenaRw;\n     TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n@@ -263,17 +283,24 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n   OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n-  const TfLiteTensor* weights_feature =\n-      GetInput(context, node, kWeightsFeatureTensor);\n-  const TfLiteTensor* weights_time =\n-      GetInput(context, node, kWeightsTimeTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n+  const TfLiteTensor* weights_feature;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n+                                          &weights_feature));\n+  const TfLiteTensor* weights_time;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n   const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n \n-  TfLiteTensor* scratch = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetTemporarySafe(context, node, /*index=*/0, &scratch));\n \n   TfLiteTensor* state = GetVariableInput(context, node, kStateTensor);\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   switch (weights_feature->type) {\n     case kTfLiteFloat32: {\n@@ -286,14 +313,21 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       if (input->type == kTfLiteFloat32) {\n-        TfLiteTensor* input_quantized =\n-            GetTemporary(context, node, /*index=*/1);\n-        TfLiteTensor* scaling_factors =\n-            GetTemporary(context, node, /*index=*/2);\n-        TfLiteTensor* float_weights_time =\n-            GetTemporary(context, node, /*index=*/3);\n-        TfLiteTensor* zero_points = GetTemporary(context, node, /*index=*/4);\n-        TfLiteTensor* row_sums = GetTemporary(context, node, /*index=*/5);\n+        TfLiteTensor* input_quantized;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                    &input_quantized));\n+        TfLiteTensor* scaling_factors;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n+                                                    &scaling_factors));\n+        TfLiteTensor* float_weights_time;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n+                                                    &float_weights_time));\n+        TfLiteTensor* zero_points;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/4,\n+                                                    &zero_points));\n+        TfLiteTensor* row_sums;\n+        TF_LITE_ENSURE_OK(\n+            context, GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n         // Dequantize weights time.\n         // TODO(alanchiao): this dequantization initialization only needs to\n         // happen once per model and should theoretically be placed in either\n@@ -322,7 +356,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n             input->quantization.params);\n         auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n             output->quantization.params);\n-        TfLiteTensor* output_temp = GetTemporary(context, node, /*index=*/1);\n+        TfLiteTensor* output_temp;\n+        TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n+                                                    &output_temp));\n \n         // Currently supports only ReLU.\n         // TODO(jianlijianli): support other activations."