"diff --git a/tensorflow/lite/kernels/transpose_conv.cc b/tensorflow/lite/kernels/transpose_conv.cc\nindex 9ecd16274a0..52ee0414dd6 100644\n--- a/tensorflow/lite/kernels/transpose_conv.cc\n+++ b/tensorflow/lite/kernels/transpose_conv.cc\n@@ -250,13 +250,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n \n   // Retrieve tensors\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &weights));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kDataInputTensor, &input));\n   const TfLiteTensor* bias = nullptr;\n \n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n \n   // Tensor sanity checks\n   TF_LITE_ENSURE_EQ(context, NumDimensions(output_shape), 1);\n@@ -306,7 +313,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   TfLiteTensor* col2im = nullptr;\n   if (data->has_col2im) {\n     node->temporaries->data[data->col2im_index] = data->col2im_id;\n-    col2im = GetTemporary(context, node, user_data->col2im_index);\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, user_data->col2im_index, &col2im));\n   }\n \n   if (!IsConstantTensor(output_shape)) {\n@@ -326,8 +335,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   if (data->weights_are_transposed) {\n     node->temporaries->data[data->transposed_weights_index] =\n         data->transposed_weights_id;\n-    TfLiteTensor* transposed_weights =\n-        GetTemporary(context, node, user_data->transposed_weights_index);\n+    TfLiteTensor* transposed_weights;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, user_data->transposed_weights_index,\n+                         &transposed_weights));\n     if (!IsConstantTensor(weights)) {\n       SetTensorToDynamic(transposed_weights);\n     } else {\n@@ -339,8 +351,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       input->type == kTfLiteInt16) {\n     node->temporaries->data[data->scratch_tensor_index] =\n         data->scratch_tensor_id;\n-    TfLiteTensor* scratch_buffer =\n-        GetTemporary(context, node, data->scratch_tensor_index);\n+    TfLiteTensor* scratch_buffer;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                  &scratch_buffer));\n     if (input->type == kTfLiteInt16) {\n       scratch_buffer->type = kTfLiteInt64;\n     } else {\n@@ -549,15 +563,22 @@ void EvalQuantizedPerChannel16x8(\n template <KernelType kernel_type>\n TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   // Retrieve tensors (All should be allocated by now)\n-  const TfLiteTensor* output_shape =\n-      GetInput(context, node, kOutputShapeTensor);\n-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);\n-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);\n+  const TfLiteTensor* output_shape;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n+  const TfLiteTensor* weights;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kWeightsTensor, &weights));\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, kDataInputTensor, &input));\n   const TfLiteTensor* bias =\n       (NumInputs(node) == 4)\n           ? GetOptionalInputTensor(context, node, kBiasTensor)\n           : nullptr;\n-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kOutputTensor, &output));\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   TfLiteTensor* col2im = data->has_col2im\n                              ? GetTemporary(context, node, data->col2im_index)\n@@ -604,8 +625,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteUInt8: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));\n@@ -621,8 +644,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteInt8: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));\n@@ -636,8 +661,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       break;\n     }\n     case kTfLiteInt16: {\n-      TfLiteTensor* scratch_buffer =\n-          GetTemporary(context, node, data->scratch_tensor_index);\n+      TfLiteTensor* scratch_buffer;\n+      TF_LITE_ENSURE_OK(\n+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n+                                    &scratch_buffer));\n       if (IsDynamicTensor(scratch_buffer)) {\n         TF_LITE_ENSURE_OK(context,\n                           ResizeTensor(context, output_shape, scratch_buffer));"