"diff --git a/tensorflow/lite/kernels/unidirectional_sequence_lstm.cc b/tensorflow/lite/kernels/unidirectional_sequence_lstm.cc\nindex d6c9fb93d0a..240d7125a5f 100644\n--- a/tensorflow/lite/kernels/unidirectional_sequence_lstm.cc\n+++ b/tensorflow/lite/kernels/unidirectional_sequence_lstm.cc\n@@ -20,6 +20,7 @@ limitations under the License.\n #include \"tensorflow/lite/c/builtin_op_data.h\"\n #include \"tensorflow/lite/c/common.h\"\n #include \"tensorflow/lite/kernels/cpu_backend_context.h\"\n+#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n #include \"tensorflow/lite/kernels/internal/kernel_utils.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n@@ -88,14 +89,19 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_EQ(context, input_to_input_weights->dims->data[1], n_input);\n   }\n \n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n+                   &input_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_forget_weights->dims->data[1], n_input);\n \n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, lstm::full::kInputToCellWeightsTensor);\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n+                                          lstm::full::kInputToCellWeightsTensor,\n+                                          &input_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, input_to_cell_weights->dims->data[1], n_input);\n@@ -110,16 +116,22 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                       n_output);\n   }\n \n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n+                   &recurrent_to_forget_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[0],\n                     n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_forget_weights->dims->data[1],\n                     n_output);\n \n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n+                   &recurrent_to_cell_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[0], n_cell);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_cell_weights->dims->data[1],\n@@ -176,18 +188,24 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n     TF_LITE_ENSURE_EQ(context, input_gate_bias->dims->data[0], n_cell);\n   }\n \n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kForgetGateBiasTensor,\n+                            &forget_gate_bias));\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, forget_gate_bias->dims->data[0], n_cell);\n \n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, lstm::full::kCellGateBiasTensor);\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, lstm::full::kCellGateBiasTensor,\n+                                 &cell_gate_bias));\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, cell_gate_bias->dims->data[0], n_cell);\n \n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kOutputGateBiasTensor,\n+                            &output_gate_bias));\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->size, 1);\n   TF_LITE_ENSURE_EQ(context, output_gate_bias->dims->data[0], n_cell);\n \n@@ -229,27 +247,33 @@ TfLiteStatus CheckInputTensorDimensions(TfLiteContext* context,\n                               kTfLiteFloat32);\n     }\n \n-    const TfLiteTensor* forget_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kForgetLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, forget_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* forget_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node,\n+                              lstm::full::kForgetLayerNormCoefficientsTensor,\n+                              &forget_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, forget_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, forget_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n     TF_LITE_ENSURE_TYPES_EQ(context, forget_layer_norm_coefficients->type,\n                             kTfLiteFloat32);\n \n-    const TfLiteTensor* cell_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kCellLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, cell_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* cell_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetInputSafe(context, node,\n+                                   lstm::full::kCellLayerNormCoefficientsTensor,\n+                                   &cell_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, cell_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, cell_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n     TF_LITE_ENSURE_TYPES_EQ(context, cell_layer_norm_coefficients->type,\n                             kTfLiteFloat32);\n \n-    const TfLiteTensor* output_layer_norm_coefficients =\n-        GetInput(context, node, lstm::full::kOutputLayerNormCoefficientsTensor);\n-    TF_LITE_ENSURE(context, output_layer_norm_coefficients != nullptr);\n+    const TfLiteTensor* output_layer_norm_coefficients;\n+    TF_LITE_ENSURE_OK(\n+        context, GetInputSafe(context, node,\n+                              lstm::full::kOutputLayerNormCoefficientsTensor,\n+                              &output_layer_norm_coefficients));\n     TF_LITE_ENSURE_EQ(context, output_layer_norm_coefficients->dims->size, 1);\n     TF_LITE_ENSURE_EQ(context, output_layer_norm_coefficients->dims->data[0],\n                       n_cell);\n@@ -291,7 +315,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n \n   // Inferring batch size, number of outputs and sequence length and\n   // number of cells from the input tensors.\n-  const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n   TF_LITE_ENSURE(context, input->dims->size > 1);\n   const auto* params =\n@@ -301,14 +327,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   const int n_batch = time_major ? input->dims->data[1] : input->dims->data[0];\n   const int n_input = input->dims->data[2];\n \n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n+                   &input_to_output_weights));\n   const int n_cell = input_to_output_weights->dims->data[0];\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, input_to_output_weights->dims->data[1], n_input);\n \n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n+                   &recurrent_to_output_weights));\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->size, 2);\n   TF_LITE_ENSURE_EQ(context, recurrent_to_output_weights->dims->data[0],\n                     n_cell);\n@@ -320,7 +352,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                n_cell, is_layer_norm_lstm));\n \n   // Get the pointer to output, output_state and cell_state buffer tensors.\n-  TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                           lstm::full::kOutputTensor, &output));\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n@@ -351,7 +385,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n       scratch_tensor_index + kScratchBuffer;\n \n   // Create a scratch buffer tensor.\n-  TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);\n+  TfLiteTensor* scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScratchBuffer,\n+                                              &scratch_buffer));\n   scratch_buffer->type = input->type;\n   scratch_buffer->allocation_type = kTfLiteArenaRw;\n \n@@ -376,8 +412,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // output_state and cell_state tensors.\n     node->temporaries->data[kInputQuantized] =\n         scratch_tensor_index + kInputQuantized;\n-    TfLiteTensor* input_quantized =\n-        GetTemporary(context, node, kInputQuantized);\n+    TfLiteTensor* input_quantized;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kInputQuantized,\n+                                                &input_quantized));\n     input_quantized->type = input_to_output_weights->type;\n     input_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n@@ -387,8 +424,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateQuantized] =\n         scratch_tensor_index + kOutputStateQuantized;\n-    TfLiteTensor* output_state_quantized =\n-        GetTemporary(context, node, kOutputStateQuantized);\n+    TfLiteTensor* output_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateQuantized,\n+                                       &output_state_quantized));\n     output_state_quantized->type = input_to_output_weights->type;\n     output_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(output_state_quantized->dims,\n@@ -401,8 +440,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kCellStateQuantized] =\n         scratch_tensor_index + kCellStateQuantized;\n-    TfLiteTensor* cell_state_quantized =\n-        GetTemporary(context, node, kCellStateQuantized);\n+    TfLiteTensor* cell_state_quantized;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kCellStateQuantized,\n+                                       &cell_state_quantized));\n     cell_state_quantized->type = input_to_output_weights->type;\n     cell_state_quantized->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqual(cell_state_quantized->dims, cell_state->dims)) {\n@@ -420,7 +461,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // the scaling factor of the matrix).\n     node->temporaries->data[kInputScalingFactors] =\n         op_data->scratch_tensor_index + kInputScalingFactors;\n-    TfLiteTensor* input_sf = GetTemporary(context, node, kInputScalingFactors);\n+    TfLiteTensor* input_sf;\n+    TF_LITE_ENSURE_OK(\n+        context,\n+        GetTemporarySafe(context, node, kInputScalingFactors, &input_sf));\n     input_sf->type = kTfLiteFloat32;\n     input_sf->allocation_type = kTfLiteArenaRw;\n     int scaling_dims[1] = {n_batch};\n@@ -432,8 +476,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateScalingFactors] =\n         op_data->scratch_tensor_index + kOutputStateScalingFactors;\n-    TfLiteTensor* output_state_sf =\n-        GetTemporary(context, node, kOutputStateScalingFactors);\n+    TfLiteTensor* output_state_sf;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kOutputStateScalingFactors,\n+                                  &output_state_sf));\n     output_state_sf->type = kTfLiteFloat32;\n     output_state_sf->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_sf->dims, 1, scaling_dims)) {\n@@ -444,8 +490,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kProductScalingFactors] =\n         scratch_tensor_index + kProductScalingFactors;\n-    TfLiteTensor* prod_scaling_factors =\n-        GetTemporary(context, node, kProductScalingFactors);\n+    TfLiteTensor* prod_scaling_factors;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kProductScalingFactors,\n+                                       &prod_scaling_factors));\n     prod_scaling_factors->type = kTfLiteFloat32;\n     prod_scaling_factors->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(prod_scaling_factors->dims, 1,\n@@ -461,8 +509,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // this is used for diagonal matrices, only need to store n_cell values.\n     node->temporaries->data[kRecoveredCellWeights] =\n         scratch_tensor_index + kRecoveredCellWeights;\n-    TfLiteTensor* recovered_cell_weights =\n-        GetTemporary(context, node, kRecoveredCellWeights);\n+    TfLiteTensor* recovered_cell_weights;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRecoveredCellWeights,\n+                                       &recovered_cell_weights));\n     recovered_cell_weights->type = kTfLiteFloat32;\n     recovered_cell_weights->allocation_type = kTfLiteArenaRw;\n     int recovered_cell_dims[1] = {n_cell};\n@@ -478,7 +528,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     // Allocate a temporary tensor to store the accumulated int32 values.\n     node->temporaries->data[kAccumScratch] =\n         scratch_tensor_index + kAccumScratch;\n-    TfLiteTensor* accum_scratch = GetTemporary(context, node, kAccumScratch);\n+    TfLiteTensor* accum_scratch;\n+    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kAccumScratch,\n+                                                &accum_scratch));\n     accum_scratch->type = kTfLiteInt32;\n     accum_scratch->allocation_type = kTfLiteArenaRw;\n     int accum_scratch_dims[2] = {n_cell, n_batch};\n@@ -492,7 +544,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kInputZeroPoints] =\n         op_data->scratch_tensor_index + kInputZeroPoints;\n-    TfLiteTensor* input_zp = GetTemporary(context, node, kInputZeroPoints);\n+    TfLiteTensor* input_zp;\n+    TF_LITE_ENSURE_OK(\n+        context, GetTemporarySafe(context, node, kInputZeroPoints, &input_zp));\n     input_zp->type = kTfLiteFloat32;\n     input_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(input_zp->dims, 1, scaling_dims)) {\n@@ -503,8 +557,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n     }\n     node->temporaries->data[kOutputStateZeroPoints] =\n         op_data->scratch_tensor_index + kOutputStateZeroPoints;\n-    TfLiteTensor* output_state_zp =\n-        GetTemporary(context, node, kOutputStateZeroPoints);\n+    TfLiteTensor* output_state_zp;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kOutputStateZeroPoints,\n+                                       &output_state_zp));\n     output_state_zp->type = kTfLiteFloat32;\n     output_state_zp->allocation_type = kTfLiteArenaRw;\n     if (!TfLiteIntArrayEqualsArray(output_state_zp->dims, 1, scaling_dims)) {\n@@ -514,7 +570,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n                                                        output_state_zp_size));\n     }\n     node->temporaries->data[kRowSums] = scratch_tensor_index + kRowSums;\n-    TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+    TfLiteTensor* row_sums;\n+    TF_LITE_ENSURE_OK(context,\n+                      GetTemporarySafe(context, node, kRowSums, &row_sums));\n     row_sums->type = kTfLiteInt32;\n     row_sums->allocation_type = kTfLiteArenaRwPersistent;\n     int row_sums_rows = use_cifg ? 6 : 8;\n@@ -542,25 +600,44 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   const OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n   const bool is_layer_norm_lstm = op_data->is_layer_norm_lstm;\n   const bool time_major = params->time_major;\n-  const TfLiteTensor* input = GetInput(context, node, lstm::full::kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n \n   const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights =\n-      GetInput(context, node, lstm::full::kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights =\n-      GetInput(context, node, lstm::full::kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights =\n-      GetInput(context, node, lstm::full::kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n+                   &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n+                                          lstm::full::kInputToCellWeightsTensor,\n+                                          &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n+                   &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights =\n-      GetInput(context, node, lstm::full::kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n+                   &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n+                   &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n+                   &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kCellToInputWeightsTensor);\n@@ -571,12 +648,18 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n \n   const TfLiteTensor* input_gate_bias =\n       GetOptionalInputTensor(context, node, lstm::full::kInputGateBiasTensor);\n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, lstm::full::kCellGateBiasTensor);\n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kForgetGateBiasTensor,\n+                            &forget_gate_bias));\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetInputSafe(context, node, lstm::full::kCellGateBiasTensor,\n+                                 &cell_gate_bias));\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node, lstm::full::kOutputGateBiasTensor,\n+                            &output_gate_bias));\n \n   const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n       context, node, lstm::full::kProjectionWeightsTensor);\n@@ -584,14 +667,16 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n       GetOptionalInputTensor(context, node, lstm::full::kProjectionBiasTensor);\n \n   // Index the scratch buffers pointers to the global scratch buffer.\n-  TfLiteTensor* scratch_buffer = GetTemporary(context, node, kScratchBuffer);\n+  TfLiteTensor* scratch_buffer;\n+  TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, kScratchBuffer,\n+                                              &scratch_buffer));\n \n   TfLiteTensor* output_state =\n       GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n-  TF_LITE_ENSURE(context, output_state != nullptr);\n+  TFLITE_DCHECK(output_state != nullptr);\n   TfLiteTensor* cell_state =\n       GetVariableInput(context, node, lstm::full::kCellStateTensor);\n-  TF_LITE_ENSURE(context, cell_state != nullptr);\n+  TFLITE_DCHECK(cell_state != nullptr);\n \n   const TfLiteTensor* input_layer_norm_coefficients =\n       is_layer_norm_lstm\n@@ -614,7 +699,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n                      lstm::full::kOutputLayerNormCoefficientsTensor)\n           : nullptr;\n \n-  TfLiteTensor* output = GetOutput(context, node, lstm::full::kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node,\n+                                           lstm::full::kOutputTensor, &output));\n \n   // Copy out the LSTM specific params so they can be passed in the function.\n   TfLiteLSTMParams lstm_params;\n@@ -647,7 +734,9 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n     case kTfLiteUInt8:\n     case kTfLiteInt8: {\n       OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n-      TfLiteTensor* row_sums = GetTemporary(context, node, kRowSums);\n+      TfLiteTensor* row_sums;\n+      TF_LITE_ENSURE_OK(context,\n+                        GetTemporarySafe(context, node, kRowSums, &row_sums));\n       const int row_sums_size = row_sums->dims->data[0];\n       return lstm_eval::EvalHybrid(\n           input, input_to_input_weights,"