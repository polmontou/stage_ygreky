"diff --git a/tensorflow/lite/micro/test_helpers.cc b/tensorflow/lite/micro/test_helpers.cc\nindex dd5e996ac26..26575a4d98d 100644\n--- a/tensorflow/lite/micro/test_helpers.cc\n+++ b/tensorflow/lite/micro/test_helpers.cc\n@@ -601,7 +601,8 @@ TfLiteStatus SimpleStatefulOp::Prepare(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n \n   // Make sure that the input is in uint8_t with at least 1 data entry.\n-  const TfLiteTensor* input = tflite::GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   if (input->type != kTfLiteUInt8) return kTfLiteError;\n   if (NumElements(input->dims) == 0) return kTfLiteError;\n \n@@ -622,7 +623,8 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n   OpData* data = reinterpret_cast<OpData*>(node->user_data);\n   *data->invoke_count += 1;\n \n-  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n   const uint8_t* input_data = GetTensorData<uint8_t>(input);\n   int size = NumElements(input->dims);\n \n@@ -641,9 +643,13 @@ TfLiteStatus SimpleStatefulOp::Invoke(TfLiteContext* context,\n     }\n   }\n \n-  TfLiteTensor* median = GetOutput(context, node, kMedianTensor);\n+  TfLiteTensor* median;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kMedianTensor, &median));\n   uint8_t* median_data = GetTensorData<uint8_t>(median);\n-  TfLiteTensor* invoke_count = GetOutput(context, node, kInvokeCount);\n+  TfLiteTensor* invoke_count;\n+  TF_LITE_ENSURE_OK(context,\n+                    GetOutputSafe(context, node, kInvokeCount, &invoke_count));\n   int32_t* invoke_count_data = GetTensorData<int32_t>(invoke_count);\n \n   median_data[0] = sorting_buffer[size / 2];\n@@ -681,11 +687,14 @@ TfLiteStatus MockCustom::Prepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n TfLiteStatus MockCustom::Invoke(TfLiteContext* context, TfLiteNode* node) {\n-  const TfLiteTensor* input = tflite::GetInput(context, node, 0);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   const int32_t* input_data = input->data.i32;\n-  const TfLiteTensor* weight = tflite::GetInput(context, node, 1);\n+  const TfLiteTensor* weight;\n+  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &weight));\n   const uint8_t* weight_data = weight->data.uint8;\n-  TfLiteTensor* output = GetOutput(context, node, 0);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n   int32_t* output_data = output->data.i32;\n   output_data[0] =\n       0;  // Catch output tensor sharing memory with an input tensor"