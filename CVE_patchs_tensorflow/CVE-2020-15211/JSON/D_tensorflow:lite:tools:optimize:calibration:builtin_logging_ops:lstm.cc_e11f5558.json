"diff --git a/tensorflow/lite/tools/optimize/calibration/builtin_logging_ops/lstm.cc b/tensorflow/lite/tools/optimize/calibration/builtin_logging_ops/lstm.cc\nindex 1ac996abe87..6249649f4b7 100644\n--- a/tensorflow/lite/tools/optimize/calibration/builtin_logging_ops/lstm.cc\n+++ b/tensorflow/lite/tools/optimize/calibration/builtin_logging_ops/lstm.cc\n@@ -466,26 +466,51 @@ TfLiteStatus lstm_eval(TfLiteContext* context, TfLiteNode* node, Logger* logger,\n                        ErrorReporter* error_reporter) {\n   const auto* params = static_cast<TfLiteLSTMParams*>(node->builtin_data);\n \n-  const TfLiteTensor* input =\n-      GetInput(context, node, ops::builtin::lstm::full::kInputTensor);\n+  const TfLiteTensor* input;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node,\n+                            ops::builtin::lstm::full::kInputTensor, &input));\n \n   const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n       context, node, ops::builtin::lstm::full::kInputToInputWeightsTensor);\n-  const TfLiteTensor* input_to_forget_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kInputToForgetWeightsTensor);\n-  const TfLiteTensor* input_to_cell_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kInputToCellWeightsTensor);\n-  const TfLiteTensor* input_to_output_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kInputToOutputWeightsTensor);\n+  const TfLiteTensor* input_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node,\n+                   ops::builtin::lstm::full::kInputToForgetWeightsTensor,\n+                   &input_to_forget_weights));\n+  const TfLiteTensor* input_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node,\n+                            ops::builtin::lstm::full::kInputToCellWeightsTensor,\n+                            &input_to_cell_weights));\n+  const TfLiteTensor* input_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node,\n+                   ops::builtin::lstm::full::kInputToOutputWeightsTensor,\n+                   &input_to_output_weights));\n \n   const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n       context, node, ops::builtin::lstm::full::kRecurrentToInputWeightsTensor);\n-  const TfLiteTensor* recurrent_to_forget_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kRecurrentToForgetWeightsTensor);\n-  const TfLiteTensor* recurrent_to_cell_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kRecurrentToCellWeightsTensor);\n-  const TfLiteTensor* recurrent_to_output_weights = GetInput(\n-      context, node, ops::builtin::lstm::full::kRecurrentToOutputWeightsTensor);\n+  const TfLiteTensor* recurrent_to_forget_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node,\n+                   ops::builtin::lstm::full::kRecurrentToForgetWeightsTensor,\n+                   &recurrent_to_forget_weights));\n+  const TfLiteTensor* recurrent_to_cell_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node,\n+                   ops::builtin::lstm::full::kRecurrentToCellWeightsTensor,\n+                   &recurrent_to_cell_weights));\n+  const TfLiteTensor* recurrent_to_output_weights;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node,\n+                   ops::builtin::lstm::full::kRecurrentToOutputWeightsTensor,\n+                   &recurrent_to_output_weights));\n \n   const TfLiteTensor* cell_to_input_weights = GetOptionalInputTensor(\n       context, node, ops::builtin::lstm::full::kCellToInputWeightsTensor);\n@@ -509,12 +534,21 @@ TfLiteStatus lstm_eval(TfLiteContext* context, TfLiteNode* node, Logger* logger,\n \n   const TfLiteTensor* input_gate_bias = GetOptionalInputTensor(\n       context, node, ops::builtin::lstm::full::kInputGateBiasTensor);\n-  const TfLiteTensor* forget_gate_bias =\n-      GetInput(context, node, ops::builtin::lstm::full::kForgetGateBiasTensor);\n-  const TfLiteTensor* cell_gate_bias =\n-      GetInput(context, node, ops::builtin::lstm::full::kCellGateBiasTensor);\n-  const TfLiteTensor* output_gate_bias =\n-      GetInput(context, node, ops::builtin::lstm::full::kOutputGateBiasTensor);\n+  const TfLiteTensor* forget_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node,\n+                            ops::builtin::lstm::full::kForgetGateBiasTensor,\n+                            &forget_gate_bias));\n+  const TfLiteTensor* cell_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context,\n+      GetInputSafe(context, node, ops::builtin::lstm::full::kCellGateBiasTensor,\n+                   &cell_gate_bias));\n+  const TfLiteTensor* output_gate_bias;\n+  TF_LITE_ENSURE_OK(\n+      context, GetInputSafe(context, node,\n+                            ops::builtin::lstm::full::kOutputGateBiasTensor,\n+                            &output_gate_bias));\n \n   const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n       context, node, ops::builtin::lstm::full::kProjectionWeightsTensor);\n@@ -522,7 +556,9 @@ TfLiteStatus lstm_eval(TfLiteContext* context, TfLiteNode* node, Logger* logger,\n       context, node, ops::builtin::lstm::full::kProjectionBiasTensor);\n \n   // Index the scratch buffers pointers to the global scratch buffer.\n-  TfLiteTensor* scratch_buffer = GetTemporary(context, node, /*index=*/0);\n+  TfLiteTensor* scratch_buffer;\n+  TF_LITE_ENSURE_OK(\n+      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_buffer));\n \n   TfLiteTensor* output_state = GetVariableInput(\n       context, node, ops::builtin::lstm::full::kOutputStateTensor);\n@@ -531,8 +567,10 @@ TfLiteStatus lstm_eval(TfLiteContext* context, TfLiteNode* node, Logger* logger,\n       context, node, ops::builtin::lstm::full::kCellStateTensor);\n   TF_LITE_ENSURE(context, cell_state != nullptr);\n \n-  TfLiteTensor* output =\n-      GetOutput(context, node, ops::builtin::lstm::full::kOutputTensor);\n+  TfLiteTensor* output;\n+  TF_LITE_ENSURE_OK(\n+      context, GetOutputSafe(context, node,\n+                             ops::builtin::lstm::full::kOutputTensor, &output));\n \n   std::vector<int> intermediate_tensor_indexes(node->intermediates->size);\n   for (int i = 0; i < node->intermediates->size; ++i) {"