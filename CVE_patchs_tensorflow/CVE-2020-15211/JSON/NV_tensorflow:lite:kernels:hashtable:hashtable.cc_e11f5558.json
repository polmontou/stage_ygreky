"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <string>\n\n#include \"flatbuffers/flexbuffers.h\"  // from @flatbuffers\n#include \"tensorflow/lite/c/builtin_op_data.h\"\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/core/api/flatbuffer_conversions.h\"\n#include \"tensorflow/lite/core/subgraph.h\"\n#include \"tensorflow/lite/experimental/resource/lookup_interfaces.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/schema/schema_generated.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace custom {\nnamespace hashtable {\n\nstatic constexpr int kResourceHandleTensor = 0;\nstatic constexpr const char kSharedNameStr[] = \"shared_name\";\nstatic constexpr const char kKeyDtypeStr[] = \"key_dtype\";\nstatic constexpr const char kValueDtypeStr[] = \"value_dtype\";\n\n// TODO(b/144728911): The following structure should be moved to\n// builtin_op_data.h when it is ready to become a builtin op.\ntypedef struct {\n  std::string table_name;\n  TfLiteType key_dtype;\n  TfLiteType value_dtype;\n} TfLiteHashtableParams;\n\nvoid* InitHashtable(TfLiteContext* context, const char* buffer, size_t length) {\n  TFLITE_CHECK(buffer != nullptr);\n\n  const uint8_t* buffer_t = reinterpret_cast<const uint8_t*>(buffer);\n  const flexbuffers::Map& m = flexbuffers::GetRoot(buffer_t, length).AsMap();\n  const std::string table_name = m[kSharedNameStr].AsString().str();\n\n  TfLiteType key_dtype, value_dtype;\n  ConvertTensorType(static_cast<TensorType>(m[kKeyDtypeStr].AsInt32()),\n                    &key_dtype, nullptr);\n  ConvertTensorType(static_cast<TensorType>(m[kValueDtypeStr].AsInt32()),\n                    &value_dtype, nullptr);\n\n  TfLiteHashtableParams* option = new TfLiteHashtableParams;\n  option->table_name = table_name;\n  option->key_dtype = key_dtype;\n  option->value_dtype = value_dtype;\n\n  return option;\n}\n\nvoid FreeHashtable(TfLiteContext* context, void* buffer) {\n  delete reinterpret_cast<TfLiteHashtableParams*>(buffer);\n}\n\nTfLiteStatus PrepareHashtable(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 0);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  TF_LITE_ENSURE(context, node->user_data != nullptr);\n  const auto* params =\n      reinterpret_cast<const TfLiteHashtableParams*>(node->user_data);\n\n  TF_LITE_ENSURE(context, !params->table_name.empty());\n  TF_LITE_ENSURE(context, (params->key_dtype == kTfLiteInt64 &&\n                           params->value_dtype == kTfLiteString) ||\n                              (params->key_dtype == kTfLiteString &&\n                               params->value_dtype == kTfLiteInt64));\n\n  TfLiteTensor* resource_handle_tensor;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kResourceHandleTensor,\n                                           &resource_handle_tensor));\n  TF_LITE_ENSURE_EQ(context, resource_handle_tensor->type, kTfLiteInt32);\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n  outputSize->data[0] = 1;\n  return context->ResizeTensor(context, resource_handle_tensor, outputSize);\n}\n\nTfLiteStatus EvalHashtable(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE(context, node->user_data != nullptr);\n  const auto* params =\n      reinterpret_cast<const TfLiteHashtableParams*>(node->user_data);\n\n  // The resource id is generated based on the given table name.\n  const int resource_id = std::hash<std::string>{}(params->table_name);\n\n  TfLiteTensor* resource_handle_tensor;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, kResourceHandleTensor,\n                                           &resource_handle_tensor));\n  auto* resource_handle_data =\n      GetTensorData<std::int32_t>(resource_handle_tensor);\n  resource_handle_data[0] = resource_id;\n\n  Subgraph* subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n  auto& resources = subgraph->resources();\n  resource::CreateHashtableResourceIfNotAvailable(\n      &resources, resource_id, params->key_dtype, params->value_dtype);\n  return kTfLiteOk;\n}\n\n}  // namespace hashtable\n\nTfLiteRegistration* Register_HASHTABLE() {\n  static TfLiteRegistration r = {\n      hashtable::InitHashtable, hashtable::FreeHashtable,\n      hashtable::PrepareHashtable, hashtable::EvalHashtable};\n  return &r;\n}\n\n}  // namespace custom\n}  // namespace ops\n}  // namespace tflite"