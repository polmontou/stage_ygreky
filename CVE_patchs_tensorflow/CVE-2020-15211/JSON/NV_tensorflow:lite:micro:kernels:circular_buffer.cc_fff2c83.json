"/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/c/builtin_op_data.h\"\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n#include \"tensorflow/lite/kernels/internal/quantization_util.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/kernels/op_macros.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_util.h\"\n\n/*\n * The circular buffer custom operator is used to implement strided streaming\n * convolutions on TFLite Micro.  Each time this operator is invoked, it checks\n * whether or not to run, based on a predetermined stride in time.  If the op\n * runs, it inserts the input into the end of the output buffer and shifts the\n * output values towards the start of the buffer.  It discards the oldest value\n * in the output buffer.\n *\n * Input: [<input N+1]\n * Before shifting:\n * Output: [<input 1>, <input 2>, <input ...>, <input N>]\n *\n * After shifting:\n * Output: [<input 2>, <input 3>, <input ...>, <input N+1>]\n *\n * We make some assumptions in this custom operator:\n * - Input shape must be [1, 1, 1, depth]\n * - Output shape must be [1, num_slots, 1, depth]\n * - Input and output types must match.\n * - Input and output quantization params must be identical.\n */\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nnamespace circular_buffer {\n\nnamespace {\n\n// The CircularBuffer op has one input and one output tensor.\nconstexpr int kInputTensor = 0;\nconstexpr int kOutputTensor = 0;\n\n// TODO(b/149795762): Add this to TfLiteStatus enum.\nconstexpr int kTfLiteAbort = -9;\n\n// These fields control the stride period of a strided streaming model. This op\n// returns kTfLiteAbort until cycles_until_run-- is zero.  At this time,\n// cycles_until_run is reset to cycles_max.\nstruct OpData {\n  int cycles_until_run;\n  int cycles_max;\n};\n\n// These constants represent constants specific to the music detect model.\n// They exist until (b/132070898) is fixed.\nconstexpr int kMaxOpDataSize = 7;\nint op_data_counter = 0;\nOpData op_data_array[kMaxOpDataSize];\n\n}  // namespace\n\nvoid Free(TfLiteContext* context, void* buffer) { op_data_counter = 0; }\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  TF_LITE_ENSURE(context, input != nullptr);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  TF_LITE_ENSURE(context, output != nullptr);\n\n  TF_LITE_ENSURE(context, input != nullptr);\n  TF_LITE_ENSURE(context, output != nullptr);\n  TF_LITE_ENSURE_EQ(context, 1, output->dims->data[0]);\n  TF_LITE_ENSURE_EQ(context, 1, input->dims->data[0]);\n  TF_LITE_ENSURE_EQ(context, 1, input->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, 1, output->dims->data[2]);\n  TF_LITE_ENSURE_EQ(context, 1, input->dims->data[2]);\n  TF_LITE_ENSURE_EQ(context, output->dims->data[3], input->dims->data[3]);\n\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  // The circular buffer custom operator currently only supports int8_t.\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteInt8);\n\n  // TODO(b/132070898): Use statically slotted OpData structures until a\n  // scratch memory API is ready.\n  TFLITE_DCHECK_LE(op_data_counter, kMaxOpDataSize);\n  OpData* op_data = &op_data_array[op_data_counter++];\n  // The last circular buffer layer (length 5) simply accumulates outputs, and\n  // does not run periodically.\n  // TODO(b/150001379): Move this special case logic to the tflite flatbuffer.\n  if (output->dims->data[1] == 5) {\n    op_data->cycles_max = 1;\n  } else {\n    op_data->cycles_max = 2;\n  }\n  op_data->cycles_until_run = op_data->cycles_max;\n  node->user_data = op_data;\n\n  return kTfLiteOk;\n}\n\n// Shifts buffer over by the output depth, and write new input to end of buffer.\n// num_slots is the number of samples stored in the output buffer.\n// depth is the size of each sample.\nvoid EvalInt8(const int8_t* input, int num_slots, int depth, int8_t* output) {\n  memmove(output, &output[depth], (num_slots - 1) * depth);\n  memcpy(&output[(num_slots - 1) * depth], input, depth);\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteEvalTensor* input =\n      tflite::micro::GetEvalInput(context, node, kInputTensor);\n  TfLiteEvalTensor* output =\n      tflite::micro::GetEvalOutput(context, node, kOutputTensor);\n\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  int num_slots = output->dims->data[1];\n  int depth = output->dims->data[3];\n\n  if (input->type == kTfLiteInt8) {\n    EvalInt8(tflite::micro::GetTensorData<int8_t>(input), num_slots, depth,\n             tflite::micro::GetTensorData<int8_t>(output));\n  } else {\n    TF_LITE_KERNEL_LOG(context, \"Type %s (%d) not supported.\",\n                       TfLiteTypeGetName(input->type), input->type);\n    return kTfLiteError;\n  }\n\n  if (--data->cycles_until_run != 0) {\n    // Signal the interpreter to end current run if the delay before op invoke\n    // has not been reached.\n    // TODO(b/149795762): Add kTfLiteAbort to TfLiteStatus enum.\n    return static_cast<TfLiteStatus>(kTfLiteAbort);\n  }\n\n  // If prepare is ever called more than one time (for example, when testing the\n  // ambient model, the interpreter is created a few times), this op data\n  // counter needs to be reset so that future instances do not overrun this op\n  // data array.\n  op_data_counter = 0;\n\n  data->cycles_until_run = data->cycles_max;\n\n  return kTfLiteOk;\n}\n\n}  // namespace circular_buffer\n\nTfLiteRegistration* Register_CIRCULAR_BUFFER() {\n  static TfLiteRegistration r = {/*init=*/nullptr,\n                                 /*free=*/circular_buffer::Free,\n                                 /*prepare=*/circular_buffer::Prepare,\n                                 /*invoke=*/circular_buffer::Eval,\n                                 /*profiling_string=*/nullptr,\n                                 /*builtin_code=*/0,\n                                 /*custom_name=*/nullptr,\n                                 /*version=*/0};\n  return &r;\n}\n\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite"