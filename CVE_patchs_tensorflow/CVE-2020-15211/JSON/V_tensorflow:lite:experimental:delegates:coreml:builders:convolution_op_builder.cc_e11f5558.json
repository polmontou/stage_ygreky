"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/lite/experimental/delegates/coreml/builders/convolution_op_builder.h\"\n\n#include \"google/protobuf/repeated_field.h\"\n#include \"external/coremltools/mlmodel/format/NeuralNetwork.pb.h\"\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/experimental/delegates/coreml/builders/activation_layer_builder.h\"\n#include \"tensorflow/lite/experimental/delegates/coreml/builders/op_factory.h\"\n#include \"tensorflow/lite/experimental/delegates/coreml/builders/op_validator.h\"\n#include \"tensorflow/lite/kernels/internal/optimized/optimized_ops.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace delegates {\nnamespace coreml {\nconst char* ConvolutionOpBuilder::DebugName() {\n  if (!str_debug_name_[0])\n    GetDebugName(\"ConvolutionOpBuilder\", node_id_, str_debug_name_);\n  return str_debug_name_;\n}\n\nvoid ConvolutionOpBuilder::SetWeights(TfLiteTensor* weights) {\n  weights_ = weights;\n}\n\nvoid ConvolutionOpBuilder::SetBias(TfLiteTensor* bias) { bias_ = bias; }\n\nvoid ConvolutionOpBuilder::SetOutputShape(TfLiteTensor* output_shape) {\n  output_shape_ = output_shape;\n}\n\nCoreML::Specification::NeuralNetworkLayer* ConvolutionOpBuilder::Build() {\n  if (layer_ == nullptr) {\n    layer_.reset(new CoreML::Specification::NeuralNetworkLayer);\n  }\n  layer_->set_name(DebugName());\n\n  int stride_height = 0;\n  int stride_width = 0;\n  int dilation_height = 0;\n  int dilation_width = 0;\n  TfLitePadding padding;\n\n  switch (conv_type_) {\n    case ConvolutionType::kConv: {\n      const auto* conv_params =\n          reinterpret_cast<const TfLiteConvParams*>(builtin_data_);\n      stride_height = conv_params->stride_height;\n      stride_width = conv_params->stride_width;\n      dilation_height = conv_params->dilation_height_factor;\n      dilation_width = conv_params->dilation_width_factor;\n      padding = conv_params->padding;\n\n      layer_->mutable_convolution()->set_ngroups(1);\n      break;\n    }\n    case ConvolutionType::kDepthwiseConv: {\n      const auto* depthwise_conv_params =\n          reinterpret_cast<const TfLiteDepthwiseConvParams*>(builtin_data_);\n      stride_height = depthwise_conv_params->stride_height;\n      stride_width = depthwise_conv_params->stride_width;\n      dilation_height = depthwise_conv_params->dilation_height_factor;\n      dilation_width = depthwise_conv_params->dilation_width_factor;\n      padding = depthwise_conv_params->padding;\n\n      // n_groups = kernel_channel / depth_multiplier\n      layer_->mutable_convolution()->set_ngroups(\n          weights_->dims->data[3] / depthwise_conv_params->depth_multiplier);\n      break;\n    }\n    case ConvolutionType::kTransposeConv: {\n      const auto* transpose_conv_params =\n          reinterpret_cast<const TfLiteTransposeConvParams*>(builtin_data_);\n      const int height_index = 1;\n      const int width_index = 2;\n\n      stride_height = transpose_conv_params->stride_height;\n      stride_width = transpose_conv_params->stride_width;\n      padding = transpose_conv_params->padding;\n\n      layer_->mutable_convolution()->mutable_outputshape()->Add(\n          GetTensorData<int32_t>(output_shape_)[height_index]);\n      layer_->mutable_convolution()->mutable_outputshape()->Add(\n          GetTensorData<int32_t>(output_shape_)[width_index]);\n      break;\n    }\n  }\n\n  // If not set, it will default to (1,1)\n  if (stride_height) {\n    layer_->mutable_convolution()->add_stride(stride_height);\n    layer_->mutable_convolution()->add_stride(stride_width);\n  }\n\n  if (dilation_height) {\n    layer_->mutable_convolution()->add_dilationfactor(dilation_height);\n    layer_->mutable_convolution()->add_dilationfactor(dilation_width);\n  }\n\n  switch (padding) {\n    case kTfLitePaddingSame:\n      layer_->mutable_convolution()->mutable_same();\n      break;\n    case kTfLitePaddingValid:\n      layer_->mutable_convolution()->mutable_valid();\n      break;\n    case kTfLitePaddingUnknown:\n      fprintf(stderr, \"Padding is unknown.\\n\");\n      break;\n  }\n\n  FillCoreMLWeights();\n  FillCoreMLBias();\n\n  return layer_.release();\n}\n\nvoid ConvolutionOpBuilder::FillCoreMLWeights() {\n  if (conv_type_ == ConvolutionType::kDepthwiseConv) {\n    layer_->mutable_convolution()->set_kernelchannels(1);\n    layer_->mutable_convolution()->set_outputchannels(weights_->dims->data[3]);\n  } else {\n    layer_->mutable_convolution()->set_kernelchannels(weights_->dims->data[3]);\n    layer_->mutable_convolution()->set_outputchannels(weights_->dims->data[0]);\n  }\n  layer_->mutable_convolution()->add_kernelsize(weights_->dims->data[1]);\n  layer_->mutable_convolution()->add_kernelsize(weights_->dims->data[2]);\n\n  TransposeKernelWeights();  // Should be called after CoreML shape is set.\n}\n\nvoid ConvolutionOpBuilder::TransposeKernelWeights() {\n  RuntimeShape tfl_shape(4, weights_->dims->data);\n  // CoreML kernel has shape of (C_out, C_in, H, W)\n  RuntimeShape coreml_shape(\n      {static_cast<int>(layer_->convolution().outputchannels()),\n       static_cast<int>(layer_->convolution().kernelchannels()),\n       static_cast<int>(layer_->convolution().kernelsize()[0]),\n       static_cast<int>(layer_->convolution().kernelsize()[1])});\n\n  TransposeParams params;\n\n  if (conv_type_ == ConvolutionType::kDepthwiseConv) {\n    // DepthwiseConv2D: TFL kernel has shape of (1, H, W, C_out),\n    // and CoreML kernel has shape of (C_out, 1, H, W)\n    params = {/*perm_count=*/4, /*perm=*/{3, 0, 1, 2}};\n  } else {\n    // Conv2D and TransposeConv: TFL kernel has shape of (C_out, H, W, C_in),\n    // and CoreML kernel has shape of (C_out, C_in, H, W)\n    params = {/*perm_count=*/4, /*perm=*/{0, 3, 1, 2}};\n  }\n\n  if (conv_type_ == ConvolutionType::kTransposeConv) {\n    layer_->mutable_convolution()->set_isdeconvolution(true);\n  }\n\n  if (weights_->type == kTfLiteFloat32) {\n    auto* coreml_weights =\n        layer_->mutable_convolution()->mutable_weights()->mutable_floatvalue();\n    coreml_weights->Resize(NumElements(weights_), 0);\n\n    optimized_ops::Transpose<float>(params, tfl_shape, weights_->data.f,\n                                    coreml_shape,\n                                    coreml_weights->mutable_data());\n  } else if (weights_->type == kTfLiteFloat16) {\n    auto* coreml_weights = layer_->mutable_convolution()\n                               ->mutable_weights()\n                               ->mutable_float16value();\n    // float16value has type of bytes (std::string)\n    coreml_weights->resize(weights_->bytes, 0);\n\n    optimized_ops::Transpose<uint16_t>(\n        params, tfl_shape, reinterpret_cast<uint16_t*>(weights_->data.raw),\n        coreml_shape, reinterpret_cast<uint16_t*>(&coreml_weights->front()));\n  }\n}\n\nvoid ConvolutionOpBuilder::FillCoreMLBias() {\n  if (bias_ != nullptr) {\n    layer_->mutable_convolution()->set_hasbias(true);\n    if (bias_->type == kTfLiteFloat32) {\n      std::copy(bias_->data.f, bias_->data.f + NumElements(bias_->dims),\n                google::protobuf::RepeatedFieldBackInserter(layer_->mutable_convolution()\n                                                      ->mutable_bias()\n                                                      ->mutable_floatvalue()));\n    } else if (bias_->type == kTfLiteFloat16) {\n      // float16value has type of bytes (std::string)\n      layer_->mutable_convolution()\n          ->mutable_bias()\n          ->mutable_float16value()\n          ->assign(bias_->data.raw, bias_->bytes);\n    }\n  }\n}\n\nTfLiteStatus ConvolutionOpBuilder::PopulateSubgraph(TfLiteContext* context) {\n  TfLiteFusedActivation activation;\n  switch (conv_type_) {\n    case ConvolutionType::kConv: {\n      const auto* conv_params =\n          reinterpret_cast<const TfLiteConvParams*>(builtin_data_);\n      activation = conv_params->activation;\n      break;\n    }\n    case ConvolutionType::kDepthwiseConv: {\n      const auto* depthwise_conv_params =\n          reinterpret_cast<const TfLiteDepthwiseConvParams*>(builtin_data_);\n      activation = depthwise_conv_params->activation;\n      break;\n    }\n    case ConvolutionType::kTransposeConv: {\n      activation = kTfLiteActNone;\n      break;\n    }\n  }\n\n  if (activation == kTfLiteActNone) {\n    builder_output_ = AddOutput();\n  } else {\n    ActivationLayerBuilder* activation_builder =\n        reinterpret_cast<ActivationLayerBuilder*>(\n            graph_builder_->AddBuilder(CreateActivationLayerBuilder, nullptr));\n    activation_builder->SetActivation(activation);\n    activation_builder->AddInput(AddOutput());\n    activation_builder->PopulateSubgraph(context);\n    builder_output_ = activation_builder->GetOutput(context);\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus ConvolutionOpBuilder::RegisterInputs(const TfLiteIntArray* inputs,\n                                                  TfLiteContext* context) {\n  if (conv_type_ == ConvolutionType::kTransposeConv) {\n    if (inputs->size != 3) {\n      TF_LITE_KERNEL_LOG(context,\n                         \"Transpose Conv should have 3 inputs, %d given.\",\n                         inputs->size);\n      return kTfLiteError;\n    }\n    AddInput(inputs->data[2]);\n    SetOutputShape(&context->tensors[inputs->data[0]]);\n  } else {\n    if (inputs->size != 2 && inputs->size != 3) {\n      TF_LITE_KERNEL_LOG(context,\n                         \"Convolution and depthwise convolution should have 2 \"\n                         \"or 3 inputs, %d given.\",\n                         inputs->size);\n      return kTfLiteError;\n    }\n    AddInput(inputs->data[0]);\n    if (inputs->size > 2) {\n      SetBias(&context->tensors[inputs->data[2]]);\n    }\n  }\n  SetWeights(&context->tensors[inputs->data[1]]);\n  return kTfLiteOk;\n}\n\nTfLiteStatus ConvolutionOpBuilder::RegisterOutputs(\n    const TfLiteIntArray* outputs, TfLiteContext* context) {\n  if (outputs->size != 1) {\n    TF_LITE_KERNEL_LOG(context, \"Wrong # of outputs!.\");\n    return kTfLiteError;\n  }\n  TensorID output_tensor = GetOutput(context);\n  if (output_tensor.NodeID() == -1) {\n    TF_LITE_KERNEL_LOG(context, \"Failed to build output tensor.\");\n    return kTfLiteError;\n  }\n  graph_builder_->AddTensorWithID(outputs->data[0], output_tensor);\n  return kTfLiteOk;\n}\n\nOpBuilder* CreateConvolutionOpBuilder(GraphBuilder* graph_builder) {\n  return new ConvolutionOpBuilder(graph_builder, ConvolutionType::kConv);\n}\n\nOpBuilder* CreateDepthwiseConvolutionOpBuilder(GraphBuilder* graph_builder) {\n  return new ConvolutionOpBuilder(graph_builder,\n                                  ConvolutionType::kDepthwiseConv);\n}\n\nOpBuilder* CreateTransposeConvolutionOpBuilder(GraphBuilder* graph_builder) {\n  return new ConvolutionOpBuilder(graph_builder,\n                                  ConvolutionType::kTransposeConv);\n}\n\nbool IsConvolutionOpSupported(const TfLiteRegistration* registration,\n                              const TfLiteNode* node, TfLiteContext* context) {\n  if (node->builtin_data == nullptr) return false;\n\n  TfLiteFusedActivation activation;\n\n  if (registration->builtin_code == kTfLiteBuiltinConv2d) {\n    const auto* conv_params =\n        reinterpret_cast<const TfLiteConvParams*>(node->builtin_data);\n    activation = conv_params->activation;\n  } else if (registration->builtin_code == kTfLiteBuiltinDepthwiseConv2d) {\n    const auto* depthwise_conv_params =\n        reinterpret_cast<const TfLiteDepthwiseConvParams*>(node->builtin_data);\n    activation = depthwise_conv_params->activation;\n  } else if (registration->builtin_code == kTfLiteBuiltinTransposeConv) {\n    activation = kTfLiteActNone;\n  } else {\n    TF_LITE_KERNEL_LOG(\n        context,\n        \"Invalid op: op must be Conv2D, DepthwiseConv2D or TransposeConv.\");\n    return false;\n  }\n\n  if (activation == kTfLiteActSignBit) {\n    return false;\n  }\n\n  const int kOutputShapeTensor = 0;  // Only used for TransposeConv\n  const int kWeightTensor = 1;\n  const int kBiasTensor = 2;  // Only used for non-TransposeConv\n  const TfLiteTensor* weights = GetInput(context, node, kWeightTensor);\n  const int max_kernel_size = 16384;\n  if (!IsConstantTensor(weights)) {\n    return false;\n  }\n  if (weights->dims->data[1] > max_kernel_size ||\n      weights->dims->data[2] > max_kernel_size) {\n    return false;\n  }\n  if (registration->builtin_code == kTfLiteBuiltinTransposeConv) {\n    if (!IsConstantTensor(GetInput(context, node, kOutputShapeTensor))) {\n      return false;\n    }\n  } else {\n    if (node->inputs->size >= kBiasTensor &&\n        !IsConstantTensor(GetInput(context, node, kBiasTensor))) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nbool IsDepthwiseConvolutionOpSupported(const TfLiteRegistration* registration,\n                                       const TfLiteNode* node,\n                                       TfLiteContext* context) {\n  return IsConvolutionOpSupported(registration, node, context);\n}\n\nbool IsTransposeConvolutionOpSupported(const TfLiteRegistration* registration,\n                                       const TfLiteNode* node,\n                                       TfLiteContext* context) {\n  return IsConvolutionOpSupported(registration, node, context);\n}\n\n}  // namespace coreml\n}  // namespace delegates\n}  // namespace tflite"