"/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <algorithm>\n#include <complex>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/optimized/optimized_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/kernels/op_macros.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace cast {\nconstexpr int kInputTensor = 0;\nconstexpr int kOutputTensor = 0;\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  // TODO(ahentz): these two checks would make the new implementation\n  // incompatible with some existing models, where params is not specified. It\n  // is OK not to have them because toco would have set input and output types\n  // to match the parameters.\n  // auto* params = reinterpret_cast<TfLiteCastParams*>(node->builtin_data);\n  // TF_LITE_ENSURE_EQ(context, input->type, params->in_data_type);\n  // TF_LITE_ENSURE_EQ(context, output->type, params->out_data_type);\n\n  return context->ResizeTensor(context, output,\n                               TfLiteIntArrayCopy(input->dims));\n}\n\ntemplate <typename FromT, typename ToT>\nvoid copyCast(const FromT* in, ToT* out, int num_elements) {\n  std::transform(in, in + num_elements, out,\n                 [](FromT a) { return static_cast<ToT>(a); });\n}\n\ntemplate <typename ToT>\nvoid copyCast(const std::complex<float>* in, ToT* out, int num_elements) {\n  std::transform(in, in + num_elements, out, [](std::complex<float> a) {\n    return static_cast<ToT>(std::real(a));\n  });\n}\n\ntemplate <>\nvoid copyCast(const std::complex<float>* in, std::complex<float>* out,\n              int num_elements) {\n  std::transform(in, in + num_elements, out,\n                 [](std::complex<float> a) { return a; });\n}\n\ntemplate <typename FromT>\nTfLiteStatus copyToTensor(TfLiteContext* context, const FromT* in,\n                          TfLiteTensor* out, int num_elements) {\n  switch (out->type) {\n    case kTfLiteInt64:\n      copyCast(in, out->data.i64, num_elements);\n      break;\n    case kTfLiteInt32:\n      copyCast(in, out->data.i32, num_elements);\n      break;\n    case kTfLiteUInt8:\n      copyCast(in, out->data.uint8, num_elements);\n      break;\n    case kTfLiteFloat32:\n      copyCast(in, GetTensorData<float>(out), num_elements);\n      break;\n    case kTfLiteBool:\n      copyCast(in, out->data.b, num_elements);\n      break;\n    case kTfLiteComplex64:\n      copyCast(in, reinterpret_cast<std::complex<float>*>(out->data.c64),\n               num_elements);\n      break;\n    default:\n      // Unsupported type.\n      TF_LITE_UNSUPPORTED_TYPE(context, out->type, \"Cast\");\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  const int num_elements = NumElements(input);\n  TF_LITE_ENSURE_EQ(context, num_elements, NumElements(output));\n  switch (input->type) {\n    case kTfLiteInt64:\n      return copyToTensor(context, input->data.i64, output, num_elements);\n    case kTfLiteInt32:\n      return copyToTensor(context, input->data.i32, output, num_elements);\n    case kTfLiteUInt8:\n      return copyToTensor(context, input->data.uint8, output, num_elements);\n    case kTfLiteFloat32:\n      return copyToTensor(context, GetTensorData<float>(input), output,\n                          num_elements);\n    case kTfLiteBool:\n      return copyToTensor(context, input->data.b, output, num_elements);\n    case kTfLiteComplex64:\n      return copyToTensor(\n          context, reinterpret_cast<std::complex<float>*>(input->data.c64),\n          output, num_elements);\n    default:\n      // Unsupported type.\n      TF_LITE_UNSUPPORTED_TYPE(context, input->type, \"Cast\");\n  }\n  return kTfLiteOk;\n}\n}  // namespace cast\n\nTfLiteRegistration* Register_CAST() {\n  static TfLiteRegistration r = {nullptr, nullptr, cast::Prepare, cast::Eval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite"