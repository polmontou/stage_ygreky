"/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/lite/kernels/internal/reference/comparisons.h\"\n\n#include <stdint.h>\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/compatibility.h\"\n#include \"tensorflow/lite/kernels/internal/quantization_util.h\"\n#include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/internal/types.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/string_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace builtin {\nnamespace comparisons {\nnamespace {\n\nconstexpr int kInputTensor1 = 0;\nconstexpr int kInputTensor2 = 1;\nconstexpr int kOutputTensor = 0;\n\nTfLiteStatus ComparisonPrepareCommon(TfLiteContext* context, TfLiteNode* node,\n                                     bool is_string_allowed) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  // Don't support string.\n  if (!is_string_allowed) {\n    TF_LITE_ENSURE(context, input1->type != kTfLiteString);\n  }\n  // Currently only support tensors have the same type.\n  TF_LITE_ENSURE_TYPES_EQ(context, input1->type, input2->type);\n  output->type = kTfLiteBool;\n\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n\n  TfLiteIntArray* output_size = nullptr;\n  if (requires_broadcast) {\n    TF_LITE_ENSURE_OK(context, CalculateShapeForBroadcast(\n                                   context, input1, input2, &output_size));\n  } else {\n    output_size = TfLiteIntArrayCopy(input1->dims);\n  }\n\n  return context->ResizeTensor(context, output, output_size);\n}\n\nTfLiteStatus ComparisonPrepare(TfLiteContext* context, TfLiteNode* node) {\n  return ComparisonPrepareCommon(context, node, false);\n}\n\nTfLiteStatus ComparisonPrepareStringAllowed(TfLiteContext* context,\n                                            TfLiteNode* node) {\n  return ComparisonPrepareCommon(context, node, true);\n}\n\ntemplate <typename input_dtype, reference_ops::ComparisonFn<int32> opname>\nvoid ComparisonQuantized(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                         TfLiteTensor* output, bool requires_broadcast) {\n  if (input1->type == kTfLiteUInt8 || input1->type == kTfLiteInt8) {\n    auto input1_offset = -input1->params.zero_point;\n    auto input2_offset = -input2->params.zero_point;\n    const int left_shift = 8;\n\n    int32 input1_multiplier;\n    int input1_shift;\n    QuantizeMultiplierSmallerThanOneExp(input1->params.scale,\n                                        &input1_multiplier, &input1_shift);\n    int32 input2_multiplier;\n    int input2_shift;\n    QuantizeMultiplierSmallerThanOneExp(input2->params.scale,\n                                        &input2_multiplier, &input2_shift);\n\n    ComparisonParams op_params;\n    op_params.left_shift = left_shift;\n    op_params.input1_offset = input1_offset;\n    op_params.input1_multiplier = input1_multiplier;\n    op_params.input1_shift = input1_shift;\n    op_params.input2_offset = input2_offset;\n    op_params.input2_multiplier = input2_multiplier;\n    op_params.input2_shift = input2_shift;\n    if (requires_broadcast) {\n      reference_ops::BroadcastComparison4DSlowWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    } else {\n      reference_ops::ComparisonWithScaling<input_dtype, opname>(\n          op_params, GetTensorShape(input1), GetTensorData<input_dtype>(input1),\n          GetTensorShape(input2), GetTensorData<input_dtype>(input2),\n          GetTensorShape(output), GetTensorData<bool>(output));\n    }\n  }\n}\n\ntemplate <typename T, reference_ops::ComparisonFn<T> opname>\nvoid Comparison(const TfLiteTensor* input1, const TfLiteTensor* input2,\n                TfLiteTensor* output, bool requires_broadcast) {\n  ComparisonParams op_params;\n  requires_broadcast\n      ? reference_ops::BroadcastComparison4DSlowImpl<T, opname>(\n            op_params, GetTensorShape(input1), GetTensorData<T>(input1),\n            GetTensorShape(input2), GetTensorData<T>(input2),\n            GetTensorShape(output), GetTensorData<bool>(output))\n      : reference_ops::ComparisonImpl<T, opname>(\n            op_params, GetTensorShape(input1), GetTensorData<T>(input1),\n            GetTensorShape(input2), GetTensorData<T>(input2),\n            GetTensorShape(output), GetTensorData<bool>(output));\n}\n\nvoid ComparisonString(bool (*opname)(const StringRef&, const StringRef&),\n                      const TfLiteTensor* input1, const TfLiteTensor* input2,\n                      TfLiteTensor* output, bool requires_broadcast) {\n  bool* output_data = GetTensorData<bool>(output);\n  if (requires_broadcast) {\n    reference_ops::BroadcastComparison4DSlowStringImpl(\n        opname, GetTensorShape(input1), input1, GetTensorShape(input2), input2,\n        GetTensorShape(output), output_data);\n  } else {\n    reference_ops::ComparisonStringImpl(opname, GetTensorShape(input1), input1,\n                                        GetTensorShape(input2), input2,\n                                        GetTensorShape(output), output_data);\n  }\n}\n\nTfLiteStatus EqualEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteBool:\n      Comparison<bool, reference_ops::EqualFn>(input1, input2, output,\n                                               requires_broadcast);\n      break;\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::EqualFn>(input1, input2, output,\n                                                requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::EqualFn>(input1, input2, output,\n                                                  requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::EqualFn>(input1, input2, output,\n                                                  requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::EqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::EqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteString:\n      ComparisonString(reference_ops::StringRefEqualFn, input1, input2, output,\n                       requires_broadcast);\n      break;\n    default:\n      context->ReportError(\n          context,\n          \"Does not support type %d, requires bool|float|int|uint8|string\",\n          input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus NotEqualEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteBool:\n      Comparison<bool, reference_ops::NotEqualFn>(input1, input2, output,\n                                                  requires_broadcast);\n      break;\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::NotEqualFn>(input1, input2, output,\n                                                   requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::NotEqualFn>(input1, input2, output,\n                                                     requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::NotEqualFn>(input1, input2, output,\n                                                     requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::NotEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::NotEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteString:\n      ComparisonString(reference_ops::StringRefNotEqualFn, input1, input2,\n                       output, requires_broadcast);\n      break;\n    default:\n      context->ReportError(\n          context,\n          \"Does not support type %d, requires bool|float|int|uint8|string\",\n          input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus GreaterEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::GreaterFn>(input1, input2, output,\n                                                  requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::GreaterFn>(input1, input2, output,\n                                                    requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::GreaterFn>(input1, input2, output,\n                                                    requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::GreaterFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::GreaterFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Does not support type %d, requires float|int|uint8\",\n                           input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus GreaterEqualEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::GreaterEqualFn>(input1, input2, output,\n                                                       requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::GreaterEqualFn>(input1, input2, output,\n                                                         requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::GreaterEqualFn>(input1, input2, output,\n                                                         requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::GreaterEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::GreaterEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Does not support type %d, requires float|int|uint8\",\n                           input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus LessEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::LessFn>(input1, input2, output,\n                                               requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::LessFn>(input1, input2, output,\n                                                 requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::LessFn>(input1, input2, output,\n                                                 requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::LessFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::LessFn>(input1, input2, output,\n                                                         requires_broadcast);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Does not support type %d, requires float|int|uint8\",\n                           input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus LessEqualEval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input1 = GetInput(context, node, kInputTensor1);\n  const TfLiteTensor* input2 = GetInput(context, node, kInputTensor2);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  bool requires_broadcast = !HaveSameShapes(input1, input2);\n  switch (input1->type) {\n    case kTfLiteFloat32:\n      Comparison<float, reference_ops::LessEqualFn>(input1, input2, output,\n                                                    requires_broadcast);\n      break;\n    case kTfLiteInt32:\n      Comparison<int32_t, reference_ops::LessEqualFn>(input1, input2, output,\n                                                      requires_broadcast);\n      break;\n    case kTfLiteInt64:\n      Comparison<int64_t, reference_ops::LessEqualFn>(input1, input2, output,\n                                                      requires_broadcast);\n      break;\n    case kTfLiteUInt8:\n      ComparisonQuantized<uint8_t, reference_ops::LessEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    case kTfLiteInt8:\n      ComparisonQuantized<int8_t, reference_ops::LessEqualFn>(\n          input1, input2, output, requires_broadcast);\n      break;\n    default:\n      context->ReportError(context,\n                           \"Does not support type %d, requires float|int|uint8\",\n                           input1->type);\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\n}  // namespace\n}  // namespace comparisons\n\nTfLiteRegistration* Register_EQUAL() {\n  static TfLiteRegistration r = {nullptr, nullptr,\n                                 comparisons::ComparisonPrepareStringAllowed,\n                                 comparisons::EqualEval};\n  return &r;\n}\n\nTfLiteRegistration* Register_NOT_EQUAL() {\n  static TfLiteRegistration r = {nullptr, nullptr,\n                                 comparisons::ComparisonPrepareStringAllowed,\n                                 comparisons::NotEqualEval};\n  return &r;\n}\n\nTfLiteRegistration* Register_GREATER() {\n  static TfLiteRegistration r = {nullptr, nullptr,\n                                 comparisons::ComparisonPrepare,\n                                 comparisons::GreaterEval};\n  return &r;\n}\n\nTfLiteRegistration* Register_GREATER_EQUAL() {\n  static TfLiteRegistration r = {nullptr, nullptr,\n                                 comparisons::ComparisonPrepare,\n                                 comparisons::GreaterEqualEval};\n  return &r;\n}\n\nTfLiteRegistration* Register_LESS() {\n  static TfLiteRegistration r = {\n      nullptr, nullptr, comparisons::ComparisonPrepare, comparisons::LessEval};\n  return &r;\n}\n\nTfLiteRegistration* Register_LESS_EQUAL() {\n  static TfLiteRegistration r = {nullptr, nullptr,\n                                 comparisons::ComparisonPrepare,\n                                 comparisons::LessEqualEval};\n  return &r;\n}\n\n}  // namespace builtin\n}  // namespace ops\n}  // namespace tflite"