"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <math.h>\n#include <stddef.h>\n#include <stdint.h>\n#include <string.h>\n\n#include <algorithm>\n#include <complex>\n\n#include \"third_party/fft2d/fft2d.h\"\n#include \"ruy/profiler/instrumentation.h\"  // from @ruy\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/tensor.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/internal/types.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace custom {\nnamespace rfft2d {\n\nusing std::complex;\n\nconstexpr int kInputTensor = 0;\nconstexpr int kFftLengthTensor = 1;\nconstexpr int kOutputTensor = 0;\nconstexpr int kFftIntegerWorkingAreaTensor = 0;\nconstexpr int kFftDoubleWorkingAreaTensor = 1;\nconstexpr int kTensorNotAllocated = -1;\n\nstruct OpData {\n  // IDs are the arbitrary identifiers used by TF Lite to identify and access\n  // memory buffers.\n  int fft_integer_working_area_id = kTensorNotAllocated;\n  int fft_double_working_area_id = kTensorNotAllocated;\n};\n\nbool IsPowerOfTwo(uint32_t v) { return v && !(v & (v - 1)); }\n\nstatic TfLiteStatus InitTemporaryTensors(TfLiteContext* context,\n                                         TfLiteNode* node) {\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n  // The prepare function may be executed multiple times. But temporary tensors\n  // only need to be initiated once.\n  if (data->fft_integer_working_area_id != kTensorNotAllocated &&\n      data->fft_double_working_area_id != kTensorNotAllocated) {\n    return kTfLiteOk;\n  }\n\n  TfLiteIntArrayFree(node->temporaries);\n  // Create two temporary tensors.\n  node->temporaries = TfLiteIntArrayCreate(2);\n  int first_new_index;\n  TF_LITE_ENSURE_STATUS(context->AddTensors(context, 2, &first_new_index));\n  node->temporaries->data[kFftIntegerWorkingAreaTensor] = first_new_index;\n  data->fft_integer_working_area_id = first_new_index;\n  node->temporaries->data[kFftDoubleWorkingAreaTensor] = first_new_index + 1;\n  data->fft_double_working_area_id = first_new_index + 1;\n\n  // Set up FFT integer working area buffer.\n  TfLiteTensor* fft_integer_working_area =\n      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n  fft_integer_working_area->type = kTfLiteInt32;\n  // If fft_length is not a constant tensor, fft_integer_working_area will be\n  // set to dynamic later in Prepare.\n  fft_integer_working_area->allocation_type = kTfLiteArenaRw;\n\n  // Set up FFT double working area buffer.\n  TfLiteTensor* fft_double_working_area =\n      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n  // fft_double_working_area is a double tensor. Ideally, double should be\n  // added into tflite data types. However, since fft_double_working_area is a\n  // temporary tensor, and there are no ops having double input/output tensors\n  // in tflite at this point, adding double as a tflite data type may confuse\n  // users that double is supported. As a results, kTfLiteInt64 is used here\n  // for memory allocation. And it will be cast into double in Eval when being\n  // used.\n  fft_double_working_area->type = kTfLiteInt64;\n  // If fft_length is not a constant tensor, fft_double_working_area will be\n  // set to dynamic later in Prepare.\n  fft_double_working_area->allocation_type = kTfLiteArenaRw;\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus ResizeOutputandTemporaryTensors(TfLiteContext* context,\n                                             TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  const int num_dims = NumDimensions(input);\n  TF_LITE_ENSURE(context, num_dims >= 2);\n  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n  const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n  // The lib, fft2d, can only handle fft_lengths of power of 2.\n  TF_LITE_ENSURE(context, IsPowerOfTwo(fft_length_data[0]));\n  TF_LITE_ENSURE(context, IsPowerOfTwo(fft_length_data[1]));\n\n  int fft_height, fft_width;\n  fft_height = fft_length_data[0];\n  fft_width = fft_length_data[1];\n  int fft_working_length = std::max(fft_height, fft_width / 2);\n  int half_fft_working_length = fft_working_length / 2;\n\n  // Resize output tensor.\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCopy(input->dims);\n  output_shape->data[num_dims - 2] = fft_length_data[0];\n  output_shape->data[num_dims - 1] = fft_length_data[1] / 2 + 1;\n  TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\n\n  // Resize temporary tensors, fft_integer_working_area.\n  TfLiteTensor* fft_integer_working_area =\n      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n  TfLiteIntArray* fft_integer_working_area_shape = TfLiteIntArrayCreate(1);\n  fft_integer_working_area_shape->data[0] =\n      2 + static_cast<int>(sqrt(fft_working_length));\n  TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, fft_integer_working_area,\n                                              fft_integer_working_area_shape));\n\n  // Resize temporary tensors, fft_double_working_area.\n  TfLiteTensor* fft_double_working_area =\n      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n  TfLiteIntArray* fft_double_working_area_shape = TfLiteIntArrayCreate(1);\n  fft_double_working_area_shape->data[0] =\n      half_fft_working_length + fft_width / 4;\n  TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, fft_double_working_area,\n                                              fft_double_working_area_shape));\n\n  return kTfLiteOk;\n}\n\nvoid* Init(TfLiteContext* context, const char* buffer, size_t length) {\n  auto* data = new OpData;\n  return data;\n}\n\nvoid Free(TfLiteContext* context, void* buffer) {\n  delete reinterpret_cast<OpData*>(buffer);\n}\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  // Check type and shape of the input tensor\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  TF_LITE_ENSURE(context, NumDimensions(input) >= 2);\n  if (input->type != kTfLiteFloat32) {\n    context->ReportError(context,\n                         \"Type '%s' for input is not supported by rfft2d.\",\n                         TfLiteTypeGetName(input->type));\n    return kTfLiteError;\n  }\n\n  // Check type and shape of the fft_length tensor\n  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n  const RuntimeShape fft_length_shape = GetTensorShape(fft_length);\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(fft_length), 1);\n  TF_LITE_ENSURE_EQ(context, fft_length_shape.Dims(0), 2);\n  if (fft_length->type != kTfLiteInt32) {\n    context->ReportError(context,\n                         \"Type '%s' for fft_length is not supported by rfft2d.\",\n                         TfLiteTypeGetName(fft_length->type));\n    return kTfLiteError;\n  }\n\n  // Setup temporary tensors for fft computation.\n  TF_LITE_ENSURE_STATUS(InitTemporaryTensors(context, node));\n\n  // Set output type\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  output->type = kTfLiteComplex64;\n\n  // Exit early if fft_length is a non-const tensor. Set output tensor and\n  // temporary tensors to dynamic, so that their tensor sizes can be determined\n  // in Eval.\n  if (!IsConstantTensor(fft_length)) {\n    TfLiteTensor* fft_integer_working_area =\n        GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n    TfLiteTensor* fft_double_working_area =\n        GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n    SetTensorToDynamic(fft_integer_working_area);\n    SetTensorToDynamic(fft_double_working_area);\n    SetTensorToDynamic(output);\n    return kTfLiteOk;\n  }\n\n  TF_LITE_ENSURE_STATUS(ResizeOutputandTemporaryTensors(context, node));\n  return kTfLiteOk;\n}\n\n// Reorder the result so that it matches the pattern of tf.signal.rfft2d.\n// In tf.signal.fft2d the frequency matrix of a 4x4 input is\n//    [[F(0, 0),  F(0, 1/4),   F(0, 2/4)],\n//    [F(1/4, 0), F(1/4, 1/4), F(1/4, 2/4)],\n//    [F(2/4, 0), F(2/4, 1/4), F(2/4, 2/4)],\n//    [F(3/4, 0), F(3/4, 1/4), F(3/4, 2/4)]]\n// While in rdft2d, the frequency matrix of a 4x4 input is\n//    [[(F(0, 0), F(0, -2/4))       F(0, -1/4),   0],\n//     [ F(-1/4, 0),                F(-1/4, -1/4), 0],\n//     [(F(-2/4, 0),F(-2/4, -2/4)), F(-2/4, -1/4), 0],\n//     [ j*F(-3/4, -2/4),           F(-3/4, -1/4), 0]]\n// Since real fft has the property that\n//   Real(u,v) = Real(-u, -v)\n//   Img(u,v) = - Img(-u, -v)\n// Result of rdft2d can be reordered and match the pattern of tf.signal.rfft2d.\n// For example,\n//   Real(-3/4, 0) = Real(1/4, 0) = Real(-1/4, 0)\n//   Img(-3/4, 0) = Img(1/4, 0) = -Img(-1/4, 0)\nvoid Rfft2dReorder(int fft_height, int fft_width, double** fft_input_output) {\n  int fft_height_half;\n  ruy::profiler::ScopeLabel label(\"Rfft2dReorder\");\n  double real, img;\n\n  fft_height_half = fft_height >> 1;\n  // Use 4x4 input as an example, reorder the frequency matrix from\n  //    [[(F(0, 0), F(0, -2/4))       F(0, -1/4),   0],\n  //     [ F(-1/4, 0),                F(-1/4, -1/4), 0],\n  //     [(F(-2/4, 0),F(-2/4, -2/4)), F(-2/4, -1/4), 0],\n  //     [ j*F(-3/4, -2/4),           F(-3/4, -1/4), 0]]\n  // to\n  //    [[F(0, 0),  F(0, -1/4),   F(0, -2/4)],\n  //    [F(-1/4, 0), F(-1/4, -1/4), F(-1/4, -2/4)],\n  //    [F(-2/4, 0), F(-2/4, -1/4), F(-2/4, -2/4)],\n  //    [F(-3/4, 0), F(-3/4, -1/4), F(-3/4, -2/4)]]\n  for (int i = fft_height_half + 1; i < fft_height; ++i) {\n    real = fft_input_output[i][0];\n    img = fft_input_output[i][1];\n    fft_input_output[i][fft_width] = img;\n    fft_input_output[i][fft_width + 1] = real;\n    fft_input_output[fft_height - i][fft_width] = img;\n    fft_input_output[fft_height - i][fft_width + 1] = -real;\n    fft_input_output[i][0] = fft_input_output[fft_height - i][0];\n    fft_input_output[i][1] = -fft_input_output[fft_height - i][1];\n  }\n\n  double temp = fft_input_output[0][1];\n  fft_input_output[0][fft_width + 1] = 0;\n  fft_input_output[0][1] = 0;\n  fft_input_output[fft_height_half][fft_width] =\n      fft_input_output[fft_height_half][1];\n  fft_input_output[fft_height_half][fft_width + 1] = 0;\n  fft_input_output[fft_height_half][1] = 0;\n  fft_input_output[0][fft_width] = temp;\n\n  // Reorder the frequency matrix from\n  //    [[F(0, 0),  F(0, -1/4),   F(0, -2/4)],\n  //    [F(-1/4, 0), F(-1/4, -1/4), F(-1/4, -2/4)],\n  //    [F(-2/4, 0), F(-2/4, -1/4), F(-2/4, -2/4)],\n  //    [F(-3/4, 0), F(-3/4, -1/4), F(-3/4, -2/4)]]\n  // to\n  //    [[F(0, 0),  F(0, 1/4),   F(0, 2/4)],\n  //    [F(1/4, 0), F(1/4, 1/4), F(1/4, 2/4)],\n  //    [F(2/4, 0), F(2/4, 1/4), F(2/4, 2/4)],\n  //    [F(3/4, 0), F(3/4, 1/4), F(3/4, 2/4)]]\n  for (int i = 0; i < fft_height; ++i) {\n    for (int j = 1; j < fft_width + 2; j += 2) {\n      fft_input_output[i][j] = -fft_input_output[i][j];\n    }\n  }\n}\n\nvoid Rfft2dImpl(int fft_height, int fft_width, double** fft_input_output,\n                int* fft_integer_working_area_data,\n                double* fft_double_working_area_data) {\n  ruy::profiler::ScopeLabel label(\"Rfft2dImpl\");\n\n  // Working data areas for the FFT routines.\n  double* fft_dynamic_working_area = nullptr;\n  const int kForwardFft = 1;\n  rdft2d(fft_height, fft_width, kForwardFft, fft_input_output,\n         fft_dynamic_working_area, fft_integer_working_area_data,\n         fft_double_working_area_data);\n  Rfft2dReorder(fft_height, fft_width, fft_input_output);\n}\n\nvoid PrepareInputBuffer(const float* input_data, int input_height,\n                        int input_width, int fft_height, int fft_width,\n                        double** fft_input_output) {\n  int valid_input_height = std::min(input_height, fft_height);\n  int valid_input_width = std::min(input_width, fft_width);\n  for (int i = 0; i < valid_input_height; ++i) {\n    int in_pos = i * input_width;\n    for (int j = 0; j < valid_input_width; ++j) {\n      fft_input_output[i][j] = input_data[in_pos++];\n    }\n    // Zero-pad the rest of the input buffer\n    for (int j = valid_input_width; j < fft_width + 2; ++j) {\n      fft_input_output[i][j] = 0;\n    }\n  }\n\n  // Zero-pad input buffer, if fft_height is greater than valid_input_height.\n  for (int i = valid_input_height; i < fft_height; ++i) {\n    for (int j = 0; j < fft_width + 2; ++j) {\n      fft_input_output[i][j] = 0;\n    }\n  }\n}\n\nvoid PrepareOutputBuffer(complex<float>* output_data, int fft_height,\n                         int fft_width, double** fft_input_output) {\n  int cnt = 0;\n  for (int i = 0; i < fft_height; ++i) {\n    for (int j = 0; j < fft_width / 2 + 1; ++j) {\n      output_data[cnt++] = complex<float>(fft_input_output[i][j * 2],\n                                          fft_input_output[i][j * 2 + 1]);\n    }\n  }\n}\n\nTfLiteStatus Rfft2dHelper(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  const float* input_data = GetTensorData<float>(input);\n  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n  const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n  complex<float>* output_data = GetTensorData<complex<float>>(output);\n\n  int fft_height, fft_width;\n  fft_height = fft_length_data[0];\n  fft_width = fft_length_data[1];\n\n  // FFT is processed for every slice on the inner most 2 dimensions.\n  // Count the number of slices in the input tensor.\n  const RuntimeShape input_shape = GetTensorShape(input);\n  const int input_dims_count = input_shape.DimensionsCount();\n  const auto* input_dims_data = input_shape.DimsData();\n  int num_slices = 1;\n  for (int i = 0; i < input_dims_count - 2; ++i) {\n    num_slices *= input_dims_data[i];\n  }\n\n  int input_height = input_dims_data[input_dims_count - 2];\n  int input_width = input_dims_data[input_dims_count - 1];\n  int input_slice_size = input_height * input_width;\n  int output_slice_size = fft_height * (fft_width / 2 + 1);\n\n  // Create input/output buffer for FFT\n  double** fft_input_output = new double*[fft_height];\n  for (int i = 0; i < fft_height; ++i) {\n    fft_input_output[i] = new double[fft_width + 2];\n  }\n\n  // Get buffer for integer working area.\n  TfLiteTensor* fft_integer_working_area =\n      GetTemporary(context, node, kFftIntegerWorkingAreaTensor);\n  int* fft_integer_working_area_data =\n      GetTensorData<int>(fft_integer_working_area);\n\n  // Get buffer for double working area.\n  TfLiteTensor* fft_double_working_area =\n      GetTemporary(context, node, kFftDoubleWorkingAreaTensor);\n  // Get double value out of the memory of fft_double_working_area_data.\n  double* fft_double_working_area_data = reinterpret_cast<double*>(\n      GetTensorData<int64_t>(fft_double_working_area));\n\n  // Process every slice in the input buffer\n  for (int i = 0; i < num_slices; ++i) {\n    PrepareInputBuffer(input_data, input_height, input_width, fft_height,\n                       fft_width, fft_input_output);\n    memset(fft_integer_working_area_data, 0, fft_integer_working_area->bytes);\n    memset(fft_double_working_area_data, 0, fft_double_working_area->bytes);\n    Rfft2dImpl(fft_height, fft_width, fft_input_output,\n               fft_integer_working_area_data, fft_double_working_area_data);\n    PrepareOutputBuffer(output_data, fft_height, fft_width, fft_input_output);\n    input_data += input_slice_size;\n    output_data += output_slice_size;\n  }\n\n  // Delete the input buffer\n  for (int i = 0; i < fft_height; ++i) {\n    delete[] fft_input_output[i];\n  }\n  delete[] fft_input_output;\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, kInputTensor);\n  const TfLiteTensor* fft_length = GetInput(context, node, kFftLengthTensor);\n  const int32_t* fft_length_data = GetTensorData<int32_t>(fft_length);\n  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);\n\n  if (output->type != kTfLiteComplex64) {\n    context->ReportError(context,\n                         \"Type '%s' for output is not supported by rfft2d.\",\n                         TfLiteTypeGetName(output->type));\n    return kTfLiteError;\n  }\n\n  // Resize the output tensor if the fft_length tensor is not constant.\n  // Otherwise, check if the output shape is correct.\n  if (!IsConstantTensor(fft_length)) {\n    TF_LITE_ENSURE_STATUS(ResizeOutputandTemporaryTensors(context, node));\n  } else {\n    int num_dims_output = NumDimensions(output);\n    const RuntimeShape output_shape = GetTensorShape(output);\n    TF_LITE_ENSURE_EQ(context, num_dims_output, NumDimensions(input));\n    TF_LITE_ENSURE(context, num_dims_output >= 2);\n    TF_LITE_ENSURE_EQ(context, output_shape.Dims(num_dims_output - 2),\n                      fft_length_data[0]);\n    TF_LITE_ENSURE_EQ(context, output_shape.Dims(num_dims_output - 1),\n                      fft_length_data[1] / 2 + 1);\n  }\n\n  return Rfft2dHelper(context, node);\n}\n\n}  // namespace rfft2d\n\nTfLiteRegistration* Register_RFFT2D() {\n  static TfLiteRegistration r = {rfft2d::Init, rfft2d::Free, rfft2d::Prepare,\n                                 rfft2d::Eval};\n  return &r;\n}\n\n}  // namespace custom\n}  // namespace ops\n}  // namespace tflite"