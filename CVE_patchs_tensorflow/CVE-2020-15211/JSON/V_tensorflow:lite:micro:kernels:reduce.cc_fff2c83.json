"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/kernels/internal/reference/reduce.h\"\n\n#include \"tensorflow/lite/c/builtin_op_data.h\"\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/quantization_util.h\"\n#include \"tensorflow/lite/kernels/internal/reference/integer_ops/mean.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/internal/types.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/micro_utils.h\"\n\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nnamespace reduce {\n\nconstexpr int kMaxNumberOfAxis = 4;\nconstexpr int kMaxNumberOfReducedAxis = 2;\n\nstruct OpData {\n  int32_t multiplier;\n  int shift;\n  int temp_buffer_idx;\n  int resolved_axis_idx;\n  int input_zp;\n  float input_scale;\n  int output_zp;\n  float output_scale;\n  int num_output_elements;\n};\n\nvoid* InitReduce(TfLiteContext* context, const char* buffer, size_t length) {\n  return context->AllocatePersistentBuffer(context, sizeof(OpData));\n}\n\nTfLiteStatus PrepareSimple(TfLiteContext* context, TfLiteNode* node) {\n  // Inputs Tensor (dtype depends on quantization):\n  // [0] = Input\n  // [1] = Axis\n  const TfLiteTensor* input = GetInput(context, node, 0);\n\n  // Outputs Tensor (dtype depends on quantization):\n  // [0] = Output\n\n  // Validate number of inputs and outputs\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 2);\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n\n  // Validate axis type\n  const TfLiteTensor* axis = GetInput(context, node, 1);\n  TF_LITE_ENSURE_TYPES_EQ(context, axis->type, kTfLiteInt32);\n\n  if (input->type == kTfLiteInt8) {\n    OpData* data = static_cast<OpData*>(node->user_data);\n    const TfLiteTensor* output = GetOutput(context, node, 0);\n    const double real_multiplier = static_cast<double>(input->params.scale) /\n                                   static_cast<double>(output->params.scale);\n    QuantizeMultiplier(real_multiplier, &data->multiplier, &data->shift);\n  }\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus PrepareMax(TfLiteContext* context, TfLiteNode* node) {\n  TF_LITE_ENSURE_OK(context, PrepareSimple(context, node));\n\n  OpData* op_data = static_cast<OpData*>(node->user_data);\n  const TfLiteTensor* input = GetInput(context, node, 0);\n  const TfLiteTensor* output = GetOutput(context, node, 0);\n  const TfLiteTensor* axis = GetInput(context, node, 1);\n\n  op_data->input_scale = input->params.scale;\n  op_data->output_scale = output->params.scale;\n  op_data->num_output_elements = NumElements(output);\n\n  context->RequestScratchBufferInArena(context, sizeof(int) * input->dims->size,\n                                       &op_data->temp_buffer_idx);\n  context->RequestScratchBufferInArena(\n      context, sizeof(int) * static_cast<int>(ElementCount(*axis->dims)),\n      &op_data->resolved_axis_idx);\n\n  return kTfLiteOk;\n}\n\nTfLiteStatus PrepareMeanOrSum(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* input = GetInput(context, node, 0);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  const TfLiteTensor* output = GetOutput(context, node, 0);\n  if (input->type == kTfLiteInt8) {\n    const double real_multiplier = static_cast<double>(input->params.scale) /\n                                   static_cast<double>(output->params.scale);\n    QuantizeMultiplier(real_multiplier, &op_data->multiplier, &op_data->shift);\n  }\n\n  int output_size = NumElements(output);\n  if (input->type == kTfLiteInt8 || input->type == kTfLiteUInt8) {\n    context->RequestScratchBufferInArena(context, output_size * sizeof(int32_t),\n                                         &op_data->temp_buffer_idx);\n    op_data->input_zp = input->params.zero_point;\n    op_data->input_scale = input->params.scale;\n    op_data->output_zp = output->params.zero_point;\n    op_data->output_scale = output->params.scale;\n  }\n\n  TF_LITE_ENSURE_OK(context, PrepareSimple(context, node));\n  // TODO(b/144955155): Support uint8_t(b/144955155) and int8_t(b/144955018)\n  return kTfLiteOk;\n}\n\nvoid ResolveAxis(const int* axis_data, int axis_count,\n                 tflite::MeanParams* op_params) {\n  int i = 0;\n  for (; i < axis_count; ++i) {\n    op_params->axis[i] = static_cast<int16_t>(axis_data[i]);\n  }\n  for (; i < 4; ++i) {\n    op_params->axis[i] = 1;\n  }\n  op_params->axis_count = axis_count;\n}\n\nTfLiteStatus EvalMean(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteEvalTensor* input = tflite::micro::GetEvalInput(context, node, 0);\n  const TfLiteEvalTensor* axis = tflite::micro::GetEvalInput(context, node, 1);\n  TfLiteEvalTensor* output = tflite::micro::GetEvalOutput(context, node, 0);\n  TfLiteReducerParams* params =\n      reinterpret_cast<TfLiteReducerParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n\n  int num_axis = static_cast<int>(ElementCount(*axis->dims));\n  int temp_index[kMaxNumberOfAxis];\n  int resolved_axis[kMaxNumberOfReducedAxis];\n\n  tflite::MeanParams op_params;\n  ResolveAxis(tflite::micro::GetTensorData<int>(axis), num_axis, &op_params);\n  // TODO(b/146571391): Support only 4D Input and 2D Axis for Mean until\n  // scratch tensor allocation has been implemented in (b/132070898)\n  bool is_valid_inputs = (input->dims->size == 4 && op_params.axis_count == 2 &&\n                          ((op_params.axis[0] == 1 && op_params.axis[1] == 2) ||\n                           (op_params.axis[0] == 2 && op_params.axis[1] == 1)));\n  TF_LITE_ENSURE_MSG(\n      context, is_valid_inputs == true,\n      \"Number of Input \"\n      \"dimensions != 4 OR the Axis is not either [1, 2] or [2, 1]\");\n  switch (input->type) {\n    case kTfLiteFloat32: {\n      // TODO(b/139102329): Handle the below special case in the combined\n      // reference method.\n      // Defer to specialized implementation for 4D Mean across axes 1 & 2.\n      if (params->keep_dims) {\n        reference_ops::Mean(op_params, tflite::micro::GetTensorShape(input),\n                            tflite::micro::GetTensorData<float>(input),\n                            tflite::micro::GetTensorShape(output),\n                            tflite::micro::GetTensorData<float>(output));\n      } else {\n        TF_LITE_ENSURE(\n            context,\n            reference_ops::Mean(\n                tflite::micro::GetTensorData<float>(input), input->dims->data,\n                input->dims->size, tflite::micro::GetTensorData<float>(output),\n                output->dims->data, output->dims->size,\n                tflite::micro::GetTensorData<int>(axis), num_axis,\n                params->keep_dims, temp_index, resolved_axis,\n                tflite::micro::GetTensorData<float>(output)));\n      }\n    } break;\n    case kTfLiteInt8: {\n      if (params->keep_dims) {\n        reference_integer_ops::Mean(\n            op_params, op_data->multiplier, op_data->shift,\n            tflite::micro::GetTensorShape(input),\n            tflite::micro::GetTensorData<int8_t>(input), op_data->input_zp,\n            tflite::micro::GetTensorShape(output),\n            tflite::micro::GetTensorData<int8_t>(output), op_data->output_zp);\n      } else if (op_data->input_zp == op_data->output_zp &&\n                 op_data->input_scale == op_data->output_scale) {\n        int32_t* temp_buffer = static_cast<int32_t*>(\n            context->GetScratchBuffer(context, op_data->temp_buffer_idx));\n        TF_LITE_ENSURE(\n            context,\n            reference_ops::Mean(\n                tflite::micro::GetTensorData<int8_t>(input), input->dims->data,\n                input->dims->size, tflite::micro::GetTensorData<int8_t>(output),\n                output->dims->data, output->dims->size,\n                tflite::micro::GetTensorData<int>(axis), num_axis,\n                params->keep_dims, temp_index, resolved_axis, temp_buffer));\n      } else {\n        int32_t* temp_buffer = static_cast<int32_t*>(\n            context->GetScratchBuffer(context, op_data->temp_buffer_idx));\n        TF_LITE_ENSURE(\n            context,\n            reference_ops::QuantizedMeanOrSum(\n                tflite::micro::GetTensorData<int8_t>(input), op_data->input_zp,\n                op_data->input_scale, input->dims->data, input->dims->size,\n                tflite::micro::GetTensorData<int8_t>(output),\n                op_data->output_zp, op_data->output_scale, output->dims->data,\n                output->dims->size, tflite::micro::GetTensorData<int>(axis),\n                num_axis, params->keep_dims, temp_index, resolved_axis,\n                temp_buffer, false));\n      }\n    } break;\n    case kTfLiteUInt8: {\n      if (params->keep_dims) {\n        reference_ops::Mean(op_params, tflite::micro::GetTensorShape(input),\n                            tflite::micro::GetTensorData<uint8_t>(input),\n                            op_data->input_zp, op_data->input_scale,\n                            tflite::micro::GetTensorShape(output),\n                            tflite::micro::GetTensorData<uint8_t>(output),\n                            op_data->output_zp, op_data->output_scale);\n      } else if (op_data->input_zp == op_data->output_zp &&\n                 op_data->input_scale == op_data->output_scale) {\n        uint32_t* temp_buffer = static_cast<uint32_t*>(\n            context->GetScratchBuffer(context, op_data->temp_buffer_idx));\n        TF_LITE_ENSURE(\n            context,\n            reference_ops::Mean(tflite::micro::GetTensorData<uint8_t>(input),\n                                input->dims->data, input->dims->size,\n                                tflite::micro::GetTensorData<uint8_t>(output),\n                                output->dims->data, output->dims->size,\n                                tflite::micro::GetTensorData<int>(axis),\n                                num_axis, params->keep_dims, temp_index,\n                                resolved_axis, temp_buffer));\n      } else {\n        uint32_t* temp_buffer = static_cast<uint32_t*>(\n            context->GetScratchBuffer(context, op_data->temp_buffer_idx));\n        TF_LITE_ENSURE(\n            context,\n            reference_ops::QuantizedMeanOrSum(\n                tflite::micro::GetTensorData<uint8_t>(input), op_data->input_zp,\n                op_data->input_scale, input->dims->data, input->dims->size,\n                tflite::micro::GetTensorData<uint8_t>(output),\n                op_data->output_zp, op_data->output_scale, output->dims->data,\n                output->dims->size, tflite::micro::GetTensorData<int>(axis),\n                num_axis, params->keep_dims, temp_index, resolved_axis,\n                temp_buffer, false));\n      }\n    } break;\n    default:\n      // TODO(b/144955155): Support uint8_t(b/144955155) and int8_t(b/144955018)\n      TF_LITE_ENSURE_MSG(context, false,\n                         \"Currently, only float32, int8 or uint8 input type \"\n                         \"is supported.\");\n  }\n  return kTfLiteOk;\n}\n\nTfLiteStatus EvalMax(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteEvalTensor* input = tflite::micro::GetEvalInput(context, node, 0);\n  const TfLiteEvalTensor* axis = tflite::micro::GetEvalInput(context, node, 1);\n  TfLiteEvalTensor* output = tflite::micro::GetEvalOutput(context, node, 0);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n  TfLiteReducerParams* params =\n      static_cast<TfLiteReducerParams*>(node->builtin_data);\n  OpData* op_data = static_cast<OpData*>(node->user_data);\n\n  // Interpret an axis tensor with null dimensions as a scalar\n  int num_axis = static_cast<int>(ElementCount(*axis->dims));\n  int* temp_buffer = static_cast<int*>(\n      context->GetScratchBuffer(context, op_data->temp_buffer_idx));\n  int* resolved_axis = static_cast<int*>(\n      context->GetScratchBuffer(context, op_data->resolved_axis_idx));\n  switch (input->type) {\n    case kTfLiteFloat32:\n      TF_LITE_ENSURE(\n          context,\n          reference_ops::ReduceGeneric<float>(\n              tflite::micro::GetTensorData<float>(input), input->dims->data,\n              input->dims->size, tflite::micro::GetTensorData<float>(output),\n              output->dims->data, output->dims->size,\n              tflite::micro::GetTensorData<int>(axis), num_axis,\n              params->keep_dims, temp_buffer, resolved_axis,\n              std::numeric_limits<float>::lowest(),\n              [](const float current, const float in) -> float {\n                return (in > current) ? in : current;\n              }));\n      break;\n    case kTfLiteInt8:\n      TF_LITE_ENSURE_EQ(context, static_cast<double>(op_data->input_scale),\n                        static_cast<double>(op_data->output_scale));\n      TF_LITE_ENSURE_EQ(context, op_data->input_zp, op_data->output_zp);\n      TF_LITE_ENSURE(\n          context,\n          reference_ops::ReduceGeneric<int8_t>(\n              tflite::micro::GetTensorData<int8_t>(input), input->dims->data,\n              input->dims->size, tflite::micro::GetTensorData<int8_t>(output),\n              output->dims->data, output->dims->size,\n              tflite::micro::GetTensorData<int>(axis), num_axis,\n              params->keep_dims, temp_buffer, resolved_axis,\n              std::numeric_limits<int8_t>::lowest(),\n              [](const int8_t current, const int8_t in) -> int8_t {\n                return (in > current) ? in : current;\n              }));\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Only float32 and int8 types are supported.\\n\");\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}\n\n}  // namespace reduce\n\nTfLiteRegistration Register_MEAN() {\n  return {/*init=*/reduce::InitReduce,\n          /*free=*/nullptr,\n          /*prepare=*/reduce::PrepareMeanOrSum,\n          /*invoke=*/reduce::EvalMean,\n          /*profiling_string=*/nullptr,\n          /*builtin_code=*/0,\n          /*custom_name=*/nullptr,\n          /*version=*/0};\n}\n\nTfLiteRegistration Register_REDUCE_MAX() {\n  return {/*init=*/reduce::InitReduce,\n          /*free=*/nullptr,\n          /*prepare=*/reduce::PrepareMax,\n          /*invoke=*/reduce::EvalMax,\n          /*profiling_string=*/nullptr,\n          /*builtin_code=*/0,\n          /*custom_name=*/nullptr,\n          /*version=*/0};\n}\n\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite"