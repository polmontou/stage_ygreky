diff --git a/tensorflow/lite/kernels/transpose_conv.cc b/tensorflow/lite/kernels/transpose_conv.cc
index 9ecd16274a0..52ee0414dd6 100644
--- a/tensorflow/lite/kernels/transpose_conv.cc
+++ b/tensorflow/lite/kernels/transpose_conv.cc
@@ -250,13 +250,20 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);
 
   // Retrieve tensors
-  const TfLiteTensor* output_shape =
-      GetInput(context, node, kOutputShapeTensor);
-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);
-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);
+  const TfLiteTensor* output_shape;
+  TF_LITE_ENSURE_OK(
+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));
+  const TfLiteTensor* weights;
+  TF_LITE_ENSURE_OK(context,
+                    GetInputSafe(context, node, kWeightsTensor, &weights));
+  const TfLiteTensor* input;
+  TF_LITE_ENSURE_OK(context,
+                    GetInputSafe(context, node, kDataInputTensor, &input));
   const TfLiteTensor* bias = nullptr;
 
-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
+  TfLiteTensor* output;
+  TF_LITE_ENSURE_OK(context,
+                    GetOutputSafe(context, node, kOutputTensor, &output));
 
   // Tensor sanity checks
   TF_LITE_ENSURE_EQ(context, NumDimensions(output_shape), 1);
@@ -306,7 +313,9 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   TfLiteTensor* col2im = nullptr;
   if (data->has_col2im) {
     node->temporaries->data[data->col2im_index] = data->col2im_id;
-    col2im = GetTemporary(context, node, user_data->col2im_index);
+    TF_LITE_ENSURE_OK(
+        context,
+        GetTemporarySafe(context, node, user_data->col2im_index, &col2im));
   }
 
   if (!IsConstantTensor(output_shape)) {
@@ -326,8 +335,11 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   if (data->weights_are_transposed) {
     node->temporaries->data[data->transposed_weights_index] =
         data->transposed_weights_id;
-    TfLiteTensor* transposed_weights =
-        GetTemporary(context, node, user_data->transposed_weights_index);
+    TfLiteTensor* transposed_weights;
+    TF_LITE_ENSURE_OK(
+        context,
+        GetTemporarySafe(context, node, user_data->transposed_weights_index,
+                         &transposed_weights));
     if (!IsConstantTensor(weights)) {
       SetTensorToDynamic(transposed_weights);
     } else {
@@ -339,8 +351,10 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
       input->type == kTfLiteInt16) {
     node->temporaries->data[data->scratch_tensor_index] =
         data->scratch_tensor_id;
-    TfLiteTensor* scratch_buffer =
-        GetTemporary(context, node, data->scratch_tensor_index);
+    TfLiteTensor* scratch_buffer;
+    TF_LITE_ENSURE_OK(
+        context, GetTemporarySafe(context, node, data->scratch_tensor_index,
+                                  &scratch_buffer));
     if (input->type == kTfLiteInt16) {
       scratch_buffer->type = kTfLiteInt64;
     } else {
@@ -549,15 +563,22 @@ void EvalQuantizedPerChannel16x8(
 template <KernelType kernel_type>
 TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
   // Retrieve tensors (All should be allocated by now)
-  const TfLiteTensor* output_shape =
-      GetInput(context, node, kOutputShapeTensor);
-  const TfLiteTensor* weights = GetInput(context, node, kWeightsTensor);
-  const TfLiteTensor* input = GetInput(context, node, kDataInputTensor);
+  const TfLiteTensor* output_shape;
+  TF_LITE_ENSURE_OK(
+      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));
+  const TfLiteTensor* weights;
+  TF_LITE_ENSURE_OK(context,
+                    GetInputSafe(context, node, kWeightsTensor, &weights));
+  const TfLiteTensor* input;
+  TF_LITE_ENSURE_OK(context,
+                    GetInputSafe(context, node, kDataInputTensor, &input));
   const TfLiteTensor* bias =
       (NumInputs(node) == 4)
           ? GetOptionalInputTensor(context, node, kBiasTensor)
           : nullptr;
-  TfLiteTensor* output = GetOutput(context, node, kOutputTensor);
+  TfLiteTensor* output;
+  TF_LITE_ENSURE_OK(context,
+                    GetOutputSafe(context, node, kOutputTensor, &output));
   OpData* data = reinterpret_cast<OpData*>(node->user_data);
   TfLiteTensor* col2im = data->has_col2im
                              ? GetTemporary(context, node, data->col2im_index)
@@ -604,8 +625,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
       break;
     }
     case kTfLiteUInt8: {
-      TfLiteTensor* scratch_buffer =
-          GetTemporary(context, node, data->scratch_tensor_index);
+      TfLiteTensor* scratch_buffer;
+      TF_LITE_ENSURE_OK(
+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,
+                                    &scratch_buffer));
       if (IsDynamicTensor(scratch_buffer)) {
         TF_LITE_ENSURE_OK(context,
                           ResizeTensor(context, output_shape, scratch_buffer));
@@ -621,8 +644,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
       break;
     }
     case kTfLiteInt8: {
-      TfLiteTensor* scratch_buffer =
-          GetTemporary(context, node, data->scratch_tensor_index);
+      TfLiteTensor* scratch_buffer;
+      TF_LITE_ENSURE_OK(
+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,
+                                    &scratch_buffer));
       if (IsDynamicTensor(scratch_buffer)) {
         TF_LITE_ENSURE_OK(context,
                           ResizeTensor(context, output_shape, scratch_buffer));
@@ -636,8 +661,10 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
       break;
     }
     case kTfLiteInt16: {
-      TfLiteTensor* scratch_buffer =
-          GetTemporary(context, node, data->scratch_tensor_index);
+      TfLiteTensor* scratch_buffer;
+      TF_LITE_ENSURE_OK(
+          context, GetTemporarySafe(context, node, data->scratch_tensor_index,
+                                    &scratch_buffer));
       if (IsDynamicTensor(scratch_buffer)) {
         TF_LITE_ENSURE_OK(context,
                           ResizeTensor(context, output_shape, scratch_buffer));