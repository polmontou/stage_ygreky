"// This file is part of Eigen, a lightweight C++ template library\n// for linear algebra.\n//\n// Copyright (C) 2015 Benoit Steiner <benoit.steiner.goog@gmail.com>\n//\n// This Source Code Form is subject to the terms of the Mozilla\n// Public License v. 2.0. If a copy of the MPL was not distributed\n// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\n\n#ifndef CXX11_SRC_FIXEDPOINT_FIXEDPOINTTYPES_H_\n#define CXX11_SRC_FIXEDPOINT_FIXEDPOINTTYPES_H_\n\n#include <cmath>\n#include <iostream>\n\nnamespace Eigen {\n\n// The mantissa part of the fixed point representation. See\n// go/tensorfixedpoint for details\nstruct QInt8;\nstruct QUInt8;\nstruct QInt16;\nstruct QUInt16;\nstruct QInt32;\n\ntemplate <>\nstruct NumTraits<QInt8> : GenericNumTraits<int8_t> {};\ntemplate <>\nstruct NumTraits<QUInt8> : GenericNumTraits<uint8_t> {};\ntemplate <>\nstruct NumTraits<QInt16> : GenericNumTraits<int16_t> {};\ntemplate <>\nstruct NumTraits<QUInt16> : GenericNumTraits<uint16_t> {};\ntemplate <>\nstruct NumTraits<QInt32> : GenericNumTraits<int32_t> {};\n\nnamespace internal {\ntemplate <>\nstruct scalar_product_traits<QInt32, double> {\n  enum {\n    // Cost = NumTraits<T>::MulCost,\n    Defined = 1\n  };\n  typedef QInt32 ReturnType;\n};\n}\n\n// Wrap the 8bit int into a QInt8 struct instead of using a typedef to prevent\n// the compiler from silently type cast the mantissa into a bigger or a smaller\n// representation.\nstruct QInt8 {\n  QInt8() : value(0) {}\n  QInt8(const int8_t v) : value(v) {}\n  QInt8(const QInt32 v);\n\n  operator int() const { return static_cast<int>(value); }\n\n  int8_t value;\n};\n\nstruct QUInt8 {\n  QUInt8() : value(0) {}\n  QUInt8(const uint8_t v) : value(v) {}\n  QUInt8(const QInt32 v);\n\n  operator int() const { return static_cast<int>(value); }\n\n  uint8_t value;\n};\n\nstruct QInt16 {\n  QInt16() : value(0) {}\n  QInt16(const int16_t v) : value(v) {}\n  QInt16(const QInt32 v);\n  operator int() const { return static_cast<int>(value); }\n\n  int16_t value;\n};\n\nstruct QUInt16 {\n  QUInt16() : value(0) {}\n  QUInt16(const uint16_t v) : value(v) {}\n  QUInt16(const QInt32 v);\n  operator int() const { return static_cast<int>(value); }\n\n  uint16_t value;\n};\n\nstruct QInt32 {\n  QInt32() : value(0) {}\n  QInt32(const int8_t v) : value(v) {}\n  QInt32(const int32_t v) : value(v) {}\n  QInt32(const uint32_t v) : value(static_cast<int32_t>(v)) {}\n  QInt32(const QInt8 v) : value(v.value) {}\n  QInt32(const float v) : value(static_cast<int32_t>(lrint(v))) {}\n#ifdef EIGEN_MAKING_DOCS\n  // Workaround to fix build on PPC.\n  QInt32(unsigned long v) : value(v) {}\n#endif\n\n  operator float() const { return static_cast<float>(value); }\n\n  int32_t value;\n};\n\nEIGEN_STRONG_INLINE QInt8::QInt8(const QInt32 v)\n    : value(v.value > 127 ? 127 : (v.value < -128 ? -128 : v.value)) {}\nEIGEN_STRONG_INLINE QUInt8::QUInt8(const QInt32 v)\n    : value(v.value > 255 ? 255 : (v.value < 0 ? 0 : v.value)) {}\nEIGEN_STRONG_INLINE QInt16::QInt16(const QInt32 v)\n    : value(v.value > 32767 ? 32767 : (v.value < -32768 ? -32768 : v.value)) {}\nEIGEN_STRONG_INLINE QUInt16::QUInt16(const QInt32 v)\n    : value(v.value > 65535 ? 65535 : (v.value < 0 ? 0 : v.value)) {}\n\n// Basic widening 8-bit operations: This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt8 a, const QInt8 b) {\n  return QInt32(static_cast<int32_t>(a.value) * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt8 a, const QUInt8 b) {\n  return QInt32(static_cast<int32_t>(a.value) * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt8 a, const QInt8 b) {\n  return QInt32(static_cast<int32_t>(a.value) + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt8 a, const QInt8 b) {\n  return QInt32(static_cast<int32_t>(a.value) - static_cast<int32_t>(b.value));\n}\n\n// Basic widening 16-bit operations: This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt16 a, const QInt16 b) {\n  return QInt32(static_cast<int32_t>(a.value) * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt16 a, const QUInt16 b) {\n  return QInt32(static_cast<int32_t>(a.value) * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt16 a, const QInt16 b) {\n  return QInt32(static_cast<int32_t>(a.value) + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt16 a, const QInt16 b) {\n  return QInt32(static_cast<int32_t>(a.value) - static_cast<int32_t>(b.value));\n}\n\n// Mixed QInt32 op QInt8 operations. This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt32 a, const QInt8 b) {\n  return QInt32(a.value + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) + b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a, const QInt8 b) {\n  return QInt32(a.value - static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) - b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const QInt8 b) {\n  return QInt32(a.value * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) * b.value);\n}\n\n// Mixed QInt32 op QInt16 operations. This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt32 a, const QInt16 b) {\n  return QInt32(a.value + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) + b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a, const QInt16 b) {\n  return QInt32(a.value - static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) - b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const QInt16 b) {\n  return QInt32(a.value * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) * b.value);\n}\n\n// Mixed QInt32 op QUInt8 operations. This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt32 a, const QUInt8 b) {\n  return QInt32(a.value + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QUInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) + b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a, const QUInt8 b) {\n  return QInt32(a.value - static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QUInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) - b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const QUInt8 b) {\n  return QInt32(a.value * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QUInt8 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) * b.value);\n}\n\n// Mixed QInt32 op QUInt16 operations. This will be vectorized in future CLs.\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt32 a, const QUInt16 b) {\n  return QInt32(a.value + static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator+(const QUInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) + b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a, const QUInt16 b) {\n  return QInt32(a.value - static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QUInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) - b.value);\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const QUInt16 b) {\n  return QInt32(a.value * static_cast<int32_t>(b.value));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QUInt16 a, const QInt32 b) {\n  return QInt32(static_cast<int32_t>(a.value) * b.value);\n}\n\n// Basic arithmetic operations on QInt32, which behaves like a int32_t.\nEIGEN_STRONG_INLINE QInt32 operator+(const QInt32 a, const QInt32 b) {\n  return a.value + b.value;\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a, const QInt32 b) {\n  return a.value - b.value;\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const QInt32 b) {\n  return a.value * b.value;\n}\nEIGEN_STRONG_INLINE QInt32 operator/(const QInt32 a, const QInt32 b) {\n  return a.value / b.value;\n}\nEIGEN_STRONG_INLINE QInt32& operator+=(QInt32& a, const QInt32 b) {\n  a.value += b.value;\n  return a;\n}\nEIGEN_STRONG_INLINE QInt32& operator-=(QInt32& a, const QInt32 b) {\n  a.value -= b.value;\n  return a;\n}\nEIGEN_STRONG_INLINE QInt32& operator*=(QInt32& a, const QInt32 b) {\n  a.value *= b.value;\n  return a;\n}\nEIGEN_STRONG_INLINE QInt32& operator/=(QInt32& a, const QInt32 b) {\n  a.value /= b.value;\n  return a;\n}\nEIGEN_STRONG_INLINE QInt32 operator-(const QInt32 a) { return -a.value; }\n\n// Scaling QInt32 by double. We do the arithmetic in double because\n// float only has 23 bits of mantissa, so casting QInt32 to float might reduce\n// accuracy by discarding up to 7 (least significant) bits.\nEIGEN_STRONG_INLINE QInt32 operator*(const QInt32 a, const double b) {\n  return static_cast<int32_t>(lrint(static_cast<double>(a.value) * b));\n}\nEIGEN_STRONG_INLINE QInt32 operator*(const double a, const QInt32 b) {\n  return static_cast<int32_t>(lrint(a * static_cast<double>(b.value)));\n}\nEIGEN_STRONG_INLINE QInt32& operator*=(QInt32& a, const double b) {\n  a.value = static_cast<int32_t>(lrint(static_cast<double>(a.value) * b));\n  return a;\n}\n\n// Comparisons\nEIGEN_STRONG_INLINE bool operator==(const QInt8 a, const QInt8 b) {\n  return a.value == b.value;\n}\nEIGEN_STRONG_INLINE bool operator==(const QUInt8 a, const QUInt8 b) {\n  return a.value == b.value;\n}\nEIGEN_STRONG_INLINE bool operator==(const QInt16 a, const QInt16 b) {\n  return a.value == b.value;\n}\nEIGEN_STRONG_INLINE bool operator==(const QUInt16 a, const QUInt16 b) {\n  return a.value == b.value;\n}\nEIGEN_STRONG_INLINE bool operator==(const QInt32 a, const QInt32 b) {\n  return a.value == b.value;\n}\n\nEIGEN_STRONG_INLINE bool operator<(const QInt8 a, const QInt8 b) {\n  return a.value < b.value;\n}\nEIGEN_STRONG_INLINE bool operator<(const QUInt8 a, const QUInt8 b) {\n  return a.value < b.value;\n}\nEIGEN_STRONG_INLINE bool operator<(const QInt16 a, const QInt16 b) {\n  return a.value < b.value;\n}\nEIGEN_STRONG_INLINE bool operator<(const QUInt16 a, const QUInt16 b) {\n  return a.value < b.value;\n}\nEIGEN_STRONG_INLINE bool operator<(const QInt32 a, const QInt32 b) {\n  return a.value < b.value;\n}\n\nEIGEN_STRONG_INLINE bool operator>(const QInt8 a, const QInt8 b) {\n  return a.value > b.value;\n}\nEIGEN_STRONG_INLINE bool operator>(const QUInt8 a, const QUInt8 b) {\n  return a.value > b.value;\n}\nEIGEN_STRONG_INLINE bool operator>(const QInt16 a, const QInt16 b) {\n  return a.value > b.value;\n}\nEIGEN_STRONG_INLINE bool operator>(const QUInt16 a, const QUInt16 b) {\n  return a.value > b.value;\n}\nEIGEN_STRONG_INLINE bool operator>(const QInt32 a, const QInt32 b) {\n  return a.value > b.value;\n}\n\nEIGEN_STRONG_INLINE std::ostream& operator<<(std::ostream& os, QInt8 a) {\n  os << static_cast<int>(a.value);\n  return os;\n}\nEIGEN_STRONG_INLINE std::ostream& operator<<(std::ostream& os, QUInt8 a) {\n  os << static_cast<int>(a.value);\n  return os;\n}\nEIGEN_STRONG_INLINE std::ostream& operator<<(std::ostream& os, QInt16 a) {\n  os << static_cast<int>(a.value);\n  return os;\n}\nEIGEN_STRONG_INLINE std::ostream& operator<<(std::ostream& os, QUInt16 a) {\n  os << static_cast<int>(a.value);\n  return os;\n}\nEIGEN_STRONG_INLINE std::ostream& operator<<(std::ostream& os, QInt32 a) {\n  os << a.value;\n  return os;\n}\n\n}  // namespace Eigen\n\n#endif  // CXX11_SRC_FIXEDPOINT_FIXEDPOINTTYPES_H_"