"diff --git a/tensorflow/core/platform/file_system_helper.cc b/tensorflow/core/platform/file_system_helper.cc\nindex 7bd34cd0156..f8ce2a9226e 100644\n--- a/tensorflow/core/platform/file_system_helper.cc\n+++ b/tensorflow/core/platform/file_system_helper.cc\n@@ -52,115 +52,217 @@ void ForEach(int first, int last, const std::function<void(int)>& f) {\n #endif\n }\n \n+// A globbing pattern can only start with these characters:\n+static const char kGlobbingChars[] = \"*?[\\\\\";\n+\n+static inline bool IsGlobbingPattern(const std::string& pattern) {\n+  return (pattern.find_first_of(kGlobbingChars) != std::string::npos);\n+}\n+\n+// Make sure that the first entry in `dirs` during glob expansion does not\n+// contain a glob pattern. This is to prevent a corner-case bug where\n+// `<pattern>` would be treated differently than `./<pattern>`.\n+static std::string PatchPattern(const std::string& pattern) {\n+  const std::string fixed_prefix =\n+      pattern.substr(0, pattern.find_first_of(kGlobbingChars));\n+\n+  // Patching is needed when there is no directory part in `prefix`\n+  if (io::Dirname(fixed_prefix).empty()) {\n+    return io::JoinPath(\".\", pattern);\n+  }\n+\n+  // No patching needed\n+  return pattern;\n+}\n+\n+static std::vector<std::string> AllDirectoryPrefixes(const std::string& d) {\n+  std::vector<std::string> dirs;\n+  const std::string patched = PatchPattern(d);\n+  StringPiece dir(patched);\n+\n+  // If the pattern ends with a `/` (or `\\\\` on Windows), we need to strip it\n+  // otherwise we would have one additional matching step and the result set\n+  // would be empty.\n+  bool is_directory = d[d.size() - 1] == '/';\n+#ifdef PLATFORM_WINDOWS\n+  is_directory = is_directory || (d[d.size() - 1] == '\\\\');\n+#endif\n+  if (is_directory) {\n+    dir = io::Dirname(dir);\n+  }\n+\n+  while (!dir.empty()) {\n+    dirs.emplace_back(dir);\n+    StringPiece new_dir(io::Dirname(dir));\n+    // io::Dirname(\"/\") returns \"/\" so we need to break the loop.\n+    // On Windows, io::Dirname(\"C:\\\\\") would return \"C:\\\\\", so we check for\n+    // identity of the result instead of checking for dir[0] == `/`.\n+    if (dir == new_dir) break;\n+    dir = new_dir;\n+  }\n+\n+  // Order the array from parent to ancestor (reverse order).\n+  std::reverse(dirs.begin(), dirs.end());\n+\n+  return dirs;\n+}\n+\n+static inline int GetFirstGlobbingEntry(const std::vector<std::string>& dirs) {\n+  int i = 0;\n+  for (const auto& d : dirs) {\n+    if (IsGlobbingPattern(d)) {\n+      break;\n+    }\n+    i++;\n+  }\n+  return i;\n+}\n+\n }  // namespace\n \n Status GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                         std::vector<string>* results) {\n+  // Check that `fs`, `env` and `results` are non-null.\n+  if (fs == nullptr || env == nullptr || results == nullptr) {\n+    return Status(tensorflow::error::INVALID_ARGUMENT,\n+                  \"Filesystem calls GetMatchingPaths with nullptr arguments\");\n+  }\n+\n+  // By design, we don't match anything on empty pattern\n   results->clear();\n   if (pattern.empty()) {\n     return Status::OK();\n   }\n \n-  string fixed_prefix = pattern.substr(0, pattern.find_first_of(\"*?[\\\\\"));\n-  string eval_pattern = pattern;\n-  string dir(io::Dirname(fixed_prefix));\n-  // If dir is empty then we need to fix up fixed_prefix and eval_pattern to\n-  // include . as the top level directory.\n-  if (dir.empty()) {\n-    dir = \".\";\n-    fixed_prefix = io::JoinPath(dir, fixed_prefix);\n-    eval_pattern = io::JoinPath(dir, eval_pattern);\n-  }\n-  bool is_directory = pattern[pattern.size() - 1] == '/';\n-#ifdef PLATFORM_WINDOWS\n-  is_directory = is_directory || pattern[pattern.size() - 1] == '\\\\';\n-#endif\n-  std::vector<string> dirs;\n-  if (!is_directory) {\n-    dirs.emplace_back(eval_pattern);\n-  }\n-  StringPiece tmp_dir(io::Dirname(eval_pattern));\n-  while (tmp_dir.size() > dir.size()) {\n-    dirs.emplace_back(string(tmp_dir));\n-    tmp_dir = io::Dirname(tmp_dir);\n+  // The pattern can contain globbing characters at multiple levels, e.g.:\n+  //\n+  //   foo/ba?/baz/f*r\n+  //\n+  // To match the full pattern, we must match every prefix subpattern and then\n+  // operate on the children for each match. Thus, we separate all subpatterns\n+  // in the `dirs` vector below.\n+  std::vector<std::string> dirs = AllDirectoryPrefixes(pattern);\n+\n+  // We can have patterns that have several parents where no globbing is being\n+  // done, for example, `foo/bar/baz/*`. We don't need to expand the directories\n+  // which don't contain the globbing characters.\n+  int matching_index = GetFirstGlobbingEntry(dirs);\n+\n+  // If we don't have globbing characters in the pattern then it specifies a\n+  // path in the filesystem. We add it to the result set if it exists.\n+  if (matching_index == dirs.size()) {\n+    if (fs->FileExists(pattern).ok()) {\n+      results->emplace_back(pattern);\n+    }\n+    return Status::OK();\n   }\n-  dirs.emplace_back(dir);\n-  std::reverse(dirs.begin(), dirs.end());\n-  // Setup a parallel BFS to explore everything under dir.\n-  std::deque<std::pair<string, int>> dir_q;\n-  std::deque<std::pair<string, int>> next_dir_q;\n-  dir_q.emplace_back(std::make_pair(dirs[0], 0));\n-  Status ret;  // Status to return.\n-  mutex results_mutex;\n-  condition_variable results_cond;\n-  mutex next_que_mutex;\n-  condition_variable next_que_cond;\n-  while (!dir_q.empty()) {\n-    next_dir_q.clear();\n-    std::vector<Status> new_rets(dir_q.size());\n-    auto handle_level = [fs, &results, &dir_q, &next_dir_q, &new_rets,\n-                         &is_directory, &dirs, &results_mutex, &results_cond,\n-                         &next_que_mutex, &next_que_cond](int i) {\n-      string current_dir = dir_q.at(i).first;\n-      int dir_index = dir_q.at(i).second;\n-      dir_index++;\n-      std::vector<string> children;\n-      Status s = fs->GetChildren(current_dir, &children);\n-      // In case PERMISSION_DENIED is encountered, we bail here.\n+\n+  // To expand the globbing, we do a BFS from `dirs[matching_index-1]`.\n+  // At every step, we work on a pair `{dir, ix}` such that `dir` is a real\n+  // directory, `ix < dirs.size() - 1` and `dirs[ix+1]` is a globbing pattern.\n+  // To expand the pattern, we select from all the children of `dir` only those\n+  // that match against `dirs[ix+1]`.\n+  // If there are more entries in `dirs` after `dirs[ix+1]` this mean we have\n+  // more patterns to match. So, we add to the queue only those children that\n+  // are also directories, paired with `ix+1`.\n+  // If there are no more entries in `dirs`, we return all children as part of\n+  // the answer.\n+  // Since we can get into a combinatorial explosion issue (e.g., pattern\n+  // `/*/*/*`), we process the queue in parallel. Each parallel processing takes\n+  // elements from `expand_queue` and adds them to `next_expand_queue`, after\n+  // which we swap these two queues (similar to double buffering algorithms).\n+  // PRECONDITION: `IsGlobbingPattern(dirs[0]) == false`\n+  // PRECONDITION: `matching_index > 0`\n+  // INVARIANT: If `{d, ix}` is in queue, then `d` and `dirs[ix]` are at the\n+  //            same level in the filesystem tree.\n+  // INVARIANT: If `{d, _}` is in queue, then `IsGlobbingPattern(d) == false`.\n+  // INVARIANT: If `{d, _}` is in queue, then `d` is a real directory.\n+  // INVARIANT: If `{_, ix}` is in queue, then `ix < dirs.size() - 1`.\n+  // INVARIANT: If `{_, ix}` is in queue, `IsGlobbingPattern(dirs[ix + 1])`.\n+  std::deque<std::pair<string, int>> expand_queue;\n+  std::deque<std::pair<string, int>> next_expand_queue;\n+  expand_queue.emplace_back(dirs[matching_index - 1], matching_index - 1);\n+\n+  // Adding to `result` or `new_expand_queue` need to be protected by mutexes\n+  // since there are multiple threads writing to these.\n+  mutex result_mutex;\n+  mutex queue_mutex;\n+\n+  while (!expand_queue.empty()) {\n+    next_expand_queue.clear();\n+\n+    // The work item for every item in `expand_queue`.\n+    // pattern, we process them in parallel.\n+    auto handle_level = [&fs, &results, &dirs, &expand_queue,\n+                         &next_expand_queue, &result_mutex,\n+                         &queue_mutex](int i) {\n+      // See invariants above, all of these are valid accesses.\n+      const auto& queue_item = expand_queue.at(i);\n+      const std::string& parent = queue_item.first;\n+      const int index = queue_item.second + 1;\n+      const std::string& match_pattern = dirs[index];\n+\n+      // Get all children of `parent`. If this fails, return early.\n+      std::vector<std::string> children;\n+      Status s = fs->GetChildren(parent, &children);\n       if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n         return;\n       }\n-      new_rets[i] = s;\n-      if (children.empty()) return;\n-\n-      // children_dir_status holds is_dir status for children. It can have three\n-      // possible values: OK for true; FAILED_PRECONDITION for false; CANCELLED\n-      // if we don't calculate IsDirectory (we might do that because there isn't\n-      // any point in exploring that child path).\n-      std::vector<Status> children_dir_status;\n-\n-      // This IsDirectory call can be expensive for some FS. Parallelizing it.\n-      children_dir_status.resize(children.size());\n-      auto handle_children = [fs, &current_dir, &children, &dirs, dir_index,\n-                              is_directory, &children_dir_status](int j) {\n-        const string child_path = io::JoinPath(current_dir, children[j]);\n-        if (!fs->Match(child_path, dirs[dir_index])) {\n-          children_dir_status[j] =\n+\n+      // Also return early if we don't have any children\n+      if (children.empty()) {\n+        return;\n+      }\n+\n+      // Since we can get extremely many children here and on some filesystems\n+      // `IsDirectory` is expensive, we process the children in parallel.\n+      // We also check that children match the pattern in parallel, for speedup.\n+      // We store the status of the match and `IsDirectory` in\n+      // `children_status` array, one element for each children.\n+      std::vector<Status> children_status(children.size());\n+      auto handle_children = [&fs, &match_pattern, &parent, &children,\n+                              &children_status](int j) {\n+        const std::string path = io::JoinPath(parent, children[j]);\n+        if (!fs->Match(path, match_pattern)) {\n+          children_status[j] =\n               Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n-        } else if (dir_index != dirs.size() - 1) {\n-          children_dir_status[j] = fs->IsDirectory(child_path);\n         } else {\n-          children_dir_status[j] =\n-              is_directory ? fs->IsDirectory(child_path) : Status::OK();\n+          children_status[j] = fs->IsDirectory(path);\n         }\n       };\n       ForEach(0, children.size(), handle_children);\n \n-      for (size_t j = 0; j < children.size(); ++j) {\n-        const string child_path = io::JoinPath(current_dir, children[j]);\n-        // If the IsDirectory call was cancelled we bail.\n-        if (children_dir_status[j].code() == tensorflow::error::CANCELLED) {\n+      // At this point, pairing `children` with `children_status` will tell us\n+      // if a children:\n+      //   * does not match the pattern\n+      //   * matches the pattern and is a directory\n+      //   * matches the pattern and is not a directory\n+      // We fully ignore the first case.\n+      // If we matched the last pattern (`index == dirs.size() - 1`) then all\n+      // remaining children get added to the result.\n+      // Otherwise, only the directories get added to the next queue.\n+      for (size_t j = 0; j < children.size(); j++) {\n+        if (children_status[j].code() == tensorflow::error::CANCELLED) {\n           continue;\n         }\n-        if (children_dir_status[j].ok()) {\n-          if (dir_index != dirs.size() - 1) {\n-            mutex_lock lk(next_que_mutex);\n-            next_dir_q.emplace_back(std::make_pair(child_path, dir_index));\n-            next_que_cond.notify_one();\n-          } else {\n-            mutex_lock lk(results_mutex);\n-            results->emplace_back(child_path);\n-            results_cond.notify_one();\n-          }\n+\n+        const std::string path = io::JoinPath(parent, children[j]);\n+        if (index == dirs.size() - 1) {\n+          mutex_lock l(result_mutex);\n+          results->emplace_back(path);\n+        } else if (children_status[j].ok()) {\n+          mutex_lock l(queue_mutex);\n+          next_expand_queue.emplace_back(path, index);\n         }\n       }\n     };\n-    ForEach(0, dir_q.size(), handle_level);\n+    ForEach(0, expand_queue.size(), handle_level);\n \n-    ret.Update(new_rets[dir_q.size() - 1]);\n-    std::swap(dir_q, next_dir_q);\n+    // After evaluating one level, swap the \"buffers\"\n+    std::swap(expand_queue, next_expand_queue);\n   }\n-  return ret;\n+\n+  return Status::OK();\n }\n \n }  // namespace internal"