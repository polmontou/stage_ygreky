"/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/platform/file_system_helper.h\"\n\n#include <deque>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/platform/cpu_info.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/file_system.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/path.h\"\n#include \"tensorflow/core/platform/platform.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/str_util.h\"\n#include \"tensorflow/core/platform/threadpool.h\"\n\nnamespace tensorflow {\nnamespace internal {\n\nnamespace {\n\nconst int kNumThreads = port::NumSchedulableCPUs();\n\n// Run a function in parallel using a ThreadPool, but skip the ThreadPool\n// on the iOS platform due to its problems with more than a few threads.\nvoid ForEach(int first, int last, const std::function<void(int)>& f) {\n#if TARGET_OS_IPHONE\n  for (int i = first; i < last; i++) {\n    f(i);\n  }\n#else\n  int num_threads = std::min(kNumThreads, last - first);\n  thread::ThreadPool threads(Env::Default(), \"ForEach\", num_threads);\n  for (int i = first; i < last; i++) {\n    threads.Schedule([f, i] { f(i); });\n  }\n#endif\n}\n\n// A globbing pattern can only start with these characters:\nstatic const char kGlobbingChars[] = \"*?[\\\\\";\n\nstatic inline bool IsGlobbingPattern(const std::string& pattern) {\n  return (pattern.find_first_of(kGlobbingChars) != std::string::npos);\n}\n\n// Make sure that the first entry in `dirs` during glob expansion does not\n// contain a glob pattern. This is to prevent a corner-case bug where\n// `<pattern>` would be treated differently than `./<pattern>`.\nstatic std::string PatchPattern(const std::string& pattern) {\n  const std::string fixed_prefix =\n      pattern.substr(0, pattern.find_first_of(kGlobbingChars));\n\n  // Patching is needed when there is no directory part in `prefix`\n  if (io::Dirname(fixed_prefix).empty()) {\n    return io::JoinPath(\".\", pattern);\n  }\n\n  // No patching needed\n  return pattern;\n}\n\nstatic std::vector<std::string> AllDirectoryPrefixes(const std::string& d) {\n  std::vector<std::string> dirs;\n  const std::string patched = PatchPattern(d);\n  StringPiece dir(patched);\n\n  // If the pattern ends with a `/` (or `\\\\` on Windows), we need to strip it\n  // otherwise we would have one additional matching step and the result set\n  // would be empty.\n  bool is_directory = d[d.size() - 1] == '/';\n#ifdef PLATFORM_WINDOWS\n  is_directory = is_directory || (d[d.size() - 1] == '\\\\');\n#endif\n  if (is_directory) {\n    dir = io::Dirname(dir);\n  }\n\n  while (!dir.empty()) {\n    dirs.emplace_back(dir);\n    StringPiece new_dir(io::Dirname(dir));\n    // io::Dirname(\"/\") returns \"/\" so we need to break the loop.\n    // On Windows, io::Dirname(\"C:\\\\\") would return \"C:\\\\\", so we check for\n    // identity of the result instead of checking for dir[0] == `/`.\n    if (dir == new_dir) break;\n    dir = new_dir;\n  }\n\n  // Order the array from parent to ancestor (reverse order).\n  std::reverse(dirs.begin(), dirs.end());\n\n  return dirs;\n}\n\nstatic inline int GetFirstGlobbingEntry(const std::vector<std::string>& dirs) {\n  int i = 0;\n  for (const auto& d : dirs) {\n    if (IsGlobbingPattern(d)) {\n      break;\n    }\n    i++;\n  }\n  return i;\n}\n\n}  // namespace\n\nStatus GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  // Check that `fs`, `env` and `results` are non-null.\n  if (fs == nullptr || env == nullptr || results == nullptr) {\n    return Status(tensorflow::error::INVALID_ARGUMENT,\n                  \"Filesystem calls GetMatchingPaths with nullptr arguments\");\n  }\n\n  // By design, we don't match anything on empty pattern\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  // The pattern can contain globbing characters at multiple levels, e.g.:\n  //\n  //   foo/ba?/baz/f*r\n  //\n  // To match the full pattern, we must match every prefix subpattern and then\n  // operate on the children for each match. Thus, we separate all subpatterns\n  // in the `dirs` vector below.\n  std::vector<std::string> dirs = AllDirectoryPrefixes(pattern);\n\n  // We can have patterns that have several parents where no globbing is being\n  // done, for example, `foo/bar/baz/*`. We don't need to expand the directories\n  // which don't contain the globbing characters.\n  int matching_index = GetFirstGlobbingEntry(dirs);\n\n  // If we don't have globbing characters in the pattern then it specifies a\n  // path in the filesystem. We add it to the result set if it exists.\n  if (matching_index == dirs.size()) {\n    if (fs->FileExists(pattern).ok()) {\n      results->emplace_back(pattern);\n    }\n    return Status::OK();\n  }\n\n  // To expand the globbing, we do a BFS from `dirs[matching_index-1]`.\n  // At every step, we work on a pair `{dir, ix}` such that `dir` is a real\n  // directory, `ix < dirs.size() - 1` and `dirs[ix+1]` is a globbing pattern.\n  // To expand the pattern, we select from all the children of `dir` only those\n  // that match against `dirs[ix+1]`.\n  // If there are more entries in `dirs` after `dirs[ix+1]` this mean we have\n  // more patterns to match. So, we add to the queue only those children that\n  // are also directories, paired with `ix+1`.\n  // If there are no more entries in `dirs`, we return all children as part of\n  // the answer.\n  // Since we can get into a combinatorial explosion issue (e.g., pattern\n  // `/*/*/*`), we process the queue in parallel. Each parallel processing takes\n  // elements from `expand_queue` and adds them to `next_expand_queue`, after\n  // which we swap these two queues (similar to double buffering algorithms).\n  // PRECONDITION: `IsGlobbingPattern(dirs[0]) == false`\n  // PRECONDITION: `matching_index > 0`\n  // INVARIANT: If `{d, ix}` is in queue, then `d` and `dirs[ix]` are at the\n  //            same level in the filesystem tree.\n  // INVARIANT: If `{d, _}` is in queue, then `IsGlobbingPattern(d) == false`.\n  // INVARIANT: If `{d, _}` is in queue, then `d` is a real directory.\n  // INVARIANT: If `{_, ix}` is in queue, then `ix < dirs.size() - 1`.\n  // INVARIANT: If `{_, ix}` is in queue, `IsGlobbingPattern(dirs[ix + 1])`.\n  std::deque<std::pair<string, int>> expand_queue;\n  std::deque<std::pair<string, int>> next_expand_queue;\n  expand_queue.emplace_back(dirs[matching_index - 1], matching_index - 1);\n\n  // Adding to `result` or `new_expand_queue` need to be protected by mutexes\n  // since there are multiple threads writing to these.\n  mutex result_mutex;\n  mutex queue_mutex;\n\n  while (!expand_queue.empty()) {\n    next_expand_queue.clear();\n\n    // The work item for every item in `expand_queue`.\n    // pattern, we process them in parallel.\n    auto handle_level = [&fs, &results, &dirs, &expand_queue,\n                         &next_expand_queue, &result_mutex,\n                         &queue_mutex](int i) {\n      // See invariants above, all of these are valid accesses.\n      const auto& queue_item = expand_queue.at(i);\n      const std::string& parent = queue_item.first;\n      const int index = queue_item.second + 1;\n      const std::string& match_pattern = dirs[index];\n\n      // Get all children of `parent`. If this fails, return early.\n      std::vector<std::string> children;\n      Status s = fs->GetChildren(parent, &children);\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n\n      // Also return early if we don't have any children\n      if (children.empty()) {\n        return;\n      }\n\n      // Since we can get extremely many children here and on some filesystems\n      // `IsDirectory` is expensive, we process the children in parallel.\n      // We also check that children match the pattern in parallel, for speedup.\n      // We store the status of the match and `IsDirectory` in\n      // `children_status` array, one element for each children.\n      std::vector<Status> children_status(children.size());\n      auto handle_children = [&fs, &match_pattern, &parent, &children,\n                              &children_status](int j) {\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (!fs->Match(path, match_pattern)) {\n          children_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else {\n          children_status[j] = fs->IsDirectory(path);\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      // At this point, pairing `children` with `children_status` will tell us\n      // if a children:\n      //   * does not match the pattern\n      //   * matches the pattern and is a directory\n      //   * matches the pattern and is not a directory\n      // We fully ignore the first case.\n      // If we matched the last pattern (`index == dirs.size() - 1`) then all\n      // remaining children get added to the result.\n      // Otherwise, only the directories get added to the next queue.\n      for (size_t j = 0; j < children.size(); j++) {\n        if (children_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (index == dirs.size() - 1) {\n          mutex_lock l(result_mutex);\n          results->emplace_back(path);\n        } else if (children_status[j].ok()) {\n          mutex_lock l(queue_mutex);\n          next_expand_queue.emplace_back(path, index);\n        }\n      }\n    };\n    ForEach(0, expand_queue.size(), handle_level);\n\n    // After evaluating one level, swap the \"buffers\"\n    std::swap(expand_queue, next_expand_queue);\n  }\n\n  return Status::OK();\n}\n\n}  // namespace internal\n}  // namespace tensorflow"