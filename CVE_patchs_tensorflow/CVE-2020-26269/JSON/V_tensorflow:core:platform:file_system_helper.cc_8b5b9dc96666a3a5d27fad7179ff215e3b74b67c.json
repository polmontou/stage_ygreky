"/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/platform/file_system_helper.h\"\n\n#include <deque>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/platform/cpu_info.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/file_system.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/path.h\"\n#include \"tensorflow/core/platform/platform.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/str_util.h\"\n#include \"tensorflow/core/platform/threadpool.h\"\n\nnamespace tensorflow {\nnamespace internal {\n\nnamespace {\n\nconst int kNumThreads = port::NumSchedulableCPUs();\n\n// Run a function in parallel using a ThreadPool, but skip the ThreadPool\n// on the iOS platform due to its problems with more than a few threads.\nvoid ForEach(int first, int last, const std::function<void(int)>& f) {\n#if TARGET_OS_IPHONE\n  for (int i = first; i < last; i++) {\n    f(i);\n  }\n#else\n  int num_threads = std::min(kNumThreads, last - first);\n  thread::ThreadPool threads(Env::Default(), \"ForEach\", num_threads);\n  for (int i = first; i < last; i++) {\n    threads.Schedule([f, i] { f(i); });\n  }\n#endif\n}\n\n}  // namespace\n\nStatus GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  string fixed_prefix = pattern.substr(0, pattern.find_first_of(\"*?[\\\\\"));\n  string eval_pattern = pattern;\n  string dir(io::Dirname(fixed_prefix));\n  // If dir is empty then we need to fix up fixed_prefix and eval_pattern to\n  // include . as the top level directory.\n  if (dir.empty()) {\n    dir = \".\";\n    fixed_prefix = io::JoinPath(dir, fixed_prefix);\n    eval_pattern = io::JoinPath(dir, eval_pattern);\n  }\n  bool is_directory = pattern[pattern.size() - 1] == '/';\n#ifdef PLATFORM_WINDOWS\n  is_directory = is_directory || pattern[pattern.size() - 1] == '\\\\';\n#endif\n  std::vector<string> dirs;\n  if (!is_directory) {\n    dirs.emplace_back(eval_pattern);\n  }\n  StringPiece tmp_dir(io::Dirname(eval_pattern));\n  while (tmp_dir.size() > dir.size()) {\n    dirs.emplace_back(string(tmp_dir));\n    tmp_dir = io::Dirname(tmp_dir);\n  }\n  dirs.emplace_back(dir);\n  std::reverse(dirs.begin(), dirs.end());\n  // Setup a parallel BFS to explore everything under dir.\n  std::deque<std::pair<string, int>> dir_q;\n  std::deque<std::pair<string, int>> next_dir_q;\n  dir_q.emplace_back(std::make_pair(dirs[0], 0));\n  Status ret;  // Status to return.\n  mutex results_mutex;\n  condition_variable results_cond;\n  mutex next_que_mutex;\n  condition_variable next_que_cond;\n  while (!dir_q.empty()) {\n    next_dir_q.clear();\n    std::vector<Status> new_rets(dir_q.size());\n    auto handle_level = [fs, &results, &dir_q, &next_dir_q, &new_rets,\n                         &is_directory, &dirs, &results_mutex, &results_cond,\n                         &next_que_mutex, &next_que_cond](int i) {\n      string current_dir = dir_q.at(i).first;\n      int dir_index = dir_q.at(i).second;\n      dir_index++;\n      std::vector<string> children;\n      Status s = fs->GetChildren(current_dir, &children);\n      // In case PERMISSION_DENIED is encountered, we bail here.\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n      new_rets[i] = s;\n      if (children.empty()) return;\n\n      // children_dir_status holds is_dir status for children. It can have three\n      // possible values: OK for true; FAILED_PRECONDITION for false; CANCELLED\n      // if we don't calculate IsDirectory (we might do that because there isn't\n      // any point in exploring that child path).\n      std::vector<Status> children_dir_status;\n\n      // This IsDirectory call can be expensive for some FS. Parallelizing it.\n      children_dir_status.resize(children.size());\n      auto handle_children = [fs, &current_dir, &children, &dirs, dir_index,\n                              is_directory, &children_dir_status](int j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        if (!fs->Match(child_path, dirs[dir_index])) {\n          children_dir_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else if (dir_index != dirs.size() - 1) {\n          children_dir_status[j] = fs->IsDirectory(child_path);\n        } else {\n          children_dir_status[j] =\n              is_directory ? fs->IsDirectory(child_path) : Status::OK();\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      for (size_t j = 0; j < children.size(); ++j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        // If the IsDirectory call was cancelled we bail.\n        if (children_dir_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n        if (children_dir_status[j].ok()) {\n          if (dir_index != dirs.size() - 1) {\n            mutex_lock lk(next_que_mutex);\n            next_dir_q.emplace_back(std::make_pair(child_path, dir_index));\n            next_que_cond.notify_one();\n          } else {\n            mutex_lock lk(results_mutex);\n            results->emplace_back(child_path);\n            results_cond.notify_one();\n          }\n        }\n      }\n    };\n    ForEach(0, dir_q.size(), handle_level);\n\n    ret.Update(new_rets[dir_q.size() - 1]);\n    std::swap(dir_q, next_dir_q);\n  }\n  return ret;\n}\n\n}  // namespace internal\n}  // namespace tensorflow"