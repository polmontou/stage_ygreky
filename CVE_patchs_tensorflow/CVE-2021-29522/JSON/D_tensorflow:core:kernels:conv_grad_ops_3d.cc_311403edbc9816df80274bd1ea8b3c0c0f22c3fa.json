"diff --git a/tensorflow/core/kernels/conv_grad_ops_3d.cc b/tensorflow/core/kernels/conv_grad_ops_3d.cc\nindex 8c72d01578d..c0b57a7ae56 100644\n--- a/tensorflow/core/kernels/conv_grad_ops_3d.cc\n+++ b/tensorflow/core/kernels/conv_grad_ops_3d.cc\n@@ -239,6 +239,14 @@ class Conv3DBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -360,6 +368,14 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n       input_shape = context->input(0).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -444,6 +460,11 @@ class Conv3DCustomBackpropInputOp : public OpKernel {\n     // contraction compared to sharding and matmuls.\n     const bool use_parallel_contraction = dims.batch_size == 1;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1\n@@ -724,6 +745,14 @@ class Conv3DBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -850,6 +879,14 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n       filter_shape = context->input(1).shape();\n     }\n \n+    OP_REQUIRES(context, input_shape.dims() == 5,\n+                errors::InvalidArgument(\"input tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, filter_shape.dims() == 5,\n+        errors::InvalidArgument(\"filter_sizes tensor must have 5 dimensions\"));\n+    OP_REQUIRES(\n+        context, out_backprop_shape.dims() == 5,\n+        errors::InvalidArgument(\"out_backprop tensor must have 5 dimensions\"));\n     OP_REQUIRES(\n         context, input_shape.dim_size(4) == filter_shape.dim_size(3),\n         errors::InvalidArgument(\"input and filter_sizes must have the same \"\n@@ -936,6 +973,11 @@ class Conv3DCustomBackpropFilterOp : public OpKernel {\n \n     const int64 work_unit_size = size_A + size_B + size_C;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;\n "