"/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include \"tensorflow/core/data/compression_utils.h\"\n\n#include \"tensorflow/core/common_runtime/dma_helper.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/platform/snappy.h\"\n\nnamespace tensorflow {\nnamespace data {\n\nStatus CompressElement(const std::vector<Tensor>& element,\n                       CompressedElement* out) {\n  // Step 1: Determine the total uncompressed size. This requires serializing\n  // non-memcopyable tensors, which we save to use again later.\n  std::vector<TensorProto> non_memcpy_components;\n  int64 total_size = 0;\n  for (auto& component : element) {\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        total_size += buffer->size();\n      }\n    } else {\n      non_memcpy_components.emplace_back();\n      component.AsProtoTensorContent(&non_memcpy_components.back());\n      total_size += non_memcpy_components.back().ByteSizeLong();\n    }\n  }\n\n  // Step 2: Write the tensor data to a buffer, and compress that buffer.\n  // We use tstring for access to resize_uninitialized.\n  tstring uncompressed;\n  uncompressed.resize_uninitialized(total_size);\n  // Position in `uncompressed` to write the next component.\n  char* position = uncompressed.mdata();\n  int non_memcpy_component_index = 0;\n  for (auto& component : element) {\n    CompressedComponentMetadata* metadata =\n        out->mutable_component_metadata()->Add();\n    metadata->set_dtype(component.dtype());\n    component.shape().AsProto(metadata->mutable_tensor_shape());\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        memcpy(position, buffer->data(), buffer->size());\n        metadata->set_tensor_size_bytes(buffer->size());\n      }\n    } else {\n      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n      proto.SerializeToArray(position, proto.ByteSizeLong());\n      metadata->set_tensor_size_bytes(proto.ByteSizeLong());\n    }\n    position += metadata->tensor_size_bytes();\n  }\n  DCHECK_EQ(position, uncompressed.mdata() + total_size);\n\n  if (!port::Snappy_Compress(uncompressed.mdata(), total_size,\n                             out->mutable_data())) {\n    return errors::Internal(\"Failed to compress using snappy.\");\n  }\n  VLOG(3) << \"Compressed element from \" << total_size << \" bytes to \"\n          << out->data().size() << \" bytes\";\n  return Status::OK();\n}\n\nStatus UncompressElement(const CompressedElement& compressed,\n                         std::vector<Tensor>* out) {\n  int num_components = compressed.component_metadata_size();\n  out->clear();\n  out->reserve(num_components);\n\n  // Step 1: Prepare the memory that we will uncompress into.\n  std::vector<struct iovec> iov(num_components);\n  // We use tstring for access to resize_uninitialized.\n  std::vector<tstring> tensor_proto_strs;\n  // num_components is a conservative estimate. It is important to reserve\n  // vector space so that the vector doesn't resize itself, which could\n  // invalidate pointers to its strings' data.\n  tensor_proto_strs.reserve(num_components);\n  int64 total_size = 0;\n  for (int i = 0; i < num_components; ++i) {\n    const CompressedComponentMetadata& metadata =\n        compressed.component_metadata(i);\n    if (DataTypeCanUseMemcpy(metadata.dtype())) {\n      out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n      TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n      if (buffer) {\n        iov[i].iov_base = buffer->data();\n        iov[i].iov_len = buffer->size();\n      } else {\n        iov[i].iov_base = nullptr;\n        iov[i].iov_len = 0;\n      }\n    } else {\n      // Allocate an empty Tensor. We will fill it out later after\n      // uncompressing into the tensor_proto_str.\n      out->emplace_back();\n      tensor_proto_strs.emplace_back();\n      tstring& tensor_proto_str = tensor_proto_strs.back();\n      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());\n      iov[i].iov_base = tensor_proto_str.mdata();\n      iov[i].iov_len = tensor_proto_str.size();\n    }\n    total_size += iov[i].iov_len;\n  }\n\n  // Step 2: Uncompress into the iovec.\n  const std::string& compressed_data = compressed.data();\n  size_t uncompressed_size;\n  if (!port::Snappy_GetUncompressedLength(\n          compressed_data.data(), compressed_data.size(), &uncompressed_size)) {\n    return errors::Internal(\n        \"Could not get snappy uncompressed length. Compressed data size: \",\n        compressed_data.size());\n  }\n  if (uncompressed_size != static_cast<size_t>(total_size)) {\n    return errors::Internal(\n        \"Uncompressed size mismatch. Snappy expects \", uncompressed_size,\n        \" whereas the tensor metadata suggests \", total_size);\n  }\n  if (!port::Snappy_UncompressToIOVec(compressed_data.data(),\n                                      compressed_data.size(), iov.data(),\n                                      num_components)) {\n    return errors::Internal(\"Failed to perform snappy decompression.\");\n  }\n\n  // Step 3: Deserialize tensor proto strings to tensors.\n  int tensor_proto_strs_index = 0;\n  for (int i = 0; i < num_components; ++i) {\n    if (DataTypeCanUseMemcpy(compressed.component_metadata(i).dtype())) {\n      continue;\n    }\n    TensorProto tp;\n    if (!tp.ParseFromString(tensor_proto_strs[tensor_proto_strs_index++])) {\n      return errors::Internal(\"Could not parse TensorProto\");\n    }\n    if (!out->at(i).FromProto(tp)) {\n      return errors::Internal(\"Could not parse Tensor\");\n    }\n  }\n  return Status::OK();\n}\n\n}  // namespace data\n}  // namespace tensorflow"