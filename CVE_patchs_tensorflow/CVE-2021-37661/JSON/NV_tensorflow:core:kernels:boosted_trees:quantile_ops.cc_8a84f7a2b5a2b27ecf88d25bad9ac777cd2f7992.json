"// Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n// =============================================================================\n#include <algorithm>\n#include <iterator>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/framework/device_base.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/resource_mgr.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/quantile_stream_resource.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_stream.h\"\n#include \"tensorflow/core/kernels/boosted_trees/quantiles/weighted_quantiles_summary.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/refcount.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\nconst char* const kExampleWeightsName = \"example_weights\";\nconst char* const kMaxElementsName = \"max_elements\";\nconst char* const kGenerateQuantiles = \"generate_quantiles\";\nconst char* const kNumBucketsName = \"num_buckets\";\nconst char* const kEpsilonName = \"epsilon\";\nconst char* const kBucketBoundariesName = \"bucket_boundaries\";\nconst char* const kBucketsName = \"buckets\";\nconst char* const kSummariesName = \"summaries\";\nconst char* const kNumStreamsName = \"num_streams\";\nconst char* const kNumFeaturesName = \"num_features\";\nconst char* const kFloatFeaturesName = \"float_values\";\nconst char* const kResourceHandleName = \"quantile_stream_resource_handle\";\n\nusing QuantileStreamResource = BoostedTreesQuantileStreamResource;\nusing QuantileStream =\n    boosted_trees::quantiles::WeightedQuantilesStream<float, float>;\nusing QuantileSummary =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float, float>;\nusing QuantileSummaryEntry =\n    boosted_trees::quantiles::WeightedQuantilesSummary<float,\n                                                       float>::SummaryEntry;\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateBoundaries(const QuantileStream& stream,\n                                      const int64_t num_boundaries) {\n  std::vector<float> boundaries = stream.GenerateBoundaries(num_boundaries);\n\n  // Uniquify elements as we may get dupes.\n  auto end_it = std::unique(boundaries.begin(), boundaries.end());\n  boundaries.resize(std::distance(boundaries.begin(), end_it));\n  return boundaries;\n}\n\n// Generates quantiles on a finalized QuantileStream.\nstd::vector<float> GenerateQuantiles(const QuantileStream& stream,\n                                     const int64_t num_quantiles) {\n  // Do not de-dup boundaries. Exactly num_quantiles+1 boundary values\n  // will be returned.\n  std::vector<float> boundaries = stream.GenerateQuantiles(num_quantiles - 1);\n  CHECK_EQ(boundaries.size(), num_quantiles);\n  return boundaries;\n}\n\nstd::vector<float> GetBuckets(const int32_t feature,\n                              const OpInputList& buckets_list) {\n  const auto& buckets = buckets_list[feature].flat<float>();\n  std::vector<float> buckets_vector(buckets.data(),\n                                    buckets.data() + buckets.size());\n  return buckets_vector;\n}\n\nREGISTER_RESOURCE_HANDLE_KERNEL(BoostedTreesQuantileStreamResource);\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"IsBoostedTreesQuantileStreamResourceInitialized\").Device(DEVICE_CPU),\n    IsResourceInitialized<BoostedTreesQuantileStreamResource>);\n\nclass BoostedTreesCreateQuantileStreamResourceOp : public OpKernel {\n public:\n  explicit BoostedTreesCreateQuantileStreamResourceOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kMaxElementsName, &max_elements_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n    OP_REQUIRES(context, num_streams >= 0,\n                errors::InvalidArgument(\n                    \"Num_streams input cannot be a negative integer\"));\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }\n\n private:\n  // An upper bound on the number of entries that the summaries might have\n  // for a feature.\n  int64 max_elements_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesCreateQuantileStreamResource\").Device(DEVICE_CPU),\n    BoostedTreesCreateQuantileStreamResourceOp);\n\nclass BoostedTreesMakeQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesMakeQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n\n    // Parse example weights and get batch size.\n    const Tensor* example_weights_t;\n    OP_REQUIRES_OK(context,\n                   context->input(kExampleWeightsName, &example_weights_t));\n    DCHECK(float_features_list.size() > 0) << \"Got empty feature list\";\n    auto example_weights = example_weights_t->flat<float>();\n    const int64_t weight_size = example_weights.size();\n    const int64_t batch_size = float_features_list[0].flat<float>().size();\n    OP_REQUIRES(\n        context, weight_size == 1 || weight_size == batch_size,\n        errors::InvalidArgument(strings::Printf(\n            \"Weights should be a single value or same size as features.\")));\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        const auto feature_values = float_features_list[index].flat<float>();\n        QuantileStream stream(epsilon, batch_size + 1);\n        // Run quantile summary generation.\n        for (int64_t j = 0; j < batch_size; j++) {\n          stream.PushEntry(feature_values(j), (weight_size > 1)\n                                                  ? example_weights(j)\n                                                  : example_weights(0));\n        }\n        stream.Finalize();\n        const auto summary_entry_list = stream.GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        OP_REQUIRES_OK(\n            context,\n            summaries_output_list.allocate(\n                index,\n                TensorShape({static_cast<int64>(summary_entry_list.size()), 4}),\n                &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_entry_list.size(); row++) {\n          const auto& entry = summary_entry_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * batch_size;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesMakeQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesMakeQuantileSummariesOp);\n\nclass BoostedTreesFlushQuantileSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesFlushQuantileSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpOutputList summaries_output_list;\n    OP_REQUIRES_OK(\n        context, context->output_list(kSummariesName, &summaries_output_list));\n\n    auto do_quantile_summary_gen = [&](const int64_t begin, const int64_t end) {\n      // Iterating features.\n      for (int64_t index = begin; index < end; index++) {\n        QuantileStream* stream = stream_resource->stream(index);\n        stream->Finalize();\n\n        const auto summary_list = stream->GetFinalSummary().GetEntryList();\n        Tensor* output_t;\n        const int64_t summary_list_size =\n            static_cast<int64>(summary_list.size());\n        OP_REQUIRES_OK(context, summaries_output_list.allocate(\n                                    index, TensorShape({summary_list_size, 4}),\n                                    &output_t));\n        auto output = output_t->matrix<float>();\n        for (auto row = 0; row < summary_list_size; row++) {\n          const auto& entry = summary_list[row];\n          output(row, 0) = entry.value;\n          output(row, 1) = entry.weight;\n          output(row, 2) = entry.min_rank;\n          output(row, 3) = entry.max_rank;\n        }\n      }\n    };\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_summary_gen);\n    stream_resource->ResetStreams();\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesFlushQuantileSummaries\").Device(DEVICE_CPU),\n    BoostedTreesFlushQuantileSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceAddSummariesOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceAddSummariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    OpInputList summaries_list;\n    OP_REQUIRES_OK(context,\n                   context->input_list(kSummariesName, &summaries_list));\n    int32_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(static_cast<int>(num_streams), summaries_list.size());\n\n    auto do_quantile_add_summary = [&](const int64_t begin, const int64_t end) {\n      // Iterating all features.\n      for (int64_t feature_idx = begin; feature_idx < end; ++feature_idx) {\n        QuantileStream* stream = stream_resource->stream(feature_idx);\n        if (stream->IsFinalized()) {\n          VLOG(1) << \"QuantileStream has already been finalized for feature\"\n                  << feature_idx << \".\";\n          continue;\n        }\n        const Tensor& summaries = summaries_list[feature_idx];\n        const auto summary_values = summaries.matrix<float>();\n        const auto& tensor_shape = summaries.shape();\n        const int64_t entries_size = tensor_shape.dim_size(0);\n        CHECK_EQ(tensor_shape.dim_size(1), 4);\n        std::vector<QuantileSummaryEntry> summary_entries;\n        summary_entries.reserve(entries_size);\n        for (int64_t i = 0; i < entries_size; i++) {\n          float value = summary_values(i, 0);\n          float weight = summary_values(i, 1);\n          float min_rank = summary_values(i, 2);\n          float max_rank = summary_values(i, 3);\n          QuantileSummaryEntry entry(value, weight, min_rank, max_rank);\n          summary_entries.push_back(entry);\n        }\n        stream_resource->stream(feature_idx)->PushSummary(summary_entries);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_add_summary);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceAddSummaries\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceAddSummariesOp);\n\nclass BoostedTreesQuantileStreamResourceDeserializeOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceDeserializeOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumStreamsName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    core::RefCountPtr<QuantileStreamResource> streams_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, HandleFromInput(context, 0),\n                                           &streams_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*streams_resource->mutex());\n\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n\n    auto do_quantile_deserialize = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const Tensor& bucket_boundaries_t = bucket_boundaries_list[stream_idx];\n        const auto& bucket_boundaries = bucket_boundaries_t.vec<float>();\n        std::vector<float> result;\n        result.reserve(bucket_boundaries.size());\n        for (size_t i = 0; i < bucket_boundaries.size(); ++i) {\n          result.push_back(bucket_boundaries(i));\n        }\n        streams_resource->set_boundaries(result, stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_deserialize);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceDeserialize\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceDeserializeOp);\n\nclass BoostedTreesQuantileStreamResourceFlushOp : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceFlushOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context,\n                   context->GetAttr(kGenerateQuantiles, &generate_quantiles_));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const Tensor* num_buckets_t;\n    OP_REQUIRES_OK(context, context->input(kNumBucketsName, &num_buckets_t));\n    const int64_t num_buckets = num_buckets_t->scalar<int64>()();\n    const int64_t num_streams = stream_resource->num_streams();\n\n    auto do_quantile_flush = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; ++stream_idx) {\n        QuantileStream* stream = stream_resource->stream(stream_idx);\n        stream->Finalize();\n        stream_resource->set_boundaries(\n            generate_quantiles_ ? GenerateQuantiles(*stream, num_buckets)\n                                : GenerateBoundaries(*stream, num_buckets),\n            stream_idx);\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_flush);\n\n    stream_resource->ResetStreams();\n    stream_resource->set_buckets_ready(true);\n  }\n\n private:\n  bool generate_quantiles_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceFlush\").Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceFlushOp);\n\nclass BoostedTreesQuantileStreamResourceGetBucketBoundariesOp\n    : public OpKernel {\n public:\n  explicit BoostedTreesQuantileStreamResourceGetBucketBoundariesOp(\n      OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    ResourceHandle handle;\n    OP_REQUIRES_OK(context,\n                   HandleFromInput(context, kResourceHandleName, &handle));\n    core::RefCountPtr<QuantileStreamResource> stream_resource;\n    // Create a reference to the underlying resource using the handle.\n    OP_REQUIRES_OK(context, LookupResource(context, handle, &stream_resource));\n    // Remove the reference at the end of this scope.\n    mutex_lock l(*stream_resource->mutex());\n\n    const int64_t num_streams = stream_resource->num_streams();\n    CHECK_EQ(num_features_, num_streams);\n    OpOutputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketBoundariesName,\n                                                 &bucket_boundaries_list));\n\n    auto do_quantile_get_buckets = [&](const int64_t begin, const int64_t end) {\n      // Iterating over all streams.\n      for (int64_t stream_idx = begin; stream_idx < end; stream_idx++) {\n        const auto& boundaries = stream_resource->boundaries(stream_idx);\n        Tensor* bucket_boundaries_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       bucket_boundaries_list.allocate(\n                           stream_idx, {static_cast<int64>(boundaries.size())},\n                           &bucket_boundaries_t));\n        auto* quantiles_flat = bucket_boundaries_t->flat<float>().data();\n        memcpy(quantiles_flat, boundaries.data(),\n               sizeof(float) * boundaries.size());\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_streams;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_streams,\n          kCostPerUnit, do_quantile_get_buckets);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(\n    Name(\"BoostedTreesQuantileStreamResourceGetBucketBoundaries\")\n        .Device(DEVICE_CPU),\n    BoostedTreesQuantileStreamResourceGetBucketBoundariesOp);\n\n// Given the calculated quantiles thresholds and input data, this operation\n// converts the input features into the buckets (categorical values), depending\n// on which quantile they fall into.\nclass BoostedTreesBucketizeOp : public OpKernel {\n public:\n  explicit BoostedTreesBucketizeOp(OpKernelConstruction* const context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(kNumFeaturesName, &num_features_));\n  }\n\n  void Compute(OpKernelContext* const context) override {\n    // Read float features list;\n    OpInputList float_features_list;\n    OP_REQUIRES_OK(\n        context, context->input_list(kFloatFeaturesName, &float_features_list));\n    OpInputList bucket_boundaries_list;\n    OP_REQUIRES_OK(context, context->input_list(kBucketBoundariesName,\n                                                &bucket_boundaries_list));\n    OP_REQUIRES(context,\n                tensorflow::TensorShapeUtils::IsVector(\n                    bucket_boundaries_list[0].shape()),\n                errors::InvalidArgument(\n                    strings::Printf(\"Buckets should be flat vectors.\")));\n    OpOutputList buckets_list;\n    OP_REQUIRES_OK(context, context->output_list(kBucketsName, &buckets_list));\n\n    auto do_quantile_get_quantiles = [&](const int64_t begin,\n                                         const int64_t end) {\n      // Iterating over all resources\n      for (int64_t feature_idx = begin; feature_idx < end; feature_idx++) {\n        const Tensor& values_tensor = float_features_list[feature_idx];\n        const int64_t num_values = values_tensor.dim_size(0);\n\n        Tensor* output_t = nullptr;\n        OP_REQUIRES_OK(context,\n                       buckets_list.allocate(\n                           feature_idx, TensorShape({num_values}), &output_t));\n        auto output = output_t->flat<int32>();\n\n        const std::vector<float>& bucket_boundaries_vector =\n            GetBuckets(feature_idx, bucket_boundaries_list);\n        auto flat_values = values_tensor.flat<float>();\n        const auto& iter_begin = bucket_boundaries_vector.begin();\n        const auto& iter_end = bucket_boundaries_vector.end();\n        for (int64_t instance = 0; instance < num_values; instance++) {\n          if (iter_begin == iter_end) {\n            output(instance) = 0;\n            continue;\n          }\n          const float value = flat_values(instance);\n          auto bucket_iter = std::lower_bound(iter_begin, iter_end, value);\n          if (bucket_iter == iter_end) {\n            --bucket_iter;\n          }\n          const int32_t bucket = static_cast<int32>(bucket_iter - iter_begin);\n          // Bucket id.\n          output(instance) = bucket;\n        }\n      }\n    };\n\n    // TODO(tanzheny): comment on the magic number.\n    const int64_t kCostPerUnit = 500 * num_features_;\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *context->device()->tensorflow_cpu_worker_threads();\n    Shard(worker_threads.num_threads, worker_threads.workers, num_features_,\n          kCostPerUnit, do_quantile_get_quantiles);\n  }\n\n private:\n  int64 num_features_;\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"BoostedTreesBucketize\").Device(DEVICE_CPU),\n                        BoostedTreesBucketizeOp);\n\n}  // namespace tensorflow"