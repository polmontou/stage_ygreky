"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/array_ops.cc.\n\n#ifdef INTEL_MKL\n#define EIGEN_USE_THREADS\n\n#include <math.h>\n\n#include \"mkldnn.hpp\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/meta_support.h\"\n#include \"tensorflow/core/kernels/no_op.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/util/mkl_util.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\n\ntemplate <typename Device, typename Toutput>\nclass MklRequantizePerChannelOp : public OpKernel {\n public:\n  explicit MklRequantizePerChannelOp(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"out_type\", &out_type_));\n    OP_REQUIRES(ctx, out_type_ == DT_QINT8 || out_type_ == DT_QUINT8,\n                errors::InvalidArgument(\n                    \"out_type must be qint8 or quint8, but got: \", out_type_));\n  }\n  virtual ~MklRequantizePerChannelOp() {}\n  void Compute(OpKernelContext* ctx) override {\n    try {\n      const Tensor& input = ctx->input(kInputTensorIndex);\n      OP_REQUIRES(\n          ctx, input.dims() == 4,\n          errors::InvalidArgument(\"Current RequantizePerChannel operator\"\n                                  \"supports 4D tensors only.\"));\n\n      const Tensor& input_min_vec = ctx->input(kInputMinVecIndex);\n      size_t depth = input_min_vec.NumElements();\n      float* input_min_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_min_vec.flat<float>().data()));\n\n      const Tensor& input_max_vec = ctx->input(kInputMaxVecIndex);\n      OP_REQUIRES(\n          ctx, input_max_vec.NumElements() == depth,\n          errors::InvalidArgument(\"input_max has incorrect size, expected \",\n                                  depth, \" was \", input_max_vec.NumElements()));\n      float* input_max_vec_data = (float*)const_cast<void*>(\n          static_cast<const void*>(input_max_vec.flat<float>().data()));\n\n      const Tensor& input_requested_min = ctx->input(this->kRequestMinIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_min must be a scalar\"));\n      const float input_requested_min_float =\n          input_requested_min.flat<float>()(0);\n\n      const Tensor& input_requested_max = ctx->input(this->kRequestMaxIndex);\n      OP_REQUIRES(\n          ctx, input_requested_min.NumElements() == 1,\n          errors::InvalidArgument(\"requested_output_max must be a scalar\"));\n      const float input_requested_max_float =\n          input_requested_max.flat<float>()(0);\n\n      if (out_type_ == DT_QINT8) {\n        OP_REQUIRES(ctx, input_requested_min_float < 0.0f,\n                    errors::InvalidArgument(\n                        \"If out_type is QINT8, requested_output_max must be \"\n                        \"non negative, got \",\n                        input_requested_min_float));\n      }\n\n      const float factor = (out_type_ == DT_QINT8) ? 127.0f : 255.0f;\n      const float requested_min_max =\n          std::max(std::abs(input_requested_min_float),\n                   std::abs(input_requested_max_float));\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(kOutputTensorIndex,\n                                               input.shape(), &output));\n\n      std::vector<float> scales(depth);\n      for (int i = 0; i < depth; ++i) {\n        float min_max_from_vec = std::max(std::abs(input_min_vec_data[i]),\n                                          std::abs(input_max_vec_data[i]));\n        scales[i] = factor * (min_max_from_vec / requested_min_max /\n                              static_cast<float>(1L << 31));\n      }\n\n      mkldnn::primitive_attr reorder_attr;\n      reorder_attr.set_output_scales(2, scales);\n\n      memory::dims dims_mkl_order =\n          TFShapeToMklDnnDimsInNCHW(input.shape(), FORMAT_NHWC);\n      memory::desc input_md = memory::desc(dims_mkl_order, MklDnnType<qint32>(),\n                                           memory::format_tag::nhwc);\n      memory::desc output_md =\n          (out_type_ == DT_QINT8)\n              ? memory::desc(dims_mkl_order, MklDnnType<qint8>(),\n                             memory::format_tag::nhwc)\n              : memory::desc(dims_mkl_order, MklDnnType<quint8>(),\n                             memory::format_tag::nhwc);\n\n      void* input_buf =\n          static_cast<void*>(const_cast<qint32*>(input.flat<qint32>().data()));\n      void* output_buf;\n      if (out_type_ == DT_QINT8) {\n        output_buf = static_cast<void*>(\n            const_cast<qint8*>(output->flat<qint8>().data()));\n      } else {\n        output_buf = static_cast<void*>(\n            const_cast<quint8*>(output->flat<quint8>().data()));\n      }\n\n      std::unique_ptr<memory> input_mem_prim(\n          new memory(input_md, cpu_engine_, input_buf));\n      std::unique_ptr<memory> output_mem_prim(\n          new memory(output_md, cpu_engine_, output_buf));\n\n      mkldnn::reorder::primitive_desc reorder_pd =\n          ReorderPd(cpu_engine_, input_mem_prim->get_desc(), cpu_engine_,\n                    output_mem_prim->get_desc(), reorder_attr);\n      std::shared_ptr<stream> reorder_stream;\n      MklDnnThreadPool eigen_tp(ctx);\n      reorder_stream.reset(CreateStream(&eigen_tp, cpu_engine_));\n      std::unordered_map<int, mkldnn::memory> reorder_args = {\n          {MKLDNN_ARG_FROM, *input_mem_prim},\n          {MKLDNN_ARG_TO, *output_mem_prim}};\n      std::unique_ptr<mkldnn::primitive> reorder_prim(\n          new mkldnn::reorder(reorder_pd));\n      reorder_prim->execute(*reorder_stream, reorder_args);\n\n      Tensor* output_min = nullptr;\n      Tensor* output_max = nullptr;\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMinIndex, {}, &output_min));\n      OP_REQUIRES_OK(ctx,\n                     ctx->allocate_output(kOutputMaxIndex, {}, &output_max));\n\n      output_min->flat<float>()(0) = input_requested_min_float;\n      output_max->flat<float>()(0) = input_requested_max_float;\n    } catch (mkldnn::error& e) {\n      string error_msg = \"Status: \" + std::to_string(e.status) +\n                         \", message: \" + std::string(e.message) + \", in file \" +\n                         std::string(__FILE__) + \":\" + std::to_string(__LINE__);\n      OP_REQUIRES_OK(\n          ctx, errors::Aborted(\"Operation received an exception:\", error_msg));\n    }\n  }\n\n private:\n  const int kInputTensorIndex = 0;\n  const int kInputMinVecIndex = 1;\n  const int kInputMaxVecIndex = 2;\n  const int kRequestMinIndex = 3;\n  const int kRequestMaxIndex = 4;\n  const int kOutputTensorIndex = 0;\n  const int kOutputMinIndex = 1;\n  const int kOutputMaxIndex = 2;\n  DataType out_type_;\n  engine cpu_engine_ = engine(engine::kind::cpu, 0);\n};\n\n// Registration for out_type: qint8\nREGISTER_KERNEL_BUILDER(Name(\"RequantizePerChannel\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<qint32>(\"T\")\n                            .TypeConstraint<qint8>(\"out_type\"),\n                        MklRequantizePerChannelOp<CPUDevice, qint8>);\n// Registration for out_type: quint8\nREGISTER_KERNEL_BUILDER(Name(\"RequantizePerChannel\")\n                            .Device(DEVICE_CPU)\n                            .TypeConstraint<qint32>(\"T\")\n                            .TypeConstraint<quint8>(\"out_type\"),\n                        MklRequantizePerChannelOp<CPUDevice, quint8>);\n\n}  // namespace tensorflow\n#endif  // INTEL_MKL"