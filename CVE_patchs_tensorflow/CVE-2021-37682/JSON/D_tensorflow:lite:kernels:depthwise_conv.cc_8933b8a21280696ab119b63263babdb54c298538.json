"diff --git a/tensorflow/lite/kernels/depthwise_conv.cc b/tensorflow/lite/kernels/depthwise_conv.cc\nindex c19e01cf33b..060b0827daf 100644\n--- a/tensorflow/lite/kernels/depthwise_conv.cc\n+++ b/tensorflow/lite/kernels/depthwise_conv.cc\n@@ -176,6 +176,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   if (data_type != kTfLiteFloat32) {\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                       kTfLiteAffineQuantization);\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);\n@@ -195,6 +196,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n   }\n \n   if (is_hybrid) {\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);\n@@ -495,6 +497,7 @@ TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n   op_params.weights_offset = 0;\n   op_params.float_activation_min = output_activation_min;\n   op_params.float_activation_max = output_activation_max;\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n   const auto* affine_quantization =\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n   if (kernel_type == kReference) {"