"diff --git a/tensorflow/lite/kernels/pooling.cc b/tensorflow/lite/kernels/pooling.cc\nindex 474bd3825f4..d54bd89b221 100644\n--- a/tensorflow/lite/kernels/pooling.cc\n+++ b/tensorflow/lite/kernels/pooling.cc\n@@ -117,117 +117,126 @@ TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n }\n \n template <KernelType kernel_type>\n-void AverageEvalFloat(TfLiteContext* context, TfLiteNode* node,\n-                      TfLitePoolParams* params, OpData* data,\n-                      const TfLiteTensor* input, TfLiteTensor* output) {\n+TfLiteStatus AverageEvalFloat(TfLiteContext* context, TfLiteNode* node,\n+                              TfLitePoolParams* params, OpData* data,\n+                              const TfLiteTensor* input, TfLiteTensor* output) {\n   float activation_min, activation_max;\n   CalculateActivationRange(params->activation, &activation_min,\n                            &activation_max);\n-#define TF_LITE_AVERAGE_POOL(type)                                       \\\n-  tflite::PoolParams op_params;                                          \\\n-  op_params.stride_height = params->stride_height;                       \\\n-  op_params.stride_width = params->stride_width;                         \\\n-  op_params.filter_height = params->filter_height;                       \\\n-  op_params.filter_width = params->filter_width;                         \\\n-  op_params.padding_values.height = data->padding.height;                \\\n-  op_params.padding_values.width = data->padding.width;                  \\\n-  op_params.float_activation_min = activation_min;                       \\\n-  op_params.float_activation_max = activation_max;                       \\\n-  type::AveragePool(op_params, GetTensorShape(input),                    \\\n-                    GetTensorData<float>(input), GetTensorShape(output), \\\n-                    GetTensorData<float>(output))\n+#define TF_LITE_AVERAGE_POOL(type)                                            \\\n+  tflite::PoolParams op_params;                                               \\\n+  op_params.stride_height = params->stride_height;                            \\\n+  op_params.stride_width = params->stride_width;                              \\\n+  op_params.filter_height = params->filter_height;                            \\\n+  op_params.filter_width = params->filter_width;                              \\\n+  op_params.padding_values.height = data->padding.height;                     \\\n+  op_params.padding_values.width = data->padding.width;                       \\\n+  op_params.float_activation_min = activation_min;                            \\\n+  op_params.float_activation_max = activation_max;                            \\\n+  TF_LITE_ENSURE(context, type::AveragePool(op_params, GetTensorShape(input), \\\n+                                            GetTensorData<float>(input),      \\\n+                                            GetTensorShape(output),           \\\n+                                            GetTensorData<float>(output)))\n   if (kernel_type == kReference) {\n     TF_LITE_AVERAGE_POOL(reference_ops);\n   } else {\n     TF_LITE_AVERAGE_POOL(optimized_ops);\n   }\n #undef TF_LITE_AVERAGE_POOL\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type>\n-void AverageEvalQuantizedUint8(TfLiteContext* context, TfLiteNode* node,\n-                               TfLitePoolParams* params, OpData* data,\n-                               const TfLiteTensor* input,\n-                               TfLiteTensor* output) {\n+TfLiteStatus AverageEvalQuantizedUint8(TfLiteContext* context, TfLiteNode* node,\n+                                       TfLitePoolParams* params, OpData* data,\n+                                       const TfLiteTensor* input,\n+                                       TfLiteTensor* output) {\n   int32_t activation_min;\n   int32_t activation_max;\n   (void)CalculateActivationRangeQuantized(context, params->activation, output,\n                                           &activation_min, &activation_max);\n-#define TF_LITE_AVERAGE_POOL(type)                                         \\\n-  tflite::PoolParams op_params;                                            \\\n-  op_params.stride_height = params->stride_height;                         \\\n-  op_params.stride_width = params->stride_width;                           \\\n-  op_params.filter_height = params->filter_height;                         \\\n-  op_params.filter_width = params->filter_width;                           \\\n-  op_params.padding_values.height = data->padding.height;                  \\\n-  op_params.padding_values.width = data->padding.width;                    \\\n-  op_params.quantized_activation_min = activation_min;                     \\\n-  op_params.quantized_activation_max = activation_max;                     \\\n-  type::AveragePool(op_params, GetTensorShape(input),                      \\\n-                    GetTensorData<uint8_t>(input), GetTensorShape(output), \\\n-                    GetTensorData<uint8_t>(output))\n+#define TF_LITE_AVERAGE_POOL(type)                                            \\\n+  tflite::PoolParams op_params;                                               \\\n+  op_params.stride_height = params->stride_height;                            \\\n+  op_params.stride_width = params->stride_width;                              \\\n+  op_params.filter_height = params->filter_height;                            \\\n+  op_params.filter_width = params->filter_width;                              \\\n+  op_params.padding_values.height = data->padding.height;                     \\\n+  op_params.padding_values.width = data->padding.width;                       \\\n+  op_params.quantized_activation_min = activation_min;                        \\\n+  op_params.quantized_activation_max = activation_max;                        \\\n+  TF_LITE_ENSURE(context, type::AveragePool(op_params, GetTensorShape(input), \\\n+                                            GetTensorData<uint8_t>(input),    \\\n+                                            GetTensorShape(output),           \\\n+                                            GetTensorData<uint8_t>(output)))\n   if (kernel_type == kReference) {\n     TF_LITE_AVERAGE_POOL(reference_ops);\n   } else {\n     TF_LITE_AVERAGE_POOL(optimized_ops);\n   }\n #undef TF_LITE_AVERAGE_POOL\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type>\n-void AverageEvalQuantizedInt8(TfLiteContext* context, TfLiteNode* node,\n-                              TfLitePoolParams* params, OpData* data,\n-                              const TfLiteTensor* input, TfLiteTensor* output) {\n+TfLiteStatus AverageEvalQuantizedInt8(TfLiteContext* context, TfLiteNode* node,\n+                                      TfLitePoolParams* params, OpData* data,\n+                                      const TfLiteTensor* input,\n+                                      TfLiteTensor* output) {\n   int32_t activation_min;\n   int32_t activation_max;\n \n   (void)CalculateActivationRangeQuantized(context, params->activation, output,\n                                           &activation_min, &activation_max);\n-#define TF_LITE_AVERAGE_POOL(type)                                        \\\n-  tflite::PoolParams op_params;                                           \\\n-  op_params.stride_height = params->stride_height;                        \\\n-  op_params.stride_width = params->stride_width;                          \\\n-  op_params.filter_height = params->filter_height;                        \\\n-  op_params.filter_width = params->filter_width;                          \\\n-  op_params.padding_values.height = data->padding.height;                 \\\n-  op_params.padding_values.width = data->padding.width;                   \\\n-  op_params.quantized_activation_min = activation_min;                    \\\n-  op_params.quantized_activation_max = activation_max;                    \\\n-  type::AveragePool(op_params, GetTensorShape(input),                     \\\n-                    GetTensorData<int8_t>(input), GetTensorShape(output), \\\n-                    GetTensorData<int8_t>(output))\n+#define TF_LITE_AVERAGE_POOL(type)                                            \\\n+  tflite::PoolParams op_params;                                               \\\n+  op_params.stride_height = params->stride_height;                            \\\n+  op_params.stride_width = params->stride_width;                              \\\n+  op_params.filter_height = params->filter_height;                            \\\n+  op_params.filter_width = params->filter_width;                              \\\n+  op_params.padding_values.height = data->padding.height;                     \\\n+  op_params.padding_values.width = data->padding.width;                       \\\n+  op_params.quantized_activation_min = activation_min;                        \\\n+  op_params.quantized_activation_max = activation_max;                        \\\n+  TF_LITE_ENSURE(context, type::AveragePool(op_params, GetTensorShape(input), \\\n+                                            GetTensorData<int8_t>(input),     \\\n+                                            GetTensorShape(output),           \\\n+                                            GetTensorData<int8_t>(output)))\n   if (kernel_type == kReference) {\n     TF_LITE_AVERAGE_POOL(reference_integer_ops);\n   } else {\n     TF_LITE_AVERAGE_POOL(optimized_integer_ops);\n   }\n #undef TF_LITE_AVERAGE_POOL\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type>\n-void AverageEvalQuantizedInt16(TfLiteContext* context, TfLiteNode* node,\n-                               TfLitePoolParams* params, OpData* data,\n-                               const TfLiteTensor* input,\n-                               TfLiteTensor* output) {\n+TfLiteStatus AverageEvalQuantizedInt16(TfLiteContext* context, TfLiteNode* node,\n+                                       TfLitePoolParams* params, OpData* data,\n+                                       const TfLiteTensor* input,\n+                                       TfLiteTensor* output) {\n   int32_t activation_min;\n   int32_t activation_max;\n   CalculateActivationRangeQuantized(context, params->activation, output,\n                                     &activation_min, &activation_max);\n-#define TF_LITE_AVERAGE_POOL(type)                                         \\\n-  tflite::PoolParams op_params;                                            \\\n-  op_params.stride_height = params->stride_height;                         \\\n-  op_params.stride_width = params->stride_width;                           \\\n-  op_params.filter_height = params->filter_height;                         \\\n-  op_params.filter_width = params->filter_width;                           \\\n-  op_params.padding_values.height = data->padding.height;                  \\\n-  op_params.padding_values.width = data->padding.width;                    \\\n-  op_params.quantized_activation_min = activation_min;                     \\\n-  op_params.quantized_activation_max = activation_max;                     \\\n-  type::AveragePool(op_params, GetTensorShape(input),                      \\\n-                    GetTensorData<int16_t>(input), GetTensorShape(output), \\\n-                    GetTensorData<int16_t>(output))\n+#define TF_LITE_AVERAGE_POOL(type)                                            \\\n+  tflite::PoolParams op_params;                                               \\\n+  op_params.stride_height = params->stride_height;                            \\\n+  op_params.stride_width = params->stride_width;                              \\\n+  op_params.filter_height = params->filter_height;                            \\\n+  op_params.filter_width = params->filter_width;                              \\\n+  op_params.padding_values.height = data->padding.height;                     \\\n+  op_params.padding_values.width = data->padding.width;                       \\\n+  op_params.quantized_activation_min = activation_min;                        \\\n+  op_params.quantized_activation_max = activation_max;                        \\\n+  TF_LITE_ENSURE(context, type::AveragePool(op_params, GetTensorShape(input), \\\n+                                            GetTensorData<int16_t>(input),    \\\n+                                            GetTensorShape(output),           \\\n+                                            GetTensorData<int16_t>(output)))\n   TF_LITE_AVERAGE_POOL(reference_integer_ops);\n #undef TF_LITE_AVERAGE_POOL\n+  return kTfLiteOk;\n }\n \n template <KernelType kernel_type>\n@@ -380,20 +389,17 @@ TfLiteStatus AverageEval(TfLiteContext* context, TfLiteNode* node) {\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n   switch (input->type) {  // Already know in/out types are same.\n     case kTfLiteFloat32:\n-      AverageEvalFloat<kernel_type>(context, node, params, data, input, output);\n-      break;\n+      return AverageEvalFloat<kernel_type>(context, node, params, data, input,\n+                                           output);\n     case kTfLiteUInt8:\n-      AverageEvalQuantizedUint8<kernel_type>(context, node, params, data, input,\n-                                             output);\n-      break;\n+      return AverageEvalQuantizedUint8<kernel_type>(context, node, params, data,\n+                                                    input, output);\n     case kTfLiteInt8:\n-      AverageEvalQuantizedInt8<kernel_type>(context, node, params, data, input,\n-                                            output);\n-      break;\n+      return AverageEvalQuantizedInt8<kernel_type>(context, node, params, data,\n+                                                   input, output);\n     case kTfLiteInt16:\n-      AverageEvalQuantizedInt16<kernel_type>(context, node, params, data, input,\n-                                             output);\n-      break;\n+      return AverageEvalQuantizedInt16<kernel_type>(context, node, params, data,\n+                                                    input, output);\n     default:\n       TF_LITE_KERNEL_LOG(context, \"Type %s not currently supported.\",\n                          TfLiteTypeGetName(input->type));"