"/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <algorithm>\n#include <cmath>\n#include <cstdlib>\n#include <functional>\n#include <iterator>\n#include <limits>\n#include <random>\n#include <string>\n#include <vector>\n\n#include <gtest/gtest.h>\n#include \"tensorflow/lite/kernels/internal/optimized/integer_ops/pooling.h\"\n#include \"tensorflow/lite/kernels/internal/reference/integer_ops/pooling.h\"\n#include \"tensorflow/lite/kernels/internal/test_util.h\"\n\nnamespace tflite {\nnamespace {\n\n// Runs the reference and optimized AveragePool functions and asserts the values\n// are the same.\nvoid RunOneAveragePoolTest(const PoolParams& params,\n                           const RuntimeShape& input_shape,\n                           const int8* input_data,\n                           const RuntimeShape& output_shape) {\n  const int buffer_size = output_shape.FlatSize();\n  std::vector<int8> optimized_averagePool_output(buffer_size);\n  std::vector<int8> reference_averagePool_output(buffer_size);\n\n  reference_integer_ops::AveragePool(params, input_shape, input_data,\n                                     output_shape,\n                                     reference_averagePool_output.data());\n  optimized_integer_ops::AveragePool(params, input_shape, input_data,\n                                     output_shape,\n                                     optimized_averagePool_output.data());\n\n  for (int i = 0; i < buffer_size; i++) {\n    EXPECT_TRUE(reference_averagePool_output[i] ==\n                optimized_averagePool_output[i]);\n  }\n}\n\n// Creates random input shape (batch, height, width, depth), then computes\n// output shape based on value of `padding_same`:\n// `padding_same` == true, calculate output with padding == \"SAME\"\n// `padding_same` == false, calculate output with padding == \"VALID\"\n// With input/output shapes computed, fills the input data and calls the\n// test function.\nvoid CreateDataAndRunAveragePool(bool padding_same) {\n  const int batch = UniformRandomInt(1, 2);\n  const int input_depth = UniformRandomInt(1, 700);\n  const int output_depth = input_depth;\n  const int input_width_offset = UniformRandomInt(1, 30);\n  const int input_height_offset = UniformRandomInt(1, 30);\n  const int stride_width = UniformRandomInt(1, 10);\n  const int stride_height = UniformRandomInt(1, 10);\n  const int filter_width = UniformRandomInt(1, 10);\n  const int filter_height = UniformRandomInt(1, 10);\n  const int input_width = input_width_offset + filter_width;\n  const int input_height = input_height_offset + filter_height;\n  const int output_width =\n      padding_same ? (input_width + stride_width - 1) / stride_width\n                   : (input_width - filter_width + stride_width) / stride_width;\n  const int output_height =\n      padding_same\n          ? (input_height + stride_height - 1) / stride_height\n          : (input_height - filter_height + stride_height) / stride_height;\n\n  auto input_shape =\n      RuntimeShape({batch, input_height, input_width, input_depth});\n  auto output_shape =\n      RuntimeShape({batch, output_height, output_width, output_depth});\n  const int buffer_size = input_shape.FlatSize();\n  std::vector<int8> input_data(buffer_size);\n  FillRandom(&input_data);\n\n  PoolParams params;\n  params.stride_height = stride_height;\n  params.stride_width = stride_width;\n  params.filter_height = filter_height;\n  params.filter_width = filter_width;\n  params.quantized_activation_min =\n      static_cast<int8_t>(std::numeric_limits<int8_t>::lowest());\n  params.quantized_activation_max =\n      static_cast<int8_t>(std::numeric_limits<int8_t>::max());\n  auto compute_padding = [](int stride, int in_size, int filter_size,\n                            int out_size) {\n    int padding = ((out_size - 1) * stride + filter_size - in_size) / 2;\n    return padding > 0 ? padding : 0;\n  };\n  params.padding_values.width =\n      compute_padding(stride_width, input_width, filter_width, output_width);\n  params.padding_values.height = compute_padding(stride_height, input_height,\n                                                 filter_height, output_height);\n  RunOneAveragePoolTest(params, input_shape, input_data.data(), output_shape);\n}\n\nTEST(TestAveragePool, SymmetricQuantAveragePool) {\n  const int kTestsToRun = 10;\n  for (int i = 0; i < kTestsToRun; i++) {\n    CreateDataAndRunAveragePool(/*padding_same=*/true);\n    CreateDataAndRunAveragePool(/*padding_same=*/false);\n  }\n}\n\n// Creates random input shape (batch, height, width, depth), then computes\n// output shape based on value of `padding_same`:\n// `padding_same` == true, calculate output with padding == \"SAME\"\n// `padding_same` == false, calculate output with padding == \"VALID\"\n// With input/output shapes computed, fills the input data and calls the\n// test function.\nvoid CreateExtremalDataAndRunAveragePool(bool padding_same) {\n  const int batch = UniformRandomInt(1, 2);\n  const int input_depth = UniformRandomInt(1, 700);\n  const int output_depth = input_depth;\n  const int input_width_offset = UniformRandomInt(1, 30);\n  const int input_height_offset = UniformRandomInt(1, 30);\n  const int stride_width = UniformRandomInt(1, 128);\n  const int stride_height = UniformRandomInt(1, 128);\n  const int filter_width = UniformRandomInt(1, 28);\n  const int filter_height = UniformRandomInt(1, 28);\n  if (filter_width * filter_height > 64) {\n    std::cout << \"should test 32 version\" << std::endl;\n  }\n  const int input_width = input_width_offset + filter_width;\n  const int input_height = input_height_offset + filter_height;\n  const int output_width =\n      padding_same ? (input_width + stride_width - 1) / stride_width\n                   : (input_width - filter_width + stride_width) / stride_width;\n  const int output_height =\n      padding_same\n          ? (input_height + stride_height - 1) / stride_height\n          : (input_height - filter_height + stride_height) / stride_height;\n\n  auto input_shape =\n      RuntimeShape({batch, input_height, input_width, input_depth});\n  auto output_shape =\n      RuntimeShape({batch, output_height, output_width, output_depth});\n\n  PoolParams params;\n  params.stride_height = stride_height;\n  params.stride_width = stride_width;\n  params.filter_height = filter_height;\n  params.filter_width = filter_width;\n  params.quantized_activation_min =\n      static_cast<int8_t>(std::numeric_limits<int8_t>::lowest());\n  params.quantized_activation_max =\n      static_cast<int8_t>(std::numeric_limits<int8_t>::max());\n  auto compute_padding = [](int stride, int in_size, int filter_size,\n                            int out_size) {\n    int padding = ((out_size - 1) * stride + filter_size - in_size) / 2;\n    return padding > 0 ? padding : 0;\n  };\n  params.padding_values.width =\n      compute_padding(stride_width, input_width, filter_width, output_width);\n  params.padding_values.height = compute_padding(stride_height, input_height,\n                                                 filter_height, output_height);\n\n  const int buffer_size = input_shape.FlatSize();\n  std::vector<int8> input_data(buffer_size);\n\n  // Test small values\n  int8 min = std::numeric_limits<int8>::min();\n  int8 max = std::numeric_limits<int8>::min() + 10;\n  FillRandom(&input_data, min, max);\n  RunOneAveragePoolTest(params, input_shape, input_data.data(), output_shape);\n\n  // Test large values\n  min = std::numeric_limits<int8>::max() - 10;\n  max = std::numeric_limits<int8>::max();\n  FillRandom(&input_data, min, max);\n  RunOneAveragePoolTest(params, input_shape, input_data.data(), output_shape);\n}\n\nTEST(TestAveragePool, SymmetricQuantExtremalAveragePool) {\n  CreateExtremalDataAndRunAveragePool(/*padding_same=*/true);\n  CreateExtremalDataAndRunAveragePool(/*padding_same=*/false);\n}\n\n}  // namespace\n}  // namespace tflite"