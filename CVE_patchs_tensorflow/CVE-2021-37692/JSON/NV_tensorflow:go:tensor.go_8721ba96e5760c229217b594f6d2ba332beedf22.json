"/*\nCopyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage tensorflow\n\n/*\n#include <stdlib.h>\n#include <string.h>\n#include \"tensorflow/c/c_api.h\"\n\nvoid toNewTString(_GoString_ gstr, TF_TString *tstr) {\n    TF_TString_Init(tstr);\n    TF_TString_Copy(tstr, _GoStringPtr(gstr), _GoStringLen(gstr));\n}\n*/\nimport \"C\"\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/bits\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"unsafe\"\n)\n\n// DataType holds the type for a scalar value.  E.g., one slot in a tensor.\ntype DataType C.TF_DataType\n\n// Types of scalar values in the TensorFlow type system.\nconst (\n\tFloat      DataType = C.TF_FLOAT\n\tDouble     DataType = C.TF_DOUBLE\n\tInt32      DataType = C.TF_INT32\n\tUint32     DataType = C.TF_UINT32\n\tUint8      DataType = C.TF_UINT8\n\tInt16      DataType = C.TF_INT16\n\tInt8       DataType = C.TF_INT8\n\tString     DataType = C.TF_STRING\n\tComplex64  DataType = C.TF_COMPLEX64\n\tComplex    DataType = C.TF_COMPLEX\n\tInt64      DataType = C.TF_INT64\n\tUint64     DataType = C.TF_UINT64\n\tBool       DataType = C.TF_BOOL\n\tQint8      DataType = C.TF_QINT8\n\tQuint8     DataType = C.TF_QUINT8\n\tQint32     DataType = C.TF_QINT32\n\tBfloat16   DataType = C.TF_BFLOAT16\n\tQint16     DataType = C.TF_QINT16\n\tQuint16    DataType = C.TF_QUINT16\n\tUint16     DataType = C.TF_UINT16\n\tComplex128 DataType = C.TF_COMPLEX128\n\tHalf       DataType = C.TF_HALF\n)\n\n// Tensor holds a multi-dimensional array of elements of a single data type.\ntype Tensor struct {\n\tc     *C.TF_Tensor\n\tshape []int64\n}\n\n// NewTensor converts from a Go value to a Tensor. Valid values are scalars,\n// slices, and arrays. Every element of a slice must have the same length so\n// that the resulting Tensor has a valid shape.\nfunc NewTensor(value interface{}) (*Tensor, error) {\n\tval := reflect.ValueOf(value)\n\tshape, dataType, err := shapeAndDataTypeOf(val)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnflattened := numElements(shape)\n\tnbytes := TypeOf(dataType, nil).Size() * uintptr(nflattened)\n\tif dataType == String {\n\t\tnbytes = uintptr(nflattened) * C.sizeof_TF_TString\n\t}\n\tvar shapePtr *C.int64_t\n\tif len(shape) > 0 {\n\t\tshapePtr = (*C.int64_t)(unsafe.Pointer(&shape[0]))\n\t}\n\tt := &Tensor{\n\t\tc:     C.TF_AllocateTensor(C.TF_DataType(dataType), shapePtr, C.int(len(shape)), C.size_t(nbytes)),\n\t\tshape: shape,\n\t}\n\n\traw := tensorData(t.c)\n\n\tdefer runtime.SetFinalizer(t, func(t *Tensor) {\n\t\tif dataType == String {\n\t\t\tt.clearTStrings(raw, int64(nbytes/C.sizeof_TF_TString))\n\t\t}\n\n\t\tt.finalize()\n\t})\n\n\tbuf := bytes.NewBuffer(raw[:0:len(raw)])\n\n\tif isAllArray(val.Type()) {\n\t\t// We have arrays all the way down, or just primitive types. We can\n\t\t// just copy the memory in as it is all contiguous.\n\t\tif _, err := copyPtr(buf, unpackEFace(value).data, int(val.Type().Size())); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\t// When there are slices involved the memory for each leaf slice may\n\t\t// not be contiguous with the others or in the order we might\n\t\t// expect, so we need to work our way down to each slice of\n\t\t// primitives and copy them individually\n\t\tif n, err := encodeTensorWithSlices(buf, val, shape); err != nil {\n\t\t\t// Set nbytes to count of bytes written for deferred call to\n\t\t\t// runtime.SetFinalizer\n\t\t\tnbytes = uintptr(n)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif uintptr(buf.Len()) != nbytes {\n\t\treturn nil, bug(\"NewTensor incorrectly calculated the size of a tensor with type %v and shape %v as %v bytes instead of %v\", dataType, shape, nbytes, buf.Len())\n\t}\n\treturn t, nil\n}\n\n// isAllArray returns true if type is a primitive type or an array of primitive\n// types or an array of ... etc.. When this is true the data we want is\n// contiguous in RAM.\nfunc isAllArray(typ reflect.Type) bool {\n\tswitch typ.Kind() {\n\tcase reflect.String:\n\t\treturn false\n\tcase reflect.Slice:\n\t\treturn false\n\tcase reflect.Array:\n\t\treturn isAllArray(typ.Elem())\n\tdefault:\n\t\t// We know the type is slices/arrays of slices/arrays of primitive types.\n\t\treturn true\n\t}\n}\n\n// eface defines what an interface type actually is: a pointer to type\n// information about the encapsulated type and a pointer to the encapsulated\n// value.\ntype eface struct {\n\trtype unsafe.Pointer\n\tdata  unsafe.Pointer\n}\n\n// unpackEFace gives us an effient way to get us a pointer to the value carried\n// in an interface. If you wrap a pointer type in an interface then the pointer\n// is directly stored in the interface struct. If you wrap a value type in an\n// interface then the compiler copies the value into a newly allocated piece of\n// memory and stores a pointer to that memory in the interface. So we're\n// guaranteed to get a pointer. Go reflection doesn't expose the pointer to\n// value types straightforwardly as it doesn't want you to think you have a\n// reference to the original value. But we just want a pointer to make it\n// efficient to read the value, so cheating like this should be safe and\n// reasonable.\nfunc unpackEFace(obj interface{}) *eface {\n\treturn (*eface)(unsafe.Pointer(&obj))\n}\n\n// ReadTensor constructs a Tensor with the provided type and shape from the\n// serialized tensor contents in r.\n//\n// See also WriteContentsTo.\nfunc ReadTensor(dataType DataType, shape []int64, r io.Reader) (*Tensor, error) {\n\tif err := isTensorSerializable(dataType); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar shapePtr *C.int64_t\n\tif len(shape) > 0 {\n\t\tfor _, dim := range shape {\n\t\t\tif dim < 0 {\n\t\t\t\treturn nil, fmt.Errorf(\"all shape dimentions should be non-negative: %v\", shape)\n\t\t\t}\n\t\t}\n\t\tshapePtr = (*C.int64_t)(unsafe.Pointer(&shape[0]))\n\t}\n\n\tnbytes := TypeOf(dataType, nil).Size() * uintptr(numElements(shape))\n\tt := &Tensor{\n\t\tc:     C.TF_AllocateTensor(C.TF_DataType(dataType), shapePtr, C.int(len(shape)), C.size_t(nbytes)),\n\t\tshape: shape,\n\t}\n\truntime.SetFinalizer(t, (*Tensor).finalize)\n\traw := tensorData(t.c)\n\tif _, err := io.ReadFull(r, raw); err != nil {\n\t\treturn nil, err\n\t}\n\treturn t, nil\n}\n\n// newTensorFromC takes ownership of c and returns the owning Tensor.\nfunc newTensorFromC(c *C.TF_Tensor) *Tensor {\n\tvar shape []int64\n\tif ndims := int(C.TF_NumDims(c)); ndims > 0 {\n\t\tshape = make([]int64, ndims)\n\t}\n\tfor i := range shape {\n\t\tshape[i] = int64(C.TF_Dim(c, C.int(i)))\n\t}\n\tt := &Tensor{c: c, shape: shape}\n\truntime.SetFinalizer(t, (*Tensor).finalize)\n\treturn t\n}\n\nfunc (t *Tensor) clearTStrings(raw []byte, n int64) {\n\ttstrs := (*(*[]C.TF_TString)(unsafe.Pointer(&raw)))[:n]\n\n\tfor _, tstr := range tstrs {\n\t\tC.TF_TString_Dealloc(&tstr)\n\t}\n}\n\nfunc (t *Tensor) finalize() { C.TF_DeleteTensor(t.c) }\n\n// DataType returns the scalar datatype of the Tensor.\nfunc (t *Tensor) DataType() DataType { return DataType(C.TF_TensorType(t.c)) }\n\n// Shape returns the shape of the Tensor.\nfunc (t *Tensor) Shape() []int64 { return t.shape }\n\n// Reshape  updates tensor's shape in place if this is possible or returns an error otherwise.\nfunc (t *Tensor) Reshape(newShape []int64) error {\n\toldShapeSize := numElements(t.shape)\n\tnewShapeSize := numElements(newShape)\n\n\tif oldShapeSize != newShapeSize {\n\t\treturn fmt.Errorf(\"unable to convert shape %v (num_elements: %d) into shape %v (num_elements: %d)\", t.shape, oldShapeSize, newShape, newShapeSize)\n\t}\n\n\tif len(newShape) == 0 {\n\t\treturn nil\n\t}\n\n\tvar shapePtr *C.int64_t\n\tshapePtr = (*C.int64_t)(unsafe.Pointer(&newShape[0]))\n\n\tstatus := newStatus()\n\tC.TF_TensorBitcastFrom(t.c, C.TF_TensorType(t.c), t.c, shapePtr, C.int(len(newShape)), status.c)\n\n\tif err := status.Err(); err != nil {\n\t\treturn err\n\t}\n\tt.shape = newShape\n\treturn nil\n}\n\n// Value converts the Tensor to a Go value. For now, not all Tensor types are\n// supported, and this function may panic if it encounters an unsupported\n// DataType.\n//\n// The type of the output depends on the Tensor type and dimensions.\n// For example:\n// Tensor(int64, 0): int64\n// Tensor(float64, 3): [][][]float64\nfunc (t *Tensor) Value() interface{} {\n\traw := tensorData(t.c)\n\tshape := t.Shape()\n\tdt := t.DataType()\n\treturn decodeTensor(raw, shape, dt).Interface()\n}\n\nfunc decodeTensor(raw []byte, shape []int64, dt DataType) reflect.Value {\n\t// Create a 1-dimensional slice of the base large enough for the data and\n\t// copy the data in.\n\tn := int(numElements(shape))\n\n\tvar (\n\t\tslice reflect.Value\n\t\ttyp   reflect.Type\n\t)\n\tif dt == String {\n\t\tstrs, err := decodeOneDimString(raw, n)\n\t\tif err != nil {\n\t\t\tpanic(bug(\"unable to decode string with shape %v: %v\", shape, err))\n\t\t}\n\t\tslice = reflect.ValueOf(strs)\n\t\ttyp = slice.Type()\n\t} else {\n\t\ttyp = typeForDataType(dt)\n\t\tl := n * int(typ.Size())\n\t\ttyp = reflect.SliceOf(typ)\n\t\tslice = reflect.MakeSlice(typ, n, n)\n\t\tbaseBytes := *(*[]byte)(unsafe.Pointer(&sliceHeader{\n\t\t\tData: unsafe.Pointer(slice.Pointer()),\n\t\t\tLen:  l,\n\t\t\tCap:  l,\n\t\t}))\n\t\tcopy(baseBytes, raw)\n\t}\n\n\t// Now we have the data in place in the base slice we can add the\n\t// dimensions. We want to walk backwards through the shape. If the shape is\n\t// length 1 or 0 then we're already done.\n\tif len(shape) == 0 {\n\t\treturn slice.Index(0)\n\t}\n\tif len(shape) == 1 {\n\t\treturn slice\n\t}\n\t// We have a special case if the tensor has no data. Our backing slice is\n\t// empty, but we still want to create slices following the shape. In this\n\t// case only the final part of the shape will be 0 and we want to recalculate\n\t// n at this point ignoring that 0.\n\t// For example if our shape is 3 * 2 * 0 then n will be zero, but we still\n\t// want 6 zero length slices to group as follows.\n\t// {{} {}} {{} {}} {{} {}}\n\tif n == 0 {\n\t\tn = int(numElements(shape[:len(shape)-1]))\n\t}\n\tfor i := len(shape) - 2; i >= 0; i-- {\n\t\tunderlyingSize := typ.Elem().Size()\n\t\ttyp = reflect.SliceOf(typ)\n\t\tsubsliceLen := int(shape[i+1])\n\t\tif subsliceLen != 0 {\n\t\t\tn = n / subsliceLen\n\t\t}\n\t\t// Just using reflection it is difficult to avoid unnecessary\n\t\t// allocations while setting up the sub-slices as the Slice function on\n\t\t// a slice Value allocates. So we end up doing pointer arithmetic!\n\t\t// Pointer() on a slice gives us access to the data backing the slice.\n\t\t// We insert slice headers directly into this data.\n\t\tdata := unsafe.Pointer(slice.Pointer())\n\t\tnextSlice := reflect.MakeSlice(typ, n, n)\n\n\t\tfor j := 0; j < n; j++ {\n\t\t\t// This is equivalent to nSlice[j] = slice[j*subsliceLen: (j+1)*subsliceLen]\n\t\t\tsetSliceInSlice(nextSlice, j, sliceHeader{\n\t\t\t\tData: unsafe.Pointer(uintptr(data) + (uintptr(j*subsliceLen) * underlyingSize)),\n\t\t\t\tLen:  subsliceLen,\n\t\t\t\tCap:  subsliceLen,\n\t\t\t})\n\t\t}\n\n\t\tslice = nextSlice\n\t}\n\treturn slice\n}\n\n// setSliceInSlice sets slice[index] = content.\nfunc setSliceInSlice(slice reflect.Value, index int, content sliceHeader) {\n\tconst sliceSize = unsafe.Sizeof(sliceHeader{})\n\t// We must cast slice.Pointer to uninptr & back again to avoid GC issues.\n\t// See https://github.com/google/go-cmp/issues/167#issuecomment-546093202\n\t*(*sliceHeader)(unsafe.Pointer(uintptr(unsafe.Pointer(slice.Pointer())) + (uintptr(index) * sliceSize))) = content\n}\n\n// decodeOneDimString decodes a string tensor into a one-dimensional []string.\nfunc decodeOneDimString(raw []byte, nStrings int) ([]string, error) {\n\tstrs := make([]string, nStrings)\n\ttstrs := (*(*[]C.TF_TString)(unsafe.Pointer(&raw)))[:nStrings]\n\n\tfor i, tstr := range tstrs {\n\t\tdst := C.TF_TString_GetDataPointer(&tstr)\n\t\tdstLen := C.TF_TString_GetSize(&tstr)\n\n\t\tstrs[i] = C.GoStringN(dst, C.int(dstLen))\n\t}\n\n\treturn strs, nil\n}\n\n// WriteContentsTo writes the serialized contents of t to w.\n//\n// Returns the number of bytes written. See ReadTensor for\n// reconstructing a Tensor from the serialized form.\n//\n// WARNING: WriteContentsTo is not comprehensive and will fail\n// if t.DataType() is non-numeric (e.g., String). See\n// https://github.com/tensorflow/tensorflow/issues/6003.\nfunc (t *Tensor) WriteContentsTo(w io.Writer) (int64, error) {\n\tif err := isTensorSerializable(t.DataType()); err != nil {\n\t\treturn 0, err\n\t}\n\treturn io.Copy(w, bytes.NewReader(tensorData(t.c)))\n}\n\nfunc tensorData(c *C.TF_Tensor) []byte {\n\t// See: https://github.com/golang/go/wiki/cgo#turning-c-arrays-into-go-slices\n\tcbytes := C.TF_TensorData(c)\n\tif cbytes == nil {\n\t\treturn nil\n\t}\n\tlength := int(C.TF_TensorByteSize(c))\n\tvar slice []byte\n\tif unsafe.Sizeof(unsafe.Pointer(nil)) == 8 {\n\t\tslice = (*[1<<50 - 1]byte)(unsafe.Pointer(cbytes))[:length:length]\n\t} else {\n\t\tslice = (*[1 << 30]byte)(unsafe.Pointer(cbytes))[:length:length]\n\t}\n\treturn slice\n}\n\nvar types = []struct {\n\ttyp      reflect.Type\n\tdataType C.TF_DataType\n}{\n\t{reflect.TypeOf(float32(0)), C.TF_FLOAT},\n\t{reflect.TypeOf(float64(0)), C.TF_DOUBLE},\n\t{reflect.TypeOf(int32(0)), C.TF_INT32},\n\t{reflect.TypeOf(uint32(0)), C.TF_UINT32},\n\t{reflect.TypeOf(uint8(0)), C.TF_UINT8},\n\t{reflect.TypeOf(int16(0)), C.TF_INT16},\n\t{reflect.TypeOf(int8(0)), C.TF_INT8},\n\t{reflect.TypeOf(\"\"), C.TF_STRING},\n\t{reflect.TypeOf(complex(float32(0), float32(0))), C.TF_COMPLEX64},\n\t{reflect.TypeOf(int64(0)), C.TF_INT64},\n\t{reflect.TypeOf(uint64(0)), C.TF_UINT64},\n\t{reflect.TypeOf(false), C.TF_BOOL},\n\t{reflect.TypeOf(uint16(0)), C.TF_UINT16},\n\t{reflect.TypeOf(complex(float64(0), float64(0))), C.TF_COMPLEX128},\n\t// TODO(apassos): support DT_RESOURCE representation in go.\n\t// TODO(keveman): support DT_VARIANT representation in go.\n}\n\n// shapeAndDataTypeOf returns the data type and shape of the Tensor\n// corresponding to a Go type.\nfunc shapeAndDataTypeOf(val reflect.Value) (shape []int64, dt DataType, err error) {\n\ttyp := val.Type()\n\tfor typ.Kind() == reflect.Array || typ.Kind() == reflect.Slice {\n\t\tshape = append(shape, int64(val.Len()))\n\t\tif val.Len() > 0 {\n\t\t\t// In order to check tensor structure properly in general case we need to iterate over all slices of the tensor to check sizes match\n\t\t\t// Since we already going to iterate over all elements in encodeTensor() let's\n\t\t\t// 1) do the actual check in encodeTensor() to save some cpu cycles here\n\t\t\t// 2) assume the shape is represented by lengths of elements with zero index in each dimension\n\t\t\tval = val.Index(0)\n\t\t}\n\t\ttyp = typ.Elem()\n\t}\n\tfor _, t := range types {\n\t\tif typ.Kind() == t.typ.Kind() {\n\t\t\treturn shape, DataType(t.dataType), nil\n\t\t}\n\t}\n\treturn shape, dt, fmt.Errorf(\"unsupported type %v\", typ)\n}\n\nfunc typeForDataType(dt DataType) reflect.Type {\n\tfor _, t := range types {\n\t\tif dt == DataType(t.dataType) {\n\t\t\treturn t.typ\n\t\t}\n\t}\n\tpanic(bug(\"DataType %v is not supported (see https://www.tensorflow.org/code/tensorflow/core/framework/types.proto)\", dt))\n}\n\n// TypeOf converts from a DataType and Shape to the equivalent Go type.\nfunc TypeOf(dt DataType, shape []int64) reflect.Type {\n\tret := typeForDataType(dt)\n\tfor range shape {\n\t\tret = reflect.SliceOf(ret)\n\t}\n\treturn ret\n}\n\nfunc numElements(shape []int64) int64 {\n\tn := int64(1)\n\tfor _, d := range shape {\n\t\tn *= d\n\t}\n\treturn n\n}\n\n// sizeVarUint determines how many bytes it would take to encode the int v as\n// an unsigned varint\nfunc sizeVarUint(v uint64) int {\n\tif v < 0x80 {\n\t\treturn 1\n\t}\n\tbits := bits.Len64(v)\n\treturn (bits + 6) / 7\n}\n\n// encodeTensorWithSlices writes v to the specified buffer using the format specified in\n// c_api.h. Use stringEncoder for String tensors.\nfunc encodeTensorWithSlices(w *bytes.Buffer, v reflect.Value, shape []int64) (int, error) {\n\t// If current dimension is a slice, verify that it has the expected size\n\t// Go's type system makes that guarantee for arrays.\n\tif v.Kind() == reflect.Slice {\n\t\texpected := int(shape[0])\n\t\tif v.Len() != expected {\n\t\t\treturn 0, fmt.Errorf(\"mismatched slice lengths: %d and %d\", v.Len(), expected)\n\t\t}\n\t} else if v.Kind() == reflect.String {\n\t\ts := v.Interface().(string)\n\t\tvar tstr C.TF_TString\n\t\tC.toNewTString(s, &tstr)\n\t\tptr := unsafe.Pointer(&tstr)\n\t\treturn copyPtr(w, ptr, C.sizeof_TF_TString)\n\t} else if v.Kind() != reflect.Array {\n\t\treturn 0, fmt.Errorf(\"unsupported type %v\", v.Type())\n\t}\n\n\t// Once we have just a single dimension we can just copy the data\n\tif len(shape) == 1 && v.Len() > 0 && v.Index(0).Kind() != reflect.String {\n\t\telt := v.Index(0)\n\t\tif !elt.CanAddr() {\n\t\t\tpanic(\"cannot take address\")\n\t\t}\n\t\tptr := unsafe.Pointer(elt.Addr().Pointer())\n\t\treturn copyPtr(w, ptr, v.Len()*int(elt.Type().Size()))\n\t}\n\n\tn := 0\n\tsubShape := shape[1:]\n\tfor i := 0; i < v.Len(); i++ {\n\t\tj, err := encodeTensorWithSlices(w, v.Index(i), subShape)\n\t\tif err != nil {\n\t\t\treturn n + j, err\n\t\t}\n\t\tn += j\n\t}\n\n\treturn n, nil\n}\n\n// It isn't safe to use reflect.SliceHeader as it uses a uintptr for Data and\n// this is not inspected by the garbage collector\ntype sliceHeader struct {\n\tData unsafe.Pointer\n\tLen  int\n\tCap  int\n}\n\n// copyPtr copies the backing data for a slice or array directly into w. Note\n// we don't need to worry about byte ordering because we want the natural byte\n// order for the machine we're running on.\nfunc copyPtr(w *bytes.Buffer, ptr unsafe.Pointer, l int) (int, error) {\n\t// Convert our slice header into a []byte so we can call w.Write\n\tb := *(*[]byte)(unsafe.Pointer(&sliceHeader{\n\t\tData: ptr,\n\t\tLen:  l,\n\t\tCap:  l,\n\t}))\n\treturn w.Write(b)\n}\n\nfunc bug(format string, args ...interface{}) error {\n\treturn fmt.Errorf(\"BUG: Please report at https://github.com/tensorflow/tensorflow/issues with the note: Go TensorFlow %v: %v\", Version(), fmt.Sprintf(format, args...))\n}\n\nfunc isTensorSerializable(dataType DataType) error {\n\t// For numeric types, the serialized Tensor matches the in-memory\n\t// representation.  See the implementation of Tensor::AsProtoContent in\n\t// https://www.tensorflow.org/code/tensorflow/core/framework/tensor.cc\n\t//\n\t// The more appropriate way to be in sync with Tensor::AsProtoContent\n\t// would be to have the TensorFlow C library export functions for\n\t// serialization and deserialization of Tensors.  Till then capitalize\n\t// on knowledge of the implementation for numeric types.\n\tswitch dataType {\n\tcase Float, Double, Int32, Uint8, Int16, Int8, Complex, Int64, Bool, Quint8, Qint32, Bfloat16, Qint16, Quint16, Uint16, Complex128, Half:\n\t\treturn nil\n\tdefault:\n\t\treturn fmt.Errorf(\"serialization of tensors with the DataType %d is not yet supported, see https://github.com/tensorflow/tensorflow/issues/6003\", dataType)\n\t}\n}"