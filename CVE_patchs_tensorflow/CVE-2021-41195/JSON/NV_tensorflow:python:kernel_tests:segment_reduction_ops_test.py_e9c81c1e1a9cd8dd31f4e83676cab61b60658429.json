"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for segment reduction ops.\"\"\"\n\nimport itertools\n\nimport numpy as np\n\nfrom tensorflow.python.client import session\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes as dtypes_lib\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import gradient_checker_v2\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import test\n\n\nclass SegmentReductionHelper(test.TestCase):\n\n  def _input(self, input_shape, dtype=dtypes_lib.int32):\n    num_elem = 1\n    for x in input_shape:\n      num_elem *= x\n    values = np.arange(1, num_elem + 1)\n    np_values = values.reshape(input_shape).astype(dtype.as_numpy_dtype)\n    # Add a non-zero imaginary component to complex types.\n    if dtype.is_complex:\n      np_values -= 1j * np_values\n    return constant_op.constant(\n        np_values, shape=input_shape, dtype=dtype), np_values\n\n  def _segmentReduce(self, indices, x, op1, op2=None, num_segments=None,\n                     initial_value=0):\n    if not x.size:\n      return np.array([])\n    indices = np.asarray(indices)\n    if num_segments is None:\n      num_segments = indices[-1] + 1\n    output = [None] * num_segments\n    slice_shape = x.shape[indices.ndim:]\n    x_flat = x.reshape((indices.size,) + slice_shape)\n    for i, index in enumerate(indices.ravel()):\n      if (output[index] is not None) and op1 == np.max:\n        for j in range(0, output[index].shape[0]):\n          output[index][j] = op1([output[index][j], x_flat[i][j]])\n      elif output[index] is not None:\n        output[index] = op1(output[index], x_flat[i])\n      else:\n        output[index] = x_flat[i]\n    # zero initialize values that are still uncalculated.\n    initial_value_slice = np.ones(slice_shape) * initial_value\n    output = [o if o is not None else initial_value_slice for o in output]\n    if op2 is not None:\n      output = [op2(o) for o in output]\n    output = [o.reshape(slice_shape) for o in output]\n    return np.array(output)\n\n  def _mean_cum_op(self, x, y):\n    return (x[0] + y, x[1] + 1) if isinstance(x, tuple) else (x + y, 2)\n\n  def _mean_reduce_op(self, x):\n    return x[0] / x[1] if isinstance(x, tuple) else x\n\n  def _sqrt_n_reduce_op(self, x):\n    return x[0] / np.sqrt(x[1]) if isinstance(x, tuple) else x\n\n\nclass SegmentReductionOpTest(SegmentReductionHelper):\n\n  def testValues(self):\n    dtypes = [\n        dtypes_lib.float32, dtypes_lib.float64, dtypes_lib.int64,\n        dtypes_lib.int32, dtypes_lib.complex64, dtypes_lib.complex128\n    ]\n\n    # Each item is np_op1, np_op2, tf_op\n    ops_list = [(np.add, None, math_ops.segment_sum),\n                (self._mean_cum_op, self._mean_reduce_op,\n                 math_ops.segment_mean),\n                (np.ndarray.__mul__, None, math_ops.segment_prod),\n                (np.minimum, None, math_ops.segment_min),\n                (np.maximum, None, math_ops.segment_max)]\n\n    # A subset of ops has been enabled for complex numbers\n    complex_ops_list = [(np.add, None, math_ops.segment_sum),\n                        (np.ndarray.__mul__, None, math_ops.segment_prod),\n                        (self._mean_cum_op, self._mean_reduce_op,\n                         math_ops.segment_mean)]\n\n    n = 10\n    # Note that the GPU implem has different paths for different inner sizes.\n    for shape in [[n, 1], [n, 2], [n, 3], [n, 32]]:\n      indices = [i // 3 for i in range(n)]\n      for dtype in dtypes:\n        if dtype in (dtypes_lib.complex64, dtypes_lib.complex128):\n          curr_ops_list = complex_ops_list\n        else:\n          curr_ops_list = ops_list\n        for use_gpu in [True, False]:\n          with self.cached_session(use_gpu=use_gpu):\n            tf_x, np_x = self._input(shape, dtype=dtype)\n            for np_op1, np_op2, tf_op in curr_ops_list:\n              initial_value = 1 if tf_op is math_ops.segment_prod else 0\n              np_ans = self._segmentReduce(\n                  indices, np_x, np_op1, np_op2, initial_value=initial_value)\n              s = tf_op(data=tf_x, segment_ids=indices)\n              tf_ans = self.evaluate(s)\n              self.assertAllClose(np_ans, tf_ans)\n              # NOTE(mrry): The static shape inference that computes\n              # `tf_ans.shape` can only infer that sizes from dimension 1\n              # onwards, because the size of dimension 0 is data-dependent\n              # and may therefore vary dynamically.\n              self.assertAllEqual(np_ans.shape[1:], tf_ans.shape[1:])\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsShape(self):\n    shape = [4, 4]\n    tf_x, _ = self._input(shape)\n    indices = constant_op.constant([0, 1, 2, 2], shape=[2, 2])\n    with self.assertRaises(ValueError):\n      math_ops.segment_sum(data=tf_x, segment_ids=indices)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsSize(self):\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, _ = self._input(shape)\n        indices = [0, 1]\n        s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        with self.assertRaisesOpError(\"segment_ids should be the same size\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsValid(self):\n    # This is a baseline for the following SegmentIdsInvalid* tests.\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, _ = self._input(shape, dtype=dtypes_lib.float32)\n        indices = [0, 0, 0, 1]\n        result = math_ops.segment_sum(data=tf_x, segment_ids=indices).eval()\n        self.assertAllEqual([[15, 18, 21, 24], [13, 14, 15, 16]], result)\n\n  def testSegmentIdsGreaterThanZero(self):\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, np_x = self._input(shape, dtype=dtypes_lib.float32)\n        indices = [1, 1, 2, 2]\n        np_ans = self._segmentReduce(indices, np_x, np.add)\n        s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n\n  def testSegmentIdsHole(self):\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, np_x = self._input(shape, dtype=dtypes_lib.float32)\n        indices = [0, 0, 3, 3]\n        np_ans = self._segmentReduce(indices, np_x, np.add)\n        s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsInvalid1(self):\n    shape = [4, 4]\n    with self.cached_session():\n      tf_x, _ = self._input(shape)\n      indices = [-1, -1, 0, 0]\n      s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n      with self.assertRaisesOpError(\n          r\"Segment id -1 out of range \\[0, 1\\), possibly because \"\n          \"'segment_ids' input is not sorted.\"):\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsInvalid2(self):\n    shape = [4, 4]\n    with self.cached_session():\n      tf_x, _ = self._input(shape)\n      indices = [0, 1, 0, 1]\n      s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n      with self.assertRaisesOpError(\"segment ids are not increasing\"):\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsInvalid3(self):\n    shape = [4, 4]\n    with self.cached_session():\n      tf_x, _ = self._input(shape)\n      indices = [0, 1, 2, 0]\n      s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n      with self.assertRaisesOpError(\n          r\"Segment id 1 out of range \\[0, 1\\), possibly \"\n          \"because 'segment_ids' input is not sorted.\"):\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsInvalid4(self):\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, _ = self._input(shape, dtype=dtypes_lib.float32)\n        indices = [0, 0, 0, -1]\n        s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        with self.assertRaisesOpError(\"segment ids must be >= 0\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentIdsInvalid5(self):\n    shape = [4, 4]\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        tf_x, _ = self._input(shape, dtype=dtypes_lib.float32)\n        indices = [0, 0, 0, -2]\n        s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        with self.assertRaisesOpError(\"segment ids must be >= 0\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradient(self):\n    shape = [4, 4]\n    indices = [0, 1, 2, 2]\n    for tf_op in [\n        math_ops.segment_sum, math_ops.segment_mean, math_ops.segment_min,\n        math_ops.segment_max\n    ]:\n      with self.cached_session():\n        tf_x, np_x = self._input(shape, dtype=dtypes_lib.float64)\n        s = tf_op(data=tf_x, segment_ids=indices)\n        jacob_t, jacob_n = gradient_checker.compute_gradient(\n            tf_x,\n            shape,\n            s, [3, 4],\n            x_init_value=np_x.astype(np.double),\n            delta=1)\n      self.assertAllClose(jacob_t, jacob_n)\n\n  def testDataInvalid(self):\n    # Test case for GitHub issue 40653.\n    for use_gpu in [True, False]:\n      with self.cached_session(use_gpu=use_gpu):\n        with self.assertRaisesRegex(\n            (ValueError, errors_impl.InvalidArgumentError),\n            \"must be at least rank 1\"):\n          s = math_ops.segment_mean(\n              data=np.uint16(10), segment_ids=np.array([]).astype(\"int64\"))\n          self.evaluate(s)\n\n  def testInvalidIds(self):\n    # Test case for GitHub issue 46888.\n    for op in [\n        math_ops.segment_max,\n        math_ops.segment_min,\n        math_ops.segment_mean,\n        math_ops.segment_sum,\n        math_ops.segment_prod,\n    ]:\n      with self.cached_session(use_gpu=False):\n        with self.assertRaises((ValueError, errors_impl.InternalError)):\n          s = op(data=np.ones((1, 10, 1)), segment_ids=[1676240524292489355])\n          self.evaluate(s)\n\n\nclass UnsortedSegmentTest(SegmentReductionHelper):\n\n  def __init__(self, methodName='runTest'):\n    # Each item is np_op1, np_op2, tf_op, initial_value functor\n    self.ops_list = [(np.add, None,\n                      math_ops.unsorted_segment_sum, lambda t: 0),\n                     (self._mean_cum_op, self._mean_reduce_op,\n                      math_ops.unsorted_segment_mean, lambda t: 0),\n                     (self._mean_cum_op, self._sqrt_n_reduce_op,\n                      math_ops.unsorted_segment_sqrt_n, lambda t: 0),\n                     (np.ndarray.__mul__, None,\n                      math_ops.unsorted_segment_prod, lambda t: 1),\n                     (np.minimum, None,\n                      math_ops.unsorted_segment_min, lambda t: t.max),\n                     (np.maximum, None,\n                      math_ops.unsorted_segment_max, lambda t: t.min)]\n\n    # A subset of ops has been enabled for complex numbers\n    self.complex_ops_list = [(np.add, None,\n                              math_ops.unsorted_segment_sum, lambda t: 0),\n                             (np.ndarray.__mul__, None,\n                              math_ops.unsorted_segment_prod, lambda t: 1)]\n    self.differentiable_dtypes = [dtypes_lib.float16, dtypes_lib.float32,\n                                  dtypes_lib.float64]\n    self.all_dtypes = (self.differentiable_dtypes +\n                       [dtypes_lib.bfloat16,\n                        dtypes_lib.int64, dtypes_lib.int32,\n                        dtypes_lib.complex64, dtypes_lib.complex128])\n    super(UnsortedSegmentTest, self).__init__(methodName=methodName)\n\n  def testValues(self):\n    indices_flat = np.array([0, 4, 0, 8, 3, 8, 4, 7, 7, 3])\n    num_segments = 12\n    for indices in indices_flat, indices_flat.reshape(5, 2):\n      # Note that the GPU implem has different paths for different inner sizes.\n      for inner_size in [1, 2, 3, 32]:\n        shape = indices.shape + (inner_size,)\n        for dtype in self.all_dtypes:\n          ops_list = (\n              self.complex_ops_list if dtype.is_complex else self.ops_list)\n          tf_x, np_x = self._input(shape, dtype=dtype)\n          for use_gpu in [True, False]:\n            with self.cached_session():\n              for np_op1, np_op2, tf_op, init_op in ops_list:\n                # sqrt_n doesn't support integers\n                if (np_op2 == self._sqrt_n_reduce_op and dtype.is_integer):\n                  continue\n                # todo(philjd): enable this test once real_div supports bfloat16\n                if (np_op2 in [self._sqrt_n_reduce_op, self._mean_reduce_op] and\n                    dtype == dtypes_lib.bfloat16):\n                  continue\n                np_ans = self._segmentReduce(\n                    indices,\n                    np_x,\n                    np_op1,\n                    np_op2,\n                    num_segments=num_segments,\n                    initial_value=init_op(dtype))\n                s = tf_op(tf_x, segment_ids=indices, num_segments=num_segments)\n                tf_ans = self.evaluate(s)\n                if dtype is dtypes_lib.bfloat16:\n                  tf_ans = tf_ans.astype(np.float32)\n                self.assertAllCloseAccordingToType(np_ans, tf_ans)\n                self.assertShapeEqual(np_ans, s)\n\n  def testNumSegmentsTypes(self):\n    dtypes = [dtypes_lib.int32, dtypes_lib.int64]\n    indices_flat = np.array([0, 4, 0, 8, 3, 8, 4, 7, 7, 3])\n    num_segments = 12\n    for indices in indices_flat, indices_flat.reshape(5, 2):\n      shape = indices.shape + (2,)\n      for dtype in dtypes:\n        with self.cached_session():\n          tf_x, np_x = self._input(shape)\n          num_segments_constant = constant_op.constant(\n              num_segments, dtype=dtype)\n          np_ans = self._segmentReduce(\n              indices, np_x, np.add, op2=None, num_segments=num_segments)\n          s = math_ops.unsorted_segment_sum(\n              data=tf_x,\n              segment_ids=indices,\n              num_segments=num_segments_constant)\n          tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n        self.assertShapeEqual(np_ans, s)\n\n  @test_util.run_deprecated_v1\n  def testGradientsTFGradients(self):\n    num_cols = 2\n    indices_flat = np.array([0, 4, 0, -1, 3, -1, 4, 7, 7, 3])\n    num_segments = max(indices_flat) + 3\n    for dtype in self.differentiable_dtypes:\n      ops_list = self.complex_ops_list if dtype.is_complex else self.ops_list\n      for indices in indices_flat, indices_flat.reshape(5, 2):\n        shape = indices.shape + (num_cols,)\n        # test CPU and GPU as tf.gather behaves differently on each device\n        for use_gpu in [False, True]:\n          with self.cached_session(use_gpu=use_gpu):\n            for _, _, tf_op, _ in ops_list:\n              tf_x, np_x = self._input(shape, dtype=dtype)\n              s = tf_op(tf_x, indices, num_segments)\n              jacob_t, jacob_n = gradient_checker.compute_gradient(\n                  tf_x,\n                  shape,\n                  s, [num_segments, num_cols],\n                  x_init_value=np_x,\n                  delta=1.)\n              self.assertAllCloseAccordingToType(jacob_t, jacob_n,\n                                                 half_atol=1e-2)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testGradientsGradientTape(self):\n    num_cols = 2\n    indices_flat = np.array([0, 4, 0, -1, 3, -1, 4, 7, 7, 3])\n    num_segments = max(indices_flat) + 3\n    for dtype in self.differentiable_dtypes:\n      ops_list = self.complex_ops_list if dtype.is_complex else self.ops_list\n      for indices in indices_flat, indices_flat.reshape(5, 2):\n        shape = indices.shape + (num_cols,)\n        # test CPU and GPU as tf.gather behaves differently on each device\n        for use_gpu in [test_util.use_gpu, test_util.force_cpu]:\n          with use_gpu():\n            for _, _, tf_op, _ in ops_list:\n              _, np_x = self._input(shape, dtype=dtype)\n              # pylint: disable=cell-var-from-loop\n              def f(x):\n                return tf_op(x, indices, num_segments)\n              gradient_tape_jacob_t, jacob_n = (\n                  gradient_checker_v2.compute_gradient(\n                      f, [np_x], delta=1.))\n              # pylint: enable=cell-var-from-loop\n              self.assertAllCloseAccordingToType(jacob_n, gradient_tape_jacob_t,\n                                                 half_atol=1e-2)\n\n  @test_util.run_deprecated_v1\n  def testProdGrad(self):\n    # additional test for the prod gradient to ensure correct handling of zeros\n    values = np.array([0, 0, 1, 0, 2, 2, 3, 3, 3], dtype=np.float32)\n    indices = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2], dtype=np.int32)\n    indices_neg = np.array([-1, 0, 0, -1, 1, 1, -1, 2, 2], dtype=np.int32)\n    values_tf = constant_op.constant(values)\n    # ground truth partial derivatives\n    gradients_indices = np.zeros((9, 3), dtype=np.float32)\n    gradients_indices_neg = np.zeros((9, 3), dtype=np.float32)\n    # the derivative w.r.t. to the other segments is zero, so here we only\n    # explicitly set the grad values for the corresponding segment\n    gradients_indices[range(9), indices] = [0, 0, 0, 4, 0, 0, 9, 9, 9]\n    gradients_indices_neg[range(9), indices_neg] = [0, 1, 0, 0, 2, 2, 0, 3, 3]\n    for use_gpu in [False, True]:\n      with self.cached_session(use_gpu=use_gpu):\n        for ind, grad_gt in [(indices, gradients_indices),\n                             (indices_neg, gradients_indices_neg)]:\n          s = math_ops.unsorted_segment_prod(values_tf,\n                                             constant_op.constant(ind), 3)\n          jacob_t, jacob_n = gradient_checker.compute_gradient(\n              values_tf, (9,), s, (3,), x_init_value=values, delta=1)\n          self.assertAllClose(jacob_t, jacob_n)\n          self.assertAllClose(jacob_t, grad_gt)\n\n  @test_util.run_deprecated_v1\n  def testGradientMatchesSegmentSum(self):\n    # Strategy: compute the gradient for UnsortedSegmentSum and SegmentSum\n    # and compare the outputs, which should be identical.\n    # NB: for this test to work, indices must be valid for SegmentSum, namely\n    # it must be sorted, the indices must be contiguous, and num_segments\n    # must be max(indices) + 1.\n    indices = [0, 0, 1, 1, 1, 2, 3, 4, 5]\n    n = len(indices)\n    num_cols = 2\n    shape = [n, num_cols]\n    num_segments = max(indices) + 1\n    for dtype in self.differentiable_dtypes:\n      with self.cached_session():\n        tf_x, np_x = self._input(shape, dtype=dtype)\n        # Results from UnsortedSegmentSum\n        unsorted_s = math_ops.unsorted_segment_sum(\n            data=tf_x, segment_ids=indices, num_segments=num_segments)\n        unsorted_jacob_t, unsorted_jacob_n = (\n            gradient_checker.compute_gradient(tf_x, shape, unsorted_s,\n                                              [num_segments, num_cols],\n                                              x_init_value=np_x, delta=1))\n\n        # Results from SegmentSum\n        sorted_s = math_ops.segment_sum(data=tf_x, segment_ids=indices)\n        sorted_jacob_t, sorted_jacob_n = gradient_checker.compute_gradient(\n            tf_x,\n            shape,\n            sorted_s, [num_segments, num_cols],\n            x_init_value=np_x,\n            delta=1)\n      self.assertAllClose(unsorted_jacob_t, sorted_jacob_t)\n      self.assertAllClose(unsorted_jacob_n, sorted_jacob_n)\n\n  @test_util.run_deprecated_v1\n  def testBadIndices(self):\n    # Note: GPU kernel does not return the out-of-range error needed for this\n    # test, so this test is marked as cpu-only.\n    # Note: With PR #13055 a negative index will be ignored silently.\n    with self.session(use_gpu=False):\n      for bad in [[2]], [[7]]:\n        unsorted = math_ops.unsorted_segment_sum([[17]], bad, num_segments=2)\n        with self.assertRaisesOpError(\n            r\"segment_ids\\[0,0\\] = %d is out of range \\[0, 2\\)\" % bad[0][0]):\n          self.evaluate(unsorted)\n\n  @test_util.run_deprecated_v1\n  def testEmptySecondDimension(self):\n    dtypes = [np.float16, np.float32, np.float64, np.int64, np.int32,\n              np.complex64, np.complex128]\n    with self.session():\n      for dtype in dtypes:\n        for itype in (np.int32, np.int64):\n          data = np.zeros((2, 0), dtype=dtype)\n          segment_ids = np.array([0, 1], dtype=itype)\n          unsorted = math_ops.unsorted_segment_sum(data, segment_ids, 2)\n          self.assertAllEqual(unsorted, np.zeros((2, 0), dtype=dtype))\n\n  def testDropNegatives(self):\n    # Note: the test is done by replacing segment_ids with 8 to -1\n    # for index  and replace values generated by numpy with 0.\n    indices_flat = np.array([0, 4, 0, 8, 3, 8, 4, 7, 7, 3])\n    num_segments = 12\n    for indices in indices_flat, indices_flat.reshape(5, 2):\n      shape = indices.shape + (2,)\n      for dtype in self.all_dtypes:\n        with self.session():\n          tf_x, np_x = self._input(shape, dtype=dtype)\n          np_ans = self._segmentReduce(\n              indices, np_x, np.add, op2=None, num_segments=num_segments)\n          # Replace np_ans[8] with 0 for the value\n          np_ans[8:] = 0\n          # Replace 8 with -1 in indices\n          np.place(indices, indices == 8, [-1])\n          s = math_ops.unsorted_segment_sum(\n              data=tf_x, segment_ids=indices, num_segments=num_segments)\n          tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n        self.assertShapeEqual(np_ans, s)\n\n\nclass SparseSegmentReductionHelper(SegmentReductionHelper):\n\n  def _sparse_input(self, input_shape, num_indices, dtype=dtypes_lib.int32):\n    a, b = super(SparseSegmentReductionHelper, self)._input(input_shape, dtype)\n    indices = np.random.randint(0, input_shape[0], num_indices).astype(np.int32)\n    return (constant_op.constant(\n        indices, dtype=dtypes_lib.int32), indices, a, b)\n\n  def _sparseSegmentReduce(self,\n                           x,\n                           indices,\n                           segment_indices,\n                           op1,\n                           op2=None,\n                           num_segments=None):\n    return self._segmentReduce(\n        segment_indices, x[indices], op1, op2, num_segments=num_segments)\n\n  def _sparseSegmentReduceGrad(self, ygrad, indices, segment_ids, output_dim0,\n                               mode):\n    assert mode in (\"sum\", \"mean\", \"sqrtn\")\n    if mode != \"sum\":\n      weights = np.zeros(ygrad.shape[0], ygrad.dtype)\n      for segment in segment_ids:\n        weights[segment] += 1\n      weights = 1. / weights if mode == \"mean\" else 1. / np.sqrt(weights)\n    xgrad = np.zeros([output_dim0, ygrad.shape[1]], ygrad.dtype)\n    for segment, index in zip(segment_ids, indices):\n      if mode == \"sum\":\n        xgrad[index] += ygrad[segment]\n      else:\n        xgrad[index] += ygrad[segment] * weights[segment]\n    return xgrad\n\n\nclass SparseSegmentReductionOpTest(SparseSegmentReductionHelper):\n\n  def testValues(self):\n    dtypes = [\n        dtypes_lib.float32, dtypes_lib.float64, dtypes_lib.int64,\n        dtypes_lib.int32\n    ]\n\n    index_dtypes = [dtypes_lib.int32, dtypes_lib.int64]\n    segment_ids_dtypes = [dtypes_lib.int32, dtypes_lib.int64]\n\n    mean_dtypes = [dtypes_lib.float32, dtypes_lib.float64]\n\n    # Each item is np_op1, np_op2, tf_op\n    ops_list = [(np.add, None, math_ops.sparse_segment_sum),\n                (self._mean_cum_op, self._mean_reduce_op,\n                 math_ops.sparse_segment_mean)]\n\n    n = 400\n    # Note that the GPU implem has different paths for different inner sizes.\n    for inner_size in [1, 2, 3, 32]:\n      shape = [n, inner_size]\n      segment_indices = []\n      for i in range(20):\n        for _ in range(i + 1):\n          segment_indices.append(i)\n      num_indices = len(segment_indices)\n      for dtype in dtypes:\n        for index_dtype in index_dtypes:\n          for segment_ids_dtype in segment_ids_dtypes:\n            with self.cached_session():\n              tf_indices, np_indices, tf_x, np_x = self._sparse_input(\n                  shape, num_indices, dtype=dtype)\n              for np_op1, np_op2, tf_op in ops_list:\n                if (tf_op == math_ops.sparse_segment_mean and\n                    dtype not in mean_dtypes):\n                  continue\n                np_ans = self._sparseSegmentReduce(np_x, np_indices,\n                                                   segment_indices, np_op1,\n                                                   np_op2)\n                s = tf_op(\n                    data=tf_x,\n                    indices=math_ops.cast(tf_indices, index_dtype),\n                    segment_ids=math_ops.cast(segment_indices,\n                                              segment_ids_dtype))\n                tf_ans = self.evaluate(s)\n                self.assertAllClose(np_ans, tf_ans)\n                # NOTE(mrry): The static shape inference that computes\n                # `tf_ans.shape` can only infer that sizes from dimension 1\n                # onwards, because the size of dimension 0 is data-dependent\n                # and may therefore vary dynamically.\n                self.assertAllEqual(np_ans.shape[1:], tf_ans.shape[1:])\n\n  def testSegmentIdsHole(self):\n    tf_x, np_x = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [(np.add, None, math_ops.sparse_segment_sum), (\n        self._mean_cum_op, self._mean_reduce_op, math_ops.sparse_segment_mean)]\n    segment_indices = [0, 2, 2, 2]\n    tf_indices = [8, 3, 0, 9]\n    with self.session():\n      for np_op1, np_op2, tf_op in ops_list:\n        np_ans = self._sparseSegmentReduce(np_x, tf_indices, segment_indices,\n                                           np_op1, np_op2)\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n\n  def testWithNumSegments(self):\n    tf_x, np_x = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [(np.add, None, math_ops.sparse_segment_sum_with_num_segments),\n                (self._mean_cum_op, self._mean_reduce_op,\n                 math_ops.sparse_segment_mean_with_num_segments)]\n    segment_indices = [0, 2, 2, 2]\n    tf_indices = [8, 3, 0, 9]\n    num_segments = 5\n    with self.session():\n      for np_op1, np_op2, tf_op in ops_list:\n        np_ans = self._sparseSegmentReduce(\n            np_x,\n            tf_indices,\n            segment_indices,\n            np_op1,\n            np_op2,\n            num_segments=num_segments)\n        s = tf_op(\n            data=tf_x,\n            indices=tf_indices,\n            segment_ids=segment_indices,\n            num_segments=num_segments)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n\n  def testWithEmptySegments(self):\n    tf_x = constant_op.constant([], shape=[0, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_with_num_segments,\n        math_ops.sparse_segment_mean_with_num_segments\n    ]\n    segment_indices = []\n    tf_indices = []\n    num_segments = 5\n    with self.session():\n      for tf_op in ops_list:\n        s = tf_op(\n            data=tf_x,\n            indices=tf_indices,\n            segment_ids=segment_indices,\n            num_segments=num_segments)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np.zeros([5, 4]), tf_ans)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSegmentScalarIdiRaisesInvalidArgumentError(self):\n    \"\"\"Test for github #46897.\"\"\"\n    ops_list = [\n        math_ops.sparse_segment_sum,\n        math_ops.sparse_segment_mean,\n        math_ops.sparse_segment_sqrt_n,\n    ]\n    for op in ops_list:\n      with self.assertRaisesRegex(\n          (ValueError, errors_impl.InvalidArgumentError),\n          \"Shape must be at least rank 1\"):\n        op(data=1.0, indices=[0], segment_ids=[3])\n\n  def testSegmentIdsGreaterThanZero(self):\n    tf_x, np_x = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [(np.add, None, math_ops.sparse_segment_sum), (\n        self._mean_cum_op, self._mean_reduce_op, math_ops.sparse_segment_mean)]\n    segment_indices = [1, 2, 2, 2]\n    tf_indices = [8, 3, 0, 9]\n    with self.session():\n      for np_op1, np_op2, tf_op in ops_list:\n        np_ans = self._sparseSegmentReduce(np_x, tf_indices, segment_indices,\n                                           np_op1, np_op2)\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        tf_ans = self.evaluate(s)\n        self.assertAllClose(np_ans, tf_ans)\n\n  def testValid(self):\n    # Baseline for the test*Invalid* methods below.\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, 3, 0, 9]\n    with self.session():\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testIndicesInvalid1(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, -1, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\n            r\"indices\\[1\\] == -1 out of range \\[0, 10\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testIndicesInvalid2(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, 3, 0, 10]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\n            r\"indices\\[3\\] == 10 out of range \\[0, 10\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentsInvalid2(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 1, 0, 1]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\"segment ids are not increasing\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentsInvalid3(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 1, 2, 0]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\n            r\"Segment id 1 out of range \\[0, 1\\), possibly because \"\n            \"'segment_ids' input is not sorted\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentsInvalid4(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [-1, 0, 1, 1]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\n            r\"Segment id -1 out of range \\[0, 2\\), possibly because \"\n            \"'segment_ids' input is not sorted\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentsInvalid6(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 0, 0, -1]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\"segment ids must be >= 0\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentsInvalid7(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]\n    segment_indices = [0, 0, 0, -2]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        with self.assertRaisesOpError(\"segment ids must be >= 0\"):\n          self.evaluate(s)\n\n  def testSegmentWithNumSegmentsValid(self):\n    # Baseline for the test*WithNumSegmentsInvalid* methods below.\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_with_num_segments,\n        math_ops.sparse_segment_mean_with_num_segments,\n    ]\n    num_segments = 5\n    segment_indices = [0, 1, 3, 3]\n    tf_indices = [8, 3, 0, 9]\n    with self.session():\n      for tf_op in ops_list:\n        s = tf_op(\n            data=tf_x,\n            indices=tf_indices,\n            segment_ids=segment_indices,\n            num_segments=num_segments)\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentWithNumSegmentsInvalid1(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_with_num_segments,\n        math_ops.sparse_segment_mean_with_num_segments,\n    ]\n    num_segments = 5\n    segment_indices = [0, 1, 3, 5]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(\n            data=tf_x,\n            indices=tf_indices,\n            segment_ids=segment_indices,\n            num_segments=num_segments)\n        with self.assertRaisesOpError(\"segment ids must be < num_segments\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testSegmentWithNumSegmentsInvalid2(self):\n    tf_x, _ = self._input([10, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_with_num_segments,\n        math_ops.sparse_segment_mean_with_num_segments,\n    ]\n    num_segments = -2\n    segment_indices = [0, 1, 3, 3]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        with self.assertRaisesRegex(\n            ValueError, \"Cannot specify a negative value for num_segments\"):\n          tf_op(\n              data=tf_x,\n              indices=tf_indices,\n              segment_ids=segment_indices,\n              num_segments=num_segments)\n\n  @test_util.run_deprecated_v1\n  def testGradient(self):\n    shape = [10, 4]\n\n    segment_indices = [0, 1, 2, 2]\n    num_indices = len(segment_indices)\n    for tf_op in [math_ops.sparse_segment_sum, math_ops.sparse_segment_mean]:\n      with self.cached_session():\n        tf_indices, _, tf_x, np_x = self._sparse_input(\n            shape, num_indices, dtype=dtypes_lib.float64)\n        s = tf_op(data=tf_x, indices=tf_indices, segment_ids=segment_indices)\n        jacob_t, jacob_n = gradient_checker.compute_gradient(\n            tf_x,\n            shape,\n            s, [3, 4],\n            x_init_value=np_x.astype(np.double),\n            delta=1)\n      self.assertAllClose(jacob_t, jacob_n)\n\n  @test_util.run_deprecated_v1\n  def testGradientWithEmptySegmentsAtEnd(self):\n    shape = [10, 4]\n\n    num_segments = 5\n    segment_indices = [0, 1, 2, 2]\n    num_indices = len(segment_indices)\n    for tf_op in [\n        math_ops.sparse_segment_sum_with_num_segments,\n        math_ops.sparse_segment_mean_with_num_segments,\n    ]:\n      with self.cached_session():\n        tf_indices, _, tf_x, np_x = self._sparse_input(\n            shape, num_indices, dtype=dtypes_lib.float64)\n        s = tf_op(\n            data=tf_x,\n            indices=tf_indices,\n            segment_ids=segment_indices,\n            num_segments=num_segments)\n        jacob_t, jacob_n = gradient_checker.compute_gradient(\n            tf_x,\n            shape,\n            s, [5, 4],\n            x_init_value=np_x.astype(np.double),\n            delta=1)\n      self.assertAllClose(jacob_t, jacob_n)\n\n  def testGradientExplicit(self):\n    # Note that the GPU implem has different paths for different inner sizes.\n    for inner_size in (1, 2, 3, 32):\n      with self.session():\n        tf_ygrad, np_ygrad = self._input([3, inner_size],\n                                         dtype=dtypes_lib.float32)\n        segment_ids = [0, 1, 2, 2, 2]\n        indices = [8, 3, 0, 9, 3]\n        output_dim0 = 10\n        ops_list = [\n            (math_ops.sparse_segment_sum_grad, \"sum\"),\n            (math_ops.sparse_segment_mean_grad, \"mean\"),\n            (math_ops.sparse_segment_sqrt_n_grad, \"sqrtn\"),\n        ]\n        for tf_op, mode in ops_list:\n          np_xgrad = self._sparseSegmentReduceGrad(np_ygrad, indices,\n                                                   segment_ids, output_dim0,\n                                                   mode)\n          tf_xgrad = tf_op(tf_ygrad, indices, segment_ids, output_dim0)\n          self.assertAllClose(tf_xgrad, np_xgrad)\n\n  def testGradientExplicitSingleOutput(self):\n    # The GPU implem has a special case when there is a single output.\n    for inner_size in (1, 2, 3, 32):\n      with self.session():\n        tf_ygrad, np_ygrad = self._input([3, inner_size],\n                                         dtype=dtypes_lib.float32)\n        segment_ids = [0, 1, 2, 2, 2]\n        indices = [0, 0, 0, 0, 0]\n        output_dim0 = 1\n        ops_list = [\n            (math_ops.sparse_segment_sum_grad, \"sum\"),\n            (math_ops.sparse_segment_mean_grad, \"mean\"),\n            (math_ops.sparse_segment_sqrt_n_grad, \"sqrtn\"),\n        ]\n        for tf_op, mode in ops_list:\n          np_xgrad = self._sparseSegmentReduceGrad(np_ygrad, indices,\n                                                   segment_ids, output_dim0,\n                                                   mode)\n          tf_xgrad = tf_op(tf_ygrad, indices, segment_ids, output_dim0)\n          self.assertAllClose(tf_xgrad, np_xgrad)\n\n  def testGradientValid(self):\n    # Baseline for the testGradient*Invalid* methods below.\n    tf_x, _ = self._input([3, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientIndicesInvalid1(self):\n    tf_x, _ = self._input([3, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, 3, 0, 10]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(r\"Index 10 out of range \\[0, 10\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientIndicesInvalid2(self):\n    tf_x, _ = self._input([3, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 2, 2]\n    tf_indices = [8, 3, -1, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(r\"Index -1 out of range \\[0, 10\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientSegmentsInvalid1(self):\n    tf_x, _ = self._input(\n        [3, 4], dtype=dtypes_lib.float32)  # expecting 3 segments\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 1, 4]  # 5 segments\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(\"Invalid number of segments\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientSegmentsInvalid2(self):\n    tf_x, _ = self._input([1, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 2, 0]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(r\"Segment id 1 out of range \\[0, 1\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientSegmentsInvalid3(self):\n    tf_x, _ = self._input([2, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [-1, 0, 1, 1]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(r\"Segment id -1 out of range \\[0, 2\\)\"):\n          self.evaluate(s)\n\n  @test_util.run_deprecated_v1\n  def testGradientSegmentsInvalid4(self):\n    tf_x, _ = self._input([0, 4], dtype=dtypes_lib.float32)\n    ops_list = [\n        math_ops.sparse_segment_sum_grad, math_ops.sparse_segment_mean_grad,\n        math_ops.sparse_segment_sqrt_n_grad\n    ]\n    segment_indices = [0, 1, 2, -1]\n    tf_indices = [8, 3, 0, 9]\n    with self.session(use_gpu=False):\n      for tf_op in ops_list:\n        s = tf_op(tf_x, tf_indices, segment_indices, 10)\n        with self.assertRaisesOpError(r\"Segment id 0 out of range \\[0, 0\\)\"):\n          self.evaluate(s)\n\n\nclass SegmentReductionOpBenchmark(test.Benchmark):\n  outer_dim_options = [2**x for x in range(9, 14, 2)]\n  ratio_options = [2**x for x in range(1, 6, 2)]\n  inner_dim_options = [2**x for x in range(9, 14, 2)]\n  # randomly generated sizes with less alignments\n  inner_dim_options += [\n      1120, 1215, 1856, 1302, 1329, 1531, 1313, 1672, 1851, 1584\n  ]\n  dtype_options = [np.float32, np.float64]\n  options = (outer_dim_options, ratio_options, inner_dim_options, dtype_options)\n  # pylint: disable=g-long-lambda\n  op_functors = [lambda vc, vs, seg_ids:\n                 (\"sorted\", math_ops.segment_sum(vc, vs)),\n                 lambda vc, vs, seg_ids:\n                 (\"unsorted\",\n                  math_ops.unsorted_segment_sum(vc, vs, seg_ids[-1]+1))]\n  # pylint: enable=g-long-lambda\n  repeat = 10\n\n  def _npTypeToStr(self, t):\n    if t == np.float32:\n      return \"fp32\"\n    if t == np.float64:\n      return \"fp64\"\n\n  def _runGraph(self, op_functor, outer_dim, ratio, inner_dim, dtype):\n    output_outer_dim = int(outer_dim / ratio)\n    const = np.random.randint(5, size=(outer_dim, inner_dim))\n    seg_ids = np.sort(np.random.randint(output_outer_dim, size=outer_dim))\n    vs = variables.Variable(seg_ids.astype(np.int32))\n    with ops.device(\"/gpu:0\"):\n      vc = variables.Variable(const.astype(dtype))\n    name, op = op_functor(vc, vs, seg_ids)\n    with session.Session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      r = self.run_op_benchmark(\n          sess,\n          op,\n          min_iters=self.repeat,\n          name=\"_\".join(\n              map(str,\n                  [name, outer_dim, ratio, inner_dim,\n                   self._npTypeToStr(dtype)])))\n    return name, r[\"wall_time\"]\n\n  def benchmarkSegmentSumGPU(self):\n    if not test.is_gpu_available(cuda_only=True):\n      return\n    for outer_dim, ratio, inner_dim, dtype in itertools.product(*self.options):\n      op_functor = self.op_functors[0]\n      with ops.Graph().as_default():\n        self._runGraph(op_functor, outer_dim, ratio, inner_dim, dtype)\n\n  def benchmarkUnsortedSegmentSumGPU(self):\n    if not test.is_gpu_available(cuda_only=True):\n      return\n    for outer_dim, ratio, inner_dim, dtype in itertools.product(*self.options):\n      op_functor = self.op_functors[1]\n      with ops.Graph().as_default():\n        self._runGraph(op_functor, outer_dim, ratio, inner_dim, dtype)\n\n\nif __name__ == \"__main__\":\n  test.main()"