"diff --git a/tensorflow/core/kernels/maxpooling_op.cc b/tensorflow/core/kernels/maxpooling_op.cc\nindex ce89b025ec5..9edd5cf6a6d 100644\n--- a/tensorflow/core/kernels/maxpooling_op.cc\n+++ b/tensorflow/core/kernels/maxpooling_op.cc\n@@ -325,6 +325,14 @@ class MaxPoolingGradOp : public OpKernel {\n     if (!context->status().ok()) {\n       return;\n     }\n+    OP_REQUIRES(context, tensor_out.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected orig_output shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", tensor_out.shape()));\n+    OP_REQUIRES(context, out_backprop.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected grad shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", out_backprop.shape()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n@@ -538,6 +546,18 @@ class MaxPoolingGradGradOp : public OpKernel {\n                           /*explicit_paddings=*/{},\n                           FORMAT_NHWC,\n                           tensor_in.shape()};\n+    if (!context->status().ok()) {\n+      return;\n+    }\n+    OP_REQUIRES(context, tensor_out.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected orig_output shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", tensor_out.shape()));\n+    OP_REQUIRES(\n+        context, out_grad_backprop.shape() == tensor_in.shape(),\n+        errors::InvalidArgument(\"Expected grad shape to be \", tensor_in.shape(),\n+                                \", but got \", out_grad_backprop.shape()));\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                 {2}, 0, tensor_out.shape(), &output));\n@@ -742,6 +762,17 @@ class MaxPoolingGradGradOp<Eigen::GpuDevice, T> : public OpKernel {\n                           /*explicit_paddings=*/{},\n                           data_format_,\n                           tensor_in.shape()};\n+    if (!context->status().ok()) {\n+      return;\n+    }\n+    OP_REQUIRES(context, tensor_out.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected orig_output shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", tensor_out.shape()));\n+    OP_REQUIRES(\n+        context, out_grad_backprop.shape() == tensor_in.shape(),\n+        errors::InvalidArgument(\"Expected grad shape to be \", tensor_in.shape(),\n+                                \", but got \", out_grad_backprop.shape()));\n \n     functor::MaxPoolGradBackwardNoMask<T>()(\n         data_format_, tensor_in.flat<T>().data(), tensor_out.flat<T>().data(),\n@@ -1096,6 +1127,14 @@ class MaxPoolingGradWithArgmaxOp : public OpKernel {\n     if (!context->status().ok()) {\n       return;\n     }\n+    OP_REQUIRES(context, grad_in.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected grad shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", grad_in.shape()));\n+    OP_REQUIRES(context, argmax.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected argmax shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", argmax.shape()));\n \n     TensorShape out_shape({params.tensor_in_batch, params.tensor_in_rows,\n                            params.tensor_in_cols, params.depth});\n@@ -1156,6 +1195,14 @@ class MaxPoolingGradGradWithArgmaxOp : public OpKernel {\n     if (!context->status().ok()) {\n       return;\n     }\n+    OP_REQUIRES(\n+        context, grad_in.shape() == tensor_in.shape(),\n+        errors::InvalidArgument(\"Expected grad shape to be \", tensor_in.shape(),\n+                                \", but got \", grad_in.shape()));\n+    OP_REQUIRES(context, argmax.shape() == params.forward_output_shape(),\n+                errors::InvalidArgument(\"Expected argmax shape to be \",\n+                                        params.forward_output_shape(),\n+                                        \", but got \", argmax.shape()));\n \n     TensorShape out_shape({params.tensor_in_batch, params.out_height,\n                            params.out_width, params.depth});"