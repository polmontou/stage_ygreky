"diff --git a/tensorflow/core/kernels/boosted_trees/stats_ops.cc b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\nindex 60c1d191f52..fe48695358b 100644\n--- a/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n+++ b/tensorflow/core/kernels/boosted_trees/stats_ops.cc\n@@ -72,7 +72,10 @@ class BoostedTreesCalculateBestGainsPerFeatureOp : public OpKernel {\n                                                 &stats_summary_list));\n     const int64_t num_buckets = stats_summary_list[0].dim_size(1);\n     // Check for single logit: 1 gradient + 1 hessian value.\n-    DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);\n+    OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,\n+                errors::InvalidArgument(\"stats_summary_list[0] must have \"\n+                                        \"exactly 2 dimensions, obtained: \",\n+                                        stats_summary_list[0].dim_size(2)));\n     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;\n     stats_summary.reserve(stats_summary_list.size());\n     for (const auto& tensor : stats_summary_list) {\n@@ -275,8 +278,13 @@ class BoostedTreesCalculateBestFeatureSplitOp : public OpKernel {\n     const int32_t num_buckets = stats_summary_t->dim_size(2) - 1;\n     const int32_t logits_dim = logits_dim_;\n     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;\n-    DCHECK_GT(hessian_dim, 0);\n-    DCHECK_LE(hessian_dim, logits_dim * logits_dim);\n+    OP_REQUIRES(context, hessian_dim > 0,\n+                errors::InvalidArgument(\"hessian dim should be < 0, got \",\n+                                        hessian_dim));\n+    OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,\n+                errors::InvalidArgument(\n+                    \"hessian dim should be <= \", logits_dim * logits_dim,\n+                    \" but got: \", hessian_dim));\n \n     const Tensor* l1_t;\n     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));\n@@ -624,8 +632,13 @@ class BoostedTreesCalculateBestFeatureSplitV2 : public OpKernel {\n     const int32_t logits_dim = logits_dim_;\n     const int32_t hessian_dim =\n         stats_summaries_list[0].dim_size(3) - logits_dim;\n-    DCHECK_GT(hessian_dim, 0);\n-    DCHECK_LE(hessian_dim, logits_dim * logits_dim);\n+    OP_REQUIRES(context, hessian_dim > 0,\n+                errors::InvalidArgument(\"hessian dim should be < 0, got \",\n+                                        hessian_dim));\n+    OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,\n+                errors::InvalidArgument(\n+                    \"hessian dim should be <= \", logits_dim * logits_dim,\n+                    \" but got: \", hessian_dim));\n \n     // Vector of stats_summaries; each element is stats for feature of shape\n     // [max_splits, feature_dim, num_buckets, logits_dim + hessian_dim].\n@@ -1002,6 +1015,10 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n     const Tensor* node_id_range_t;\n     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));\n     const auto node_id_range = node_id_range_t->vec<int32>();\n+    OP_REQUIRES(\n+        context, node_id_range.size() == 2,\n+        errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",\n+                                node_id_range.size()));\n     const int32_t node_id_first = node_id_range(0);  // inclusive\n     const int32_t node_id_last = node_id_range(1);   // exclusive\n \n@@ -1075,6 +1092,11 @@ class BoostedTreesSparseCalculateBestFeatureSplitOp : public OpKernel {\n                       \"dims, the last value in stats_summary_shape, which was \",\n                       stats_dims, \". At index (\", idx,\n                       \", 4), stats_summary_indices contains value \", stat_dim));\n+      OP_REQUIRES(context, stat_dim >= 0,\n+                  errors::InvalidArgument(\n+                      \"Stat dim, the sum of logits dim and hessian dim in \"\n+                      \"stats_summary_indices, should be >= 0, which was \",\n+                      stat_dim, \" at index \", idx));\n       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(\n           FeatureMapIterator::value_type(feature_dim, BucketMap()));\n       auto& b_map = f_insert_result.first->second;\n@@ -1307,6 +1329,12 @@ class BoostedTreesMakeStatsSummaryOp : public OpKernel {\n     const Tensor* gradients_t;\n     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));\n     const auto gradients = gradients_t->matrix<float>();\n+    OP_REQUIRES(\n+        context, node_ids.size() == gradients.dimension(0),\n+        errors::InvalidArgument(\n+            \"node_ids size should match 0th dim of gradients. node ids \"\n+            \"size: \",\n+            node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));\n     // hessians\n     const Tensor* hessians_t;\n     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));\n@@ -1376,6 +1404,13 @@ class BoostedTreesAggregateStatsOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));\n     const auto gradients = gradients_t->matrix<float>();\n \n+    OP_REQUIRES(\n+        context, node_ids.size() == gradients.dimension(0),\n+        errors::InvalidArgument(\n+            \"node_ids size should match 0th dim of gradients. node ids \"\n+            \"size: \",\n+            node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));\n+\n     // hessians.\n     const Tensor* hessians_t;\n     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));\n@@ -1406,6 +1441,9 @@ class BoostedTreesAggregateStatsOp : public OpKernel {\n \n     for (int i = 0; i < batch_size; ++i) {\n       const int32_t node = node_ids(i);\n+      OP_REQUIRES(context, node >= 0,\n+                  errors::InvalidArgument(\n+                      \"node_ids \", i, \"th entry should be >=0, got: \", node));\n       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {\n         const int32_t feature_value = feature(i, feature_dim);\n         const int32_t bucket =\n@@ -1612,7 +1650,12 @@ class BoostedTreesSparseAggregateStatsOp : public OpKernel {\n     const int64_t stats_dims = logits_dims + hessians_dims;\n     const int64_t num_sparse_entries = feature_indices_t->dim_size(0);\n     const int32_t feature_dims = feature_shape(1);\n-    DCHECK_LE(num_sparse_entries, batch_size * feature_dims);\n+    OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,\n+                errors::InvalidArgument(\n+                    \"feature_indices dim0 should be <= gradients dim0 * \"\n+                    \"feature_shape[1]. features_indices dim0: \",\n+                    num_sparse_entries, \" gradients dim0: \", batch_size,\n+                    \", feature_shape[1]: \", feature_dims));\n \n     // Aggregate statistics info to map.\n     StatsPartitionMap stats_map;"