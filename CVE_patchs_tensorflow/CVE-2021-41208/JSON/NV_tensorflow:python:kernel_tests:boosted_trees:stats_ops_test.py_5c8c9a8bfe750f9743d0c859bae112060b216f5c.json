"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for boosted_trees stats kernels.\"\"\"\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import boosted_trees_ops\nfrom tensorflow.python.ops import gen_boosted_trees_ops\nfrom tensorflow.python.ops import sparse_ops\nfrom tensorflow.python.platform import googletest\n\n\n_INEQUALITY_DEFAULT_LEFT = 'INEQUALITY_DEFAULT_LEFT'.encode('utf-8')\n_INEQUALITY_DEFAULT_RIGHT = 'INEQUALITY_DEFAULT_RIGHT'.encode('utf-8')\n_EQUALITY_DEFAULT_RIGHT = 'EQUALITY_DEFAULT_RIGHT'.encode('utf-8')\n\n\nclass StatsOpsTest(test_util.TensorFlowTestCase):\n  \"\"\"Tests stats_ops.\"\"\"\n\n  def _append_zeros_for_default_bucket(self, stats_summary):\n    summary_shapes = stats_summary.shape\n    # pad zeros for missing value bucket.\n    stats_summary = np.concatenate(\n        (stats_summary,\n         np.zeros([summary_shapes[0], summary_shapes[1], 1, summary_shapes[3]\n                  ])),\n        axis=2)\n    return stats_summary\n\n  def add_f_dim_and_append_zeros(self, stats_summaries):\n    \"\"\"Transform a list of stats summaries, adding a feature dimension.\n\n    The input shape is a list of arrays of shape [max_splits, num_buckets,\n    logits+hess dim]. This transformation returns a list of arrays of shape\n    [max_splits, 1, num_buckets + 1, logits+hess dim].\n\n    Args:\n      stats_summaries: a list of numpy arrays.\n\n    Returns:\n      A list of numpy arrays.\n    \"\"\"\n    return [\n        self._append_zeros_for_default_bucket(np.expand_dims(feature, axis=1))\n        for feature in stats_summaries\n    ]\n\n  def _get_stats_summary_for_split(self):\n    return [\n        [\n            [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .07], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .58], [0., 0.], [.3, .4]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 0\n        [\n            [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .06], [.06, .07]],  # node 1\n            [[.1, .1], [.2, .3], [-.4, .5], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 1\n    ]  # shape=[feature_dim, max_splits, num_buckets, 2]\n\n  def _get_sparse_stats_summary_for_split(self, stats_summary=None):\n    if stats_summary is None:\n      stats_summary = np.asarray(self._get_stats_summary_for_split())\n      stats_summary[0][0][1] = np.zeros([2])\n      stats_summary[1][0][2] = np.zeros([2])\n      stats_summary = np.moveaxis(stats_summary, 0, 1)\n    slices = stats_summary.nonzero()\n    values = stats_summary[slices]\n    indices = np.asarray(slices)\n    return np.moveaxis(indices, 0, 1), values, stats_summary.shape\n\n  def testCalculateBestSplitsWithoutRegularizationInSparse(self):\n    # This test uses the same data as dense, but run in sparse kernel and\n    # make sure the sparse kernel returns same result as dense kernel.\n    dense_summary = np.asarray([\n        [\n            [[0., 0.], [.0, .0], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .07], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .58], [0., 0.], [.3, .4]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 0\n        [\n            [[0., 0.], [0., 0.], [.0, .0], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .06], [.06, .07]],  # node 1\n            [[.1, .1], [.2, .3], [-.4, .5], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    node_id_range = [1, 3]\n    dense_summary = np.moveaxis(dense_summary, 0, 1)\n    dense_shape = dense_summary.shape\n\n    default_bucket_summary = np.zeros(dense_shape[0:2] + (1, dense_shape[3]))\n    sparse_summary = np.concatenate((dense_summary, default_bucket_summary),\n                                    axis=2)\n    slices = sparse_summary.nonzero()\n    summary_values = sparse_summary[slices]\n    summary_indices = np.asarray(slices)\n    summary_indices = np.moveaxis(summary_indices, 0, 1)\n    summary_shape = sparse_summary.shape\n\n    (node_ids, gains, _, _, left_node_contribs, right_node_contribs,\n     _) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.02823, 0.41184], gains)\n    self.assertAllClose([-0.6], left_node_contribs[0])\n    self.assertAllClose([-0.076923], right_node_contribs[0])\n\n  def testSparseCalculateBestSplitsWithoutRegularization(self):\n    node_id_range = [1, 3]\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split()\n\n    (node_ids, gains, feature_dimensions, thresholds, left_node_contribs,\n     right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.116495, 0.60429], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.631579], [-0.770833]], left_node_contribs)\n    self.assertAllClose([[0.833333], [0.8]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestGainsWithoutRegularization_v1_op(self):\n    \"\"\"Testing Gain calculation without any regularization.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = self._get_stats_summary_for_split()\n\n      (node_ids_list, gains_list, thresholds_list, left_node_contribs_list,\n       right_node_contribs_list\n      ) = boosted_trees_ops.calculate_best_gains_per_feature(\n          node_id_range,\n          stats_summary_list,\n          l1=0.0,\n          l2=0.0,\n          tree_complexity=0.0,\n          min_node_weight=0,\n          max_splits=max_splits)\n\n      self.assertAllEqual([[1, 2], [1, 2]], self.evaluate(node_ids_list))\n      self.assertAllClose([[0.004775, 0.41184], [0.02823, 0.41184]],\n                          self.evaluate(gains_list))\n      self.assertAllEqual([[1, 1], [1, 1]], self.evaluate(thresholds_list))\n      # The left node contrib will be later added to the previous node value to\n      # make the left node value, and the same for right node contrib.\n      self.assertAllClose([[[-.416667], [.568966]], [[-.6], [-.75]]],\n                          self.evaluate(left_node_contribs_list))\n      self.assertAllClose([[[-.592593], [-.75]], [[-.076923], [.568966]]],\n                          self.evaluate(right_node_contribs_list))\n\n  def testCalculateBestFeaturesInvalidSplitType_v2_op(self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [9, 12]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    stats_summaries = self.add_f_dim_and_append_zeros(stats_summaries)\n\n    with self.assertRaisesRegex(Exception, 'Incorrect split type'):\n      self.evaluate(\n          boosted_trees_ops.calculate_best_feature_split_v2(\n              node_id_range,\n              stats_summaries,\n              split_types=['INVALID'] * len(candidate_feature_ids),\n              candidate_feature_ids=candidate_feature_ids,\n              l1=0.0,\n              l2=0.0,\n              tree_complexity=0.0,\n              min_node_weight=0,\n              logits_dimension=1))\n\n  def testCalculateBestFeaturesWithoutRegularization_v2_op(self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [9, 12]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    stats_summaries = self.add_f_dim_and_append_zeros(stats_summaries)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range,\n             stats_summaries,\n             split_types=['inequality'] * len(candidate_feature_ids),\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature_id and dimension that has the best gain per node.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.02823, 0.41184], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllEqual([12, 9], feature_ids)\n    f_dim = 0  # Both features only have one dimension.\n    self.assertAllEqual([f_dim] * 2, feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-.6], [.568966]], left_node_contribs)\n    self.assertAllClose([[-.076923], [-.75]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureSplitsWithoutRegularization_v2_op(self):\n    \"\"\"Testing best split without any regularization for a multi-dim feature.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature_id and dimension that has the best gain per node.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.02823, 0.41184], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 0], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-.6], [.568966]], left_node_contribs)\n    self.assertAllClose([[-.076923], [-.75]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureSplitWMissingValuesWORegularization_v2_op(\n      self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.116495, 0.60429], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.631579], [-0.770833]], left_node_contribs)\n    self.assertAllClose([[0.833333], [0.8]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureEqualitySplitsWithoutRegularization_v2_op(\n      self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['equality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # 0.116495 = (-0.05)^2/0.06 + 0.36^2/0.57 - 0.31^2/0.63\n    # 0.60429 = (-0.4)^2/0.5 + 0.37^2/0.48 - 0.03^2/0.98\n    self.assertAllClose([0.116495, 0.60429], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([2, 2], thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    # left contrib 0.83 = 0.05/0.06, 0.8 = 0.4/0.5\n    self.assertAllClose([[0.833333], [.8]], left_node_contribs)\n    # right contrib -0.6315 = -0.36/0.57, -0.7708 = -0.37/0.48\n    self.assertAllClose([[-0.631579], [-0.770833]], right_node_contribs)\n    self.assertAllEqual([_EQUALITY_DEFAULT_RIGHT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureMixedSplitTypeWithoutRegularization_v2_op(\n      self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [9, 12]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Add in feature dimension.\n    stats_summaries = [\n        np.expand_dims(feature, axis=1) for feature in stats_summaries\n    ]\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range,\n             stats_summaries,\n             split_types=['inequality', 'equality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # 0.116495 = (-0.05)^2/0.06 + 0.36^2/0.57 - 0.31^2/0.63\n    # 0.60429 = (-0.4)^2/0.5 + 0.37^2/0.48 - 0.03^2/0.98\n    self.assertAllClose([0.116495, 0.60429], gains)\n    self.assertAllEqual([12, 12], feature_ids)\n    f_dim = 0  # Both features only have one dimension.\n    self.assertAllEqual([f_dim, f_dim], feature_dimensions)\n    self.assertAllEqual([2, 2], thresholds)\n    # Same result as equality only test, as feature_1 is chose for both nodes.\n    # left contrib 0.83 = 0.05/0.06, 0.8 = 0.4/0.5\n    self.assertAllClose([[0.833333], [.8]], left_node_contribs)\n    # right contrib -0.6315 = -0.36/0.57, -0.7708 = -0.37/0.48\n    self.assertAllClose([[-0.631579], [-0.770833]], right_node_contribs)\n    # Feature 1 is inequality.\n    self.assertAllEqual([_EQUALITY_DEFAULT_RIGHT, _EQUALITY_DEFAULT_RIGHT],\n                        split_types)\n\n  def testCalculateBestGainsWithL2_v1_op(self):\n    \"\"\"Testing Gain calculation with L2.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = self._get_stats_summary_for_split()\n\n      (node_ids_list, gains_list, thresholds_list, left_node_contribs_list,\n       right_node_contribs_list\n      ) = boosted_trees_ops.calculate_best_gains_per_feature(\n          node_id_range,\n          stats_summary_list,\n          l1=0.0,\n          l2=0.1,\n          tree_complexity=0.0,\n          min_node_weight=0,\n          max_splits=max_splits)\n\n      self.assertAllEqual([[1, 2], [1, 2]], self.evaluate(node_ids_list))\n      self.assertAllClose([[0., 0.33931375], [0.01879096, 0.33931375]],\n                          self.evaluate(gains_list))\n      self.assertAllEqual([[0, 1], [1, 1]], self.evaluate(thresholds_list))\n      # The left node contrib will be later added to the previous node value to\n      # make the left node value, and the same for right node contrib.\n      self.assertAllClose([[[0.], [.485294]], [[-.5], [-.6]]],\n                          self.evaluate(left_node_contribs_list))\n      self.assertAllClose([[[-.424658], [-.6]], [[-.043478], [.485294]]],\n                          self.evaluate(right_node_contribs_list))\n\n  def testCalculateMultiDimBestFeatureSplitsWithL2_v2_op(self):\n    \"\"\"Testing best split calculation with L2.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 0], feature_dimensions)\n    self.assertAllClose([0.01879096, 0.33931375], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    # # The left node contrib will be later added to the previous node value to\n    # # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-.5], [.485294]], left_node_contribs)\n    self.assertAllClose([[-.043478], [-.6]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateMultiDimBestFeatureSplitsWithMissingValuesL2_v2_op(self):\n    \"\"\"Testing best split calculation with L2.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllClose([0.077414, 0.501868], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.537313], [-0.637931]], left_node_contribs)\n    self.assertAllClose([[0.3125], [0.666667]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateMultiDimBestFeatureEqualitySplitsWithL2_v2_op(self):\n    \"\"\"Testing best split calculation with L2.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['equality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    # 0.077414 = 0.05^2/0.16 + 0.36^2/0.67 - 0.31^2/0.73\n    # 0.501868 = 0.4^2/0.6 + 0.37^2/0.58 - 0.03^2/1.08\n    self.assertAllClose([0.077414, 0.501868], gains)\n    self.assertAllEqual([2, 2], thresholds)\n    # # The left node contrib will be later added to the previous node value to\n    # # make the left node value, and the same for right node contrib.\n    # left contrib 0.3125 = 0.05/0.16, 0.6667 = 0.4/0.6\n    self.assertAllClose([[0.3125], [0.666667]], left_node_contribs)\n    # right contrib -0.5373 = -0.36/0.67, -0.6379 = -0.37/0.58\n    self.assertAllClose([[-0.537313], [-0.637931]], right_node_contribs)\n    self.assertAllEqual([_EQUALITY_DEFAULT_RIGHT] * 2, split_types)\n\n  def testSparseCalculateBestSplitsWithL2(self):\n    node_id_range = [1, 3]\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split()\n\n    (node_ids, gains, feature_dimensions, thresholds, left_node_contribs,\n     right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.077414, 0.501868], gains)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.537313], [-0.637931]], left_node_contribs)\n    self.assertAllClose([[0.3125], [0.666667]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT, _INEQUALITY_DEFAULT_LEFT],\n                        split_types)\n\n  def testCalculateBestGainsWithL1_v1_op(self):\n    \"\"\"Testing Gain calculation with L1.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = self._get_stats_summary_for_split()\n\n      l1 = 0.1\n      (node_ids_list, gains_list, thresholds_list, left_node_contribs_list,\n       right_node_contribs_list\n      ) = boosted_trees_ops.calculate_best_gains_per_feature(\n          node_id_range,\n          stats_summary_list,\n          l1=l1,\n          l2=0.0,\n          tree_complexity=0.0,\n          min_node_weight=0,\n          max_splits=max_splits)\n\n      self.assertAllEqual([[0, 1], [1, 1]], self.evaluate(thresholds_list))\n\n      self.assertAllEqual([[1, 2], [1, 2]], self.evaluate(node_ids_list))\n      self.assertAllClose([[[0.0], [0.3965517]], [[-0.4], [-0.5]]],\n                          self.evaluate(left_node_contribs_list))\n\n      self.assertAllClose([[[-0.3333333], [-0.5]], [[0.0], [0.396552]]],\n                          self.evaluate(right_node_contribs_list))\n\n      # Gain should also include an adjustment of the gradient by l1.\n      self.assertAllClose([[0.0, 0.191207], [0.01, 0.191207]],\n                          self.evaluate(gains_list))\n\n  def testCalculateBestMultiDimFeatureSplitsWithL1_v2_op(self):\n    \"\"\"Testing best split calculation with L1.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.1,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    # Gain should also include an adjustment of the gradient by l1.\n    self.assertAllClose([0.01, 0.191207], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-0.4], [-0.5]], left_node_contribs)\n    self.assertAllClose([[0.], [0.396552]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureSplitsWithMissingValuesL1_v2_op(self):\n    \"\"\"Testing best split calculation with L1.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.1,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    # Gain should also include an adjustment of the gradient by l1.\n    # (0.36-0.1)^2/0.57 + 0 - (0.31-0.1)^2/0.63 = 0.048597\n    # (0.37-0.1)^2/0.48 + (-0.4+0.1)^2/0.5 = 0.331875\n    self.assertAllClose([0.048597, 0.331875], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    # -(0.36-0.1)/0.57 = -0.45614\n    # -(0.37-0.1)/0.48 = -0.5625\n    self.assertAllClose([[-0.45614], [-0.5625]], left_node_contribs)\n    # -(-0.4+0.1)/0.5 = 0.6\n    self.assertAllClose([[0.], [0.6]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureEqualitySplitsWithL1_v2_op(self):\n    \"\"\"Testing best split calculation with L1.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['equality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.1,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # 0.048597 = 0 + 0.26^2/0.57 - 0.21^2/0.63\n    # 0.501868 = 0.3^2/0.5 + 0.27^2/0.48 - 0\n    self.assertAllClose([0.048597, 0.331875], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([2, 2], thresholds)\n    # # The left node contrib will be later added to the previous node value to\n    # # make the left node value, and the same for right node contrib.\n    # left contrib 0 (-0.05>-0.1), 0.6 = 0.3/0.5\n    self.assertAllClose([[0], [0.6]], left_node_contribs)\n    # right contrib -0.45614 = -0.26/0.57, -0.5625 = -0.27/0.48\n    self.assertAllClose([[-0.45614], [-0.5625]], right_node_contribs)\n    self.assertAllEqual([_EQUALITY_DEFAULT_RIGHT] * 2, split_types)\n\n  def testSparseCalculateBestSplitsWithL1(self):\n    node_id_range = [1, 3]\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split()\n\n    (node_ids, gains, feature_dimensions, thresholds, left_node_contribs,\n     right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.1,\n             l2=0.,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.048597, 0.331875], gains)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.45614], [-0.5625]], left_node_contribs)\n    self.assertAllClose([[0.0], [0.6]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestGainsWithTreeComplexity_v1_op(self):\n    \"\"\"Testing best gain calculation with tree complexity.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = self._get_stats_summary_for_split()\n\n      l2 = 0.1\n      tree_complexity = 3.\n      (node_ids_list, gains_list, thresholds_list, left_node_contribs_list,\n       right_node_contribs_list\n      ) = boosted_trees_ops.calculate_best_gains_per_feature(\n          node_id_range,\n          stats_summary_list,\n          l1=0.0,\n          l2=l2,\n          tree_complexity=tree_complexity,\n          min_node_weight=0,\n          max_splits=max_splits)\n\n      self.assertAllEqual([[1, 2], [1, 2]], self.evaluate(node_ids_list))\n\n      self.assertAllClose([[-3., -2.66068625], [-2.98120904, -2.66068625]],\n                          self.evaluate(gains_list))\n\n      self.assertAllEqual([[0, 1], [1, 1]], self.evaluate(thresholds_list))\n      # The left node contrib will be later added to the previous node value to\n      # make the left node value, and the same for right node contrib.\n      self.assertAllClose([[[0.], [.485294]], [[-.5], [-.6]]],\n                          self.evaluate(left_node_contribs_list))\n      self.assertAllClose([[[-.424658], [-.6]], [[-.043478], [.485294]]],\n                          self.evaluate(right_node_contribs_list))\n\n  def testCalculateBestMultiDimFeatureSplitsWithTreeComplexity_v2_op(self):\n    \"\"\"Testing best split calculation with tree complexity.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=3,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    # Gain should also include an adjustment of the gradient by l1.\n    self.assertAllClose([-2.98120904, -2.66068625], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 0], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-0.5], [0.485294]], left_node_contribs)\n    self.assertAllClose([[-0.043478], [-.6]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureSplitsWMissingValsTreeComplexity_v2_op(\n      self):\n    \"\"\"Testing best split calculation with tree complexity.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=3,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    # Get same result as v1 op (CalculateBestGainsPerFeature), and find the\n    # feature dimension that has the best gain.\n    self.assertAllEqual([1, 2], node_ids)\n    # Gain should also include an adjustment of the gradient by l1.\n    self.assertAllClose([-2.922586, -2.498132], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-0.537313], [-0.637931]], left_node_contribs)\n    self.assertAllClose([[0.3125], [0.666667]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestMultiDimFeatureEqualitySplitsWithTreeComplexity_v2_op(\n      self):\n    \"\"\"Testing best split calculation with tree complexity.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summaries = self._get_stats_summary_for_split()\n    # Convert from list of arrays to a single array and reshape to [max_splits,\n    # feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summaries, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['equality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.1,\n             tree_complexity=3,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # -2.922586 = 0.05^2/0.16 + 0.36^2/0.67 - 0.31^2/0.73 - 3\n    # -2.498132 = 0.4^2/0.6 + 0.37^2/0.58 - 0.03^2/1.08 - 3\n    self.assertAllClose([-2.922586, -2.498132], gains)\n    self.assertAllEqual([2, 2], thresholds)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    # # The left node contrib will be later added to the previous node value to\n    # # make the left node value, and the same for right node contrib.\n    # left contrib 0.3125 = 0.05/0.16, 0.6667 = 0.4/0.6\n    self.assertAllClose([[0.3125], [0.666667]], left_node_contribs)\n    # right contrib -0.5373 = -0.36/0.67, -0.6379 = -0.37/0.58\n    self.assertAllClose([[-0.537313], [-0.637931]], right_node_contribs)\n    self.assertAllEqual([_EQUALITY_DEFAULT_RIGHT] * 2, split_types)\n\n  def testSparseCalculateBestSplitsWithTreeComplexity(self):\n    \"\"\"Testing best split calculation with tree complexity.\"\"\"\n    node_id_range = [1, 3]\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split()\n\n    (node_ids, gains, feature_dimensions, thresholds, left_node_contribs,\n     right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.,\n             l2=0.1,\n             tree_complexity=3.,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([-2.922586, -2.498132], gains)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-0.537313], [-0.637931]], left_node_contribs)\n    self.assertAllClose([[0.3125], [0.666667]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestGainsWithMinNodeWeight_v1_op(self):\n    \"\"\"Testing Gain calculation with min node weight.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = [\n          [\n              [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n              [[0., 0.], [.15, .036], [.06, .07], [.1, .2]],  # node 1\n              [[0., 0.], [-.33, .68], [0., 0.], [.3, .4]],  # node 2\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n          ],  # feature 0\n          [\n              [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n              [[0., 0.], [.3, .5], [-.05, .6], [.06, .07]],  # node 1\n              [[.1, .1], [.2, .03], [-.4, .05], [.07, .08]],  # node 2\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n          ],  # feature 1\n      ]  # feature_dim * shape=[max_splits, num_buckets, 2]\n\n      (node_ids_list, gains_list, thresholds_list, left_node_contribs_list,\n       right_node_contribs_list\n      ) = boosted_trees_ops.calculate_best_gains_per_feature(\n          node_id_range,\n          stats_summary_list,\n          l1=0.0,\n          l2=0.0,\n          tree_complexity=0.0,\n          min_node_weight=1,\n          max_splits=max_splits)\n\n      # We can't split node 1 on feature 1 and node 2 on feature 2 because of\n      # the min node weight.\n      self.assertAllEqual([[2], [1]], self.evaluate(node_ids_list))\n      self.assertAllClose([[0.384314], [0.098013]], self.evaluate(gains_list))\n      self.assertAllEqual([[1], [1]], self.evaluate(thresholds_list))\n      self.assertAllClose([[[0.4852941]], [[-.6]]],\n                          self.evaluate(left_node_contribs_list))\n      self.assertAllClose([[[-0.75]], [[-0.014925]]],\n                          self.evaluate(right_node_contribs_list))\n\n  def testCalculateMultiDimBestSplitsWithMinNodeWeight_v2_op(self):\n    \"\"\"Testing best split calculation with min node weight.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .61], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .68], [0., 0.], [.3, .4]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 0\n        [\n            [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .6], [.06, .07]],  # node 1\n            [[.1, 1.], [.2, -.05], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # Reshape to [max_splits, feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=1,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # Gain should also include an adjustment of the gradient by l1.\n    self.assertAllClose([0.098013, 0.931596], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-.6], [-0.315789]], left_node_contribs)\n    self.assertAllClose([[-0.014925], [2.53846]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateMultiDimBestSplitsWithMissingValuesMinNodeWeight_v2_op(self):\n    \"\"\"Testing best split calculation with min node weight.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .61], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .68], [0., 0.], [.3, .4]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 0\n        [\n            [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .6], [.06, .07]],  # node 1\n            [[.1, 1.], [.2, -.05], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # Reshape to [max_splits, feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=1,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    # Gain should also include an adjustment of the gradient by l1.\n    self.assertAllClose([0.149398, 3.332075], gains)\n    self.assertAllEqual([4, 4], feature_ids)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[-0.631579], [-0.359223]], left_node_contribs)\n    self.assertAllClose([[0.083333], [7.999989]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testSparseCalculateBestSplitsWithMinNodeWeight(self):\n    \"\"\"Testing best split calculation with min node weight.\"\"\"\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.0, .0], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .61], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .68], [0., 0.], [.3, .4]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 0\n        [\n            [[0., 0.], [0., 0.], [.0, .0], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [-.05, .6], [.3, .5], [.06, .07]],  # node 1\n            [[.1, 1.], [.2, -.05], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # reshape to [max_splits, feature_dim, num_buckets, 2]\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split(stats_summary)\n\n    (node_ids, gains, feature_dimensions, thresholds, left_node_contribs,\n     right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.sparse_calculate_best_feature_split(\n             node_id_range,\n             summary_indices,\n             summary_values,\n             summary_shape,\n             l1=0.,\n             l2=0.,\n             tree_complexity=0.,\n             min_node_weight=1,\n             logits_dimension=1))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.149398, 3.332079], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllClose([[0.083333], [-0.359223]], left_node_contribs)\n    self.assertAllClose([[-0.631579], [7.999998]], right_node_contribs)\n    self.assertAllEqual([1, 1], feature_dimensions)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_RIGHT, _INEQUALITY_DEFAULT_LEFT],\n                        split_types)\n\n  def testCalculateBestGainsWithMinNodeWeightNoSplitOnFeaturePossible_v1_op(\n      self):\n    \"\"\"Testing Gain calculation without any regularization.\"\"\"\n    with self.cached_session() as sess:\n      max_splits = 7\n      node_id_range = [1, 3]  # node 1 through 2 will be processed.\n      stats_summary_list = [\n          [\n              [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n              [[0., 0.], [.15, .0036], [.06, .007], [.1, .2]],  # node 1\n              [[0., 0.], [-.33, .068], [0., 0.], [.3, .04]],  # node 2\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n          ],  # feature 0\n          [\n              [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n              [[0., 0.], [.3, .5], [-.05, .6], [.06, .07]],  # node 1\n              [[.1, .1], [.2, .03], [-.4, .05], [.07, .08]],  # node 2\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n              [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n          ],  # feature 1\n      ]  # feature_dim * shape=[max_splits, num_buckets, 2]\n\n      (node_ids_list, _, _, _,\n       _) = boosted_trees_ops.calculate_best_gains_per_feature(\n           node_id_range,\n           stats_summary_list,\n           l1=0.0,\n           l2=0.0,\n           tree_complexity=0.0,\n           min_node_weight=1,\n           max_splits=max_splits)\n\n      # We can't split either of the nodes on the first feature\n      self.assertEqual(2, len(self.evaluate(node_ids_list)))\n      self.assertAllEqual([], self.evaluate(node_ids_list)[0])\n      self.assertAllEqual([1], self.evaluate(node_ids_list)[1])\n\n      # Now check when we can't split on any feature\n      (node_ids_list, _, _, _,\n       _) = boosted_trees_ops.calculate_best_gains_per_feature(\n           node_id_range,\n           stats_summary_list,\n           l1=0.0,\n           l2=0.0,\n           tree_complexity=0.0,\n           min_node_weight=10,\n           max_splits=max_splits)\n      self.assertAllEqual([[], []], self.evaluate(node_ids_list))\n\n  def testCalculateBestMultiDimFeatureSplitsWithNoSplitOnFeaturePossible_v2_op(\n      self):\n    \"\"\"Testing best split calculation with min node weight and no split.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .7], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .068], [0., 0.], [.3, .04]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 0\n        [\n            [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .06], [.06, .7]],  # node 1\n            [[.1, .1], [.2, -.05], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # Reshape to [max_splits, feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, _, _, _, _, _, _,\n     _) = boosted_trees_ops.calculate_best_feature_split_v2(\n         node_id_range, [stats_summary],\n         split_types=['inequality'],\n         candidate_feature_ids=candidate_feature_ids,\n         l1=0.0,\n         l2=0.0,\n         tree_complexity=0.0,\n         min_node_weight=1,\n         logits_dimension=1)\n\n    # We can't split either of the nodes on the first feature.\n    self.assertAllEqual([1], node_ids)\n\n    # Now check when we can't split on any feature.\n    (node_ids, _, _, _, _, _, _,\n     _) = boosted_trees_ops.calculate_best_feature_split_v2(\n         node_id_range, [stats_summary],\n         split_types=['inequality'],\n         candidate_feature_ids=candidate_feature_ids,\n         l1=0.0,\n         l2=0.0,\n         tree_complexity=0.0,\n         min_node_weight=10,\n         logits_dimension=1)\n    self.assertAllEqual([], node_ids)\n\n  def testCalculateBestMultiDimFeatureEqualitySplitsWithNoSplitPossible_v2_op(\n      self):\n    \"\"\"Testing best split calculation with min node weight and no split.\"\"\"\n    candidate_feature_ids = [4]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .7], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .068], [0., 0.], [.3, .04]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 0\n        [\n            [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .06], [.06, .7]],  # node 1\n            [[.1, .1], [.2, -.05], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # f_dim 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # Reshape to [max_splits, feature_dim, num_buckets, 2].\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n\n    (node_ids, _, _, _, _, _, _,\n     _) = boosted_trees_ops.calculate_best_feature_split_v2(\n         node_id_range, [stats_summary],\n         split_types=['equality'],\n         candidate_feature_ids=candidate_feature_ids,\n         l1=0.0,\n         l2=0.0,\n         tree_complexity=0.0,\n         min_node_weight=1,\n         logits_dimension=1)\n\n    # We can't split either of the nodes on the first feature\n    self.assertAllEqual([1], node_ids)\n\n    # Now check when we can't split on any feature\n    (node_ids, _, _, _, _, _, _,\n     _) = boosted_trees_ops.calculate_best_feature_split_v2(\n         node_id_range, [stats_summary],\n         split_types=['equality'],\n         candidate_feature_ids=candidate_feature_ids,\n         l1=0.0,\n         l2=0.0,\n         tree_complexity=0.0,\n         min_node_weight=10,\n         logits_dimension=1)\n    self.assertAllEqual([], node_ids)\n\n  def testSparseCalculateBestSplitsWithMinNodeWeightNoSplitOnFeature(self):\n    \"\"\"Testing best split calculation with min node weight and no split.\"\"\"\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    stats_summary = np.asarray([\n        [\n            [[0., 0.], [.0, .0], [0., 0.], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.15, .36], [.06, .7], [.1, .2]],  # node 1\n            [[0., 0.], [-.33, .068], [0., 0.], [.3, .04]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 0\n        [\n            [[0., 0.], [0., 0.], [.0, .0], [0., 0.]],  # node 0; ignored\n            [[0., 0.], [.3, .5], [-.05, .6], [.06, .07]],  # node 1\n            [[.1, .1], [.2, .03], [-.4, .05], [.07, .08]],  # node 2\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 3; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 4; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 5; ignored\n            [[0., 0.], [0., 0.], [0., 0.], [0., 0.]],  # node 6; ignored\n        ],  # feature 1\n    ])  # feature_dim * shape=[max_splits, num_buckets, 2]\n    # reshape to [max_splits, feature_dim, num_buckets, 2]\n    stats_summary = np.moveaxis(stats_summary, 0, 1)\n    (summary_indices, summary_values,\n     summary_shape) = self._get_sparse_stats_summary_for_split(stats_summary)\n\n    (node_ids, _, _, _, _, _, _) = self.evaluate(\n        boosted_trees_ops.sparse_calculate_best_feature_split(\n            node_id_range,\n            summary_indices,\n            summary_values,\n            summary_shape,\n            l1=0.,\n            l2=0.,\n            tree_complexity=0.,\n            min_node_weight=1,\n            logits_dimension=1))\n\n    # We can't split either of the nodes on the first feature\n    self.assertAllEqual([1], node_ids)\n\n    # Now check when we can't split on any feature\n    (node_ids, _, _, _, _, _, _) = self.evaluate(\n        boosted_trees_ops.sparse_calculate_best_feature_split(\n            node_id_range,\n            summary_indices,\n            summary_values,\n            summary_shape,\n            l1=0.,\n            l2=0.,\n            tree_complexity=0.,\n            min_node_weight=10,\n            logits_dimension=1))\n    self.assertAllEqual([], node_ids)\n\n  @test_util.run_deprecated_v1\n  def testMakeStatsSummarySimple(self):\n    \"\"\"Simple test for MakeStatsSummary.\"\"\"\n    expected_stats_summary = np.asarray([1., 5., 2., 6., 3., 7., 4., 8.])\n    self.assertAllClose(\n        expected_stats_summary.reshape((1, 2, 2, 2)),\n        boosted_trees_ops.make_stats_summary(\n            node_ids=[0, 0, 1, 1],\n            gradients=[[1.], [2.], [3.], [4.]],\n            hessians=[[5.], [6.], [7.], [8.]],\n            bucketized_features_list=[[0, 1, 0, 1]],\n            max_splits=2,\n            num_buckets=2))\n\n  @test_util.run_deprecated_v1\n  def testAggregateStatsSimple(self):\n    # Get the same result as MakeStatsSummary Op.\n    expected_stats_summary = np.asarray(\n        [1., 5., 2., 6., 0., 0., 3., 7., 4., 8., 0., 0.])\n    # shape=[max_splits, num_buckets, feature_dim, stats_dim]\n    expected_stats_summary = np.reshape(expected_stats_summary, (2, 3, 1, 2))\n    # Reshape feature dim and bucket id axes\n    expected_stats_summary = np.swapaxes(expected_stats_summary, 1, 2)\n    self.assertAllClose(\n        expected_stats_summary,\n        boosted_trees_ops.boosted_trees_aggregate_stats(\n            node_ids=[0, 0, 1, 1],\n            gradients=[[1.], [2.], [3.], [4.]],\n            hessians=[[5.], [6.], [7.], [8.]],\n            feature=[[0], [1], [0], [1]],\n            max_splits=2,\n            num_buckets=2))\n\n  def testMakeStatsSummaryAccumulate(self):\n    \"\"\"Tests that Summary actually accumulates.\"\"\"\n    with self.cached_session():\n      max_splits = 3\n      num_buckets = 4\n      node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n      gradients = [[.1], [.2], [.3], [-.4], [-.05], [.06], [.07], [.08]]\n      hessians = [[.2], [.3], [.4], [.5], [.06], [.07], [.08], [.09]]\n\n      # Tests a single feature.\n      bucketized_features = [[3, 1, 2, 0, 1, 2, 0, 1]]\n      result = boosted_trees_ops.make_stats_summary(\n          node_ids, gradients, hessians, bucketized_features, max_splits,\n          num_buckets)  # shape=[max_splits, num_buckets, feature_dim, 2]\n      self.assertAllClose(\n          [[\n              [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0\n              [[0., 0.], [.15, .36], [.06, .07], [.1, .2]],  # node 1\n              [[-.33, .58], [0., 0.], [.3, .4], [0., 0.]],  # node 2\n          ]],\n          self.evaluate(result))\n\n  def testAggregateStatsAccumulate(self):\n    \"\"\"Tests that Summary actually accumulates.\"\"\"\n    max_splits = 3\n    num_buckets = 4\n    node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n    gradients = [[.1], [.2], [.3], [-.4], [-.05], [.06], [.07], [.08]]\n    hessians = [[.2], [.3], [.4], [.5], [.06], [.07], [.08], [.09]]\n\n    # Tests a single feature.\n    bucketized_features = [[3], [1], [2], [0], [1], [2], [0], [1]]\n    result = boosted_trees_ops.boosted_trees_aggregate_stats(\n        node_ids, gradients, hessians, bucketized_features, max_splits,\n        num_buckets)\n    # shape=[max_splits, num_buckets, feature_dim, stats_dim]\n    # Get the same result as MakeStatsSummary Op.\n    expected_stats_summary = [\n        [[[0., 0.]], [[.08, .09]], [[0., 0.]], [[0., 0.]], [[0., 0.]]],\n        [[[0., 0.]], [[.15, .36]], [[.06, .07]], [[.1, .2]], [[0., 0.]]],\n        [[[-.33, .58]], [[0., 0.]], [[.3, .4]], [[0., 0.]], [[0., 0.]]],\n    ]\n    # Swap feature dim and bucket id axis\n    expected_stats_summary = np.swapaxes(expected_stats_summary, 1, 2)\n    self.assertAllClose(expected_stats_summary, result)\n\n  def testAggregateStatsAccumulateWithMissingValue(self):\n    \"\"\"Tests that Summary actually accumulates.\"\"\"\n    max_splits = 3\n    num_buckets = 4\n    node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n    gradients = [[.1], [.2], [.3], [-.4], [-.05], [.06], [.07], [.08]]\n    hessians = [[.2], [.3], [.4], [.5], [.06], [.07], [.08], [.09]]\n\n    # Tests a single feature.\n    missing_feature = -1\n    bucketized_features = [[3], [1], [2], [0], [missing_feature], [2], [0], [1]]\n    result = boosted_trees_ops.boosted_trees_aggregate_stats(\n        node_ids, gradients, hessians, bucketized_features, max_splits,\n        num_buckets)\n    # shape=[max_splits, num_buckets, feature_dim, stats_dim]\n    # Get the same result as MakeStatsSummary Op.\n    expected_stats_summary = [\n        [[[0., 0.]], [[.08, .09]], [[0., 0.]], [[0., 0.]], [[0., 0.]]],\n        [[[0., 0.]], [[.2, .3]], [[.06, .07]], [[.1, .2]], [[-.05, .06]]],\n        [[[-.33, .58]], [[0., 0.]], [[.3, .4]], [[0., 0.]], [[0., 0.]]],\n    ]\n    # Swap feature dim and bucket id axis\n    expected_stats_summary = np.swapaxes(expected_stats_summary, 1, 2)\n    self.assertAllClose(expected_stats_summary, result)\n\n  def testMakeStatsSummaryMultipleFeatures(self):\n    \"\"\"Tests that MakeStatsSummary works for multiple features.\"\"\"\n    with self.cached_session():\n      max_splits = 3\n      num_buckets = 4\n      node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n      gradients = [[.1], [.2], [.3], [-.4], [-.05], [.06], [.07], [.08]]\n      hessians = [[.2], [.3], [.4], [.5], [.06], [.07], [.08], [.09]]\n\n      # Tests multiple features.\n      # The output from another feature will stored be in 3rd dimension.\n      bucketized_features = [[3, 1, 2, 0, 1, 2, 0, 1], [0, 0, 0, 2, 2, 3, 3, 2]]\n      result = boosted_trees_ops.make_stats_summary(\n          node_ids, gradients, hessians, bucketized_features, max_splits,\n          num_buckets)  # shape=[max_splits, num_buckets, feature_dim, 2]\n      self.assertAllClose(\n          [\n              [\n                  [[0., 0.], [.08, .09], [0., 0.], [0., 0.]],  # node 0\n                  [[0., 0.], [.15, .36], [.06, .07], [.1, .2]],  # node 1\n                  [[-.33, .58], [0., 0.], [.3, .4], [0., 0.]],  # node 2\n              ],  # feature 0\n              [\n                  [[0., 0.], [0., 0.], [.08, .09], [0., 0.]],  # node 0\n                  [[.3, .5], [0., 0.], [-.05, .06], [.06, .07]],  # node 1\n                  [[.3, .4], [0., 0.], [-.4, .5], [.07, .08]],  # node 2\n              ],  # feature 1\n          ],\n          self.evaluate(result))\n\n  def testAggregatesSummaryMultipleDimensionFeature(self):\n    \"\"\"Tests that MakeStatsSummary works for multiple features.\"\"\"\n    expected_stats_summary = np.asarray(\n        [[0, 0, 0, 0, .08, .09, 0, 0, 0, 0, .08, .09, 0, 0, 0, 0, 0, 0, 0, 0],\n         [\n             0, 0, .3, .5, .15, .36, 0, 0, .06, .07, -.05, .06, .1, .2, .06,\n             .07, 0, 0, 0, 0\n         ],\n         [\n             -.33, .58, .3, .4, 0, 0, 0, 0, .3, .4, -.4, .5, 0, 0, .07, .08, 0,\n             0, 0, 0\n         ]])\n    with self.cached_session():\n      max_splits = 3\n      num_buckets = 4\n      node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n      gradients = [[.1], [.2], [.3], [-.4], [-.05], [.06], [.07], [.08]]\n      hessians = [[.2], [.3], [.4], [.5], [.06], [.07], [.08], [.09]]\n\n      # Tests multiple features.\n      bucketized_features = [[3, 0], [1, 0], [2, 0], [0, 2], [1, 2], [2, 3],\n                             [0, 3], [1, 2]]\n      result = boosted_trees_ops.boosted_trees_aggregate_stats(\n          node_ids, gradients, hessians, bucketized_features, max_splits,\n          num_buckets)\n      # Reshape to [max_splits, num_buckets, feature_dim, stats_dim]\n      expected_stats_summary = np.reshape(expected_stats_summary, (3, 5, 2, 2))\n      # Swap feature_dim and bucket_id axis\n      expected_stats_summary = np.swapaxes(expected_stats_summary, 1, 2)\n      self.assertAllClose(expected_stats_summary, result)\n\n  def testAggregateStatsMultiClass(self):\n    \"\"\"Tests that Summary actually accumulates.\"\"\"\n    with self.cached_session():\n      max_splits = 3\n      num_buckets = 4\n      node_ids = [1, 1, 2, 2, 1, 1, 2, 0]\n      gradients = [[.1, .2], [.2, .4], [.3, .6], [-.4, -.8], [-.05, -.1],\n                   [.06, .12], [.07, .14], [.08, .16]]\n      hessians = [[.2, .6], [.3, .9], [.4, 1.2], [.5, 1.5], [.06, .18],\n                  [.07, .21], [.08, .24], [.09, .27]]\n\n      # Tests a single feature.\n      bucketized_features = [[3], [1], [2], [0], [1], [2], [0], [1]]\n      result = boosted_trees_ops.boosted_trees_aggregate_stats(\n          node_ids, gradients, hessians, bucketized_features, max_splits,\n          num_buckets)\n      # shape=[max_splits, num_buckets, feature_dim, stats_dim]\n      expected_stats_summary = [\n          [[[0., 0., 0., 0.]], [[.08, .16, .09, .27]], [[0., 0., 0., 0.]],\n           [[0., 0., 0., 0.]], [[0., 0., 0., 0.]]],\n          [[[0., 0., 0., 0.]], [[.15, 0.3, .36, 1.08]], [[.06, 0.12, .07,\n                                                          0.21]],\n           [[.1, .2, .2, .6]], [[0., 0., 0., 0.]]],\n          [[[-.33, -.66, .58, 1.74]], [[0., 0., 0., 0.]], [[.3, .6, .4, 1.2]],\n           [[0., 0., 0., 0.]], [[0., 0., 0., 0.]]],\n      ]\n      expected_stats_summary = np.swapaxes(expected_stats_summary, 1, 2)\n      self.assertAllClose(expected_stats_summary, result)\n\n  def _get_dense_summaries_from_sparse_features(self, max_splits, num_buckets,\n                                                batch_size, feature_dims,\n                                                logits_dims, hess_dims):\n    np.random.seed(0)\n    stats_dims = logits_dims + hess_dims\n    node_ids = np.random.randint(max_splits, size=batch_size)\n    gradients = np.random.uniform(5.0, size=(batch_size, logits_dims))\n    hessians = np.random.uniform(5.0, size=(batch_size, hess_dims))\n    dense_indices = np.random.randint(2, size=(batch_size, feature_dims))\n    feature_indices = np.argwhere(dense_indices == 1)\n    missing_feature_indices = np.argwhere(dense_indices == 0)\n    feature_values = np.random.randint(num_buckets, size=len(feature_indices))\n    feature_shape = np.asarray([batch_size, feature_dims])\n    # Last bucket is for missing values.\n    dense_summary = np.zeros(\n        (max_splits, feature_dims, num_buckets + 1, stats_dims))\n    for (instance, f_dim), bucket in zip(feature_indices, feature_values):\n      node_id = node_ids[instance]\n      dense_summary[node_id][f_dim][bucket] += np.concatenate(\n          [gradients[instance], hessians[instance]])\n\n    for instance, f_dim in missing_feature_indices:\n      node_id = node_ids[instance]\n      dense_summary[node_id][f_dim][num_buckets] += np.concatenate(\n          [gradients[instance], hessians[instance]])\n\n    return (node_ids, gradients, hessians, feature_indices, feature_values,\n            feature_shape, dense_summary)\n\n  def testMakeSparseStatsSummarySingleFeatureDimension(self):\n    batch_size = 10\n    max_splits = 2\n    num_buckets = 2\n    feature_dims = 1\n    logits_dims = 1\n    hess_dims = 1\n\n    (node_ids, gradients, hessians, feature_indices, feature_values,\n     feature_shape,\n     expected_dense_summary) = self._get_dense_summaries_from_sparse_features(\n         max_splits, num_buckets, batch_size, feature_dims, logits_dims,\n         hess_dims)\n\n    (summary_indices, summary_values,\n     summary_shape) = boosted_trees_ops.boosted_trees_sparse_aggregate_stats(\n         node_ids, gradients, hessians, feature_indices, feature_values,\n         feature_shape, max_splits, num_buckets)\n    dense_result = sparse_ops.sparse_to_dense(summary_indices, summary_shape,\n                                              summary_values)\n    self.assertAllClose(expected_dense_summary, dense_result)\n\n  def testMakeSparseStatsSummaryMultiDimFeature(self):\n    batch_size = 10\n    max_splits = 2\n    num_buckets = 2\n    feature_dims = 1\n    logits_dims = 1\n    hess_dims = 1\n\n    (node_ids, gradients, hessians, feature_indices, feature_values,\n     feature_shape,\n     expected_dense_summary) = self._get_dense_summaries_from_sparse_features(\n         max_splits, num_buckets, batch_size, feature_dims, logits_dims,\n         hess_dims)\n\n    (summary_indices, summary_values,\n     summary_shape) = boosted_trees_ops.boosted_trees_sparse_aggregate_stats(\n         node_ids, gradients, hessians, feature_indices, feature_values,\n         feature_shape, max_splits, num_buckets)\n    dense_result = sparse_ops.sparse_to_dense(summary_indices, summary_shape,\n                                              summary_values)\n    self.assertAllClose(expected_dense_summary, dense_result)\n\n  def testMakeSparseStatsSummaryMultiClass(self):\n    batch_size = 10\n    max_splits = 2\n    num_buckets = 2\n    feature_dims = 1\n    logits_dims = 2\n    hess_dims = 2\n\n    (node_ids, gradients, hessians, feature_indices, feature_values,\n     feature_shape,\n     expected_dense_summary) = self._get_dense_summaries_from_sparse_features(\n         max_splits, num_buckets, batch_size, feature_dims, logits_dims,\n         hess_dims)\n\n    (summary_indices, summary_values,\n     summary_shape) = boosted_trees_ops.boosted_trees_sparse_aggregate_stats(\n         node_ids, gradients, hessians, feature_indices, feature_values,\n         feature_shape, max_splits, num_buckets)\n    dense_result = sparse_ops.sparse_to_dense(summary_indices, summary_shape,\n                                              summary_values)\n    self.assertAllClose(expected_dense_summary, dense_result)\n\n  def testMakeSparseStatsSummaryMultiClassAndMultiFeatureDim(self):\n    batch_size = 10\n    max_splits = 2\n    num_buckets = 2\n    feature_dim = 2\n    logits_dims = 2\n    hess_dims = 2\n\n    (node_ids, gradients, hessians, feature_indices, feature_values,\n     feature_shape,\n     expected_dense_summary) = self._get_dense_summaries_from_sparse_features(\n         max_splits, num_buckets, batch_size, feature_dim, logits_dims,\n         hess_dims)\n\n    (summary_indices, summary_values,\n     summary_shape) = boosted_trees_ops.boosted_trees_sparse_aggregate_stats(\n         node_ids, gradients, hessians, feature_indices, feature_values,\n         feature_shape, max_splits, num_buckets)\n    dense_result = sparse_ops.sparse_to_dense(summary_indices, summary_shape,\n                                              summary_values)\n    self.assertAllClose(expected_dense_summary, dense_result)\n\n  def _verify_precision(self, length):\n    with self.cached_session():\n      max_splits = 1\n      num_buckets = 1\n      node_ids = array_ops.fill([length], 0)\n\n      gradients = constant_op.constant(\n          2.0 / length, dtype=dtypes.float32, shape=[length, 1])\n      hessians = constant_op.constant(\n          0.2 / length, dtype=dtypes.float32, shape=[length, 1])\n\n      bucketized_features = array_ops.zeros([length], dtype=dtypes.int32)\n\n      result = boosted_trees_ops.make_stats_summary(\n          node_ids, gradients, hessians, [bucketized_features], max_splits,\n          num_buckets)  # shape=[max_splits, num_buckets, feature_dim, 2]\n\n      self.assertAllClose([[[[2., 0.2]]]], self.evaluate(result))\n\n  def testMakeStatsSummaryNumericalPrecisionSmallBatch(self):\n    \"\"\"Tests numeric precision.\"\"\"\n    self._verify_precision(length=2000)\n\n  def testMakeStatsSummaryNumericalPrecisionMediumBatch(self):\n    \"\"\"Tests numeric precision.\"\"\"\n    self._verify_precision(length=100000)\n\n  def testMakeStatsSummaryNumericalPrecisionLargeBatch(self):\n    \"\"\"Tests numeric precision.\"\"\"\n    self._verify_precision(length=1000000)\n\n  def testMakeStatsSummaryNumericalPrecisionMegaBatch(self):\n    \"\"\"Tests numeric precision.\"\"\"\n    self._verify_precision(length=50000000)\n\n  def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):\n    node_id_range = [1, 2]\n    stats_summary_list = [[[[]]]]\n    l1 = [1.0]\n    l2 = [1.0]\n    tree_complexity = [1.0]\n    min_node_weight = [1.17]\n    max_splits = 1\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(\n          node_id_range=node_id_range,\n          stats_summary_list=stats_summary_list,\n          l1=l1,\n          l2=l2,\n          tree_complexity=tree_complexity,\n          min_node_weight=min_node_weight,\n          max_splits=max_splits)\n\n  def testBoostedTreesCalculateBestFeatureSplitSecurity(self):\n    node_id_range = [1, 2]\n    stats_summary = [[[[]]]]\n    split_type = 'equality'\n    l1 = [1.0]\n    l2 = [1.0]\n    tree_complexity = [1.0]\n    min_node_weight = [1.17]\n    logits_dimension = 5\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(\n          node_id_range=node_id_range,\n          stats_summary=stats_summary,\n          l1=l1,\n          l2=l2,\n          tree_complexity=tree_complexity,\n          min_node_weight=min_node_weight,\n          logits_dimension=logits_dimension,\n          split_type=split_type)\n\n  def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(\n          node_id_range=[0, 8],\n          stats_summary=[[[[1.0], [2.0], [3.0]]]],\n          l1=[0.5],\n          l2=[0.5],\n          tree_complexity=[0.1],\n          min_node_weight=[1.0],\n          logits_dimension=8)\n\n  def testBoostedTreesCalculateBestFeatureSplitV2Security(self):\n    node_id_range = [1, 2]\n    stats_summaries_list = [[[[[]]]]]\n    split_types = ['inequality']\n    candidate_feature_ids = [1, 2, 3, 4]\n    l1 = [1.0]\n    l2 = [1.0]\n    tree_complexity = [1.0]\n    min_node_weight = [1.17]\n    logits_dimension = 5\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(\n          node_id_range=node_id_range,\n          stats_summaries_list=stats_summaries_list,\n          split_types=split_types,\n          candidate_feature_ids=candidate_feature_ids,\n          l1=l1,\n          l2=l2,\n          tree_complexity=tree_complexity,\n          min_node_weight=min_node_weight,\n          logits_dimension=logits_dimension)\n\n  def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):\n    node_id_range = []\n    stats_summary_indices = [[]]\n    stats_summary_values = [1.0]\n    stats_summary_shape = [1, 1, 1, 1]\n    l1 = [1.0]\n    l2 = [1.0]\n    tree_complexity = [0.5]\n    min_node_weight = [1.0]\n    logits_dimension = 3\n    split_type = 'inequality'\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(\n          node_id_range=node_id_range,\n          stats_summary_indices=stats_summary_indices,\n          stats_summary_values=stats_summary_values,\n          stats_summary_shape=stats_summary_shape,\n          l1=l1,\n          l2=l2,\n          tree_complexity=tree_complexity,\n          min_node_weight=min_node_weight,\n          logits_dimension=logits_dimension,\n          split_type=split_type)\n\n  def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(\n          node_id_range=[0, 1],\n          stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],\n          stats_summary_values=[0.1, 0.2, 0.3],\n          stats_summary_shape=[1, 1, 1, 1],\n          l1=[0.5],\n          l2=[0.5],\n          tree_complexity=[0.1],\n          min_node_weight=[1.0],\n          logits_dimension=1)\n\n  def testBoostedTreesMakeStatsSummarySecurity(self):\n    node_ids = [1, 2]\n    gradients = [[]]\n    hessians = [[0.2], [0.1]]\n    bucketized_features_list = [[1], [2]]\n    max_splits = 3\n    num_buckets = 3\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_make_stats_summary(\n          node_ids=node_ids,\n          gradients=gradients,\n          hessians=hessians,\n          bucketized_features_list=bucketized_features_list,\n          max_splits=max_splits,\n          num_buckets=num_buckets)\n\n  def testBoostedTreesMakeStatsSummarySecurity2(self):\n    node_ids = [1, 2, 3]\n    gradients = [[0.1], [0.2]]\n    hessians = [[0.2], [0.1]]\n    bucketized_features_list = [[1], [2]]\n    max_splits = 3\n    num_buckets = 3\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_make_stats_summary(\n          node_ids=node_ids,\n          gradients=gradients,\n          hessians=hessians,\n          bucketized_features_list=bucketized_features_list,\n          max_splits=max_splits,\n          num_buckets=num_buckets)\n\n  def testBoostedTreesAggregateStatsSecurity(self):\n    node_ids = [1, 2]\n    gradients = [[]]\n    hessians = [[100.0]]\n    feature = [[0, 0, 0]]\n    max_splits = 100\n    num_buckets = 100\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_aggregate_stats(\n          node_ids=node_ids,\n          gradients=gradients,\n          hessians=hessians,\n          feature=feature,\n          max_splits=max_splits,\n          num_buckets=num_buckets)\n\n  def testBoostedTreesAggregateStatsSecurity2(self):\n    node_ids = [-10]\n    gradients = [[0.0, 0.0]]\n    hessians = [[100.0]]\n    feature = [[0, 0, 0]]\n    max_splits = 100\n    num_buckets = 100\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      self.evaluate(\n          gen_boosted_trees_ops.boosted_trees_aggregate_stats(\n              node_ids=node_ids,\n              gradients=gradients,\n              hessians=hessians,\n              feature=feature,\n              max_splits=max_splits,\n              num_buckets=num_buckets))\n\n  def testBoostedTreesSparseAggregateStatsSecurity(self):\n    node_ids = []\n    gradients = [[1.0]]\n    hessians = [[100.0]]\n    feature_indices = [[0, 0, 0]]\n    feature_values = [0, 0, 0]\n    feature_shape = [0, 0, 0]\n    max_splits = 100\n    num_buckets = 100\n    with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n      gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(\n          node_ids=node_ids,\n          gradients=gradients,\n          hessians=hessians,\n          feature_indices=feature_indices,\n          feature_values=feature_values,\n          feature_shape=feature_shape,\n          max_splits=max_splits,\n          num_buckets=num_buckets)\n\n\nclass BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):\n  \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"\n\n  logits_dim = 2\n\n  def _get_stats_summary_for_split_diagonal_hessian(self):\n    summary = [\n        [[[0., 0., 0., 0.], [0.08, 0.2, 0.09, 0.3], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0.08, 0.2, 0.09, 0.3],\n          [0., 0., 0., 0.]]],  # node 0\n        [[[0., 0., 0., 0.], [-0.25, -0.1, 0.36, 0.2], [-0.14, 0.25, 0.07, 0.18],\n          [0.1, 0.235, 0.2, 0.06]],\n         [[0., 0., 0., 0.], [-0.3, 0.12, 0.5, 0.31], [-0.05, 0.115, 0.11, 0.09],\n          [0.06, 0.15, 0.02, 0.04]]],  # node 1\n        [[[0., 0., 0., 0.], [-0.03, 0.21, 0.28, 0.44], [0., 0., 0., 0.],\n          [0.3, 0.04, 0.4, 0.41]],\n         [[0.4, 0.188, 0.16, -0.03], [0.2, -0.088, 0.1, -0.24],\n          [-0.4, -0.06, 0.5, 0.15], [0.07, 0.21, -0.08, 0.97]]],  # node 2\n        [[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]],  # node 3\n        [[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]],  # node 4\n        [[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]],  # node 5\n        [[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]]  # node 6\n    ]\n    # [max_splits, feature_dim, num_buckets, 4]\n    return np.array(summary)\n\n  def _add_feature_dim(self, stats_summary):\n    \"\"\"Add dimension for features; number of features will be 1.\"\"\"\n    return np.expand_dims(stats_summary, axis=1)\n\n  def testSumOfStatsSummaryValuesFromHelperFunction(self):\n    \"\"\"Sum of grads and hessians is correct from helper function.\"\"\"\n    # [max_splits, feature_dim, num_buckets, 4]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n    # Test that sum of grads/hessians are same for both features for all nodes.\n    # [max_splits, feature_dim, 4]\n    agg = stats_summary.sum(axis=2)  # Sum along buckets.\n    self.assertAllClose(agg[:, 0, :], agg[:, 1, :])  # There are two features.\n    # Test sum of hessians for each nodes. These values are used to evaluate if\n    # node meets min_node_weight criteria.\n    nodes_agg = agg[:, 0, :]\n    hessians = nodes_agg[:, self.logits_dim:]\n\n    def frobenius(x, **kwargs):\n      return np.sqrt(np.square(x).sum(**kwargs))\n\n    self.assertAllClose([0.3132092, 0.76843998, 1.08853112, 0., 0., 0., 0.],\n                        frobenius(hessians, axis=1))\n\n  def testCalculateBestFeatureSplitsSingleClassVsMultiClass(self):\n    \"\"\"Testing same results using same grads/hess with both single and multi.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n\n    # Build same stats summary in single class and multi-class form (using\n    # diagonal hessian).\n    empty = [0] * 2\n    stats_summary = [\n        [empty, [.08, .09], empty],  # node 0; ignored\n        [empty, [-0.25, 0.11], [0.1, 0.5]],  # node 1\n        [empty, [0.14, 0.1], empty],  # node 2\n        [empty, empty, empty],  # node 3; ignored\n    ]\n    # [max_splits, feature_dim, num_buckets, 2]\n    stats_summary = self._add_feature_dim(stats_summary)\n    diag_empty = [0] * 4\n    diag_stats_summary = [\n        [diag_empty, [0, .08, 0, 0.09], diag_empty],  # node 0; ignored\n        [diag_empty, [0, -0.25, 0, 0.11], [0, 0.1, 0, 0.5]],  # node 1\n        [diag_empty, [0, 0.14, 0, 0.1], diag_empty],  # node 2\n        [diag_empty, diag_empty, diag_empty],  # node 3; ignored\n    ]\n    # [max_splits, feature_dim, num_buckets, 4]\n    diag_stats_summary = self._add_feature_dim(diag_stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=1))\n\n    (diag_node_ids, diag_gains, diag_feature_ids, diag_feature_dimensions,\n     diag_thresholds, diag_left_node_contribs, diag_right_node_contribs,\n     diag_split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [diag_stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=2))\n\n    self.assertAllEqual(node_ids, diag_node_ids)\n    self.assertAllClose(gains, diag_gains)\n    self.assertAllEqual(feature_ids, diag_feature_ids)\n    self.assertAllEqual(feature_dimensions, diag_feature_dimensions)\n    self.assertAllEqual(thresholds, diag_thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    zeros = np.zeros_like(left_node_contribs)\n    self.assertAllClose(\n        np.concatenate([zeros, left_node_contribs], axis=1),\n        diag_left_node_contribs)\n    self.assertAllClose(\n        np.concatenate([zeros, right_node_contribs], axis=1),\n        diag_right_node_contribs)\n    self.assertAllEqual(split_types, diag_split_types)\n\n  def testCalculateBestFeatureSplitsDiagonalVsFull(self):\n    \"\"\"Test results are same using diagonal hessian and full hessian.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n\n    # Build same stats summary in diagonal and full hessian form, respectively.\n    diag_empty = [0] * 4\n    diag_stats_summary = [\n        [diag_empty, [.08, .09, -.1, .2], diag_empty],  # node 0; ignored\n        [diag_empty, [.15, .36, .21, -.11], [.06, .07, .67, 0.5]],  # node 1\n        [diag_empty, [-.33, .58, -.2, -.31], diag_empty],  # node 2\n        [diag_empty, diag_empty, diag_empty],  # node 3; ignored\n    ]\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    diag_stats_summary = self._add_feature_dim(diag_stats_summary)\n    full_empty = [0] * 6\n    full_stats_summary = [\n        [full_empty, [.08, .09, -.1, 0, 0, .2], full_empty],  # node 0; ignored\n        [full_empty, [.15, .36, .21, 0, 0, -.11], [.06, .07, .67, 0, 0,\n                                                   0.5]],  # node 1\n        [full_empty, [-.33, .58, -.2, 0, 0, -.31], full_empty],  # node 2\n        [full_empty, full_empty, full_empty],  # node 3; ignored\n    ]\n    # [max_splits, feature_dim, num_buckets, logits_dim + logits_dim**2]\n    full_stats_summary = self._add_feature_dim(full_stats_summary)\n    (diag_node_ids, diag_gains, diag_feature_ids, diag_feature_dimensions,\n     diag_thresholds, diag_left_node_contribs, diag_right_node_contribs,\n     diag_split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [diag_stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    (full_node_ids, full_gains, full_feature_ids, full_feature_dimensions,\n     full_thresholds, full_left_node_contribs, full_right_node_contribs,\n     full_split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [full_stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual(diag_node_ids, full_node_ids)\n    self.assertAllClose(diag_gains, full_gains)\n    self.assertAllEqual(diag_feature_ids, full_feature_ids)\n    self.assertAllEqual(diag_feature_dimensions, full_feature_dimensions)\n    self.assertAllEqual(diag_thresholds, full_thresholds)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose(diag_left_node_contribs, full_left_node_contribs)\n    self.assertAllClose(diag_right_node_contribs, full_right_node_contribs)\n    self.assertAllEqual(diag_split_types, full_split_types)\n\n  def testCalculateBestFeatureSplitsWithoutRegularization(self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.912981, 1.446218], gains)\n    self.assertAllEqual([2, 1], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[0.906977, -0.394737], [-2.307692, 0.370370]],\n                        left_node_contribs)\n    self.assertAllClose([[-0.5, -3.916667], [0.785714, -0.133928]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestFeatureSplitsWMissingValuesWoRegularization(self):\n    \"\"\"Testing best split calculation without any regularization.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.912981, 2.79444], gains)\n    self.assertAllEqual([0, 1], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.5, -3.916667], [-3.722223, -0.442857]],\n                        left_node_contribs)\n    self.assertAllClose([[0.906977, -0.394737], [0.8, 0.4]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestFeatureSplitsWithL2(self):\n    \"\"\"Testing best split calculation inith L2 regularization.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n    stats_summary = self._append_zeros_for_default_bucket(stats_summary)\n\n    l2 = 0.1\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=l2,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.475669, 1.009791], gains)\n    self.assertAllEqual([1, 1], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[0.543478, 0.333333], [-1.666667, 0.588235]],\n                        left_node_contribs)\n    self.assertAllClose([[0.108108, -1.426471], [0.634615, -0.122951]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestFeatureSplitsWithMissingValuesL2(self):\n    \"\"\"Testing best split calculation inith L2 regularization.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n\n    l2 = 0.1\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=l2,\n             tree_complexity=0.0,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.475669, 3.467833], gains)\n    self.assertAllEqual([1, 0], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[0.543478, 0.333333], [-2.611111, -0.382692]],\n                        left_node_contribs)\n    self.assertAllClose([[0.108108, -1.426471], [0.285714, 14.800049]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_RIGHT, _INEQUALITY_DEFAULT_LEFT],\n                        split_types)\n\n  def testCalculateBestFeatureSplitsWithMinNodeWeight(self):\n    \"\"\"Testing best split calculation with min_node_weight.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=0.5,\n             logits_dimension=self.logits_dim))\n\n    # Both nodes have large enough sum(hessians) so use them.\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllClose([0.912981, 2.79444], gains)\n    self.assertAllEqual([0, 1], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-0.5, -3.916667], [-3.722223, -0.442857]],\n                        left_node_contribs)\n    self.assertAllClose([[0.906977, -0.394737], [0.8, 0.4]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT] * 2, split_types)\n\n  def testCalculateBestFeatureSplitsWithTreeComplexity(self):\n    \"\"\"Testing best split calculation with tree complexity.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n\n    l2 = 0.1\n    tree_complexity = 3.\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=l2,\n             tree_complexity=tree_complexity,\n             min_node_weight=0,\n             logits_dimension=self.logits_dim))\n\n    self.assertAllEqual([1, 2], node_ids)\n    self.assertAllEqual([1, 2], node_ids)\n    # L2 test result, but subtracted by tree_complexity.\n    self.assertAllClose([-2.524331, 0.467833], gains)\n    self.assertAllEqual([1, 0], thresholds)\n    self.assertAllEqual([14, 14], feature_ids)\n    self.assertAllEqual([0, 1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[0.543478, 0.333333], [-2.611111, -0.382692]],\n                        left_node_contribs)\n    self.assertAllClose([[0.108108, -1.426471], [0.285714, 14.800049]],\n                        right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_RIGHT, _INEQUALITY_DEFAULT_LEFT],\n                        split_types)\n\n  def testCalculateBestFeatureSplitsWithMinNodeNoSplitOnFeaturePossible(self):\n    \"\"\"Test when parent node hessian doesn't meet min node weight.\"\"\"\n    candidate_feature_ids = [14]\n    node_id_range = [1, 3]  # node 1 through 2 will be processed.\n    # [max_splits, feature_dim, num_buckets, 2*logits_dim]\n    stats_summary = self._get_stats_summary_for_split_diagonal_hessian()\n\n    min_node_weight = 0.8\n    (node_ids, gains, feature_ids, feature_dimensions, thresholds,\n     left_node_contribs, right_node_contribs, split_types) = self.evaluate(\n         boosted_trees_ops.calculate_best_feature_split_v2(\n             node_id_range, [stats_summary],\n             split_types=['inequality'],\n             candidate_feature_ids=candidate_feature_ids,\n             l1=0.0,\n             l2=0.0,\n             tree_complexity=0.0,\n             min_node_weight=min_node_weight,\n             logits_dimension=self.logits_dim))\n\n    # node_1 doesn't have large enough sum(hessians) so don't return it.\n    self.assertAllEqual([2], node_ids)\n    self.assertAllClose([2.79444], gains)\n    self.assertAllEqual([1], thresholds)\n    self.assertAllEqual([14], feature_ids)\n    self.assertAllEqual([1], feature_dimensions)\n    # The left node contrib will be later added to the previous node value to\n    # make the left node value, and the same for right node contrib.\n    self.assertAllClose([[-3.722223, -0.442857]], left_node_contribs)\n    self.assertAllClose([[0.8, 0.4]], right_node_contribs)\n    self.assertAllEqual([_INEQUALITY_DEFAULT_LEFT], split_types)\n\n\nif __name__ == '__main__':\n  googletest.main()"