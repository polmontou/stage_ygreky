"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for Split Op.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.platform import test\n\n_TEST_DTYPES = (dtypes.float32, dtypes.float64, dtypes.complex64,\n                dtypes.complex128)\n\n\nclass SplitOpTest(test.TestCase):\n\n  def _makeData(self, shape, dtype):\n    data = np.random.rand(*shape).astype(dtype.as_numpy_dtype)\n    if dtype.is_complex:\n      data -= 1j * data\n    return data\n\n  @test_util.run_deprecated_v1\n  def testShapeInference(self):\n    model_input = array_ops.placeholder(dtypes.float32, shape=(1, 10))\n\n    # check that we fail during static shape inference if sizes are known\n    with self.assertRaises(ValueError):\n      # pylint: disable=expression-not-assigned\n      array_ops.split(model_input, [4], axis=1)[0]\n      # pylint: enable=expression-not-assigned\n\n    model_input = array_ops.placeholder(dtypes.float32)\n    inp = np.zeros((1, 10))\n    # check that we still fail at runtime if the shapes were unknown\n    with self.cached_session() as sess:\n      with self.assertRaises(errors_impl.InvalidArgumentError):\n        sess.run(array_ops.split(model_input, [4]), {model_input: inp})\n\n    # scalar Tensors are not permitted as num_splits\n    for axis in [0, -2]:\n      with self.cached_session() as sess:\n        with self.assertRaises(ValueError):\n          # pylint: disable=expression-not-assigned\n          sess.run(\n              array_ops.split(\n                  array_ops.ones([4, 4]),\n                  num_or_size_splits=constant_op.constant(2),\n                  axis=axis))\n          # pylint: enable=expression-not-assigned\n\n    # test that none split dimensions remain, even if we don't know how\n    # the split_dim will be split, but we do know the axis\n    result = array_ops.split(\n        array_ops.ones([5, 2]), array_ops.constant([2, 1, 2]) * 1, axis=0)\n\n    self.assertEqual(result[0].shape[1], 2)\n    self.assertEqual(result[1].shape[1], 2)\n    self.assertEqual(result[2].shape[1], 2)\n\n    model_input2 = array_ops.placeholder(dtypes.float32, shape=[None, 2])\n    result = array_ops.split(model_input2, [2, 2], axis=0)[0]\n\n    with self.cached_session() as sess:\n      sess.run(result, feed_dict={model_input2: np.ones([4, 2])})\n\n  @test_util.run_deprecated_v1\n  def testFailWithoutExplicitNum(self):\n    size_splits = array_ops.placeholder(dtype=dtypes.int32, shape=[None])\n\n    value = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n    with self.session() as sess:\n      with self.assertRaises(ValueError) as context:\n        sess.run(array_ops.split(value, size_splits), {size_splits: [2, 2, 6]})\n      self.assertIn(\"Cannot infer argument `num` from shape\",\n                    str(context.exception))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testExplicitNum(self):\n    size_splits = array_ops.constant([2, 2, 6], dtype=dtypes.int32)\n    value = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n    # Eager and Graph modes raise different exceptions\n    with self.assertRaises((errors_impl.InvalidArgumentError, ValueError)):\n      array_ops.split(value, size_splits, num=4)\n\n    r = self.evaluate(array_ops.split(value, size_splits, num=3))\n    self.assertAllEqual(r[0], value[0:2])\n    self.assertAllEqual(r[1], value[2:4])\n    self.assertAllEqual(r[2], value[4:])\n\n  @test_util.run_in_graph_and_eager_modes\n  def testListOfScalarTensors(self):\n    a = math_ops.cast(5, dtypes.int32)\n    b = math_ops.cast(6, dtypes.int32)\n\n    value = np.random.rand(11, 11)\n\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(array_ops.split(value, [a, b]))\n\n    self.assertAllEqual(result[0], value[0:5, :])\n    self.assertAllEqual(result[1], value[5:, :])\n\n  def _RunAndVerifyVariable(self, dtype, large_num_splits=False):\n    # Random dims of rank 5\n    shape = np.random.randint(1, 5, size=5)\n    split_dim = np.random.randint(-5, 5)\n    if large_num_splits:\n      num_split = np.random.randint(16, 25)\n    else:\n      num_split = np.random.randint(2, 8)\n    size_splits = np.random.randint(2, 8, num_split, dtype=np.int32)\n    shape[split_dim] = np.sum(size_splits)\n    inp = self._makeData(shape, dtype)\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(array_ops.split(inp, size_splits, split_dim))\n    slices = [slice(0, x) for x in shape]\n    offset = 0\n    for i in range(num_split):\n      slices[split_dim] = slice(offset, offset + size_splits[i])\n      offset += size_splits[i]\n      self.assertAllEqual(result[i], inp[slices])\n\n  def _testSpecialCasesVariable(self):\n    inp = np.random.rand(4, 4).astype(\"f\")\n\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(array_ops.split(inp, [4], 0))\n      self.assertAllEqual(result[0], inp)\n\n      result = self.evaluate(array_ops.split(inp, [-1, 3], 0))\n      self.assertAllEqual(result[0], inp[0:1, :])\n      self.assertAllEqual(result[1], inp[1:4, :])\n\n  def _testHugeNumberOfTensorsVariable(self, dtype):\n    num_split = 1000\n    size_splits = np.random.randint(1, 3, num_split, dtype=np.int32)\n    shape = [3, np.sum(size_splits)]\n    split_dim = 1\n    inp = self._makeData(shape, dtype)\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(array_ops.split(inp, size_splits, split_dim))\n    slices = [slice(0, x) for x in shape]\n    offset = 0\n    for i in range(num_split):\n      slices[split_dim] = slice(offset, offset + size_splits[i])\n      offset += size_splits[i]\n      self.assertAllEqual(result[i], inp[slices])\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSpecialCasesVariable(self):\n    self._testSpecialCasesVariable()\n    for dtype in _TEST_DTYPES:\n      self._testHugeNumberOfTensorsVariable(dtype)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testDegenerateVariable(self):\n    inp = np.random.rand(4, 4).astype(\"f\")\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(array_ops.split(inp, [-1, 4], 0))\n      self.assertAllEqual(result[0], inp[0:0, :])\n      self.assertAllEqual(result[1], inp[0:4, :])\n\n      result = self.evaluate(array_ops.split(inp, [4, -1], 0))\n      self.assertAllEqual(result[0], inp[0:4, :])\n      self.assertAllEqual(result[1], inp[4:4, :])\n\n      result = self.evaluate(array_ops.split(inp, [-1, 4], 1))\n      self.assertAllEqual(result[0], inp[:, 0:0])\n      self.assertAllEqual(result[1], inp[:, 0:4])\n\n      result = self.evaluate(array_ops.split(inp, [4, -1], 1))\n      self.assertAllEqual(result[0], inp[:, 0:4])\n      self.assertAllEqual(result[1], inp[:, 4:4])\n\n  def _testGradientsSimpleVariable(self, dtype):\n    inp = self._makeData((4, 4), dtype)\n    with test_util.device(use_gpu=True):\n      inp_tensor = ops.convert_to_tensor(inp)\n      s = array_ops.split(inp_tensor, [1, 3], 1)\n      inp_grads = [\n          self._makeData((4, 1), dtype), self._makeData((4, 3), dtype)\n      ]\n      grad_tensors = [constant_op.constant(x) for x in inp_grads]\n      grad = gradients_impl.gradients(s, [inp_tensor], grad_tensors)[-1]\n      result = self.evaluate(grad)\n\n    self.assertAllEqual(result[:, 0:1], inp_grads[0])\n    self.assertAllEqual(result[:, 1:4], inp_grads[1])\n\n  @test_util.run_deprecated_v1\n  def testOutputShape(self):\n    for axis in [1, -1]:\n      with self.cached_session():\n        tensor = array_ops.placeholder(dtypes.float32, shape=[None, 12])\n        size_splits = [3, 7, 2]\n        outputs = array_ops.split(tensor, size_splits, axis)\n        for i, output in enumerate(outputs):\n          self.assertEqual(output.get_shape().as_list(), [None, size_splits[i]])\n\n  def _compare(self, x, dim, num):\n    np_ans = np.split(x, num, dim)\n    with test_util.device(use_gpu=True):\n      tf_ans = array_ops.split(value=x, num_or_size_splits=num, axis=dim)\n      out = self.evaluate(tf_ans)\n    self.assertEqual(num, len(np_ans))\n    self.assertEqual(num, len(np_ans))\n    self.assertEqual(num, len(out))\n    for i in range(num):\n      self.assertAllEqual(np_ans[i], out[i])\n      self.assertShapeEqual(np_ans[i], tf_ans[i])\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSplitRows(self):\n    for dtype in _TEST_DTYPES:\n      inp = self._makeData((4, 4), dtype)\n      self._compare(inp, 0, 4)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSplitCols(self):\n    for dtype in _TEST_DTYPES:\n      inp = self._makeData((4, 4), dtype)\n      self._compare(inp, 1, 4)\n\n  def _testEmpty(self, x, dim, num, expected_shape):\n    with test_util.device(use_gpu=True):\n      tf_ans = array_ops.split(value=x, num_or_size_splits=num, axis=dim)\n      out = self.evaluate(tf_ans)\n    self.assertEqual(x.size, 0)\n    self.assertEqual(len(out), num)\n    for i in range(num):\n      self.assertEqual(out[i].shape, expected_shape)\n      self.assertEqual(expected_shape, tf_ans[i].get_shape())\n\n  @test_util.run_in_graph_and_eager_modes\n  def testEmpty(self):\n    # Note: np.split returns a rank-0 empty ndarray\n    # if the input ndarray is empty.\n    for dtype in _TEST_DTYPES:\n      inp = self._makeData((8, 0, 21), dtype)\n      self._testEmpty(inp, 0, 2, (4, 0, 21))\n      self._testEmpty(inp, 0, 4, (2, 0, 21))\n      self._testEmpty(inp, 1, 4, (8, 0, 21))\n      self._testEmpty(inp, 2, 3, (8, 0, 7))\n      self._testEmpty(inp, 2, 7, (8, 0, 3))\n\n  @test_util.run_in_graph_and_eager_modes\n  def testIdentity(self):\n    for dtype in _TEST_DTYPES:\n      inp = self._makeData((2, 2, 2), dtype)\n      self._compare(inp, 0, 1)\n      self._compare(inp, 1, 1)\n      self._compare(inp, 2, 1)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testSplitDim0(self):\n    for dtype in _TEST_DTYPES:\n      self._compare(self._makeData((6, 10, 18), dtype), 0, 3)\n      self._compare(self._makeData((6, 7, 18), dtype), 0, 3)\n      self._compare(self._makeData((6, 7, 9), dtype), 0, 3)\n\n  def _RunAndVerify(self, dtype, large_num_splits=False):\n    # Random dims of rank 5\n    shape = np.random.randint(0, 5, size=5)\n    split_dim = np.random.randint(-5, 5)\n    if large_num_splits:\n      num_split = np.random.randint(9, 15)\n    else:\n      num_split = np.random.randint(2, 8)\n    shape[split_dim] = np.random.randint(2, 5) * num_split\n    inp = self._makeData(shape, dtype)\n    with test_util.device(use_gpu=True):\n      result = self.evaluate(\n          array_ops.split(\n              value=inp, num_or_size_splits=num_split, axis=split_dim))\n    slices = [slice(0, x) for x in shape]\n    offset = 0\n    length = shape[split_dim] // num_split\n    for i in range(num_split):\n      slices[split_dim] = slice(offset, offset + length)\n      offset += length\n      self.assertAllEqual(result[i], inp[slices])\n\n  @test_util.run_in_graph_and_eager_modes\n  def testRandom(self):\n    for dtype in _TEST_DTYPES:\n      for _ in range(5):\n        self._RunAndVerify(dtype)\n        self._RunAndVerify(dtype, large_num_splits=True)\n        self._RunAndVerifyVariable(dtype)\n        self._RunAndVerifyVariable(dtype, large_num_splits=True)\n\n  def _testGradientsSimple(self, dtype):\n    inp = self._makeData((4, 4), dtype)\n    with self.cached_session():\n      inp_tensor = ops.convert_to_tensor(inp)\n      s = array_ops.split(value=inp_tensor, num_or_size_splits=4, axis=1)\n      inp_grads = [self._makeData((4, 1), dtype)for _ in range(4)]\n      grad_tensors = [constant_op.constant(x) for x in inp_grads]\n      grad = gradients_impl.gradients(s, [inp_tensor], grad_tensors)[0]\n      result = self.evaluate(grad)\n    for i in range(4):\n      self.assertAllEqual(result[:, i:i + 1], inp_grads[i])\n\n  @test_util.run_deprecated_v1\n  def testGradientsAll(self):\n    for dtype in _TEST_DTYPES:\n      self._testGradientsSimple(dtype)\n      self._testGradientsSimpleVariable(dtype)\n\n  @test_util.run_deprecated_v1\n  def testShapeFunctionEdgeCases(self):\n    # split_dim greater than rank of input.\n    with self.assertRaises(ValueError):\n      array_ops.split(value=[[0, 1], [2, 3]], num_or_size_splits=4, axis=2)\n\n    # split dim less than -(rank of input)\n    with self.assertRaises(ValueError):\n      array_ops.split(value=[[0, 1], [2, 3]], num_or_size_splits=4, axis=-3)\n\n    # num_split does not evenly divide the size in split_dim.\n    with self.assertRaisesRegex(ValueError, \"should evenly divide\"):\n      array_ops.split(value=[0, 1, 2, 3], num_or_size_splits=3, axis=0)\n\n    # Unknown split_dim.\n    splits = array_ops.split(\n        value=[[0, 1, 2, 3]],\n        num_or_size_splits=4,\n        axis=array_ops.placeholder(dtypes.int32))\n    for s in splits:\n      self.assertEqual([None, None], s.get_shape().as_list())\n\n    # Unknown split_dim and input shape.\n    splits = array_ops.split(\n        value=array_ops.placeholder(dtypes.float32),\n        num_or_size_splits=4,\n        axis=array_ops.placeholder(dtypes.int32))\n    for s in splits:\n      self.assertEqual(None, s.get_shape().ndims)\n\n  @test_util.run_deprecated_v1\n  def testVariableShapeFunction(self):\n    # size_splits too big\n    with self.assertRaises(ValueError):\n      array_ops.split([0, 1], [3, -1], axis=0)\n\n    # Correct inference of variable dimension\n    s0, s1 = array_ops.split([0, 1, 2], [2, -1], axis=0)\n    assert s0.shape.as_list() == [2]\n    assert s1.shape.as_list() == [1]\n\n  @test_util.run_deprecated_v1\n  def testNonexistentDimTensor(self):\n    x = array_ops.placeholder(dtypes.int32)\n    values = np.zeros([5, 30])\n    splits = array_ops.placeholder(dtypes.int32)\n    with self.assertRaisesRegex(ValueError, \"Cannot infer\"):\n      y = array_ops.split(values, splits, axis=x)\n\n    splits = array_ops.placeholder(dtypes.int32, [3])\n    y = array_ops.split(values, splits, axis=x)\n    with self.session() as sess:\n      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                  \"must have exactly one element\"):\n        sess.run(y, {x: np.array([], dtype=np.int32), splits: [4, 11, 15]})\n\n\nif __name__ == \"__main__\":\n  test.main()"