"diff --git a/tensorflow/python/ops/nn_fused_batchnorm_test.py b/tensorflow/python/ops/nn_fused_batchnorm_test.py\nindex fb3400fd49b..5004e8625be 100644\n--- a/tensorflow/python/ops/nn_fused_batchnorm_test.py\n+++ b/tensorflow/python/ops/nn_fused_batchnorm_test.py\n@@ -16,10 +16,13 @@\n \n import numpy as np\n \n+from tensorflow.python.eager import context\n from tensorflow.python.framework import constant_op\n from tensorflow.python.framework import dtypes\n+from tensorflow.python.framework import errors_impl\n from tensorflow.python.framework import test_util\n from tensorflow.python.ops import array_ops\n+from tensorflow.python.ops import gen_nn_ops\n from tensorflow.python.ops import gradient_checker\n from tensorflow.python.ops import gradients_impl\n from tensorflow.python.ops import math_ops\n@@ -694,6 +697,126 @@ class BatchNormalizationTest(test.TestCase):\n     y_ref = np.maximum(y_ref, 0.)\n     self.assertAllClose(y_ref, y_val, atol=1e-3)\n \n+  def testEagerShapeErrors(self):\n+    with context.eager_mode():\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((3,))\n+      offset = array_ops.ones((2,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'scale must have the same number of elements'):\n+        nn_impl.fused_batch_norm(x, scale, offset)\n+\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      offset = array_ops.ones((3,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'offset must have the same number of elements'):\n+        nn_impl.fused_batch_norm(x, scale, offset)\n+\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      offset = array_ops.ones((2,))\n+      mean = array_ops.ones((0,))\n+      variance = array_ops.ones((2,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'When is_training=false, mean must have the same number of elements'):\n+        nn_impl.fused_batch_norm(\n+            x, scale, offset, mean=mean, variance=variance, is_training=False)\n+\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      offset = array_ops.ones((2,))\n+      mean = array_ops.ones((2,))\n+      variance = array_ops.ones((0,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'When is_training=false, variance must have the same number of '\n+          'elements'):\n+        nn_impl.fused_batch_norm(\n+            x, scale, offset, mean=mean, variance=variance, is_training=False)\n+\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      offset = array_ops.ones((2,))\n+      mean = array_ops.ones((0,))\n+      variance = array_ops.ones((2,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'When exponential_avg_factor != 1, mean must have the same number of '\n+          'elements'):\n+        nn_impl.fused_batch_norm(\n+            x,\n+            scale,\n+            offset,\n+            mean=mean,\n+            variance=variance,\n+            exponential_avg_factor=0.5)\n+\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      offset = array_ops.ones((2,))\n+      mean = array_ops.ones((2,))\n+      variance = array_ops.ones((0,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'When exponential_avg_factor != 1, variance must have the same '\n+          'number of elements'):\n+        nn_impl.fused_batch_norm(\n+            x,\n+            scale,\n+            offset,\n+            mean=mean,\n+            variance=variance,\n+            exponential_avg_factor=0.5)\n+\n+  def testEagerShapeGradErrors(self):\n+    with context.eager_mode():\n+      y_backprop = array_ops.ones((2, 2, 2, 3))\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      reserve_space_1 = array_ops.ones((2,))\n+      reserve_space_2 = array_ops.ones((2,))\n+      with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n+                                  'x and y_backprop must have same shape,'):\n+        gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,\n+                                            reserve_space_1, reserve_space_2)\n+\n+      y_backprop = array_ops.ones((2, 2, 2, 2))\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((3,))\n+      reserve_space_1 = array_ops.ones((2,))\n+      reserve_space_2 = array_ops.ones((2,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'scale must have the same number of elements'):\n+        gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,\n+                                            reserve_space_1, reserve_space_2)\n+\n+      y_backprop = array_ops.ones((2, 2, 2, 2))\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      reserve_space_1 = array_ops.ones((3,))\n+      reserve_space_2 = array_ops.ones((2,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'reserve_space_1 must have the same number of elements'):\n+        gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,\n+                                            reserve_space_1, reserve_space_2)\n+\n+      y_backprop = array_ops.ones((2, 2, 2, 2))\n+      x = array_ops.ones((2, 2, 2, 2))\n+      scale = array_ops.ones((2,))\n+      reserve_space_1 = array_ops.ones((2,))\n+      reserve_space_2 = array_ops.ones((3,))\n+      with self.assertRaisesRegex(\n+          errors_impl.InvalidArgumentError,\n+          'reserve_space_2 must have the same number of elements'):\n+        gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,\n+                                            reserve_space_1, reserve_space_2)\n+\n \n if __name__ == '__main__':\n   test.main()"