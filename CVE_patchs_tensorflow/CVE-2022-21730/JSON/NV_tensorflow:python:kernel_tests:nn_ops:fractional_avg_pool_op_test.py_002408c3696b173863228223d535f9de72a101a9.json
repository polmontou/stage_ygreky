"# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for fractional average pool operation.\"\"\"\n\nimport math\n\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_nn_ops\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import nn_ops\nimport tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\nfrom tensorflow.python.platform import test\n\n\nclass FractionalAvgTest(test.TestCase):\n\n  # Random number generate with seed.\n  _PRNG = np.random.RandomState(341261000)\n  _SEED = 341261001\n\n  def _AvgPoolAlongRows(self, input_matrix, row_seq, overlapping):\n    \"\"\"Perform average pool along row of a 2-D matrix based on row_seq.\n\n    Args:\n      input_matrix: A 2-D matrix.\n      row_seq: Cumulative pooling sequence along row.\n      overlapping: Whether or not use overlapping when pooling.\n\n    Returns:\n      A 2-D matrix, with\n        * num_rows = len(row_seq)-1\n        * num_cols = input_matrix.num_cols.\n    \"\"\"\n    output_image = np.zeros(input_matrix.shape[1])\n    row_max = row_seq[-1]\n    for i in range(row_seq.shape[0] - 1):\n      row_start = row_seq[i]\n      row_end = row_seq[i + 1] + 1 if overlapping else row_seq[i + 1]\n      row_end = min(row_end, row_max)\n      output_image = np.vstack((output_image, np.mean(\n          input_matrix[row_start:row_end, :], axis=0)))  # axis 0 is along row\n    # remove the sentinel row\n    return output_image[1:, :]\n\n  def _AvgPoolAlongCols(self, input_matrix, col_seq, overlapping):\n    \"\"\"Perform average pool along column of a 2-D matrix based on col_seq.\n\n    Args:\n      input_matrix: A 2-D matrix.\n      col_seq: Cumulative pooling sequence along column.\n      overlapping: Whether or not use overlapping when pooling.\n\n    Returns:\n      A 2-D matrix, with\n        * num_rows = input_matrix.num_rows\n        * num_cols = len(col_seq)-1.\n    \"\"\"\n    input_matrix = input_matrix.transpose()\n    output_matrix = self._AvgPoolAlongRows(input_matrix, col_seq, overlapping)\n    return output_matrix.transpose()\n\n  def _GetExpectedFractionalAvgPoolResult(self, input_tensor, row_seq, col_seq,\n                                          overlapping):\n    \"\"\"Get expected fractional average pooling result.\n\n    row_seq and col_seq together defines the fractional pooling region.\n\n    Args:\n      input_tensor: Original input tensor, assuming it is a 4-D tensor, with\n        dimension as [batch, height/row, width/column, channels/depth].\n      row_seq: Cumulative pooling sequence along row.\n      col_seq: Cumulative pooling sequence along column.\n      overlapping: Use overlapping when doing pooling.\n\n    Returns:\n      A 4-D tensor that is the result of average pooling on input_tensor based\n        on pooling region defined by row_seq and col_seq, conditioned on whether\n        or not overlapping is used.\n    \"\"\"\n    input_shape = input_tensor.shape\n    output_shape = (input_shape[0], len(row_seq) - 1, len(col_seq) - 1,\n                    input_shape[3])\n    output_tensor = np.zeros(shape=output_shape, dtype=input_tensor.dtype)\n    for batch in range(input_shape[0]):\n      for channel in range(input_shape[3]):\n        two_dim_slice = input_tensor[batch, :, :, channel]\n        tmp = self._AvgPoolAlongRows(two_dim_slice, row_seq, overlapping)\n        output_tensor[batch, :, :, channel] = self._AvgPoolAlongCols(\n            tmp, col_seq, overlapping)\n\n    return output_tensor\n\n  def _ValidateFractionalAvgPoolResult(self, input_tensor, pooling_ratio,\n                                       pseudo_random, overlapping):\n    \"\"\"Validate FractionalAvgPool's result against expected.\n\n    Expected result is computed given input_tensor, and pooling region defined\n    by row_seq and col_seq.\n\n    Args:\n      input_tensor: A tensor or numpy ndarray.\n      pooling_ratio: A list or tuple of length 4, first and last element be 1.\n      pseudo_random: Use pseudo random method to generate pooling sequence.\n      overlapping: Use overlapping when pooling.\n\n    Returns:\n      None\n    \"\"\"\n    with self.cached_session() as sess:\n      p, r, c = nn_ops.fractional_avg_pool_v2(\n          input_tensor,\n          pooling_ratio,\n          pseudo_random,\n          overlapping,\n          seed=self._SEED)\n      actual, row_seq, col_seq = self.evaluate([p, r, c])\n      expected = self._GetExpectedFractionalAvgPoolResult(input_tensor, row_seq,\n                                                          col_seq, overlapping)\n      self.assertShapeEqual(expected, p)\n      self.assertAllClose(expected, actual)\n\n  def _testVisually(self):\n    \"\"\"Manual test by printing out intermediate result of a small random tensor.\n\n    Since _GetExpectedFractionalAvgPoolResult is 'automated', it feels safer to\n    have a test case that you can see what's happening.\n    This test will generate a small, random, int 2D matrix, and feed it to\n    FractionalAvgPool and _GetExpectedFractionalAvgPoolResult.\n    \"\"\"\n    num_rows = 6\n    num_cols = 6\n    tensor_shape = (1, num_rows, num_cols, 1)\n    pseudo_random = False\n    for overlapping in True, False:\n      print(\"-\" * 70)\n      print(\"Testing FractionalAvgPool with overlapping = {}\".format(\n          overlapping))\n      rand_mat = self._PRNG.randint(10, size=tensor_shape)\n      pooling_ratio = [1, math.sqrt(2), math.sqrt(2), 1]\n      with self.cached_session() as sess:\n        p, r, c = nn_ops.fractional_avg_pool_v2(\n            rand_mat.astype(np.float32),\n            pooling_ratio,\n            pseudo_random,\n            overlapping,\n            seed=self._SEED)\n        tensor_output, row_seq, col_seq = self.evaluate([p, r, c])\n        expected_result = self._GetExpectedFractionalAvgPoolResult(\n            rand_mat.astype(np.float32), row_seq, col_seq, overlapping)\n        print(\"row sequence:\")\n        print(row_seq)\n        print(\"column sequence:\")\n        print(col_seq)\n\n        print(\"Input:\")\n        # Print input with pooling region marked.\n        for i in range(num_rows):\n          row_to_print = []\n          for j in range(num_cols):\n            if j in col_seq:\n              row_to_print.append(\"|\")\n            row_to_print.append(str(rand_mat[0, i, j, 0]))\n          row_to_print.append(\"|\")\n          if i in row_seq:\n            print(\"-\" * 2 * len(row_to_print))\n          print(\" \".join(row_to_print))\n        print(\"-\" * 2 * len(row_to_print))\n\n        print(\"Output from FractionalAvgPool:\")\n        print(tensor_output[0, :, :, 0])\n        print(\"Expected result:\")\n        print(expected_result[0, :, :, 0])\n\n  def testAllInputOptions(self):\n    \"\"\"Try all possible input options for fractional_avg_pool.\n    \"\"\"\n    num_batches = 5\n    num_channels = 3\n    num_rows = 20\n    num_cols = 30\n    for pseudo_random in True, False:\n      for overlapping in True, False:\n        tensor_shape = (num_batches, num_rows, num_cols, num_channels)\n        # random tensor with value in [-500.0, 500.0)\n        rand_mat = self._PRNG.random_sample(tensor_shape) * 1000 - 500\n        self._ValidateFractionalAvgPoolResult(\n            rand_mat, [1, math.sqrt(3), math.sqrt(2), 1], pseudo_random,\n            overlapping)\n\n  def testIntegerTensorInput(self):\n    \"\"\"Test FractionalAvgPool works fine when input tensor is integer type.\n    \"\"\"\n    pseudo_random = True\n    overlapping = True\n    tensor_shape = (1, 6, 6, 1)\n    # pyformat: disable\n    mat = np.array([\n        [2, 6, 4, 1, 3, 6],\n        [8, 9, 1, 6, 6, 8],\n        [3, 9, 8, 2, 5, 6],\n        [2, 7, 9, 5, 4, 5],\n        [8, 5, 0, 5, 7, 4],\n        [4, 4, 5, 9, 7, 2]\n    ])\n    # pyformat: enable\n    self._ValidateFractionalAvgPoolResult(mat.reshape(tensor_shape),\n                                          [1, math.sqrt(3), math.sqrt(2), 1],\n                                          pseudo_random, overlapping)\n\n  def testDifferentTensorShapes(self):\n    \"\"\"Test different shapes of input tensor.\n\n    Mainly test different combinations of num_rows and num_cols.\n    \"\"\"\n    pseudo_random = True\n    overlapping = True\n    for num_batches in [1, 3]:\n      for num_channels in [1, 3]:\n        for num_rows in [10, 20, 50]:\n          for num_cols in [10, 20, 50]:\n            tensor_shape = (num_batches, num_rows, num_cols, num_channels)\n            # random tensor with value in [-500.0, 500.0)\n            rand_mat = self._PRNG.random_sample(tensor_shape) * 1000 - 500\n            self._ValidateFractionalAvgPoolResult(\n                rand_mat, [1, math.sqrt(3), math.sqrt(2), 1], pseudo_random,\n                overlapping)\n\n  def testLargePoolingRatio(self):\n    \"\"\"Test when pooling ratio is not within [1, 2).\n    \"\"\"\n    pseudo_random = True\n    overlapping = True\n    num_batches = 3\n    num_channels = 3\n    num_rows = 30\n    num_cols = 50\n    tensor_shape = (num_batches, num_rows, num_cols, num_channels)\n    for row_ratio in [math.sqrt(11), math.sqrt(37)]:\n      for col_ratio in [math.sqrt(11), math.sqrt(27)]:\n        # random tensor with value in [-500.0, 500.0)\n        rand_mat = self._PRNG.random_sample(tensor_shape) * 1000 - 500\n        self._ValidateFractionalAvgPoolResult(rand_mat,\n                                              [1, row_ratio, col_ratio, 1],\n                                              pseudo_random, overlapping)\n\n  def testDivisiblePoolingRatio(self):\n    \"\"\"Test when num of rows/cols can evenly divide pooling ratio.\n\n    This is a case regular average pooling can handle. Should be handled by\n    fractional pooling as well.\n    \"\"\"\n    pseudo_random = True\n    overlapping = True\n    num_batches = 3\n    num_channels = 3\n    num_rows = 30\n    num_cols = 50\n    tensor_shape = (num_batches, num_rows, num_cols, num_channels)\n    # random tensor with value in [-500.0, 500.0)\n    rand_mat = self._PRNG.random_sample(tensor_shape) * 1000 - 500\n    self._ValidateFractionalAvgPoolResult(rand_mat, [1, 2, 2, 1], pseudo_random,\n                                          overlapping)\n\n  @test_util.run_deprecated_v1\n  def testDifferentInputTensorShape(self):\n    \"\"\"Runs the operation in one session with different input tensor shapes.\"\"\"\n    with self.cached_session() as sess:\n      input_holder = array_ops.placeholder(dtypes.float32,\n                                           [None, None, None, 3])\n      pooling_ratio = [1, 1.5, 1.5, 1]\n      pseudo_random = False\n      overlapping = False\n      p, r, c = nn_ops.fractional_avg_pool_v2(\n          input_holder,\n          pooling_ratio,\n          pseudo_random,\n          overlapping,\n          seed=self._SEED)\n      # First run.\n      input_a = np.zeros([3, 32, 32, 3])\n      actual, row_seq, col_seq = sess.run([p, r, c], {input_holder: input_a})\n      expected = self._GetExpectedFractionalAvgPoolResult(\n          input_a, row_seq, col_seq, overlapping)\n      self.assertSequenceEqual(expected.shape, actual.shape)\n      # Second run.\n      input_b = np.zeros([4, 60, 60, 3])\n      actual, row_seq, col_seq = sess.run([p, r, c], {input_holder: input_b})\n      expected = self._GetExpectedFractionalAvgPoolResult(\n          input_b, row_seq, col_seq, overlapping)\n      self.assertSequenceEqual(expected.shape, actual.shape)\n\n  def testNegativeSeqValuesForGradOp(self):\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Row sequence tensor values must not be negative.*\"):\n      y = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n          orig_input_tensor_shape=[2, 2, 2, 2],\n          out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n                                                                      12]]]],\n          row_pooling_sequence=[-10, 1, 2, 3],\n          col_pooling_sequence=[1, 2, 3, 4],\n          overlapping=True)\n\n      self.evaluate(y)\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          r\"Column sequence tensor values must not be negative.*\"):\n        z = nn_ops.gen_nn_ops.fractional_avg_pool_grad(\n            orig_input_tensor_shape=[2, 2, 2, 2],\n            out_backprop=[[[[1, 2], [3, 4], [5, 6]], [[7, 8], [9, 10], [11,\n                                                                        12]]]],\n            row_pooling_sequence=[10, 1, 2, 3],\n            col_pooling_sequence=[1, 2, -3, 4],\n            overlapping=True)\n\n        self.evaluate(z)\n\n\nclass FractionalAvgPoolGradTest(test.TestCase):\n  \"\"\"Tests for FractionalAvgPoolGrad.\n\n  Two types of tests for FractionalAvgPoolGrad.\n  1) Test fractional_avg_pool_grad() directly.\n    This type of test relies on gen_nn_ops.avg_pool_grad() returns the\n  correct result. For example:\n    * input_tensor_shape = (1, 10, 10, 1)\n    * window_size = (1, 2, 2, 1)\n    * stride_size = (1, 2, 2, 1)\n    * padding: not really important, since 10/2 is divisible\n  avg pooling should generate the same result as fractional avg pooling with:\n    * row_sequence = [0, 2, 4, 6, 8, 10]\n    * col_sequence = [0, 2, 4, 6, 8, 10]\n    * overlapping = False\n  This also means their gradients in such case will be the same.\n\n  Similarly, when\n    * input_tensor_shape = (1, 7, 7, 1)\n    * window_size = (1, 3, 3, 1)\n    * stride_size = (1, 2, 2, 1)\n    * padding: not important\n  avg pooling should generate the same result as fractional avg pooling with:\n    * row_sequence = [0, 2, 4, 7]\n    * col_sequence = [0, 2, 4, 7]\n    * overlapping = True\n  2) Test through compute_gradient_error()\n  \"\"\"\n  _PRNG = np.random.RandomState(341261004)\n  _SEED = 341261005\n\n  def _GenerateRandomInputTensor(self, shape):\n    num_elements = 1\n    for dim_size in shape:\n      num_elements *= dim_size\n    x = self._PRNG.rand(num_elements) * 1000\n    return x.reshape(shape)\n\n  def testDirectNotUseOverlapping(self):\n    for num_batches in [1, 3]:\n      for row_window_size in [2, 5]:\n        for col_window_size in [2, 4]:\n          num_rows = row_window_size * 5\n          num_cols = col_window_size * 7\n          for num_channels in [1, 2]:\n            input_shape = (num_batches, num_rows, num_cols, num_channels)\n            with self.cached_session() as _:\n              input_tensor = constant_op.constant(\n                  self._GenerateRandomInputTensor(input_shape).astype(\n                      np.float32))\n              window_size = [1, row_window_size, col_window_size, 1]\n              stride_size = [1, row_window_size, col_window_size, 1]\n              padding = \"VALID\"\n              output_tensor = nn_ops.avg_pool(input_tensor, window_size,\n                                              stride_size, padding)\n              output_data = self.evaluate(output_tensor)\n              num_elements = 1\n              for dim_size in output_data.shape:\n                num_elements *= dim_size\n              output_backprop = (self._PRNG.rand(num_elements) *\n                                 1000).reshape(output_data.shape)\n              input_backprop_tensor = gen_nn_ops.avg_pool_grad(\n                  input_tensor.get_shape(), output_backprop, window_size,\n                  stride_size, padding)\n              input_backprop = self.evaluate(input_backprop_tensor)\n              row_seq = list(range(0, num_rows + 1, row_window_size))\n              col_seq = list(range(0, num_cols + 1, col_window_size))\n              fap_input_backprop_tensor = gen_nn_ops.fractional_avg_pool_grad(\n                  input_tensor.get_shape(),\n                  output_backprop,\n                  row_seq,\n                  col_seq,\n                  overlapping=False)\n              fap_input_backprop = self.evaluate(fap_input_backprop_tensor)\n              self.assertShapeEqual(input_backprop, fap_input_backprop_tensor)\n              self.assertAllClose(input_backprop, fap_input_backprop)\n\n  def testDirectUseOverlapping(self):\n    for num_batches in [1, 3]:\n      for row_window_size in [2, 5]:\n        for col_window_size in [2, 4]:\n          num_rows = (row_window_size - 1) * 5 + 1\n          num_cols = (col_window_size - 1) * 7 + 1\n          for num_channels in [1, 2]:\n            input_shape = (num_batches, num_rows, num_cols, num_channels)\n            with self.cached_session() as _:\n              input_tensor = constant_op.constant(\n                  self._GenerateRandomInputTensor(input_shape).astype(\n                      np.float32))\n              window_size = [1, row_window_size, col_window_size, 1]\n              stride_size = [1, row_window_size - 1, col_window_size - 1, 1]\n              padding = \"VALID\"\n              output_tensor = nn_ops.avg_pool(input_tensor, window_size,\n                                              stride_size, padding)\n              output_data = self.evaluate(output_tensor)\n              num_elements = 1\n              for dim_size in output_data.shape:\n                num_elements *= dim_size\n              output_backprop = (self._PRNG.rand(num_elements) *\n                                 1000).reshape(output_data.shape)\n              input_backprop_tensor = gen_nn_ops.avg_pool_grad(\n                  input_tensor.get_shape(), output_backprop, window_size,\n                  stride_size, padding)\n              input_backprop = self.evaluate(input_backprop_tensor)\n              row_seq = list(range(0, num_rows, row_window_size - 1))\n              col_seq = list(range(0, num_cols, col_window_size - 1))\n              row_seq[-1] += 1\n              col_seq[-1] += 1\n              fap_input_backprop_tensor = gen_nn_ops.fractional_avg_pool_grad(\n                  input_tensor.get_shape(),\n                  output_backprop,\n                  row_seq,\n                  col_seq,\n                  overlapping=True)\n              fap_input_backprop = self.evaluate(fap_input_backprop_tensor)\n              self.assertShapeEqual(input_backprop, fap_input_backprop_tensor)\n              self.assertAllClose(input_backprop, fap_input_backprop)\n\n  @test_util.run_deprecated_v1\n  def testAllInputOptionsThroughGradientError(self):\n    input_shape = (1, 7, 13, 1)\n    input_data = self._GenerateRandomInputTensor(input_shape)\n    pooling_ratio = [1, math.sqrt(2), math.sqrt(3), 1]\n\n    for pseudo_random in True, False:\n      for overlapping in True, False:\n        with self.cached_session() as _:\n          input_tensor = constant_op.constant(input_data, shape=input_shape)\n          output_tensor, unused_a, unused_b = nn_ops.fractional_avg_pool_v2(\n              input_tensor,\n              pooling_ratio,\n              pseudo_random=pseudo_random,\n              overlapping=overlapping,\n              seed=self._SEED)\n          output_data = self.evaluate(output_tensor)\n          output_shape = output_data.shape\n          # error_margin and delta setting is similar to avg_pool_grad.\n          error_margin = 1e-4\n          gradient_error = gradient_checker.compute_gradient_error(\n              input_tensor,\n              input_shape,\n              output_tensor,\n              output_shape,\n              x_init_value=input_data.reshape(input_shape),\n              delta=1e-2)\n          self.assertLess(gradient_error, error_margin)\n\n  @test_util.run_deprecated_v1\n  def testDifferentTensorShapesThroughGradientError(self):\n    pseudo_random = True\n    overlapping = True\n    pooling_ratio = [1, math.sqrt(3), math.sqrt(2), 1]\n    for num_batches in [1, 2]:\n      for num_rows in [5, 13]:\n        for num_cols in [5, 11]:\n          for num_channels in [1, 3]:\n            input_shape = (num_batches, num_rows, num_cols, num_channels)\n            input_data = self._GenerateRandomInputTensor(input_shape)\n            with self.cached_session() as _:\n              input_tensor = constant_op.constant(input_data, shape=input_shape)\n              output_tensor, unused_a, unused_b = nn_ops.fractional_avg_pool_v2(\n                  input_tensor,\n                  pooling_ratio,\n                  pseudo_random=pseudo_random,\n                  overlapping=overlapping,\n                  seed=self._SEED)\n              output_data = self.evaluate(output_tensor)\n              output_shape = output_data.shape\n              # error_margin and delta setting is similar to avg_pool_grad.\n              error_margin = 1e-4\n              gradient_error = gradient_checker.compute_gradient_error(\n                  input_tensor,\n                  input_shape,\n                  output_tensor,\n                  output_shape,\n                  x_init_value=input_data.reshape(input_shape),\n                  delta=1e-2)\n              self.assertLess(gradient_error, error_margin)\n\n  @test_util.run_deprecated_v1\n  def testLargePoolingRatioThroughGradientError(self):\n    input_shape = (1, 17, 23, 1)\n    input_data = self._GenerateRandomInputTensor(input_shape)\n    pooling_ratio = (1, math.sqrt(13), math.sqrt(7), 1)\n    output_shape = [int(a / b) for a, b in zip(input_shape, pooling_ratio)]\n    overlapping = True\n    pseudo_random = False\n\n    with self.cached_session() as _:\n      input_tensor = constant_op.constant(input_data, shape=input_shape)\n      output_tensor, unused_a, unused_b = nn_ops.fractional_avg_pool_v2(\n          input_tensor,\n          pooling_ratio,\n          pseudo_random=pseudo_random,\n          overlapping=overlapping,\n          seed=self._SEED)\n      # error_margin and delta setting is similar to avg_pool_grad.\n      error_margin = 1e-4\n      gradient_error = gradient_checker.compute_gradient_error(\n          input_tensor,\n          input_shape,\n          output_tensor,\n          output_shape,\n          x_init_value=input_data.reshape(input_shape),\n          delta=1e-2)\n      self.assertLess(gradient_error, error_margin)\n\n\nif __name__ == \"__main__\":\n  test.main()"