"diff --git a/tensorflow/lite/kernels/embedding_lookup_sparse.cc b/tensorflow/lite/kernels/embedding_lookup_sparse.cc\nindex 4ad1054340c..a0b9586203a 100644\n--- a/tensorflow/lite/kernels/embedding_lookup_sparse.cc\n+++ b/tensorflow/lite/kernels/embedding_lookup_sparse.cc\n@@ -72,6 +72,7 @@ limitations under the License.\n #include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n #include \"tensorflow/lite/kernels/internal/tensor_utils.h\"\n #include \"tensorflow/lite/kernels/kernel_util.h\"\n+#include \"tensorflow/lite/util.h\"\n \n namespace tflite {\n namespace ops {\n@@ -175,25 +176,33 @@ TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n   TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\n   TF_LITE_ENSURE(context, output_shape != nullptr);\n   int k = 0;\n-  int embedding_size = 1;\n-  int lookup_size = 1;\n+  size_t embedding_size = 1;\n+  size_t lookup_size = 1;\n   for (int i = 0; i < lookup_rank - 1; i++, k++) {\n-    const int dim = dense_shape->data.i32[i];\n-    lookup_size *= dim;\n+    const size_t dim = dense_shape->data.i32[i];\n+    TF_LITE_ENSURE_MSG(\n+        context,\n+        MultiplyAndCheckOverflow(lookup_size, dim, &lookup_size) == kTfLiteOk,\n+        \"Lookup size overflowed.\");\n     output_shape->data[k] = dim;\n   }\n   for (int i = 1; i < embedding_rank; i++, k++) {\n-    const int dim = SizeOfDimension(value, i);\n-    embedding_size *= dim;\n+    const size_t dim = SizeOfDimension(value, i);\n+    TF_LITE_ENSURE_MSG(context,\n+                       MultiplyAndCheckOverflow(embedding_size, dim,\n+                                                &embedding_size) == kTfLiteOk,\n+                       \"Embedding size overflowed.\");\n     output_shape->data[k] = dim;\n   }\n   TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\n-  const int output_size = lookup_size * embedding_size;\n+  const size_t output_size = lookup_size * embedding_size;\n   TfLiteTensorRealloc(output_size * sizeof(float), output);\n \n   float* output_ptr = GetTensorData<float>(output);\n   const float* weights_ptr = GetTensorData<float>(weights);\n   const float* value_ptr = GetTensorData<float>(value);\n+  // Makes sure reallocation was successful.\n+  TF_LITE_ENSURE(context, output_ptr != nullptr);\n \n   std::fill_n(output_ptr, output_size, 0.0f);\n "