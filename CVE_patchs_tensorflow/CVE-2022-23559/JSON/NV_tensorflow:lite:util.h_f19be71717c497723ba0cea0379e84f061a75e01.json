"/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// This file provides general C++ utility functions in TFLite.\n// For example: Converting between `TfLiteIntArray`, `std::vector` and\n// Flatbuffer vectors. These functions can't live in `context.h` since it's pure\n// C.\n\n#ifndef TENSORFLOW_LITE_UTIL_H_\n#define TENSORFLOW_LITE_UTIL_H_\n\n#include <stddef.h>\n\n#include <initializer_list>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/lite/c/common.h\"\n\nnamespace tflite {\n\n// Memory allocation parameter used by ArenaPlanner.\n// Clients (such as delegates) might look at this to ensure interop between\n// TFLite memory & hardware buffers.\n// NOTE: This only holds for tensors allocated on the arena.\nconstexpr int kDefaultTensorAlignment = 64;\n\n// The prefix of Flex op custom code.\n// This will be matched agains the `custom_code` field in `OperatorCode`\n// Flatbuffer Table.\n// WARNING: This is an experimental API and subject to change.\nconstexpr char kFlexCustomCodePrefix[] = \"Flex\";\n\n// Checks whether the prefix of the custom name indicates the operation is an\n// Flex operation.\nbool IsFlexOp(const char* custom_name);\n\n// Converts a `std::vector` to a `TfLiteIntArray`. The caller takes ownership\n// of the returned pointer.\nTfLiteIntArray* ConvertVectorToTfLiteIntArray(const std::vector<int>& input);\n\n// Converts an array (of the given size) to a `TfLiteIntArray`. The caller\n// takes ownership of the returned pointer, and must make sure 'dims' has at\n// least 'rank' elements.\nTfLiteIntArray* ConvertArrayToTfLiteIntArray(const int rank, const int* dims);\n\n// Checks whether a `TfLiteIntArray` and an int array have matching elements.\n// The caller must guarantee that 'b' has at least 'b_size' elements.\nbool EqualArrayAndTfLiteIntArray(const TfLiteIntArray* a, const int b_size,\n                                 const int* b);\n\nsize_t CombineHashes(std::initializer_list<size_t> hashes);\n\nstruct TfLiteIntArrayDeleter {\n  void operator()(TfLiteIntArray* a) {\n    if (a) TfLiteIntArrayFree(a);\n  }\n};\n\n// Helper for Building TfLiteIntArray that is wrapped in a unique_ptr,\n// So that it is automatically freed when it goes out of the scope.\nstd::unique_ptr<TfLiteIntArray, TfLiteIntArrayDeleter> BuildTfLiteIntArray(\n    const std::vector<int>& data);\n\n// Populates the size in bytes of a type into `bytes`. Returns kTfLiteOk for\n// valid types, and kTfLiteError otherwise.\nTfLiteStatus GetSizeOfType(TfLiteContext* context, const TfLiteType type,\n                           size_t* bytes);\n\n// Creates a stub TfLiteRegistration instance with the provided\n// `custom_op_name`. The op will fail if invoked, and is useful as a\n// placeholder to defer op resolution.\n// Note that `custom_op_name` must remain valid for the returned op's lifetime..\nTfLiteRegistration CreateUnresolvedCustomOp(const char* custom_op_name);\n\n// Checks whether the provided op is an unresolved custom op.\nbool IsUnresolvedCustomOp(const TfLiteRegistration& registration);\n\n// Returns a descriptive name with the given op TfLiteRegistration.\nstd::string GetOpNameByRegistration(const TfLiteRegistration& registration);\n\n// The prefix of a validation subgraph name.\n// WARNING: This is an experimental API and subject to change.\nconstexpr char kValidationSubgraphNamePrefix[] = \"VALIDATION:\";\n\n// Checks whether the prefix of the subgraph name indicates the subgraph is a\n// validation subgraph.\nbool IsValidationSubgraph(const char* name);\n\n// Multiply two sizes and return true if overflow occurred;\n// This is based off tensorflow/overflow.h but is simpler as we already\n// have unsigned numbers. It is also generalized to work where sizeof(size_t)\n// is not 8.\nTfLiteStatus MultiplyAndCheckOverflow(size_t a, size_t b, size_t* product);\n}  // namespace tflite\n\n#endif  // TENSORFLOW_LITE_UTIL_H_"