"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for the ops to generate and execute vocab remapping.\"\"\"\nimport os\n\nimport numpy as np\n\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import gen_checkpoint_ops\nfrom tensorflow.python.ops import partitioned_variables\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import flags\nfrom tensorflow.python.platform import test\nfrom tensorflow.python.training import saver\n\nFLAGS = flags.FLAGS\n\n\nclass GenerateVocabRemappingTest(test.TestCase):\n  \"\"\"Tests for the generate_vocab_remapping() method.\"\"\"\n\n  def setUp(self):\n    self.new_vocab_file = os.path.join(self.get_temp_dir(),\n                                       'keyword_shifted.txt')\n    with open(self.new_vocab_file, 'w') as f:\n      f.write('\\n'.join(['MISSING', 'knitting', 'eminem']) + '\\n')\n    self.old_vocab_file = os.path.join(self.get_temp_dir(),\n                                       'keyword.txt')\n    with open(self.old_vocab_file, 'w') as f:\n      f.write('\\n'.join(['knitting', 'eminem', 'MISSING']) + '\\n')\n\n  @test_util.run_deprecated_v1\n  def test_generate_remapping_with_no_vocab_changes(self):\n    \"\"\"Tests where vocab does not change at all.\"\"\"\n    remapping, num_present = gen_checkpoint_ops.generate_vocab_remapping(\n        new_vocab_file=self.old_vocab_file,\n        old_vocab_file=self.old_vocab_file,\n        num_new_vocab=3,\n        new_vocab_offset=0)\n    expected_remapping = range(0, 3)\n    expected_num_present = 3\n    with self.cached_session():\n      self.assertAllEqual(expected_remapping, self.evaluate(remapping))\n      self.assertAllEqual(expected_num_present, self.evaluate(num_present))\n\n  def test_generate_remapping_with_shifted_vocab(self):\n    \"\"\"Tests where vocab is the same, but shifted / ordered differently.\"\"\"\n    remapping, num_present = gen_checkpoint_ops.generate_vocab_remapping(\n        new_vocab_file=self.new_vocab_file,\n        old_vocab_file=self.old_vocab_file,\n        num_new_vocab=3,\n        new_vocab_offset=0)\n    expected_remapping = [2, 0, 1]\n    expected_num_present = 3\n    with self.cached_session():\n      self.assertAllEqual(expected_remapping, self.evaluate(remapping))\n      self.assertAllEqual(expected_num_present, self.evaluate(num_present))\n\n  def test_generate_remapping_with_offset(self):\n    \"\"\"Tests offset and num_new_vocab logic.\"\"\"\n    remapping, num_present = gen_checkpoint_ops.generate_vocab_remapping(\n        new_vocab_file=self.new_vocab_file,\n        old_vocab_file=self.old_vocab_file,\n        num_new_vocab=1,\n        new_vocab_offset=1)\n    expected_remapping = [0]\n    expected_num_present = 1\n    with self.cached_session():\n      self.assertAllEqual(expected_remapping, self.evaluate(remapping))\n      self.assertAllEqual(expected_num_present, self.evaluate(num_present))\n\n  def test_generate_remapping_with_old_vocab_size(self):\n    \"\"\"Tests where old_vocab_size is specified.\"\"\"\n    remapping, num_present = gen_checkpoint_ops.generate_vocab_remapping(\n        new_vocab_file=self.new_vocab_file,\n        old_vocab_file=self.old_vocab_file,\n        num_new_vocab=3,\n        new_vocab_offset=0,\n        # Old vocabulary becomes ['knitting', 'eminem'].\n        old_vocab_size=2)\n    expected_remapping = [-1, 0, 1]\n    expected_num_present = 2\n    with self.cached_session():\n      self.assertAllEqual(expected_remapping, self.evaluate(remapping))\n      self.assertAllEqual(expected_num_present, self.evaluate(num_present))\n\n\nclass LoadAndRemapMatrixTest(test.TestCase):\n  \"\"\"Tests for the load_and_remap_matrix() op.\"\"\"\n\n  def setUp(self):\n    ops.reset_default_graph()\n    self.old_num_rows = 5\n    self.old_num_cols = 16\n    self.matrix_value = np.reshape(\n        range(0, self.old_num_rows * self.old_num_cols), (self.old_num_rows,\n                                                          self.old_num_cols))\n    with variable_scope.variable_scope('some_scope'):\n      matrix = variable_scope.get_variable(\n          'matrix',\n          dtype=dtypes.float32,\n          initializer=constant_op.constant(\n              self.matrix_value, dtype=dtypes.float32))\n      self.old_tensor_name = 'some_scope/matrix'\n\n    save = saver.Saver([matrix])\n    with self.cached_session() as sess:\n      self.evaluate(variables.global_variables_initializer())\n      self.bundle_file = os.path.join(test.get_temp_dir(), 'bundle_checkpoint')\n      save.save(sess, self.bundle_file)\n\n  def test_load_and_remap_no_missing(self):\n    \"\"\"Tests the op's load and remap where there are no missing entries.\"\"\"\n\n    # No column remapping, new weight matrix has second row, then first row.\n    row_remapping = [1, 0]\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=row_remapping,\n        col_remapping=[],\n        initializing_values=[],\n        num_rows=2,\n        num_cols=self.old_num_cols)\n    with self.cached_session():\n      self.assertAllClose(self.matrix_value[row_remapping],\n                          self.evaluate(remapped_matrix))\n\n    # No row remapping, new weight matrix has third col, then first col.\n    row_remapping = list(range(self.old_num_rows))\n    col_remapping = [2, 0]\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=row_remapping,\n        col_remapping=col_remapping,\n        initializing_values=[],\n        num_rows=len(row_remapping),\n        num_cols=len(col_remapping))\n    with self.cached_session():\n      self.assertAllClose(self.matrix_value[row_remapping][:, col_remapping],\n                          self.evaluate(remapped_matrix))\n\n    # Both row and column remappings.\n    row_remapping = [1, 0, 4]\n    col_remapping = [1, 15]\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=row_remapping,\n        col_remapping=col_remapping,\n        initializing_values=[],\n        num_rows=len(row_remapping),\n        num_cols=len(col_remapping))\n    with self.cached_session():\n      self.assertAllClose(self.matrix_value[row_remapping][:, col_remapping],\n                          self.evaluate(remapped_matrix))\n\n  def test_load_and_remap_with_init(self):\n    \"\"\"Tests the op's load and remap where there are missing entries.\"\"\"\n    init_val = 42\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=[2, -1, 0],\n        col_remapping=[1, -1],\n        initializing_values=[init_val] * 4,\n        num_rows=3,\n        num_cols=2)\n\n    expected_remapped_matrix = np.reshape(\n        [33, init_val, init_val, init_val, 1, init_val], [3, 2])\n\n    with self.cached_session():\n      self.assertAllClose(expected_remapped_matrix,\n                          self.evaluate(remapped_matrix))\n\n  def test_load_and_remap_all_missing_rows(self):\n    \"\"\"Tests when all the rows are missing and need to be initialized.\"\"\"\n    num_rows = 7\n    initializing_values = [42] * num_rows * self.old_num_cols\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=[-1] * num_rows,\n        col_remapping=[],\n        initializing_values=initializing_values,\n        num_rows=num_rows,\n        num_cols=self.old_num_cols)\n    with self.cached_session():\n      self.assertAllClose(\n          np.reshape(initializing_values, (num_rows, self.old_num_cols)),\n          self.evaluate(remapped_matrix))\n\n  def test_load_and_remap_all_missing_rows_and_cols(self):\n    \"\"\"Tests when all the rows & cols are missing and need to be initialized.\"\"\"\n    num_rows = 7\n    num_cols = 4\n    initializing_values = [42] * num_rows * num_cols\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=[-1] * num_rows,\n        col_remapping=[-1] * num_cols,\n        initializing_values=initializing_values,\n        num_rows=num_rows,\n        num_cols=num_cols)\n    with self.cached_session():\n      self.assertAllClose(\n          np.reshape(initializing_values, (num_rows, num_cols)),\n          self.evaluate(remapped_matrix))\n\n  def test_load_and_remap_invalid_dims(self):\n    ckpt_path = constant_op.constant(\n        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n        shape=[],\n        dtype=dtypes.string)\n    old_tensor_name = constant_op.constant(\n        '/tmp/warm_starting_util_test5kl2a3pc/tmpph76tep2/model-0',\n        shape=[],\n        dtype=dtypes.string)\n    row_remapping = constant_op.constant(0, shape=[], dtype=dtypes.int64)\n    col_remapping = constant_op.constant(3, shape=[3], dtype=dtypes.int64)\n    initializing_values = constant_op.constant([],\n                                               shape=[0, 1],\n                                               dtype=dtypes.float32)\n    with self.cached_session(), self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError), 'tensor must be 1-D'):\n      self.evaluate(\n          gen_checkpoint_ops.load_and_remap_matrix(\n              ckpt_path=ckpt_path,\n              old_tensor_name=old_tensor_name,\n              row_remapping=row_remapping,\n              col_remapping=col_remapping,\n              initializing_values=initializing_values,\n              num_rows=1,\n              num_cols=1))\n\n  @test_util.run_deprecated_v1\n  def test_load_and_remap_invalid_remapping(self):\n    \"\"\"Tests that errors are raised when an ID maps to multiple new IDs.\n\n    (This should usually not happen when using public APIs).\n    \"\"\"\n    invalid_remapping = [1, 0, 0, 0, 1, 2]\n\n    # Invalid row remapping.\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=invalid_remapping,\n        col_remapping=[],\n        initializing_values=[],\n        num_rows=len(invalid_remapping),\n        num_cols=self.old_num_cols)\n    with self.cached_session(), self.assertRaises(errors.UnimplementedError):\n      self.evaluate(remapped_matrix)\n\n    # Invalid column remapping.\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=list(range(self.old_num_rows)),\n        col_remapping=invalid_remapping,\n        initializing_values=[],\n        num_rows=self.old_num_rows,\n        num_cols=len(invalid_remapping))\n    with self.cached_session(), self.assertRaises(errors.UnimplementedError):\n      self.evaluate(remapped_matrix)\n\n  @test_util.run_deprecated_v1\n  def test_load_and_remap_incorrect_initializing_values(self):\n    \"\"\"Tests that errors are raised with incorrect number of init values.\"\"\"\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=[2, -1, 0],\n        col_remapping=[1, -1],\n        # Too few initializing values - there should be 4. For some reason,\n        # initializing_values must contain no element (instead of 3 or fewer) to\n        # ensure that a seg fault would reliably occur if the check raising the\n        # InvalidArgumentError were not present.\n        initializing_values=[],\n        num_rows=3,\n        num_cols=2)\n    with self.cached_session(), self.assertRaises(errors.InvalidArgumentError):\n      self.evaluate(remapped_matrix)\n\n    remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n        ckpt_path=[self.bundle_file],\n        old_tensor_name=self.old_tensor_name,\n        row_remapping=[2, -1, 0],\n        col_remapping=[1, -1],\n        # Too many initializing values - there should be 4.\n        initializing_values=[0] * 5,\n        num_rows=3,\n        num_cols=2)\n    with self.cached_session(), self.assertRaises(errors.InvalidArgumentError):\n      self.evaluate(remapped_matrix)\n\n\nclass LoadAndRemapMatrixWithMaxRowsTest(test.TestCase):\n  \"\"\"Tests for the load_and_remap_matrix() op.\n\n  (Specifically focused on the max_rows_in_memory arg and its effects on\n  TensorBundle's BundleReader and TensorSlice logic).\n  \"\"\"\n\n  def _test_loading_variable_with_max_rows(self, np_value, partitioner,\n                                           max_rows_in_memory):\n    \"\"\"Helper function for various tests using max_rows_in_memory.\"\"\"\n    ops.reset_default_graph()\n    old_tensor_name = 'matrix_to_load_and_remap'\n    matrix = variable_scope.get_variable(\n        old_tensor_name,\n        dtype=dtypes.float32,\n        initializer=constant_op.constant(np_value, dtype=dtypes.float32),\n        partitioner=partitioner)\n\n    with self.cached_session() as sess:\n      ckpt_path = os.path.join(test.get_temp_dir(), 'temp_ckpt')\n      save = saver.Saver([matrix])\n      self.evaluate(variables.global_variables_initializer())\n      save.save(sess, ckpt_path)\n      num_rows, num_cols = np_value.shape\n\n      # Tests loading the entire tensor (except reversed).\n      remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n          ckpt_path=ckpt_path,\n          old_tensor_name=old_tensor_name,\n          # Simply reverses the rows of the matrix.\n          row_remapping=list(range(num_rows - 1, -1, -1)),\n          col_remapping=[],\n          initializing_values=[],\n          num_rows=num_rows,\n          num_cols=num_cols,\n          max_rows_in_memory=max_rows_in_memory)\n      self.assertAllClose(np_value[::-1], self.evaluate(remapped_matrix))\n\n      # Tests loading the tensor (except for the first and last rows), with\n      # uninitialized values. Requires num_rows to be at least 3 since we're\n      # skipping the first and last rows.\n      self.assertGreater(num_rows, 2)\n      prefix_rows = 2\n      suffix_rows = 3\n      remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n          ckpt_path=ckpt_path,\n          old_tensor_name=old_tensor_name,\n          # Reverses the rows of the matrix, then prepends and appends\n          # uninitialized rows.\n          row_remapping=([-1] * prefix_rows + list(range(1, num_rows - 1)) +\n                         [-1] * suffix_rows),\n          col_remapping=[],\n          initializing_values=[42] * (prefix_rows + suffix_rows) * num_cols,\n          num_rows=num_rows - 2 + prefix_rows + suffix_rows,\n          num_cols=num_cols,\n          max_rows_in_memory=max_rows_in_memory)\n      self.assertAllClose(\n          np.vstack([\n              np.tile(42, [prefix_rows, num_cols]), np_value[1:-1],\n              np.tile(42, [suffix_rows, num_cols])\n          ]), self.evaluate(remapped_matrix))\n\n      # Tests when everything is taken from initializing_values.\n      new_rows = 7\n      initializing_values = [42] * new_rows * num_cols\n      remapped_matrix = gen_checkpoint_ops.load_and_remap_matrix(\n          ckpt_path=ckpt_path,\n          old_tensor_name=old_tensor_name,\n          # Nothing is loaded from the old tensor.\n          row_remapping=[-1] * new_rows,\n          col_remapping=[],\n          initializing_values=initializing_values,\n          num_rows=new_rows,\n          num_cols=num_cols,\n          max_rows_in_memory=max_rows_in_memory)\n      self.assertAllClose(\n          np.reshape(initializing_values, (new_rows, num_cols)),\n          self.evaluate(remapped_matrix))\n\n  @test_util.run_deprecated_v1\n  def test_loading_rows_divisible_by_max_rows(self):\n    \"\"\"Tests loading normal var when rows are evenly divisible by max_rows.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=None,\n        # 9 is evenly divisible by 3.\n        max_rows_in_memory=3)\n\n  @test_util.run_deprecated_v1\n  def test_loading_rows_not_divisible_by_max_rows(self):\n    \"\"\"Tests loading normal var when rows aren't divisible by max_rows.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=None,\n        # 9 is not evenly divisible by 4.\n        max_rows_in_memory=4)\n\n  @test_util.run_deprecated_v1\n  def test_loading_rows_less_than_max_rows(self):\n    \"\"\"Tests loading normal var as a single slice.\n\n    (When the specified max_rows_in_memory is larger than the number of rows)\n    \"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=None,\n        # 10 > 9.\n        max_rows_in_memory=10)\n\n  @test_util.run_deprecated_v1\n  def test_loading_no_max_rows(self):\n    \"\"\"Tests loading normal var as a single slice with no valid max_rows.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 18)), (6, 3)),\n        partitioner=None,\n        max_rows_in_memory=-1)\n\n  @test_util.run_deprecated_v1\n  def test_loading_partitions_equals_max_rows(self):\n    \"\"\"Tests loading partitioned var sliced on partition boundary.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=partitioned_variables.fixed_size_partitioner(3),\n        # With a tensor of shape [9, 3] and 3 partitions, each partition has\n        # exactly 3 rows.\n        max_rows_in_memory=3)\n\n  @test_util.run_deprecated_v1\n  def test_loading_partitions_greater_than_max_rows(self):\n    \"\"\"Tests loading partitioned var with more slices than partitions.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=partitioned_variables.fixed_size_partitioner(3),\n        # Even though each partition has 3 rows, we'll only load the tensor one\n        # row at a time.\n        max_rows_in_memory=1)\n\n  @test_util.run_deprecated_v1\n  def test_loading_partitions_less_than_max_rows(self):\n    \"\"\"Tests loading partitioned var as a single slice.\n\n    (When the specified max_rows_in_memory is larger than the number of rows)\n    \"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=partitioned_variables.fixed_size_partitioner(3),\n        max_rows_in_memory=10)\n\n  @test_util.run_deprecated_v1\n  def test_loading_partitions_no_max_rows(self):\n    \"\"\"Tests loading partitioned var as single slice with no valid max_rows.\"\"\"\n    self._test_loading_variable_with_max_rows(\n        np_value=np.reshape(list(range(0, 36)), (9, 4)),\n        partitioner=partitioned_variables.fixed_size_partitioner(3),\n        max_rows_in_memory=-1)\n\n\nif __name__ == '__main__':\n  test.main()"