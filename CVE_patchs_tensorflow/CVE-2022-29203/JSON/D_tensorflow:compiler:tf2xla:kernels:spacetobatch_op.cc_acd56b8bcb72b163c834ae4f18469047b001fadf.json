"diff --git a/tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc b/tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc\nindex a4e9aec1c97..d6e38f1309f 100644\n--- a/tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc\n+++ b/tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc\n@@ -17,6 +17,7 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n #include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n #include \"tensorflow/compiler/xla/client/xla_builder.h\"\n+#include \"tensorflow/core/util/overflow.h\"\n \n namespace tensorflow {\n namespace {\n@@ -60,10 +61,14 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n     int64_t pad_end = paddings.Get<int64_t>({i, 1});\n     OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,\n                 errors::InvalidArgument(\"Paddings must be non-negative\"));\n+    OP_REQUIRES(ctx, block_shape[i] >= 1,\n+                errors::InvalidArgument(\n+                    \"All values in block_shape must be positive, got value, \",\n+                    block_shape[i], \" at index \", i, \".\"));\n     dim->set_edge_padding_low(pad_start);\n     dim->set_edge_padding_high(pad_end);\n     padded_shape[1 + i] += pad_start + pad_end;\n-    block_num_elems *= block_shape[i];\n+    block_num_elems = MultiplyWithoutOverflow(block_num_elems, block_shape[i]);\n   }\n   // Don't pad the remainder dimensions.\n   for (int i = 0; i < remainder_shape.size(); ++i) {\n@@ -72,6 +77,16 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   OP_REQUIRES(ctx, block_num_elems > 0,\n               errors::InvalidArgument(\n                   \"The product of the block dimensions must be positive\"));\n+  const int64_t batch_size = input_shape[0];\n+  const int64_t output_dim =\n+      MultiplyWithoutOverflow(batch_size, block_num_elems);\n+  if (output_dim < 0) {\n+    OP_REQUIRES(\n+        ctx, output_dim >= 0,\n+        errors::InvalidArgument(\"Negative output dimension size caused by \"\n+                                \"overflow when multiplying \",\n+                                batch_size, \" and \", block_num_elems));\n+  }\n \n   xla::XlaOp padded =\n       xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);\n@@ -85,7 +100,6 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   //       padded_shape[M] / block_shape[M-1],\n   //       block_shape[M-1]] +\n   //      remaining_shape\n-  const int64_t batch_size = input_shape[0];\n   std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);\n   reshaped_padded_shape[0] = batch_size;\n   for (int i = 0; i < block_rank; ++i) {\n@@ -134,7 +148,7 @@ void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n   // Determine the length of the prefix of block dims that can be combined\n   // into the batch dimension due to having no padding and block_shape=1.\n   std::vector<int64_t> output_shape(input_rank);\n-  output_shape[0] = batch_size * block_num_elems;\n+  output_shape[0] = output_dim;\n   for (int i = 0; i < block_rank; ++i) {\n     output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];\n   }"