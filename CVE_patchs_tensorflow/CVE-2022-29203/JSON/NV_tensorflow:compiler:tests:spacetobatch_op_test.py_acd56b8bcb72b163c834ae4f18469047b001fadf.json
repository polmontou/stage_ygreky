"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for SpaceToBatch and BatchToSpace ops.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.compiler.tests import xla_test\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_array_ops\nfrom tensorflow.python.platform import test\n\n\ndef space_to_batch_direct(input_array, block_shape, paddings):\n  \"\"\"Direct Python implementation of space-to-batch conversion.\n\n  This is used for tests only.\n\n  Args:\n    input_array: N-D array\n    block_shape: 1-D array of shape [num_block_dims].\n    paddings: 2-D array of shape [num_block_dims, 2].\n\n  Returns:\n    Converted tensor.\n  \"\"\"\n  input_array = np.array(input_array)\n  block_shape = np.array(block_shape)\n  num_block_dims = len(block_shape)\n  paddings = np.array(paddings).reshape((len(block_shape), 2))\n\n  padded = np.pad(input_array,\n                  pad_width=([[0, 0]] + list(paddings) + [[0, 0]] *\n                             (input_array.ndim - 1 - num_block_dims)),\n                  mode=\"constant\")\n  reshaped_padded_shape = [input_array.shape[0]]\n  output_shape = [input_array.shape[0] * np.prod(block_shape)]\n  for block_dim, block_shape_value in enumerate(block_shape):\n    reduced_size = padded.shape[block_dim + 1] // block_shape_value\n    reshaped_padded_shape.append(reduced_size)\n    output_shape.append(reduced_size)\n    reshaped_padded_shape.append(block_shape_value)\n  reshaped_padded_shape.extend(input_array.shape[num_block_dims + 1:])\n  output_shape.extend(input_array.shape[num_block_dims + 1:])\n\n  reshaped_padded = padded.reshape(reshaped_padded_shape)\n  permuted_reshaped_padded = np.transpose(reshaped_padded, (\n      list(np.arange(num_block_dims) * 2 + 2) + [0] +\n      list(np.arange(num_block_dims) * 2 + 1) + list(\n          np.arange(input_array.ndim - num_block_dims - 1) + 1 + num_block_dims\n          * 2)))\n  return permuted_reshaped_padded.reshape(output_shape)\n\n\nclass SpaceToBatchTest(xla_test.XLATestCase):\n  \"\"\"Tests input-output pairs for the SpaceToBatch and BatchToSpace ops.\"\"\"\n\n  def _testPad(self, inputs, paddings, block_size, outputs):\n    with self.session() as sess, self.test_scope():\n      for dtype in self.float_types:\n        # outputs = space_to_batch(inputs)\n        placeholder = array_ops.placeholder(dtype)\n        x_tf = gen_array_ops.space_to_batch(\n            placeholder, paddings, block_size=block_size)\n        self.assertAllEqual(sess.run(x_tf, {placeholder: inputs}), outputs)\n        # inputs = batch_to_space(outputs)\n        x_tf = gen_array_ops.batch_to_space(\n            placeholder, paddings, block_size=block_size)\n        self.assertAllEqual(sess.run(x_tf, {placeholder: outputs}), inputs)\n\n  def _testOne(self, inputs, block_size, outputs):\n    paddings = np.zeros((2, 2), dtype=np.int32)\n    self._testPad(inputs, paddings, block_size, outputs)\n\n  # [1, 2, 2, 1] <-> [4, 1, 1, 1]\n  def testSmallInput2x2(self):\n    x_np = [[[[1], [2]], [[3], [4]]]]\n    block_size = 2\n    x_out = [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n    self._testOne(x_np, block_size, x_out)\n\n  # [1, 2, 2, 1] <-> [1, 3, 3, 1] (padding) <-> [9, 1, 1, 1]\n  def testSmallInput2x2Pad1x0(self):\n    x_np = [[[[1], [2]], [[3], [4]]]]\n    paddings = np.array([[1, 0], [1, 0]], dtype=np.int32)\n    block_size = 3\n    x_out = [[[[0]]], [[[0]]], [[[0]]], [[[0]]], [[[1]]], [[[2]]], [[[0]]],\n             [[[3]]], [[[4]]]]\n    self._testPad(x_np, paddings, block_size, x_out)\n\n  # Test with depth larger than 1.\n  # [1, 2, 2, 3] <-> [4, 1, 1, 3]\n  def testDepthInput2x2(self):\n    x_np = [[[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]]\n    block_size = 2\n    x_out = [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n    self._testOne(x_np, block_size, x_out)\n\n  # Test for larger input dimensions.\n  # [1, 4, 4, 1] <-> [4, 2, 2, 1]\n  def testLargerInput2x2(self):\n    x_np = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]],\n             [[9], [10], [11], [12]], [[13], [14], [15], [16]]]]\n    block_size = 2\n    x_out = [[[[1], [3]], [[9], [11]]], [[[2], [4]], [[10], [12]]],\n             [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]]\n    self._testOne(x_np, block_size, x_out)\n\n  # Test with batch larger than 1.\n  # [2, 2, 4, 1] <-> [8, 1, 2, 1]\n  def testBatchInput2x2(self):\n    x_np = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]]],\n            [[[9], [10], [11], [12]], [[13], [14], [15], [16]]]]\n    block_size = 2\n    x_out = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],\n             [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]\n    self._testOne(x_np, block_size, x_out)\n\n  # Tests for larger input spatial dimensions AND batch larger than 1, to ensure\n  # that elements are correctly laid out spatially and properly interleaved\n  # along the batch dimension.\n  # [2, 4, 4, 1] <-> [8, 2, 2, 1]\n  def testLargerInputBatch2x2(self):\n    x_np = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]],\n             [[9], [10], [11], [12]], [[13], [14], [15], [16]]],\n            [[[17], [18], [19], [20]], [[21], [22], [23], [24]],\n             [[25], [26], [27], [28]], [[29], [30], [31], [32]]]]\n    x_out = [[[[1], [3]], [[9], [11]]], [[[17], [19]], [[25], [27]]],\n             [[[2], [4]], [[10], [12]]], [[[18], [20]], [[26], [28]]],\n             [[[5], [7]], [[13], [15]]], [[[21], [23]], [[29], [31]]],\n             [[[6], [8]], [[14], [16]]], [[[22], [24]], [[30], [32]]]]\n    block_size = 2\n    self._testOne(x_np, block_size, x_out)\n\n\nclass SpaceToBatchNDErrorHandlingTest(xla_test.XLATestCase):\n\n  def testInvalidBlockShape(self):\n    with self.assertRaisesRegex(ValueError, \"block_shape must be positive\"):\n      with self.session() as sess, self.test_scope():\n        tf_in = constant_op.constant(\n            -3.5e+35, shape=[10, 20, 20], dtype=dtypes.float32)\n        block_shape = constant_op.constant(-10, shape=[2], dtype=dtypes.int64)\n        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n\n  def testOutputSizeOutOfBounds(self):\n    with self.assertRaisesRegex(ValueError,\n                                \"Negative.* dimension size caused by overflow\"):\n      with self.session() as sess, self.test_scope():\n        tf_in = constant_op.constant(\n            -3.5e+35, shape=[10, 19, 22], dtype=dtypes.float32)\n        block_shape = constant_op.constant(\n            1879048192, shape=[2], dtype=dtypes.int64)\n        paddings = constant_op.constant(0, shape=[2, 2], dtype=dtypes.int32)\n        sess.run(array_ops.space_to_batch_nd(tf_in, block_shape, paddings))\n\n\nclass SpaceToBatchNDTest(xla_test.XLATestCase):\n  \"\"\"Tests input-output pairs for the SpaceToBatchND and BatchToSpaceND ops.\"\"\"\n\n  def _testPad(self, inputs, block_shape, paddings, outputs):\n    block_shape = np.array(block_shape)\n    paddings = np.array(paddings).reshape((len(block_shape), 2))\n    with self.session() as sess, self.test_scope():\n      for dtype in self.float_types:\n        # TODO(b/68813416): Skip bfloat16's as the input type for direct is\n        # float32 and results in a mismatch, while making testDirect provide the\n        # correctly typed input results in 'no fill-function for data-type'\n        # error.\n        if dtype == dtypes.bfloat16.as_numpy_dtype:\n          continue\n        if dtype == np.float16:\n          actual_inputs = np.array(inputs).astype(dtype)\n          actual_paddings = np.array(paddings).astype(dtype)\n          expected_outputs = np.array(outputs).astype(dtype)\n        else:\n          actual_inputs = inputs\n          actual_paddings = paddings\n          expected_outputs = outputs\n        placeholder = array_ops.placeholder(dtype)\n        # outputs = space_to_batch(inputs)\n        x_tf = array_ops.space_to_batch_nd(placeholder, block_shape,\n                                           actual_paddings)\n        self.assertAllEqual(\n            sess.run(x_tf, {placeholder: actual_inputs}), expected_outputs)\n        # inputs = batch_to_space(outputs)\n        placeholder = array_ops.placeholder(dtype)\n        x_tf = array_ops.batch_to_space_nd(placeholder, block_shape,\n                                           actual_paddings)\n        self.assertAllEqual(\n            sess.run(x_tf, {placeholder: expected_outputs}), actual_inputs)\n\n  def _testDirect(self, input_shape, block_shape, paddings):\n    inputs = np.arange(np.prod(input_shape), dtype=np.float32)\n    inputs = inputs.reshape(input_shape)\n    self._testPad(inputs, block_shape, paddings,\n                  space_to_batch_direct(inputs, block_shape, paddings))\n\n  def testZeroBlockDimsZeroRemainingDims(self):\n    self._testPad(\n        inputs=[1, 2],\n        block_shape=[],\n        paddings=[],\n        outputs=[1, 2],)\n\n  def testZeroBlockDimsOneRemainingDim(self):\n    self._testPad(\n        inputs=[[1, 2], [3, 4]],\n        block_shape=[],\n        paddings=[],\n        outputs=[[1, 2], [3, 4]])\n\n    # Same thing, but with a no-op block dim.\n    self._testPad(\n        inputs=[[1, 2], [3, 4]],\n        block_shape=[1],\n        paddings=[[0, 0]],\n        outputs=[[1, 2], [3, 4]])\n\n  def testZeroBlockDimsTwoRemainingDims(self):\n    self._testPad(\n        inputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        block_shape=[],\n        paddings=[],\n        outputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n    # Same thing, but with a no-op block dim.\n    self._testPad(\n        inputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        block_shape=[1],\n        paddings=[[0, 0]],\n        outputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n    # Same thing, but with two no-op block dims.\n    self._testPad(\n        inputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]],\n        block_shape=[1, 1],\n        paddings=[[0, 0], [0, 0]],\n        outputs=[[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\n  def testOneBlockDimZeroRemainingDims(self):\n    self._testPad(\n        inputs=[[1, 2, 3], [4, 5, 6]],\n        block_shape=[2],\n        paddings=[1, 0],\n        outputs=[[0, 2], [0, 5], [1, 3], [4, 6]])\n\n  def testOneBlockDimOneRemainingDim(self):\n    self._testPad(\n        inputs=[[[1, 11], [2, 21], [3, 31]], [[4, 41], [5, 51], [6, 61]]],\n        block_shape=[2],\n        paddings=[1, 0],\n        outputs=[[[0, 0], [2, 21]], [[0, 0], [5, 51]], [[1, 11], [3, 31]],\n                 [[4, 41], [6, 61]]])\n\n  def testDirect0(self):\n    # Test with zero-size remaining dimension.\n    self._testDirect(\n        input_shape=[3, 1, 2, 0], block_shape=[3], paddings=[[0, 2]])\n\n  def testDirect1(self):\n    # Test with zero-size blocked dimension.\n    self._testDirect(\n        input_shape=[3, 0, 2, 5], block_shape=[3], paddings=[[0, 0]])\n\n  def testDirect2(self):\n    # Test with padding up from zero size.\n    self._testDirect(\n        input_shape=[3, 0, 2, 5], block_shape=[3], paddings=[[1, 2]])\n\n  def testDirect3(self):\n    self._testDirect(\n        input_shape=[3, 3, 4, 5, 2],\n        block_shape=[3, 4, 2],\n        paddings=[[1, 2], [0, 0], [3, 0]])\n\n  def testDirect4(self):\n    self._testDirect(\n        input_shape=[3, 3, 4, 5, 2],\n        block_shape=[3, 4, 2, 2],\n        paddings=[[1, 2], [0, 0], [3, 0], [0, 0]])\n\n  def testDirect5(self):\n    self._testDirect(\n        input_shape=[3, 2, 2, 3, 4, 5, 2, 5],\n        block_shape=[1, 1, 3, 4, 2, 2],\n        paddings=[[0, 0], [0, 0], [1, 2], [0, 0], [3, 0], [0, 0]])\n\n  def testDirect6(self):\n    self._testDirect(\n        input_shape=[3, 2, 2, 3, 4, 5, 2, 5],\n        block_shape=[1, 1, 3, 4, 2, 2, 1],\n        paddings=[[0, 0], [0, 0], [1, 2], [0, 0], [3, 0], [0, 0], [0, 0]])\n\n\nif __name__ == \"__main__\":\n  test.main()"