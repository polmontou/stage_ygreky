"# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for SparseAdd.\"\"\"\n\nimport timeit\n\nimport numpy as np\n\nfrom tensorflow.python.client import session\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import sparse_tensor\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import sparse_ops\nimport tensorflow.python.ops.sparse_grad  # pylint: disable=unused-import\nfrom tensorflow.python.platform import test\n\n\ndef _sparsify(x, thresh=0.5, index_dtype=np.int64):\n  x[x < thresh] = 0\n\n  non_zero = np.where(x)\n  x_indices = np.vstack(non_zero).astype(index_dtype).T\n  x_values = x[non_zero]\n  x_shape = x.shape\n\n  return sparse_tensor.SparseTensor(\n      indices=x_indices, values=x_values, dense_shape=x_shape), len(x_values)\n\n\nclass SparseAddTest(test.TestCase):\n\n  def _randomTensor(self, size, np_dtype, sparse=True):\n    n, m = size\n    x = np.random.randn(n, m).astype(np_dtype)\n    return _sparsify(x) if sparse else x\n\n  def _SparseTensorValue_3x3(self, negate=False):\n    # [    1]\n    # [2    ]\n    # [3   4]\n    # ...or its cwise negation, if `negate`\n    ind = np.array([[0, 1], [1, 0], [2, 0], [2, 1]])\n    val = np.array([1, 2, 3, 4])\n    if negate:\n      val = -np.array([1, 2, 3, 4])\n    shape = np.array([3, 3])\n    return sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(val, np.float32), np.array(shape, np.int64))\n\n  def _SparseTensor_3x3(self, negate=False):\n    return sparse_tensor.SparseTensor.from_value(\n        self._SparseTensorValue_3x3(negate))\n\n  def _SparseTensor_3x3_v2(self):\n    # [           1]\n    # [-1.9        ]\n    # [   3    -4.2]\n    ind = np.array([[0, 1], [1, 0], [2, 0], [2, 1]])\n    val = np.array([1, -1.9, 3, -4.2])\n    shape = np.array([3, 3])\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtypes.float32),\n        constant_op.constant(shape, dtypes.int64))\n\n  def testAddSelf(self):\n    with test_util.force_cpu():\n      for sp_a in (self._SparseTensorValue_3x3(), self._SparseTensor_3x3()):\n        for sp_b in (self._SparseTensorValue_3x3(), self._SparseTensor_3x3()):\n          sp_sum = sparse_ops.sparse_add(sp_a, sp_b)\n          self.assertAllEqual((3, 3), sp_sum.get_shape())\n\n          sum_out = self.evaluate(sp_sum)\n\n          self.assertEqual(sp_sum.dense_shape.get_shape(), [2])\n          self.assertAllEqual(sum_out.indices, [[0, 1], [1, 0], [2, 0], [2, 1]])\n          self.assertAllEqual(sum_out.values, [2, 4, 6, 8])\n          self.assertAllEqual(sum_out.dense_shape, [3, 3])\n\n  def testAddSelfAndNegation(self):\n    with test_util.force_cpu():\n      sp_a = self._SparseTensor_3x3()\n      sp_b = self._SparseTensor_3x3(negate=True)\n\n      sp_sum = sparse_ops.sparse_add(sp_a, sp_b, 0.1)\n      sum_out = self.evaluate(sp_sum)\n\n      self.assertEqual(sp_sum.dense_shape.get_shape(), [2])\n      self.assertAllEqual(sum_out.indices, np.empty([0, 2]))\n      self.assertAllEqual(sum_out.values, [])\n      self.assertAllEqual(sum_out.dense_shape, [3, 3])\n\n  def testSmallValuesShouldVanish(self):\n    with test_util.force_cpu():\n      sp_a = self._SparseTensor_3x3()\n      sp_b = self._SparseTensor_3x3_v2()\n\n      # sum:\n      # [       2]\n      # [.1      ]\n      # [ 6   -.2]\n\n      # two values should vanish: |.1| < .21, and |-.2| < .21\n      sp_sum = sparse_ops.sparse_add(sp_a, sp_b, thresh=0.21)\n      sum_out = self.evaluate(sp_sum)\n\n      self.assertEqual(sp_sum.dense_shape.get_shape(), [2])\n      self.assertAllEqual(sum_out.indices, [[0, 1], [2, 0]])\n      self.assertAllEqual(sum_out.values, [2, 6])\n      self.assertAllEqual(sum_out.dense_shape, [3, 3])\n\n      # only .1 vanishes\n      sp_sum = sparse_ops.sparse_add(sp_a, sp_b, thresh=0.11)\n      sum_out = self.evaluate(sp_sum)\n\n      self.assertEqual(sp_sum.dense_shape.get_shape(), [2])\n      self.assertAllEqual(sum_out.indices, [[0, 1], [2, 0], [2, 1]])\n      self.assertAllClose(sum_out.values, [2, 6, -.2])\n      self.assertAllEqual(sum_out.dense_shape, [3, 3])\n\n  @test_util.run_deprecated_v1\n  def testGradients(self):\n    np.random.seed(1618)  # Make it reproducible.\n    with self.session(use_gpu=False):\n      for n in [10, 31]:\n        for m in [4, 17]:\n          sp_a, nnz_a = self._randomTensor([n, m], np.float32)\n          sp_b, nnz_b = self._randomTensor([n, m], np.float32)\n          sp_sum = sparse_ops.sparse_add(sp_a, sp_b)\n          nnz_sum = len(self.evaluate(sp_sum.values))\n\n          err = gradient_checker.compute_gradient_error(\n              [sp_a.values, sp_b.values], [(nnz_a,), (nnz_b,)], sp_sum.values,\n              (nnz_sum,))\n          self.assertLess(err, 1e-3)\n\n  def testAddSparseDense(self):\n    np.random.seed(1618)  # Make it reproducible.\n    n, m = np.random.randint(30, size=2)\n    for dtype in [np.float32, np.float64, np.int64, np.complex64]:\n      for index_dtype in [np.int32, np.int64]:\n        rand_vals_np = np.random.randn(n, m).astype(dtype)\n        dense_np = np.random.randn(n, m).astype(dtype)\n\n        with test_util.force_cpu():\n          sparse, unused_nnz = _sparsify(rand_vals_np, index_dtype=index_dtype)\n          s = self.evaluate(\n              sparse_ops.sparse_add(sparse, constant_op.constant(dense_np)))\n          self.assertAllEqual(dense_np + rand_vals_np, s)\n          self.assertTrue(s.dtype == dtype)\n\n          # check commutativity\n          s = self.evaluate(\n              sparse_ops.sparse_add(constant_op.constant(dense_np), sparse))\n          self.assertAllEqual(dense_np + rand_vals_np, s)\n          self.assertTrue(s.dtype == dtype)\n\n  @test_util.run_deprecated_v1\n  def testSparseTensorDenseAddGradients(self):\n    np.random.seed(1618)  # Make it reproducible.\n    n, m = np.random.randint(30, size=2)\n    rand_vals_np = np.random.randn(n, m).astype(np.float32)\n    dense_np = np.random.randn(n, m).astype(np.float32)\n\n    with self.session(use_gpu=False):\n      sparse, nnz = _sparsify(rand_vals_np)\n      dense = constant_op.constant(dense_np, dtype=dtypes.float32)\n      s = sparse_ops.sparse_add(sparse, dense)\n\n      err = gradient_checker.compute_gradient_error([sparse.values, dense],\n                                                    [(nnz,), (n, m)], s, (n, m))\n      self.assertLess(err, 1e-3)\n\n  @test_util.run_deprecated_v1\n  def testInvalidSparseTensor(self):\n    with test_util.force_cpu():\n      shape = [2, 2]\n      val = [0]\n      dense = constant_op.constant(np.zeros(shape, dtype=np.int32))\n\n      for bad_idx in [\n          [[-1, 0]],  # -1 is invalid.\n          [[1, 3]],  # ...so is 3.\n      ]:\n        sparse = sparse_tensor.SparseTensorValue(bad_idx, val, shape)\n        s = sparse_ops.sparse_add(sparse, dense)\n\n        with self.assertRaisesRegex(errors_impl.InvalidArgumentError,\n                                    \"invalid index\"):\n          self.evaluate(s)\n\n######################## Benchmarking code\n\n\ndef _s2d_add_vs_sparse_add(sparsity, n, m, num_iters=50):\n  np.random.seed(1618)\n\n  with session.Session(graph=ops.Graph()) as sess:\n    sp_vals = np.random.rand(n, m).astype(np.float32)\n    sp_t, unused_nnz = _sparsify(sp_vals, thresh=sparsity, index_dtype=np.int32)\n    vals = np.random.rand(n, m).astype(np.float32)\n\n    s2d = math_ops.add(\n        sparse_ops.sparse_tensor_to_dense(sp_t), constant_op.constant(vals))\n    sa = sparse_ops.sparse_add(sp_t, constant_op.constant(vals))\n\n    timeit.timeit(lambda: sess.run(s2d), number=3)\n    timeit.timeit(lambda: sess.run(sa), number=3)\n\n    s2d_total = timeit.timeit(lambda: sess.run(s2d), number=num_iters)\n    sa_total = timeit.timeit(lambda: sess.run(sa), number=num_iters)\n\n  # per-iter latency; secs to millis\n  return s2d_total * 1e3 / num_iters, sa_total * 1e3 / num_iters\n\n\nclass SparseAddBenchmark(test.Benchmark):\n\n  def benchmarkSparseAddDense(self):\n\n    print(\"SparseAddDense: add with sparse_to_dense vs. sparse_add\")\n    print(\"%nnz \\t n \\t m \\t millis(s2d) \\t millis(sparse_add) \\t speedup\")\n\n    for sparsity in [0.99, 0.5, 0.01]:\n      for n in [1, 256, 50000]:\n        for m in [100, 1000]:\n          s2d_dt, sa_dt = _s2d_add_vs_sparse_add(sparsity, n, m)\n          print(\"%.2f \\t %d \\t %d \\t %.4f \\t %.4f \\t %.2f\" % (sparsity, n, m,\n                                                              s2d_dt, sa_dt,\n                                                              s2d_dt / sa_dt))\n\n\nif __name__ == \"__main__\":\n  test.main()"