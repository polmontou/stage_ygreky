"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for V2 summary ops from summary_ops_v2.\"\"\"\n\nimport os\nimport unittest\n\nimport six\n\nfrom tensorflow.core.framework import graph_pb2\nfrom tensorflow.core.framework import node_def_pb2\nfrom tensorflow.core.framework import step_stats_pb2\nfrom tensorflow.core.framework import summary_pb2\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.core.util import event_pb2\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import tensor_util\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.lib.io import tf_record\nfrom tensorflow.python.module import module\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import summary_ops_v2 as summary_ops\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import gfile\nfrom tensorflow.python.platform import test\nfrom tensorflow.python.platform import tf_logging as logging\nfrom tensorflow.python.saved_model import load as saved_model_load\nfrom tensorflow.python.saved_model import loader as saved_model_loader\nfrom tensorflow.python.saved_model import save as saved_model_save\nfrom tensorflow.python.saved_model import tag_constants\n\n\nclass SummaryOpsCoreTest(test_util.TensorFlowTestCase):\n\n  def testWrite(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        output = summary_ops.write('tag', 42, step=12)\n        self.assertTrue(output.numpy())\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    value = events[1].summary.value[0]\n    self.assertEqual('tag', value.tag)\n    self.assertEqual(42, to_numpy(value))\n\n  def testWrite_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function\n      def f():\n        with writer.as_default():\n          return summary_ops.write('tag', 42, step=12)\n      output = f()\n      self.assertTrue(output.numpy())\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    value = events[1].summary.value[0]\n    self.assertEqual('tag', value.tag)\n    self.assertEqual(42, to_numpy(value))\n\n  def testWrite_metadata(self):\n    logdir = self.get_temp_dir()\n    metadata = summary_pb2.SummaryMetadata()\n    metadata.plugin_data.plugin_name = 'foo'\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        summary_ops.write('obj', 0, 0, metadata=metadata)\n        summary_ops.write('bytes', 0, 0, metadata=metadata.SerializeToString())\n        m = constant_op.constant(metadata.SerializeToString())\n        summary_ops.write('string_tensor', 0, 0, metadata=m)\n    events = events_from_logdir(logdir)\n    self.assertEqual(4, len(events))\n    self.assertEqual(metadata, events[1].summary.value[0].metadata)\n    self.assertEqual(metadata, events[2].summary.value[0].metadata)\n    self.assertEqual(metadata, events[3].summary.value[0].metadata)\n\n  def testWrite_name(self):\n    @def_function.function\n    def f():\n      output = summary_ops.write('tag', 42, step=12, name='anonymous')\n      self.assertTrue(output.name.startswith('anonymous'))\n    f()\n\n  def testWrite_ndarray(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        summary_ops.write('tag', [[1, 2], [3, 4]], step=12)\n    events = events_from_logdir(logdir)\n    value = events[1].summary.value[0]\n    self.assertAllEqual([[1, 2], [3, 4]], to_numpy(value))\n\n  def testWrite_tensor(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      t = constant_op.constant([[1, 2], [3, 4]])\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        summary_ops.write('tag', t, step=12)\n      expected = t.numpy()\n    events = events_from_logdir(logdir)\n    value = events[1].summary.value[0]\n    self.assertAllEqual(expected, to_numpy(value))\n\n  def testWrite_tensor_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function\n      def f(t):\n        with writer.as_default():\n          summary_ops.write('tag', t, step=12)\n      t = constant_op.constant([[1, 2], [3, 4]])\n      f(t)\n      expected = t.numpy()\n    events = events_from_logdir(logdir)\n    value = events[1].summary.value[0]\n    self.assertAllEqual(expected, to_numpy(value))\n\n  def testWrite_stringTensor(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        summary_ops.write('tag', [b'foo', b'bar'], step=12)\n    events = events_from_logdir(logdir)\n    value = events[1].summary.value[0]\n    self.assertAllEqual([b'foo', b'bar'], to_numpy(value))\n\n  @test_util.run_gpu_only\n  def testWrite_gpuDeviceContext(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with ops.device('/GPU:0'):\n          value = constant_op.constant(42.0)\n          step = constant_op.constant(12, dtype=dtypes.int64)\n          summary_ops.write('tag', value, step=step).numpy()\n    empty_metadata = summary_pb2.SummaryMetadata()\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    self.assertEqual(42, to_numpy(events[1].summary.value[0]))\n    self.assertEqual(empty_metadata, events[1].summary.value[0].metadata)\n\n  @test_util.also_run_as_tf_function\n  def testWrite_noDefaultWriter(self):\n    # Use assertAllEqual instead of assertFalse since it works in a defun.\n    self.assertAllEqual(False, summary_ops.write('tag', 42, step=0))\n\n  @test_util.also_run_as_tf_function\n  def testWrite_noStep_okayIfAlsoNoDefaultWriter(self):\n    # Use assertAllEqual instead of assertFalse since it works in a defun.\n    self.assertAllEqual(False, summary_ops.write('tag', 42))\n\n  def testWrite_noStep(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with self.assertRaisesRegex(ValueError, 'No step set'):\n          summary_ops.write('tag', 42)\n\n  def testWrite_noStep_okayIfNotRecordingSummaries(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with summary_ops.record_if(False):\n          self.assertFalse(summary_ops.write('tag', 42))\n\n  def testWrite_usingDefaultStep(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        with summary_ops.create_file_writer_v2(logdir).as_default():\n          summary_ops.set_step(1)\n          summary_ops.write('tag', 1.0)\n          summary_ops.set_step(2)\n          summary_ops.write('tag', 1.0)\n          mystep = variables.Variable(10, dtype=dtypes.int64)\n          summary_ops.set_step(mystep)\n          summary_ops.write('tag', 1.0)\n          mystep.assign_add(1)\n          summary_ops.write('tag', 1.0)\n      events = events_from_logdir(logdir)\n      self.assertEqual(5, len(events))\n      self.assertEqual(1, events[1].step)\n      self.assertEqual(2, events[2].step)\n      self.assertEqual(10, events[3].step)\n      self.assertEqual(11, events[4].step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepConstant_fromFunction(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        @def_function.function\n        def f():\n          with writer.as_default():\n            summary_ops.write('tag', 1.0)\n        summary_ops.set_step(1)\n        f()\n        summary_ops.set_step(2)\n        f()\n      events = events_from_logdir(logdir)\n      self.assertEqual(3, len(events))\n      self.assertEqual(1, events[1].step)\n      # The step value will still be 1 because the value was captured at the\n      # time the function was first traced.\n      self.assertEqual(1, events[2].step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepVariable_fromFunction(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        @def_function.function\n        def f():\n          with writer.as_default():\n            summary_ops.write('tag', 1.0)\n        mystep = variables.Variable(0, dtype=dtypes.int64)\n        summary_ops.set_step(mystep)\n        f()\n        mystep.assign_add(1)\n        f()\n        mystep.assign(10)\n        f()\n      events = events_from_logdir(logdir)\n      self.assertEqual(4, len(events))\n      self.assertEqual(0, events[1].step)\n      self.assertEqual(1, events[2].step)\n      self.assertEqual(10, events[3].step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepConstant_fromLegacyGraph(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.graph_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        summary_ops.set_step(1)\n        with writer.as_default():\n          write_op = summary_ops.write('tag', 1.0)\n        summary_ops.set_step(2)\n        with self.cached_session() as sess:\n          sess.run(writer.init())\n          sess.run(write_op)\n          sess.run(write_op)\n          sess.run(writer.flush())\n      events = events_from_logdir(logdir)\n      self.assertEqual(3, len(events))\n      self.assertEqual(1, events[1].step)\n      # The step value will still be 1 because the value was captured at the\n      # time the graph was constructed.\n      self.assertEqual(1, events[2].step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepVariable_fromLegacyGraph(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.graph_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        mystep = variables.Variable(0, dtype=dtypes.int64)\n        summary_ops.set_step(mystep)\n        with writer.as_default():\n          write_op = summary_ops.write('tag', 1.0)\n        first_assign_op = mystep.assign_add(1)\n        second_assign_op = mystep.assign(10)\n        with self.cached_session() as sess:\n          sess.run(writer.init())\n          sess.run(mystep.initializer)\n          sess.run(write_op)\n          sess.run(first_assign_op)\n          sess.run(write_op)\n          sess.run(second_assign_op)\n          sess.run(write_op)\n          sess.run(writer.flush())\n      events = events_from_logdir(logdir)\n      self.assertEqual(4, len(events))\n      self.assertEqual(0, events[1].step)\n      self.assertEqual(1, events[2].step)\n      self.assertEqual(10, events[3].step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStep_fromAsDefault(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        with writer.as_default(step=1):\n          summary_ops.write('tag', 1.0)\n          with writer.as_default():\n            summary_ops.write('tag', 1.0)\n            with writer.as_default(step=2):\n              summary_ops.write('tag', 1.0)\n            summary_ops.write('tag', 1.0)\n            summary_ops.set_step(3)\n          summary_ops.write('tag', 1.0)\n      events = events_from_logdir(logdir)\n      self.assertListEqual([1, 1, 2, 1, 3], [e.step for e in events[1:]])\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepVariable_fromAsDefault(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        mystep = variables.Variable(1, dtype=dtypes.int64)\n        with writer.as_default(step=mystep):\n          summary_ops.write('tag', 1.0)\n          with writer.as_default():\n            mystep.assign(2)\n            summary_ops.write('tag', 1.0)\n            with writer.as_default(step=3):\n              summary_ops.write('tag', 1.0)\n            summary_ops.write('tag', 1.0)\n            mystep.assign(4)\n          summary_ops.write('tag', 1.0)\n      events = events_from_logdir(logdir)\n      self.assertListEqual([1, 2, 3, 2, 4], [e.step for e in events[1:]])\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStep_fromSetAsDefault(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        mystep = variables.Variable(1, dtype=dtypes.int64)\n        writer.set_as_default(step=mystep)\n        summary_ops.write('tag', 1.0)\n        mystep.assign(2)\n        summary_ops.write('tag', 1.0)\n        writer.set_as_default(step=3)\n        summary_ops.write('tag', 1.0)\n        writer.flush()\n      events = events_from_logdir(logdir)\n      self.assertListEqual([1, 2, 3], [e.step for e in events[1:]])\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_usingDefaultStepVariable_fromSetAsDefault(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_file_writer_v2(logdir)\n        writer.set_as_default(step=1)\n        summary_ops.write('tag', 1.0)\n        writer.set_as_default(step=2)\n        summary_ops.write('tag', 1.0)\n        writer.set_as_default()\n        summary_ops.write('tag', 1.0)\n        writer.flush()\n      events = events_from_logdir(logdir)\n      self.assertListEqual([1, 2, 2], [e.step for e in events[1:]])\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testWrite_recordIf_constant(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        self.assertTrue(summary_ops.write('default', 1, step=0))\n        with summary_ops.record_if(True):\n          self.assertTrue(summary_ops.write('set_on', 1, step=0))\n        with summary_ops.record_if(False):\n          self.assertFalse(summary_ops.write('set_off', 1, step=0))\n    events = events_from_logdir(logdir)\n    self.assertEqual(3, len(events))\n    self.assertEqual('default', events[1].summary.value[0].tag)\n    self.assertEqual('set_on', events[2].summary.value[0].tag)\n\n  def testWrite_recordIf_constant_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function\n      def f():\n        with writer.as_default():\n          # Use assertAllEqual instead of assertTrue since it works in a defun.\n          self.assertAllEqual(summary_ops.write('default', 1, step=0), True)\n          with summary_ops.record_if(True):\n            self.assertAllEqual(summary_ops.write('set_on', 1, step=0), True)\n          with summary_ops.record_if(False):\n            self.assertAllEqual(summary_ops.write('set_off', 1, step=0), False)\n      f()\n    events = events_from_logdir(logdir)\n    self.assertEqual(3, len(events))\n    self.assertEqual('default', events[1].summary.value[0].tag)\n    self.assertEqual('set_on', events[2].summary.value[0].tag)\n\n  def testWrite_recordIf_callable(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      step = variables.Variable(-1, dtype=dtypes.int64)\n      def record_fn():\n        step.assign_add(1)\n        return int(step % 2) == 0\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with summary_ops.record_if(record_fn):\n          self.assertTrue(summary_ops.write('tag', 1, step=step))\n          self.assertFalse(summary_ops.write('tag', 1, step=step))\n          self.assertTrue(summary_ops.write('tag', 1, step=step))\n          self.assertFalse(summary_ops.write('tag', 1, step=step))\n          self.assertTrue(summary_ops.write('tag', 1, step=step))\n    events = events_from_logdir(logdir)\n    self.assertEqual(4, len(events))\n    self.assertEqual(0, events[1].step)\n    self.assertEqual(2, events[2].step)\n    self.assertEqual(4, events[3].step)\n\n  def testWrite_recordIf_callable_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      step = variables.Variable(-1, dtype=dtypes.int64)\n      @def_function.function\n      def record_fn():\n        step.assign_add(1)\n        return math_ops.equal(step % 2, 0)\n      @def_function.function\n      def f():\n        with writer.as_default():\n          with summary_ops.record_if(record_fn):\n            return [\n                summary_ops.write('tag', 1, step=step),\n                summary_ops.write('tag', 1, step=step),\n                summary_ops.write('tag', 1, step=step)]\n      self.assertAllEqual(f(), [True, False, True])\n      self.assertAllEqual(f(), [False, True, False])\n    events = events_from_logdir(logdir)\n    self.assertEqual(4, len(events))\n    self.assertEqual(0, events[1].step)\n    self.assertEqual(2, events[2].step)\n    self.assertEqual(4, events[3].step)\n\n  def testWrite_recordIf_tensorInput_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function(input_signature=[\n          tensor_spec.TensorSpec(shape=[], dtype=dtypes.int64)])\n      def f(step):\n        with writer.as_default():\n          with summary_ops.record_if(math_ops.equal(step % 2, 0)):\n            return summary_ops.write('tag', 1, step=step)\n      self.assertTrue(f(0))\n      self.assertFalse(f(1))\n      self.assertTrue(f(2))\n      self.assertFalse(f(3))\n      self.assertTrue(f(4))\n    events = events_from_logdir(logdir)\n    self.assertEqual(4, len(events))\n    self.assertEqual(0, events[1].step)\n    self.assertEqual(2, events[2].step)\n    self.assertEqual(4, events[3].step)\n\n  def testWriteRawPb(self):\n    logdir = self.get_temp_dir()\n    pb = summary_pb2.Summary()\n    pb.value.add().simple_value = 42.0\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        output = summary_ops.write_raw_pb(pb.SerializeToString(), step=12)\n        self.assertTrue(output.numpy())\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    self.assertProtoEquals(pb, events[1].summary)\n\n  def testWriteRawPb_fromFunction(self):\n    logdir = self.get_temp_dir()\n    pb = summary_pb2.Summary()\n    pb.value.add().simple_value = 42.0\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function\n      def f():\n        with writer.as_default():\n          return summary_ops.write_raw_pb(pb.SerializeToString(), step=12)\n      output = f()\n      self.assertTrue(output.numpy())\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    self.assertProtoEquals(pb, events[1].summary)\n\n  def testWriteRawPb_multipleValues(self):\n    logdir = self.get_temp_dir()\n    pb1 = summary_pb2.Summary()\n    pb1.value.add().simple_value = 1.0\n    pb1.value.add().simple_value = 2.0\n    pb2 = summary_pb2.Summary()\n    pb2.value.add().simple_value = 3.0\n    pb3 = summary_pb2.Summary()\n    pb3.value.add().simple_value = 4.0\n    pb3.value.add().simple_value = 5.0\n    pb3.value.add().simple_value = 6.0\n    pbs = [pb.SerializeToString() for pb in (pb1, pb2, pb3)]\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        output = summary_ops.write_raw_pb(pbs, step=12)\n        self.assertTrue(output.numpy())\n    events = events_from_logdir(logdir)\n    self.assertEqual(2, len(events))\n    self.assertEqual(12, events[1].step)\n    expected_pb = summary_pb2.Summary()\n    for i in range(6):\n      expected_pb.value.add().simple_value = i + 1.0\n    self.assertProtoEquals(expected_pb, events[1].summary)\n\n  def testWriteRawPb_invalidValue(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with self.assertRaisesRegex(\n            errors.DataLossError,\n            'Bad tf.compat.v1.Summary binary proto tensor string'):\n          summary_ops.write_raw_pb('notaproto', step=12)\n\n  @test_util.also_run_as_tf_function\n  def testGetSetStep(self):\n    try:\n      self.assertIsNone(summary_ops.get_step())\n      summary_ops.set_step(1)\n      # Use assertAllEqual instead of assertEqual since it works in a defun.\n      self.assertAllEqual(1, summary_ops.get_step())\n      summary_ops.set_step(constant_op.constant(2))\n      self.assertAllEqual(2, summary_ops.get_step())\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  def testGetSetStep_variable(self):\n    with context.eager_mode():\n      try:\n        mystep = variables.Variable(0)\n        summary_ops.set_step(mystep)\n        self.assertAllEqual(0, summary_ops.get_step().read_value())\n        mystep.assign_add(1)\n        self.assertAllEqual(1, summary_ops.get_step().read_value())\n        # Check that set_step() properly maintains reference to variable.\n        del mystep\n        self.assertAllEqual(1, summary_ops.get_step().read_value())\n        summary_ops.get_step().assign_add(1)\n        self.assertAllEqual(2, summary_ops.get_step().read_value())\n      finally:\n        # Reset to default state for other tests.\n        summary_ops.set_step(None)\n\n  def testGetSetStep_variable_fromFunction(self):\n    with context.eager_mode():\n      try:\n        @def_function.function\n        def set_step(step):\n          summary_ops.set_step(step)\n          return summary_ops.get_step()\n        @def_function.function\n        def get_and_increment():\n          summary_ops.get_step().assign_add(1)\n          return summary_ops.get_step()\n        mystep = variables.Variable(0)\n        self.assertAllEqual(0, set_step(mystep))\n        self.assertAllEqual(0, summary_ops.get_step().read_value())\n        self.assertAllEqual(1, get_and_increment())\n        self.assertAllEqual(2, get_and_increment())\n        # Check that set_step() properly maintains reference to variable.\n        del mystep\n        self.assertAllEqual(3, get_and_increment())\n      finally:\n        # Reset to default state for other tests.\n        summary_ops.set_step(None)\n\n  @test_util.also_run_as_tf_function\n  def testSummaryScope(self):\n    with summary_ops.summary_scope('foo') as (tag, scope):\n      self.assertEqual('foo', tag)\n      self.assertEqual('foo/', scope)\n      with summary_ops.summary_scope('bar') as (tag, scope):\n        self.assertEqual('foo/bar', tag)\n        self.assertEqual('foo/bar/', scope)\n      with summary_ops.summary_scope('with/slash') as (tag, scope):\n        self.assertEqual('foo/with/slash', tag)\n        self.assertEqual('foo/with/slash/', scope)\n      with ops.name_scope(None, skip_on_eager=False):\n        with summary_ops.summary_scope('unnested') as (tag, scope):\n          self.assertEqual('unnested', tag)\n          self.assertEqual('unnested/', scope)\n\n  @test_util.also_run_as_tf_function\n  def testSummaryScope_defaultName(self):\n    with summary_ops.summary_scope(None) as (tag, scope):\n      self.assertEqual('summary', tag)\n      self.assertEqual('summary/', scope)\n    with summary_ops.summary_scope(None, 'backup') as (tag, scope):\n      self.assertEqual('backup', tag)\n      self.assertEqual('backup/', scope)\n\n  @test_util.also_run_as_tf_function\n  def testSummaryScope_handlesCharactersIllegalForScope(self):\n    with summary_ops.summary_scope('f?o?o') as (tag, scope):\n      self.assertEqual('f?o?o', tag)\n      self.assertEqual('foo/', scope)\n    # If all characters aren't legal for a scope name, use default name.\n    with summary_ops.summary_scope('???', 'backup') as (tag, scope):\n      self.assertEqual('???', tag)\n      self.assertEqual('backup/', scope)\n\n  @test_util.also_run_as_tf_function\n  def testSummaryScope_nameNotUniquifiedForTag(self):\n    constant_op.constant(0, name='foo')\n    with summary_ops.summary_scope('foo') as (tag, _):\n      self.assertEqual('foo', tag)\n    with summary_ops.summary_scope('foo') as (tag, _):\n      self.assertEqual('foo', tag)\n    with ops.name_scope('with', skip_on_eager=False):\n      constant_op.constant(0, name='slash')\n    with summary_ops.summary_scope('with/slash') as (tag, _):\n      self.assertEqual('with/slash', tag)\n\n  def testAllV2SummaryOps(self):\n    logdir = self.get_temp_dir()\n    def define_ops():\n      result = []\n      # TF 2.0 summary ops\n      result.append(summary_ops.write('write', 1, step=0))\n      result.append(summary_ops.write_raw_pb(b'', step=0, name='raw_pb'))\n      # TF 1.x tf.contrib.summary ops\n      result.append(summary_ops.generic('tensor', 1, step=1))\n      result.append(summary_ops.scalar('scalar', 2.0, step=1))\n      result.append(summary_ops.histogram('histogram', [1.0], step=1))\n      result.append(summary_ops.image('image', [[[[1.0]]]], step=1))\n      result.append(summary_ops.audio('audio', [[1.0]], 1.0, 1, step=1))\n      return result\n    with context.graph_mode():\n      ops_without_writer = define_ops()\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with summary_ops.record_if(True):\n          ops_recording_on = define_ops()\n        with summary_ops.record_if(False):\n          ops_recording_off = define_ops()\n      # We should be collecting all ops defined with a default writer present,\n      # regardless of whether recording was set on or off, but not those defined\n      # without a writer at all.\n      del ops_without_writer\n      expected_ops = ops_recording_on + ops_recording_off\n      self.assertCountEqual(expected_ops, summary_ops.all_v2_summary_ops())\n\n  def testShouldRecordSummaries_defaultState(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      self.assertAllEqual(False, summary_ops.should_record_summaries())\n      w = summary_ops.create_file_writer_v2(logdir)\n      self.assertAllEqual(False, summary_ops.should_record_summaries())\n      with w.as_default():\n        # Should be enabled only when default writer is registered.\n        self.assertAllEqual(True, summary_ops.should_record_summaries())\n      self.assertAllEqual(False, summary_ops.should_record_summaries())\n      with summary_ops.record_if(True):\n        # Should be disabled when no default writer, even with record_if(True).\n        self.assertAllEqual(False, summary_ops.should_record_summaries())\n\n  def testShouldRecordSummaries_constants(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        with summary_ops.record_if(True):\n          self.assertAllEqual(True, summary_ops.should_record_summaries())\n        with summary_ops.record_if(False):\n          self.assertAllEqual(False, summary_ops.should_record_summaries())\n          with summary_ops.record_if(True):\n            self.assertAllEqual(True, summary_ops.should_record_summaries())\n\n  def testShouldRecordSummaries_variable(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        cond = variables.Variable(False)\n        with summary_ops.record_if(cond):\n          self.assertAllEqual(False, summary_ops.should_record_summaries())\n          cond.assign(True)\n          self.assertAllEqual(True, summary_ops.should_record_summaries())\n\n  def testShouldRecordSummaries_callable(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        cond_box = [False]\n        cond = lambda: cond_box[0]\n        with summary_ops.record_if(cond):\n          self.assertAllEqual(False, summary_ops.should_record_summaries())\n          cond_box[0] = True\n          self.assertAllEqual(True, summary_ops.should_record_summaries())\n\n  def testShouldRecordSummaries_fromFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      @def_function.function(input_signature=[\n          tensor_spec.TensorSpec(shape=[], dtype=dtypes.bool)])\n      def f(cond):\n        results = []\n        results.append(summary_ops.should_record_summaries())\n        with writer.as_default():\n          results.append(summary_ops.should_record_summaries())\n          with summary_ops.record_if(False):\n            results.append(summary_ops.should_record_summaries())\n          with summary_ops.record_if(cond):\n            results.append(summary_ops.should_record_summaries())\n        return results\n      self.assertAllEqual([False, True, False, True], f(True))\n      self.assertAllEqual([False, True, False, False], f(False))\n\n  def testHasDefaultWriter_checkWriter(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with self.subTest(name='has_writer'):\n        with summary_ops.create_file_writer_v2(logdir).as_default():\n          self.assertTrue(summary_ops.has_default_writer())\n      with self.subTest(name='no_writer'):\n        self.assertFalse(summary_ops.has_default_writer())\n\n\nclass SummaryWriterTest(test_util.TensorFlowTestCase):\n\n  def testCreate_withInitAndClose(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(\n          logdir, max_queue=1000, flush_millis=1000000)\n      get_total = lambda: len(events_from_logdir(logdir))\n      self.assertEqual(1, get_total())  # file_version Event\n      # Calling init() again while writer is open has no effect\n      writer.init()\n      self.assertEqual(1, get_total())\n      with writer.as_default():\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(1, get_total())\n        # Calling .close() should do an implicit flush\n        writer.close()\n        self.assertEqual(2, get_total())\n\n  def testCreate_fromFunction(self):\n    logdir = self.get_temp_dir()\n    @def_function.function\n    def f():\n      # Returned SummaryWriter must be stored in a non-local variable so it\n      # lives throughout the function execution.\n      if not hasattr(f, 'writer'):\n        f.writer = summary_ops.create_file_writer_v2(logdir)\n    with context.eager_mode():\n      f()\n    event_files = gfile.Glob(os.path.join(logdir, '*'))\n    self.assertEqual(1, len(event_files))\n\n  def testCreate_graphTensorArgument_raisesError(self):\n    logdir = self.get_temp_dir()\n    with context.graph_mode():\n      logdir_tensor = constant_op.constant(logdir)\n    with context.eager_mode():\n      with self.assertRaisesRegex(\n          ValueError, 'Invalid graph Tensor argument.*logdir'):\n        summary_ops.create_file_writer_v2(logdir_tensor)\n    self.assertEmpty(gfile.Glob(os.path.join(logdir, '*')))\n\n  def testCreate_fromFunction_graphTensorArgument_raisesError(self):\n    logdir = self.get_temp_dir()\n    @def_function.function\n    def f():\n      summary_ops.create_file_writer_v2(constant_op.constant(logdir))\n    with context.eager_mode():\n      with self.assertRaisesRegex(\n          ValueError, 'Invalid graph Tensor argument.*logdir'):\n        f()\n    self.assertEmpty(gfile.Glob(os.path.join(logdir, '*')))\n\n  def testCreate_fromFunction_unpersistedResource_raisesError(self):\n    logdir = self.get_temp_dir()\n    @def_function.function\n    def f():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        pass  # Calling .as_default() is enough to indicate use.\n    with context.eager_mode():\n      # TODO(nickfelt): change this to a better error\n      with self.assertRaisesRegex(\n          errors.NotFoundError, 'Resource.*does not exist'):\n        f()\n    # Even though we didn't use it, an event file will have been created.\n    self.assertEqual(1, len(gfile.Glob(os.path.join(logdir, '*'))))\n\n  def testCreate_immediateSetAsDefault_retainsReference(self):\n    logdir = self.get_temp_dir()\n    try:\n      with context.eager_mode():\n        summary_ops.create_file_writer_v2(logdir).set_as_default()\n        summary_ops.flush()\n    finally:\n      # Ensure we clean up no matter how the test executes.\n      summary_ops._summary_state.writer = None  # pylint: disable=protected-access\n\n  def testCreate_immediateAsDefault_retainsReference(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(logdir).as_default():\n        summary_ops.flush()\n\n  def testCreate_avoidsFilenameCollision(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      for _ in range(10):\n        summary_ops.create_file_writer_v2(logdir)\n    event_files = gfile.Glob(os.path.join(logdir, '*'))\n    self.assertLen(event_files, 10)\n\n  def testCreate_graphMode_avoidsFilenameCollision(self):\n    logdir = self.get_temp_dir()\n    with context.graph_mode(), ops.Graph().as_default():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      with self.cached_session() as sess:\n        for _ in range(10):\n          sess.run(writer.init())\n          sess.run(writer.close())\n    event_files = gfile.Glob(os.path.join(logdir, '*'))\n    self.assertLen(event_files, 10)\n\n  def testNoSharing(self):\n    # Two writers with the same logdir should not share state.\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer1 = summary_ops.create_file_writer_v2(logdir)\n      with writer1.as_default():\n        summary_ops.write('tag', 1, step=1)\n      event_files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(1, len(event_files))\n      file1 = event_files[0]\n\n      writer2 = summary_ops.create_file_writer_v2(logdir)\n      with writer2.as_default():\n        summary_ops.write('tag', 1, step=2)\n      event_files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(2, len(event_files))\n      event_files.remove(file1)\n      file2 = event_files[0]\n\n      # Extra writes to ensure interleaved usage works.\n      with writer1.as_default():\n        summary_ops.write('tag', 1, step=1)\n      with writer2.as_default():\n        summary_ops.write('tag', 1, step=2)\n\n    events = iter(events_from_file(file1))\n    self.assertEqual('brain.Event:2', next(events).file_version)\n    self.assertEqual(1, next(events).step)\n    self.assertEqual(1, next(events).step)\n    self.assertRaises(StopIteration, lambda: next(events))\n    events = iter(events_from_file(file2))\n    self.assertEqual('brain.Event:2', next(events).file_version)\n    self.assertEqual(2, next(events).step)\n    self.assertEqual(2, next(events).step)\n    self.assertRaises(StopIteration, lambda: next(events))\n\n  def testNoSharing_fromFunction(self):\n    logdir = self.get_temp_dir()\n    @def_function.function\n    def f1():\n      if not hasattr(f1, 'writer'):\n        f1.writer = summary_ops.create_file_writer_v2(logdir)\n      with f1.writer.as_default():\n        summary_ops.write('tag', 1, step=1)\n    @def_function.function\n    def f2():\n      if not hasattr(f2, 'writer'):\n        f2.writer = summary_ops.create_file_writer_v2(logdir)\n      with f2.writer.as_default():\n        summary_ops.write('tag', 1, step=2)\n    with context.eager_mode():\n      f1()\n      event_files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(1, len(event_files))\n      file1 = event_files[0]\n\n      f2()\n      event_files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(2, len(event_files))\n      event_files.remove(file1)\n      file2 = event_files[0]\n\n      # Extra writes to ensure interleaved usage works.\n      f1()\n      f2()\n\n    events = iter(events_from_file(file1))\n    self.assertEqual('brain.Event:2', next(events).file_version)\n    self.assertEqual(1, next(events).step)\n    self.assertEqual(1, next(events).step)\n    self.assertRaises(StopIteration, lambda: next(events))\n    events = iter(events_from_file(file2))\n    self.assertEqual('brain.Event:2', next(events).file_version)\n    self.assertEqual(2, next(events).step)\n    self.assertEqual(2, next(events).step)\n    self.assertRaises(StopIteration, lambda: next(events))\n\n  def testMaxQueue(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      with summary_ops.create_file_writer_v2(\n          logdir, max_queue=1, flush_millis=999999).as_default():\n        get_total = lambda: len(events_from_logdir(logdir))\n        # Note: First tf.compat.v1.Event is always file_version.\n        self.assertEqual(1, get_total())\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(1, get_total())\n        # Should flush after second summary since max_queue = 1\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(3, get_total())\n\n  def testWriterFlush(self):\n    logdir = self.get_temp_dir()\n    get_total = lambda: len(events_from_logdir(logdir))\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(\n          logdir, max_queue=1000, flush_millis=1000000)\n      self.assertEqual(1, get_total())  # file_version Event\n      with writer.as_default():\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(1, get_total())\n        writer.flush()\n        self.assertEqual(2, get_total())\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(2, get_total())\n      # Exiting the \"as_default()\" should do an implicit flush\n      self.assertEqual(3, get_total())\n\n  def testFlushFunction(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(\n          logdir, max_queue=999999, flush_millis=999999)\n      with writer.as_default():\n        get_total = lambda: len(events_from_logdir(logdir))\n        # Note: First tf.compat.v1.Event is always file_version.\n        self.assertEqual(1, get_total())\n        summary_ops.write('tag', 1, step=0)\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(1, get_total())\n        summary_ops.flush()\n        self.assertEqual(3, get_total())\n        # Test \"writer\" parameter\n        summary_ops.write('tag', 1, step=0)\n        self.assertEqual(3, get_total())\n        summary_ops.flush(writer=writer)\n        self.assertEqual(4, get_total())\n\n  # Regression test for b/228097117.\n  def testFlushFunction_disallowsInvalidWriterInput(self):\n    with context.eager_mode():\n      with self.assertRaisesRegex(ValueError, 'Invalid argument to flush'):\n        summary_ops.flush(writer=())\n\n  @test_util.assert_no_new_tensors\n  def testNoMemoryLeak_graphMode(self):\n    logdir = self.get_temp_dir()\n    with context.graph_mode(), ops.Graph().as_default():\n      summary_ops.create_file_writer_v2(logdir)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testNoMemoryLeak_eagerMode(self):\n    logdir = self.get_temp_dir()\n    with summary_ops.create_file_writer_v2(logdir).as_default():\n      summary_ops.write('tag', 1, step=0)\n\n  def testClose_preventsLaterUse(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      writer.close()\n      writer.close()  # redundant close() is a no-op\n      writer.flush()  # redundant flush() is a no-op\n      with self.assertRaisesRegex(RuntimeError, 'already closed'):\n        writer.init()\n      with self.assertRaisesRegex(RuntimeError, 'already closed'):\n        with writer.as_default():\n          self.fail('should not get here')\n      with self.assertRaisesRegex(RuntimeError, 'already closed'):\n        writer.set_as_default()\n\n  def testClose_closesOpenFile(self):\n    try:\n      import psutil  # pylint: disable=g-import-not-at-top\n    except ImportError:\n      raise unittest.SkipTest('test requires psutil')\n    proc = psutil.Process()\n    get_open_filenames = lambda: set(info[0] for info in proc.open_files())\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(1, len(files))\n      eventfile = files[0]\n      self.assertIn(eventfile, get_open_filenames())\n      writer.close()\n      self.assertNotIn(eventfile, get_open_filenames())\n\n  def testDereference_closesOpenFile(self):\n    try:\n      import psutil  # pylint: disable=g-import-not-at-top\n    except ImportError:\n      raise unittest.SkipTest('test requires psutil')\n    proc = psutil.Process()\n    get_open_filenames = lambda: set(info[0] for info in proc.open_files())\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      files = gfile.Glob(os.path.join(logdir, '*'))\n      self.assertEqual(1, len(files))\n      eventfile = files[0]\n      self.assertIn(eventfile, get_open_filenames())\n      del writer\n      self.assertNotIn(eventfile, get_open_filenames())\n\n\nclass SummaryWriterSavedModelTest(test_util.TensorFlowTestCase):\n\n  def testWriter_savedAsModuleProperty_loadInEagerMode(self):\n    with context.eager_mode():\n      class Model(module.Module):\n\n        def __init__(self, model_dir):\n          self._writer = summary_ops.create_file_writer_v2(\n              model_dir, experimental_trackable=True)\n\n        @def_function.function(input_signature=[\n            tensor_spec.TensorSpec(shape=[], dtype=dtypes.int64)\n        ])\n        def train(self, step):\n          with self._writer.as_default():\n            summary_ops.write('tag', 'foo', step=step)\n          return constant_op.constant(0)\n\n      logdir = self.get_temp_dir()\n      to_export = Model(logdir)\n      pre_save_files = set(events_from_multifile_logdir(logdir))\n      export_dir = os.path.join(logdir, 'export')\n      saved_model_save.save(\n          to_export, export_dir, signatures={'train': to_export.train})\n\n    # Reset context to ensure we don't share any resources with saving code.\n    context._reset_context()  # pylint: disable=protected-access\n    with context.eager_mode():\n      restored = saved_model_load.load(export_dir)\n      restored.train(1)\n      restored.train(2)\n      post_restore_files = set(events_from_multifile_logdir(logdir))\n      restored2 = saved_model_load.load(export_dir)\n      restored2.train(3)\n      restored2.train(4)\n      files_to_events = events_from_multifile_logdir(logdir)\n      post_restore2_files = set(files_to_events)\n      self.assertLen(files_to_events, 3)\n      def unwrap_singleton(iterable):\n        self.assertLen(iterable, 1)\n        return next(iter(iterable))\n      restore_file = unwrap_singleton(post_restore_files - pre_save_files)\n      restore2_file = unwrap_singleton(post_restore2_files - post_restore_files)\n      restore_events = files_to_events[restore_file]\n      restore2_events = files_to_events[restore2_file]\n      self.assertLen(restore_events, 3)\n      self.assertEqual(1, restore_events[1].step)\n      self.assertEqual(2, restore_events[2].step)\n      self.assertLen(restore2_events, 3)\n      self.assertEqual(3, restore2_events[1].step)\n      self.assertEqual(4, restore2_events[2].step)\n\n  def testWriter_savedAsModuleProperty_loadInGraphMode(self):\n    with context.eager_mode():\n\n      class Model(module.Module):\n\n        def __init__(self, model_dir):\n          self._writer = summary_ops.create_file_writer_v2(\n              model_dir, experimental_trackable=True)\n\n        @def_function.function(input_signature=[\n            tensor_spec.TensorSpec(shape=[], dtype=dtypes.int64)\n        ])\n        def train(self, step):\n          with self._writer.as_default():\n            summary_ops.write('tag', 'foo', step=step)\n          return constant_op.constant(0)\n\n      logdir = self.get_temp_dir()\n      to_export = Model(logdir)\n      pre_save_files = set(events_from_multifile_logdir(logdir))\n      export_dir = os.path.join(logdir, 'export')\n      saved_model_save.save(\n          to_export, export_dir, signatures={'train': to_export.train})\n\n    # Reset context to ensure we don't share any resources with saving code.\n    context._reset_context()  # pylint: disable=protected-access\n\n    def load_and_run_model(sess, input_values):\n      \"\"\"Load and run the SavedModel signature in the TF 1.x style.\"\"\"\n      model = saved_model_loader.load(sess, [tag_constants.SERVING], export_dir)\n      signature = model.signature_def['train']\n      inputs = list(signature.inputs.values())\n      assert len(inputs) == 1, inputs\n      outputs = list(signature.outputs.values())\n      assert len(outputs) == 1, outputs\n      input_tensor = sess.graph.get_tensor_by_name(inputs[0].name)\n      output_tensor = sess.graph.get_tensor_by_name(outputs[0].name)\n      for v in input_values:\n        sess.run(output_tensor, feed_dict={input_tensor: v})\n\n    with context.graph_mode(), ops.Graph().as_default():\n      # Since writer shared_name is fixed, within a single session, all loads of\n      # this SavedModel will refer to a single writer resouce, so it will be\n      # initialized only once and write to a single file.\n      with self.session() as sess:\n        load_and_run_model(sess, [1, 2])\n        load_and_run_model(sess, [3, 4])\n      post_restore_files = set(events_from_multifile_logdir(logdir))\n      # New session will recreate the resource and write to a second file.\n      with self.session() as sess:\n        load_and_run_model(sess, [5, 6])\n      files_to_events = events_from_multifile_logdir(logdir)\n      post_restore2_files = set(files_to_events)\n\n    self.assertLen(files_to_events, 3)\n    def unwrap_singleton(iterable):\n      self.assertLen(iterable, 1)\n      return next(iter(iterable))\n    restore_file = unwrap_singleton(post_restore_files - pre_save_files)\n    restore2_file = unwrap_singleton(post_restore2_files - post_restore_files)\n    restore_events = files_to_events[restore_file]\n    restore2_events = files_to_events[restore2_file]\n    self.assertLen(restore_events, 5)\n    self.assertEqual(1, restore_events[1].step)\n    self.assertEqual(2, restore_events[2].step)\n    self.assertEqual(3, restore_events[3].step)\n    self.assertEqual(4, restore_events[4].step)\n    self.assertLen(restore2_events, 3)\n    self.assertEqual(5, restore2_events[1].step)\n    self.assertEqual(6, restore2_events[2].step)\n\n\nclass NoopWriterTest(test_util.TensorFlowTestCase):\n\n  def testNoopWriter_doesNothing(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_noop_writer()\n      writer.init()\n      with writer.as_default():\n        result = summary_ops.write('test', 1.0, step=0)\n      writer.flush()\n      writer.close()\n    self.assertFalse(result)  # Should have found no active writer\n    files = gfile.Glob(os.path.join(logdir, '*'))\n    self.assertLen(files, 0)\n\n  def testNoopWriter_asNestedContext_isTransparent(self):\n    logdir = self.get_temp_dir()\n    with context.eager_mode():\n      writer = summary_ops.create_file_writer_v2(logdir)\n      noop_writer = summary_ops.create_noop_writer()\n      with writer.as_default():\n        result1 = summary_ops.write('first', 1.0, step=0)\n        with noop_writer.as_default():\n          result2 = summary_ops.write('second', 1.0, step=0)\n        result3 = summary_ops.write('third', 1.0, step=0)\n    # All ops should have written, including the one inside the no-op writer,\n    # since it doesn't actively *disable* writing - it just behaves as if that\n    # entire `with` block wasn't there at all.\n    self.assertAllEqual([result1, result2, result3], [True, True, True])\n\n  def testNoopWriter_setAsDefault(self):\n    try:\n      with context.eager_mode():\n        writer = summary_ops.create_noop_writer()\n        writer.set_as_default()\n        result = summary_ops.write('test', 1.0, step=0)\n      self.assertFalse(result)  # Should have found no active writer\n    finally:\n      # Ensure we clean up no matter how the test executes.\n      summary_ops._summary_state.writer = None  # pylint: disable=protected-access\n\n\nclass SummaryOpsTest(test_util.TensorFlowTestCase):\n\n  def tearDown(self):\n    summary_ops.trace_off()\n    super(SummaryOpsTest, self).tearDown()\n\n  def exec_summary_op(self, summary_op_fn):\n    assert context.executing_eagerly()\n    logdir = self.get_temp_dir()\n    writer = summary_ops.create_file_writer_v2(logdir)\n    with writer.as_default():\n      summary_op_fn()\n    writer.close()\n    events = events_from_logdir(logdir)\n    return events[1]\n\n  def run_metadata(self, *args, **kwargs):\n    assert context.executing_eagerly()\n    logdir = self.get_temp_dir()\n    writer = summary_ops.create_file_writer_v2(logdir)\n    with writer.as_default():\n      summary_ops.run_metadata(*args, **kwargs)\n    writer.close()\n    events = events_from_logdir(logdir)\n    return events[1]\n\n  def run_metadata_graphs(self, *args, **kwargs):\n    assert context.executing_eagerly()\n    logdir = self.get_temp_dir()\n    writer = summary_ops.create_file_writer_v2(logdir)\n    with writer.as_default():\n      summary_ops.run_metadata_graphs(*args, **kwargs)\n    writer.close()\n    events = events_from_logdir(logdir)\n    return events[1]\n\n  def create_run_metadata(self):\n    step_stats = step_stats_pb2.StepStats(dev_stats=[\n        step_stats_pb2.DeviceStepStats(\n            device='cpu:0',\n            node_stats=[step_stats_pb2.NodeExecStats(node_name='hello')])\n    ])\n    return config_pb2.RunMetadata(\n        function_graphs=[\n            config_pb2.RunMetadata.FunctionGraphs(\n                pre_optimization_graph=graph_pb2.GraphDef(\n                    node=[node_def_pb2.NodeDef(name='foo')]))\n        ],\n        step_stats=step_stats)\n\n  def run_trace(self, f, step=1):\n    assert context.executing_eagerly()\n    logdir = self.get_temp_dir()\n    writer = summary_ops.create_file_writer_v2(logdir)\n    summary_ops.trace_on(graph=True, profiler=False)\n    with writer.as_default():\n      f()\n      summary_ops.trace_export(name='foo', step=step)\n    writer.close()\n    events = events_from_logdir(logdir)\n    return events[1]\n\n  @test_util.run_v2_only\n  def testRunMetadata_usesNameAsTag(self):\n    meta = config_pb2.RunMetadata()\n\n    with ops.name_scope('foo', skip_on_eager=False):\n      event = self.run_metadata(name='my_name', data=meta, step=1)\n      first_val = event.summary.value[0]\n\n    self.assertEqual('foo/my_name', first_val.tag)\n\n  @test_util.run_v2_only\n  def testRunMetadata_summaryMetadata(self):\n    expected_summary_metadata = \"\"\"\n      plugin_data {\n        plugin_name: \"graph_run_metadata\"\n        content: \"1\"\n      }\n    \"\"\"\n    meta = config_pb2.RunMetadata()\n    event = self.run_metadata(name='my_name', data=meta, step=1)\n    actual_summary_metadata = event.summary.value[0].metadata\n    self.assertProtoEquals(expected_summary_metadata, actual_summary_metadata)\n\n  @test_util.run_v2_only\n  def testRunMetadata_wholeRunMetadata(self):\n    expected_run_metadata = \"\"\"\n      step_stats {\n        dev_stats {\n          device: \"cpu:0\"\n          node_stats {\n            node_name: \"hello\"\n          }\n        }\n      }\n      function_graphs {\n        pre_optimization_graph {\n          node {\n            name: \"foo\"\n          }\n        }\n      }\n    \"\"\"\n    meta = self.create_run_metadata()\n    event = self.run_metadata(name='my_name', data=meta, step=1)\n    first_val = event.summary.value[0]\n\n    actual_run_metadata = config_pb2.RunMetadata.FromString(\n        first_val.tensor.string_val[0])\n    self.assertProtoEquals(expected_run_metadata, actual_run_metadata)\n\n  @test_util.run_v2_only\n  def testRunMetadata_usesDefaultStep(self):\n    meta = config_pb2.RunMetadata()\n    try:\n      summary_ops.set_step(42)\n      event = self.run_metadata(name='my_name', data=meta)\n      self.assertEqual(42, event.step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  @test_util.run_v2_only\n  def testRunMetadataGraph_usesNameAsTag(self):\n    meta = config_pb2.RunMetadata()\n\n    with ops.name_scope('foo', skip_on_eager=False):\n      event = self.run_metadata_graphs(name='my_name', data=meta, step=1)\n      first_val = event.summary.value[0]\n\n    self.assertEqual('foo/my_name', first_val.tag)\n\n  @test_util.run_v2_only\n  def testRunMetadataGraph_summaryMetadata(self):\n    expected_summary_metadata = \"\"\"\n      plugin_data {\n        plugin_name: \"graph_run_metadata_graph\"\n        content: \"1\"\n      }\n    \"\"\"\n    meta = config_pb2.RunMetadata()\n    event = self.run_metadata_graphs(name='my_name', data=meta, step=1)\n    actual_summary_metadata = event.summary.value[0].metadata\n    self.assertProtoEquals(expected_summary_metadata, actual_summary_metadata)\n\n  @test_util.run_v2_only\n  def testRunMetadataGraph_runMetadataFragment(self):\n    expected_run_metadata = \"\"\"\n      function_graphs {\n        pre_optimization_graph {\n          node {\n            name: \"foo\"\n          }\n        }\n      }\n    \"\"\"\n    meta = self.create_run_metadata()\n\n    event = self.run_metadata_graphs(name='my_name', data=meta, step=1)\n    first_val = event.summary.value[0]\n\n    actual_run_metadata = config_pb2.RunMetadata.FromString(\n        first_val.tensor.string_val[0])\n    self.assertProtoEquals(expected_run_metadata, actual_run_metadata)\n\n  @test_util.run_v2_only\n  def testRunMetadataGraph_usesDefaultStep(self):\n    meta = config_pb2.RunMetadata()\n    try:\n      summary_ops.set_step(42)\n      event = self.run_metadata_graphs(name='my_name', data=meta)\n      self.assertEqual(42, event.step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  @test_util.run_v2_only\n  def testTrace(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    event = self.run_trace(f)\n\n    first_val = event.summary.value[0]\n    actual_run_metadata = config_pb2.RunMetadata.FromString(\n        first_val.tensor.string_val[0])\n\n    # Content of function_graphs is large and, for instance, device can change.\n    self.assertTrue(hasattr(actual_run_metadata, 'function_graphs'))\n\n  @test_util.run_v2_only\n  def testTrace_cannotEnableTraceInFunction(self):\n\n    @def_function.function\n    def f():\n      summary_ops.trace_on(graph=True, profiler=False)\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    with test.mock.patch.object(logging, 'warn') as mock_log:\n      f()\n      self.assertRegex(\n          str(mock_log.call_args), 'Cannot enable trace inside a tf.function.')\n\n  @test_util.run_v2_only\n  def testTrace_cannotEnableTraceInGraphMode(self):\n    with test.mock.patch.object(logging, 'warn') as mock_log:\n      with context.graph_mode():\n        summary_ops.trace_on(graph=True, profiler=False)\n      self.assertRegex(\n          str(mock_log.call_args), 'Must enable trace in eager mode.')\n\n  @test_util.run_v2_only\n  def testTrace_cannotExportTraceWithoutTrace(self):\n    with six.assertRaisesRegex(self, ValueError,\n                               'Must enable trace before export.'):\n      summary_ops.trace_export(name='foo', step=1)\n\n  @test_util.run_v2_only\n  def testTrace_cannotExportTraceInFunction(self):\n    summary_ops.trace_on(graph=True, profiler=False)\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      summary_ops.trace_export(name='foo', step=1)\n      return x**y\n\n    with test.mock.patch.object(logging, 'warn') as mock_log:\n      f()\n      self.assertRegex(\n          str(mock_log.call_args), 'Cannot export trace inside a tf.function.')\n\n  @test_util.run_v2_only\n  def testTrace_cannotExportTraceInGraphMode(self):\n    with test.mock.patch.object(logging, 'warn') as mock_log:\n      with context.graph_mode():\n        summary_ops.trace_export(name='foo', step=1)\n      self.assertRegex(\n          str(mock_log.call_args),\n          'Can only export trace while executing eagerly.')\n\n  @test_util.run_v2_only\n  def testTrace_usesDefaultStep(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    try:\n      summary_ops.set_step(42)\n      event = self.run_trace(f, step=None)\n      self.assertEqual(42, event.step)\n    finally:\n      # Reset to default state for other tests.\n      summary_ops.set_step(None)\n\n  @test_util.run_v2_only\n  def testTrace_withProfiler(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    assert context.executing_eagerly()\n    logdir = self.get_temp_dir()\n    writer = summary_ops.create_file_writer_v2(logdir)\n    summary_ops.trace_on(graph=True, profiler=True)\n    profiler_outdir = self.get_temp_dir()\n    with writer.as_default():\n      f()\n      summary_ops.trace_export(\n          name='foo', step=1, profiler_outdir=profiler_outdir)\n    writer.close()\n\n  @test_util.run_v2_only\n  def testGraph_graph(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    def summary_op_fn():\n      summary_ops.graph(f.get_concrete_function().graph)\n\n    event = self.exec_summary_op(summary_op_fn)\n    self.assertIsNotNone(event.graph_def)\n\n  @test_util.run_v2_only\n  def testGraph_graphDef(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    def summary_op_fn():\n      summary_ops.graph(f.get_concrete_function().graph.as_graph_def())\n\n    event = self.exec_summary_op(summary_op_fn)\n    self.assertIsNotNone(event.graph_def)\n\n  @test_util.run_v2_only\n  def testGraph_invalidData(self):\n    def summary_op_fn():\n      summary_ops.graph('hello')\n\n    with self.assertRaisesRegex(\n        ValueError,\n        r'\\'graph_data\\' is not tf.Graph or tf.compat.v1.GraphDef',\n    ):\n      self.exec_summary_op(summary_op_fn)\n\n  @test_util.run_v2_only\n  def testGraph_fromGraphMode(self):\n\n    @def_function.function\n    def f():\n      x = constant_op.constant(2)\n      y = constant_op.constant(3)\n      return x**y\n\n    @def_function.function\n    def g(graph):\n      summary_ops.graph(graph)\n\n    def summary_op_fn():\n      graph_def = f.get_concrete_function().graph.as_graph_def(add_shapes=True)\n      func_graph = constant_op.constant(graph_def.SerializeToString())\n      g(func_graph)\n\n    with self.assertRaisesRegex(\n        ValueError,\n        r'graph\\(\\) cannot be invoked inside a graph context.',\n    ):\n      self.exec_summary_op(summary_op_fn)\n\n\ndef events_from_file(filepath):\n  \"\"\"Returns all events in a single event file.\n\n  Args:\n    filepath: Path to the event file.\n\n  Returns:\n    A list of all tf.Event protos in the event file.\n  \"\"\"\n  records = list(tf_record.tf_record_iterator(filepath))\n  result = []\n  for r in records:\n    event = event_pb2.Event()\n    event.ParseFromString(r)\n    result.append(event)\n  return result\n\n\ndef events_from_logdir(logdir):\n  \"\"\"Returns all events in the single eventfile in logdir.\n\n  Args:\n    logdir: The directory in which the single event file is sought.\n\n  Returns:\n    A list of all tf.Event protos from the single event file.\n\n  Raises:\n    AssertionError: If logdir does not contain exactly one file.\n  \"\"\"\n  assert gfile.Exists(logdir)\n  files = gfile.ListDirectory(logdir)\n  assert len(files) == 1, 'Found not exactly one file in logdir: %s' % files\n  return events_from_file(os.path.join(logdir, files[0]))\n\n\ndef events_from_multifile_logdir(logdir):\n  \"\"\"Returns map of filename to events for all `tfevents` files in the logdir.\n\n  Args:\n    logdir: The directory from which to load events.\n\n  Returns:\n    A dict mapping from relative filenames to lists of tf.Event protos.\n\n  Raises:\n    AssertionError: If logdir does not contain exactly one file.\n  \"\"\"\n  assert gfile.Exists(logdir)\n  files = [file for file in gfile.ListDirectory(logdir) if 'tfevents' in file]\n  return {file: events_from_file(os.path.join(logdir, file)) for file in files}\n\n\ndef to_numpy(summary_value):\n  return tensor_util.MakeNdarray(summary_value.tensor)\n\n\nif __name__ == '__main__':\n  test.main()"