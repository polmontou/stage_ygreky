"/* Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#include <stdint.h>\n\n#include <initializer_list>\n#include <string>\n#include <vector>\n\n#include <gmock/gmock.h>\n#include <gtest/gtest.h>\n#include \"flatbuffers/flatbuffers.h\"  // from @flatbuffers\n#include \"tensorflow/lite/kernels/test_util.h\"\n#include \"tensorflow/lite/schema/schema_generated.h\"\n#include \"tensorflow/lite/string_type.h\"\n\nnamespace tflite {\nnamespace {\n\nusing ::testing::ElementsAreArray;\n\nclass GatherNdOpModel : public SingleOpModel {\n public:\n  GatherNdOpModel(const TensorData& params, const TensorData& indices) {\n    params_ = AddInput(params);\n    indices_ = AddInput(indices);\n    output_ = AddOutput(params.type);\n    SetBuiltinOp(BuiltinOperator_GATHER_ND, BuiltinOptions_GatherNdOptions,\n                 CreateGatherNdOptions(builder_).Union());\n    BuildInterpreter({GetShape(params_), GetShape(indices_)});\n  }\n\n  template <typename T>\n  void SetInput(std::initializer_list<T> data) {\n    PopulateTensor<T>(params_, data);\n  }\n\n  template <typename T>\n  void SetPositions(std::initializer_list<T> data) {\n    PopulateTensor<T>(indices_, data);\n  }\n\n  template <typename T>\n  std::vector<T> GetOutput() {\n    return ExtractVector<T>(output_);\n  }\n\n  std::vector<int> GetOutputShape() { return GetTensorShape(output_); }\n\n protected:\n  int params_;\n  int indices_;\n  int output_;\n};\n\nTEST(GatherNdOpTest, ElementIndexingIntoMatrix) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({0, 0, 1, 1});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({1.1, 2.2}));\n}\n\nTEST(GatherNdOpTest, ErrorOnOutOfBoundsTooLarge) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({0, 0, 2, 0});\n  EXPECT_EQ(m.Invoke(), kTfLiteError);\n  m.SetPositions<int32_t>({0, 0, 1, 2});\n  EXPECT_EQ(m.Invoke(), kTfLiteError);\n}\n\nTEST(GatherNdOpTest, ErrorOnOutOfBoundsNegative) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({1, -1, 1, 1});\n  EXPECT_EQ(m.Invoke(), kTfLiteError);\n}\n\nTEST(GatherNdOpTest, SliceIndexingIntoMatrix) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}}, {TensorType_INT32, {2, 1}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({2.1, 2.2, 1.1, 1.2}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoMatrix1) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}},\n                    {TensorType_INT32, {2, 1, 1}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({2.1, 2.2, 1.1, 1.2}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoMatrix2) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}},\n                    {TensorType_INT32, {2, 1, 2}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({0, 0, 1, 1});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({1.1, 2.2}));\n}\n\nTEST(GatherNdOpTest, DuplicateIndexingIntoMatrix) {\n  GatherNdOpModel m({TensorType_FLOAT32, {2, 2}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, 1.2, 2.1, 2.2});\n  m.SetPositions<int32_t>({0, 0, 0, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({1.1, 1.1}));\n}\n\nTEST(GatherNdOpTest, ElementIndexingIntoRank3Tensor) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {1, 2, 3}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 0, 1, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({-1.2, -4.1}));\n}\n\nTEST(GatherNdOpTest, SliceIndexingIntoRank3Tensor) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 1}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 2});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({1.1, -1.2, 1.3, -2.1, 2.2, 2.3, 5.1, -5.2, 5.3,\n                                6.1, -6.2, 6.3}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoRank3Tensor1) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 1, 3}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 0, 1, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({-1.2, -4.1}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoRank3Tensor2) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 1, 1}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({3.1, 3.2, -3.3, -4.1, -4.2, 4.3, 1.1, -1.2, 1.3,\n                                -2.1, 2.2, 2.3}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoRank3Tensor3) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 2, 2}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 1, 1, 0, 0, 0, 2, 1});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({-2.1, 2.2, 2.3, 3.1, 3.2, -3.3, 1.1, -1.2, 1.3,\n                                6.1, -6.2, 6.3}));\n}\n\nTEST(GatherNdOpTest, BatchedIndexingIntoRank3Tensor4) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 2, 3}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 0, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(), ElementsAreArray({-1.2, 3.2, 4.3, 6.3}));\n}\n\nTEST(GatherNdOpTest, DuplicateIndexingIntoRank3Tensor) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 1, 0, 1});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({-2.1, 2.2, 2.3, -2.1, 2.2, 2.3}));\n}\n\nTEST(GatherNdOpTest, Float32Int32) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT32, {2, 2}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({-2.1, 2.2, 2.3, 3.1, 3.2, -3.3}));\n}\n\nTEST(GatherNdOpTest, Float32Int64) {\n  GatherNdOpModel m({TensorType_FLOAT32, {3, 2, 3}},\n                    {TensorType_INT64, {2, 2}});\n  m.SetInput<float>({1.1, -1.2, 1.3, -2.1, 2.2, 2.3,   //\n                     3.1, 3.2, -3.3, -4.1, -4.2, 4.3,  //\n                     5.1, -5.2, 5.3, 6.1, -6.2, 6.3});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<float>(),\n              ElementsAreArray({-2.1, 2.2, 2.3, 3.1, 3.2, -3.3}));\n}\n\nTEST(GatherNdOpTest, Int32Int32) {\n  GatherNdOpModel m({TensorType_INT32, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<int32_t>({1, -1, 1, -2, 2, 2,   //\n                       3, 3, -3, -4, -4, 4,  //\n                       5, -5, 5, 6, -6, 6});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int32_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Int32Int64) {\n  GatherNdOpModel m({TensorType_INT32, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<int32_t>({1, -1, 1, -2, 2, 2,   //\n                       3, 3, -3, -4, -4, 4,  //\n                       5, -5, 5, 6, -6, 6});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int32_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Uint8Int32) {\n  GatherNdOpModel m({TensorType_UINT8, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<uint8_t>({1, 1, 1, 2, 2, 2,  //\n                       3, 3, 3, 4, 4, 4,  //\n                       5, 5, 5, 6, 6, 6});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<uint8_t>(), ElementsAreArray({2, 2, 2, 3, 3, 3}));\n}\n\nTEST(GatherNdOpTest, Uint8Int64) {\n  GatherNdOpModel m({TensorType_UINT8, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<uint8_t>({1, 1, 1, 2, 2, 2,  //\n                       3, 3, 3, 4, 4, 4,  //\n                       5, 5, 5, 6, 6, 6});\n  m.SetPositions<int64_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<uint8_t>(), ElementsAreArray({2, 2, 2, 3, 3, 3}));\n}\n\nTEST(GatherNdOpTest, Int8Int32) {\n  GatherNdOpModel m({TensorType_INT8, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<int8_t>({1, -1, 1, -2, 2, 2,   //\n                      3, 3, -3, -4, -4, 4,  //\n                      5, -5, 5, 6, -6, 6});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int8_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Int8Int64) {\n  GatherNdOpModel m({TensorType_INT8, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<int8_t>({1, -1, 1, -2, 2, 2,   //\n                      3, 3, -3, -4, -4, 4,  //\n                      5, -5, 5, 6, -6, 6});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int8_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Int16Int32) {\n  GatherNdOpModel m({TensorType_INT16, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<int16_t>({1, -1, 1, -2, 2, 2,   //\n                       3, 3, -3, -4, -4, 4,  //\n                       5, -5, 5, 6, -6, 6});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int16_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Int16Int64) {\n  GatherNdOpModel m({TensorType_INT16, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<int16_t>({1, -1, 1, -2, 2, 2,   //\n                       3, 3, -3, -4, -4, 4,  //\n                       5, -5, 5, 6, -6, 6});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int16_t>(), ElementsAreArray({-2, 2, 2, 3, 3, -3}));\n}\n\nTEST(GatherNdOpTest, Int64Int32) {\n  GatherNdOpModel m({TensorType_INT64, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<int64_t>({1LL, -1LL, 1LL, -2LL, 2LL, 2LL,   //\n                       3LL, 3LL, -3LL, -4LL, -4LL, 4LL,  //\n                       5LL, -5LL, 5LL, 6LL, -6LL, 6LL});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int64_t>(),\n              ElementsAreArray({-2LL, 2LL, 2LL, 3LL, 3LL, -3LL}));\n}\n\nTEST(GatherNdOpTest, Int64Int64) {\n  GatherNdOpModel m({TensorType_INT64, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<int64_t>({1LL, -1LL, 1LL, -2LL, 2LL, 2LL,   //\n                       3LL, 3LL, -3LL, -4LL, -4LL, 4LL,  //\n                       5LL, -5LL, 5LL, 6LL, -6LL, 6LL});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<int64_t>(),\n              ElementsAreArray({-2LL, 2LL, 2LL, 3LL, 3LL, -3LL}));\n}\n\nTEST(GatherNdOpTest, StringInt32) {\n  GatherNdOpModel m({TensorType_STRING, {3, 2, 3}}, {TensorType_INT32, {2, 2}});\n  m.SetInput<std::string>({\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",  //\n                           \"G\", \"H\", \"I\", \"J\", \"K\", \"L\",  //\n                           \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\"});\n  m.SetPositions<int32_t>({0, 1, 1, 0});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<std::string>(),\n              ElementsAreArray({\"D\", \"E\", \"F\", \"G\", \"H\", \"I\"}));\n}\n\nTEST(GatherNdOpTest, StringInt64) {\n  GatherNdOpModel m({TensorType_STRING, {3, 2, 3}}, {TensorType_INT64, {2, 2}});\n  m.SetInput<std::string>({\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",  //\n                           \"G\", \"H\", \"I\", \"J\", \"K\", \"L\",  //\n                           \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\"});\n  m.SetPositions<int64_t>({0LL, 1LL, 1LL, 0LL});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n\n  EXPECT_THAT(m.GetOutput<std::string>(),\n              ElementsAreArray({\"D\", \"E\", \"F\", \"G\", \"H\", \"I\"}));\n}\n\nTEST(GatherNdOpTest, EmptyParamsAndIndex) {\n  GatherNdOpModel m({TensorType_FLOAT32, {1, 0}}, {TensorType_INT32, {0, 2}});\n  ASSERT_EQ(m.Invoke(), kTfLiteOk);\n  EXPECT_THAT(m.GetOutputShape(), ElementsAreArray({0}));\n}\n\n}  // namespace\n}  // namespace tflite"