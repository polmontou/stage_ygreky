"diff --git a/tensorflow/core/kernels/requantize.cc b/tensorflow/core/kernels/requantize.cc\nindex 3259e5ddd09..bc5de171639 100644\n--- a/tensorflow/core/kernels/requantize.cc\n+++ b/tensorflow/core/kernels/requantize.cc\n@@ -18,9 +18,11 @@ limitations under the License.\n #define EIGEN_USE_THREADS\n \n #include <math.h>\n-#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n+\n #include \"tensorflow/core/framework/op.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/framework/type_traits.h\"\n #include \"tensorflow/core/framework/types.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n@@ -38,10 +40,34 @@ class RequantizeOp : public OpKernel {\n \n   void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));"