"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for Collective Operations.\"\"\"\n\nimport time\n\nfrom tensorflow.core.protobuf import config_pb2\nfrom tensorflow.core.protobuf import rewriter_config_pb2\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import config\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import kernels\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import collective_ops\nfrom tensorflow.python.ops import control_flow_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import variables\nfrom tensorflow.python.platform import test\nfrom tensorflow.python.platform import tf_logging as logging\n\n\nclass CollectiveOpTest(test.TestCase):\n\n  def setUp(self):\n    context._reset_context()  # pylint: disable=protected-access\n    super(CollectiveOpTest, self).setUp()\n\n  def _testCollectiveReduce(self,\n                            inputs,\n                            expected,\n                            set_graph_key,\n                            communication_hint='auto',\n                            fp16=False,\n                            instance_key=1,\n                            merge_op='Add',\n                            final_op='Div',\n                            timeout=0,\n                            reported_group_size=None):\n    group_key = 1\n    group_size = len(inputs)\n    if reported_group_size is None:\n      reported_group_size = group_size\n    device_type = 'CPU'\n    config = config_pb2.ConfigProto(device_count={device_type: group_size})\n    devices = ['/{}:{}'.format(device_type, i) for i in range(group_size)]\n\n    with self.session(config=config) as sess:\n      colred = []\n      for i in range(group_size):\n        with ops.device(devices[i]):\n          tensor = constant_op.constant(inputs[i], dtype=(\n              dtypes.float16 if fp16 else dtypes.float32))\n          colred.append(\n              collective_ops.all_reduce(\n                  tensor,\n                  reported_group_size,\n                  group_key,\n                  instance_key,\n                  merge_op,\n                  final_op,\n                  communication_hint=communication_hint,\n                  timeout=timeout))\n      run_options = config_pb2.RunOptions()\n      if set_graph_key:\n        run_options.experimental.collective_graph_key = 1\n      results = sess.run(colred, options=run_options)\n    tolerance = 1e-3 if fp16 else 1e-5\n    for i in range(group_size):\n      logging.info('i {} result {} expected {}'.format(i, results[i], expected))\n      self.assertAllClose(results[i], expected, rtol=tolerance, atol=tolerance)\n\n  def _testMultipleConcurrentCollectiveReduce(self, t0, t1, expected):\n    group_key = 1\n    group_size = 2\n    num_instances = 2\n    all_reduces = []\n    config = config_pb2.ConfigProto(device_count={'CPU': group_size})\n    config.experimental.collective_deterministic_sequential_execution = True\n    with self.session(config=config) as sess:\n      for cpu in range(group_size):\n        with ops.device('/CPU:%d' % cpu):\n          in_tensor = constant_op.constant(t0 if cpu == 0 else t1)\n          for instance in range(num_instances):\n            all_reduces.append(collective_ops.all_reduce(\n                in_tensor, group_size, group_key, instance, 'Add', 'Div'))\n      results = sess.run(all_reduces)\n    for i in range(group_size * num_instances):\n      self.assertAllClose(results[i], expected, rtol=1e-5, atol=1e-5)\n\n  def testCollectiveReduce(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n                  [0.3, 1.3, 2.3, 3.3, 4.3, 5.3, 6.3, 7.3]],\n          expected=[0.2, 1.2, 2.2, 3.2, 4.2, 5.2, 6.2, 7.2],\n          set_graph_key=True)\n\n  def testCollectiveAutoGraphKey(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n                  [0.3, 1.3, 2.3, 3.3, 4.3, 5.3, 6.3, 7.3]],\n          expected=[0.2, 1.2, 2.2, 3.2, 4.2, 5.2, 6.2, 7.2],\n          set_graph_key=False)\n\n  def testFp16Reduce(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n                  [0.3, 1.3, 2.3, 3.3, 4.3, 5.3, 6.3, 7.3]],\n          expected=[0.2, 1.2, 2.2, 3.2, 4.2, 5.2, 6.2, 7.2],\n          set_graph_key=True,\n          fp16=True)\n\n  def testCollectiveMultipleConcurrentReduce(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testMultipleConcurrentCollectiveReduce(\n          [0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n          [0.3, 1.3, 2.3, 3.3, 4.3, 5.3, 6.3, 7.3],\n          [0.2, 1.2, 2.2, 3.2, 4.2, 5.2, 6.2, 7.2])\n\n  def testCollectiveTimeoutV1(self):\n    timeout = 4.5\n    kwargs = dict(\n        inputs=[[i + j + 0.1 for i in range(8)] for j in range(3)],\n        expected=[1 + i + 0.1 for i in range(8)],\n        set_graph_key=True,\n        timeout=timeout)\n\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(**kwargs)\n\n    start_time = time.time()\n    with ops.Graph().as_default():\n      with self.assertRaisesRegex(\n          errors.DeadlineExceededError,\n          'Collective has timed out waiting for other workers'):\n        self._testCollectiveReduce(\n            reported_group_size=len(kwargs['inputs']) + 1, **kwargs)\n    elapsed = time.time() - start_time\n    self.assertAllGreaterEqual(elapsed, timeout)\n\n  def testNcclHintFallbackToRingReduce(self):\n    \"\"\"Tests that setting `communication_hint=nccl` works on non-GPU builds.\"\"\"\n    if kernels.get_registered_kernels_for_op('NcclAllReduce'):\n      self.skipTest('Run only on non-GPU environments')\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n                  [0.3, 1.3, 2.3, 3.3, 4.3, 5.3, 6.3, 7.3]],\n          expected=[0.2, 1.2, 2.2, 3.2, 4.2, 5.2, 6.2, 7.2],\n          set_graph_key=False,\n          communication_hint='nccl')\n\n  def _testWhile(self, num_vars, num_iterations, key_base):\n    group_size = 2\n    group_key = 1\n    instances = [(key_base + i) for i in range(num_vars)]\n    devices = ['CPU:{}'.format(i) for i in range(group_size)]\n\n    config = config_pb2.ConfigProto(device_count={'CPU': group_size})\n    rewrite_options = config.graph_options.rewrite_options\n    rewrite_options.scoped_allocator_optimization = (\n        rewriter_config_pb2.RewriterConfig.ON)\n    del rewrite_options.scoped_allocator_opts.enable_op[:]\n    rewrite_options.scoped_allocator_opts.enable_op.append('CollectiveReduce')\n\n    with self.session(config=config) as sess:\n      loop_vars = []\n      for device in devices:\n        with ops.device(device):\n          loop_vars.append(\n              [variables.VariableV1((1 << i) * 1.) for i in range(num_vars)])\n      # This variable controls number of iterations.\n      loop_vars.append(variables.VariableV1(0.))\n      def loop_body(dev0_tensors, dev1_tensors, loop_tensor):\n        return_ops = []\n        for i in range(len(devices)):\n          device = devices[i]\n          device_tensors = dev0_tensors if i == 0 else dev1_tensors\n          with ops.device(device):\n            device_collectives = []\n            for j in range(num_vars):\n              # NOTE(ayushd): we need the `cast` here to ensure that the input\n              # to `all_reduce` has an explicit device string.  We don't use\n              # `identity` because `cast` is more resilient to getting optimized\n              # away by various optimization passes.\n              input_tensor = math_ops.cast(device_tensors[j], dtypes.float16)\n              collective_op = collective_ops.all_reduce(\n                  input_tensor, group_size, group_key, instances[j],\n                  'Add', 'Id')\n              output_tensor = math_ops.cast(collective_op, dtypes.float32)\n              device_collectives.append(output_tensor)\n            return_ops.append(device_collectives)\n        return_ops.append(math_ops.add(loop_tensor, 1.))\n        return return_ops\n      # Run until last variable exceeds number of iterations.\n      loop_cond = lambda d0, d1, i: math_ops.less(i, num_iterations)\n      sess.run(variables.global_variables_initializer())\n      results = sess.run(control_flow_ops.while_loop(loop_cond, loop_body,\n                                                     loop_vars))\n      self.assertEqual(results[:-1], [\n          [((1 << (num_iterations + v)) * 1.) for v in range(num_vars)]\n          for _ in range(group_size)])\n\n  def testSimpleWhile(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testWhile(num_vars=1, num_iterations=4, key_base=20)\n\n  def testWhileMultipleAllReduce(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testWhile(num_vars=2, num_iterations=4, key_base=20)\n\n  def testWhileWithScopedAllocator(self):\n    group_size = 2\n    group_key = 1\n    instance_key0 = 1\n    instance_key1 = 2\n\n    config = config_pb2.ConfigProto(device_count={'CPU': group_size})\n    rewrite_options = config.graph_options.rewrite_options\n    rewrite_options.scoped_allocator_optimization = (\n        rewriter_config_pb2.RewriterConfig.ON)\n    del rewrite_options.scoped_allocator_opts.enable_op[:]\n    rewrite_options.scoped_allocator_opts.enable_op.append('CollectiveReduce')\n\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      with self.session(config=config) as sess:\n        run_ops = []\n        for i in range(group_size):\n          with ops.device('CPU:%d' % i):\n            constant = constant_op.constant(0.)\n            cond = lambda i: math_ops.less(i, 10.)\n            body = lambda i: math_ops.add(i, 1.)\n            input0 = control_flow_ops.while_loop(cond, body, [constant])\n            input1 = math_ops.add(constant, 5)\n            colred0 = collective_ops.all_reduce(input0, group_size, group_key,\n                                                instance_key0, 'Add', 'Id')\n            colred1 = collective_ops.all_reduce(input1, group_size, group_key,\n                                                instance_key1, 'Add', 'Id')\n            run_ops.append(math_ops.add_n([colred0, colred1]))\n        results = sess.run(run_ops)\n      self.assertEqual(results, [30., 30.])\n\n  def testCollectiveReduceScalar(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(inputs=[0.1, 0.3], expected=0.2,\n                                 set_graph_key=True)\n\n  def testCollectiveReduceMaximum(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[1., 20., 3., 40., 5.], [10., 2., 30., 4., 50.]],\n          expected=[10., 20., 30., 40., 50.],\n          set_graph_key=True,\n          instance_key=30,\n          merge_op='Max',\n          final_op='Id')\n\n  def testCollectiveReduceMinimum(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveReduce(\n          inputs=[[1., 20., 3., 40., 5.], [10., 2., 30., 4., 50.]],\n          expected=[1., 2., 3., 4., 5.],\n          set_graph_key=True,\n          instance_key=40,\n          merge_op='Min',\n          final_op='Id')\n\n  def _testCollectiveBroadcast(self, in_val):\n    group_key = 1\n    instance_key = 1\n    with self.session(\n        config=config_pb2.ConfigProto(device_count={'CPU': 2})) as sess:\n      with ops.device('/CPU:0'):\n        in0 = constant_op.constant(in_val)\n        out0 = collective_ops.broadcast_send(in0, in0.shape, in0.dtype,\n                                             2, group_key, instance_key)\n      with ops.device('/CPU:1'):\n        c1 = constant_op.constant(in_val)\n        out1 = collective_ops.broadcast_recv(c1.shape, c1.dtype,\n                                             2, group_key, instance_key)\n      run_options = config_pb2.RunOptions()\n      run_options.experimental.collective_graph_key = 1\n      results = sess.run([out0, out1], options=run_options)\n    self.assertAllClose(results[0], in_val, rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[1], in_val, rtol=1e-5, atol=1e-5)\n\n  def testCollectiveBroadcast(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveBroadcast([0.1, 1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1])\n\n  def testCollectiveBroadcastBool(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveBroadcast([True, False])\n\n  def _testCollectiveGather(self, t0, t1, expected, set_graph_key):\n    group_key = 1\n    instance_key = 1\n    with self.session(\n        config=config_pb2.ConfigProto(device_count={'CPU': 2})) as sess:\n      with ops.device('/CPU:0'):\n        in0 = constant_op.constant(t0)\n        c0 = collective_ops.all_gather(in0, 2, group_key, instance_key)\n      with ops.device('/CPU:1'):\n        in1 = constant_op.constant(t1)\n        c1 = collective_ops.all_gather(in1, 2, group_key, instance_key)\n      run_options = config_pb2.RunOptions()\n      if set_graph_key:\n        run_options.experimental.collective_graph_key = 1\n      results = sess.run([c0, c1], options=run_options)\n    self.assertAllClose(results[0], expected, rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[1], expected, rtol=1e-5, atol=1e-5)\n\n  def testCollectiveGather(self):\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      self._testCollectiveGather([0, 1, 2, 3, 4, 5, 6, 7],\n                                 [10, 11, 12, 13, 14, 15, 16, 17],\n                                 [0, 1, 2, 3, 4, 5, 6, 7,\n                                  10, 11, 12, 13, 14, 15, 16, 17],\n                                 True)\n      self._testCollectiveGather([[0, 1, 2, 3], [4, 5, 6, 7]],\n                                 [[10, 11, 12, 13], [14, 15, 16, 17]],\n                                 [[0, 1, 2, 3], [4, 5, 6, 7],\n                                  [10, 11, 12, 13], [14, 15, 16, 17]],\n                                 True)\n      self._testCollectiveGather([[[0, 1], [2, 3]], [[4, 5], [6, 7]]],\n                                 [[[10, 11], [12, 13]], [[14, 15], [16, 17]]],\n                                 [[[0, 1], [2, 3]], [[4, 5], [6, 7]],\n                                  [[10, 11], [12, 13]], [[14, 15], [16, 17]]],\n                                 True)\n\n  def testCollectiveGatherShapeMismatch(self):\n    group_key = 1\n    instance_key = 1\n    t0 = [1, 2, 3, 4]\n    t1 = [5, 6, 7, 8]\n    t2 = [9, 10]\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      with self.session(\n          config=config_pb2.ConfigProto(device_count={'CPU': 2})) as sess:\n        with ops.device('/CPU:0'):\n          in0 = constant_op.constant(t0)\n          c0 = collective_ops.all_gather(in0, 2, group_key, instance_key)\n        with ops.device('/CPU:1'):\n          in1 = constant_op.constant(t1)\n          in2 = constant_op.constant(t2)\n          c1 = collective_ops.all_gather(in1, 2, group_key, instance_key)\n          c2 = collective_ops.all_gather(in2, 2, group_key, instance_key)\n        run_options = config_pb2.RunOptions()\n        run_options.experimental.collective_graph_key = 1\n        sess.run([c0, c1], options=run_options)\n        with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                    'Shape mismatch'):\n          sess.run([c0, c2], options=run_options)\n\n  def testCollectiveGatherShapeMismatchAcrossDevices(self):\n    group_key = 1\n    instance_key = 1\n    t0 = [1, 2, 3, 4]\n    t1 = [5, 6]\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      with self.session(\n          config=config_pb2.ConfigProto(device_count={'CPU': 2})) as sess:\n        with ops.device('/CPU:0'):\n          in0 = constant_op.constant(t0)\n          c0 = collective_ops.all_gather(in0, 2, group_key, instance_key)\n        with ops.device('/CPU:1'):\n          in1 = constant_op.constant(t1)\n          c1 = collective_ops.all_gather(in1, 2, group_key, instance_key)\n        run_options = config_pb2.RunOptions()\n        run_options.experimental.collective_graph_key = 1\n        with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                    'Shape mismatch'):\n          sess.run([c0, c1], options=run_options)\n\n  def testCollectiveGatherPolymorphicShape(self):\n    t0 = [0, 1, 2, 3, 4, 5, 6, 7]\n    t1 = [10, 11, 12, 13, 14, 15, 16, 17]\n    group_size = 2\n    group_key = 1\n    instance_key = 123\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      with self.session(\n          config=config_pb2.ConfigProto(\n              device_count={'CPU': group_size})) as sess:\n        with ops.device('/CPU:0'):\n          in0 = array_ops.placeholder(dtype=dtypes.int32, shape=[None])\n          c0 = collective_ops.all_gather(in0, group_size, group_key,\n                                         instance_key)\n        with ops.device('/CPU:1'):\n          in1 = array_ops.placeholder(dtype=dtypes.int32, shape=[None])\n          c1 = collective_ops.all_gather(in1, group_size, group_key,\n                                         instance_key)\n\n        results = sess.run([c0, c1], feed_dict={in0: t0, in1: t1})\n        results_ = sess.run([c0, c1], feed_dict={in0: t0[1:], in1: t1[1:]})\n\n    expected_output = [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17]\n    self.assertAllClose(results[0], expected_output, rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results[1], expected_output, rtol=1e-5, atol=1e-5)\n\n    expected_output_ = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17]\n    self.assertAllClose(results_[0], expected_output_, rtol=1e-5, atol=1e-5)\n    self.assertAllClose(results_[1], expected_output_, rtol=1e-5, atol=1e-5)\n\n  @test_util.run_v2_only\n  @test_util.disable_tfrt(\n      'b/177270918: TFRT has dead lock when executing collective ops.')\n  def testCollectiveGroupSizeMismatch(self):\n    cpus = config.list_physical_devices('CPU')\n    self.assertEqual(len(cpus), 1)\n    config.set_logical_device_configuration(cpus[0], [\n        context.LogicalDeviceConfiguration(),\n        context.LogicalDeviceConfiguration()\n    ])\n    context.ensure_initialized()\n\n    @def_function.function\n    def run_all_reduce():\n      group_key = 10\n      instance_key = 20\n      t0 = [1, 2, 3, 4]\n      t1 = [5, 6, 7, 8]\n      with ops.device('/CPU:0'):\n        in0 = constant_op.constant(t0)\n        c0 = collective_ops.all_reduce(\n            in0, group_size=2, group_key=group_key, instance_key=instance_key,\n            merge_op='Add', final_op='Id')\n      with ops.device('/CPU:1'):\n        in1 = constant_op.constant(t1)\n        c1 = collective_ops.all_reduce(\n            in1, group_size=3, group_key=group_key, instance_key=instance_key,\n            merge_op='Add', final_op='Id')\n      return c0, c1\n\n    with self.assertRaisesRegex(errors.InternalError,\n                                'but that group has size'):\n      run_all_reduce()\n\n  @test_util.run_v2_only\n  def testCollectiveTensorsHaveNoDeviceSpecified(self):\n    cpus = config.list_physical_devices('CPU')\n    self.assertEqual(len(cpus), 1)\n    config.set_logical_device_configuration(cpus[0], [\n        context.LogicalDeviceConfiguration(),\n        context.LogicalDeviceConfiguration()\n    ])\n    context.ensure_initialized()\n\n    group_size = 2\n    group_key = 1\n    instance_key = 1\n\n    @def_function.function\n    def fn(all_args):\n      results = []\n      # The inputs have no devices set. This is expected to be a trace-time\n      # check only.\n      self.assertEqual(all_args[0].device, '')\n      self.assertEqual(all_args[1].device, '')\n\n      with ops.device('/CPU:0'):\n        results.append(\n            collective_ops.all_reduce(all_args[0], group_size, group_key,\n                                      instance_key, 'Add', 'Div'))\n      with ops.device('/CPU:1'):\n        results.append(\n            collective_ops.all_reduce(all_args[1], group_size, group_key,\n                                      instance_key, 'Add', 'Div'))\n\n      return results\n\n    with ops.device('/CPU:0'):\n      in0 = constant_op.constant(1)\n    with ops.device('/CPU:1'):\n      in1 = constant_op.constant(3)\n    result = fn([in0, in1])\n    self.assertAllClose(result, [2, 2])\n\n  def testConstantWithScopedAllocator(self):\n    group_size = 2\n    group_key = 1\n    instance_key1 = 1\n    instance_key2 = 2\n\n    graph_options = config_pb2.GraphOptions(\n        optimizer_options=config_pb2.OptimizerOptions(do_constant_folding=True))\n    cfg = config_pb2.ConfigProto(device_count={'CPU': group_size},\n                                 graph_options=graph_options)\n    rewrite_options = cfg.graph_options.rewrite_options\n    rewrite_options.scoped_allocator_optimization = (\n        rewriter_config_pb2.RewriterConfig.ON)\n    del rewrite_options.scoped_allocator_opts.enable_op[:]\n    rewrite_options.scoped_allocator_opts.enable_op.append('CollectiveReduce')\n\n    # Tests that execute collectives need to be enclosed in graph or tf.function\n    with ops.Graph().as_default():\n      with self.session(config=cfg) as sess:\n        run_ops = []\n        for i in range(group_size):\n          with ops.device('CPU:%d' % i):\n            constant = constant_op.constant(i + 1.)\n            input_tensor1 = array_ops.identity(constant)\n            input_tensor2 = array_ops.identity(constant)\n            reduced_tensor1 = collective_ops.all_reduce(\n                input_tensor1, group_size, group_key, instance_key1, 'Add',\n                'Id')\n            reduced_tensor2 = collective_ops.all_reduce(\n                input_tensor2, group_size, group_key, instance_key2, 'Add',\n                'Id')\n            run_ops.append(array_ops.identity(reduced_tensor1))\n            run_ops.append(array_ops.identity(reduced_tensor2))\n        results = sess.run(run_ops)\n    self.assertEqual(results, [3., 3., 3., 3.])\n\n\nif __name__ == '__main__':\n  test.main()"