"/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/full_type_util.h\"\n\n#include <algorithm>\n#include <string>\n\n#include \"absl/container/flat_hash_map.h\"\n#include \"tensorflow/core/framework/attr_value.pb.h\"\n#include \"tensorflow/core/framework/full_type.pb.h\"\n#include \"tensorflow/core/framework/node_def.pb.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op_def.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/hash.h\"\n#include \"tensorflow/core/platform/statusor.h\"\n#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n\nnamespace tensorflow {\n\nnamespace full_type {\n\nOpTypeConstructor NoOp() {\n  return nullptr;\n}\n\nOpTypeConstructor NoOutputs() {\n  return [](OpDef* op_def) {\n    op_def->mutable_output_arg();\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Nullary(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor Unary(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_VAR);\n    arg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryGeneric(FullTypeId t) {\n  return [t](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_ANY);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, FullTypeId dtype) {\n  return [t, dtype](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* arg = tdef->add_args();\n    arg->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = arg->add_args();\n    targ->set_type_id(dtype);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor UnaryTensorContainer(FullTypeId t, const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* targ = tdef->add_args();\n    targ->set_type_id(TFT_TENSOR);\n    FullTypeDef* varg = targ->add_args();\n    varg->set_type_id(TFT_VAR);\n    varg->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nOpTypeConstructor VariadicTensorContainer(FullTypeId t,\n                                          const string& var_name) {\n  return [t, var_name](OpDef* op_def) {\n    FullTypeDef* tdef =\n        op_def->mutable_output_arg(0)->mutable_experimental_full_type();\n    tdef->set_type_id(t);\n\n    FullTypeDef* for_each = tdef->add_args();\n    for_each->set_type_id(TFT_FOR_EACH);\n    for_each->add_args()->set_type_id(TFT_PRODUCT);\n\n    FullTypeDef* tpl = for_each->add_args();\n    tpl->set_type_id(TFT_TENSOR);\n    FullTypeDef* targ = tpl->add_args();\n    targ->set_type_id(TFT_VAR);\n    targ->set_s(var_name);\n\n    FullTypeDef* tvar = for_each->add_args();\n    tvar->set_type_id(TFT_VAR);\n    tvar->set_s(var_name);\n\n    return OkStatus();\n  };\n}\n\nnamespace {\n\ntypedef absl::flat_hash_map<StringPiece, const AttrValue*> AttrMap;\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t);\n\nStatus SubstituteVar(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 0);\n\n  StringPiece var_name = t.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    map_dtype_to_tensor(attr->type(), t);\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    if (attr_list.type_size() != 1) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"lists or other than one type element\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    map_dtype_to_tensor(attr_list.type(0), t);\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type \",\n                               attr->DebugString(), \" for name \", var_name));\n  }\n  t.clear_s();\n  return OkStatus();\n}\n\nStatus SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 3);\n\n  const auto& cont = t.args(0);\n  const auto& tmpl = t.args(1);\n  const auto& t_var = t.args(2);\n\n  StringPiece var_name = t_var.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  FullTypeDef result;\n  result.set_type_id(cont.type_id());\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    FullTypeDef* target = result.add_args();\n    *target = tmpl;\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(attrs, *target), \"while substituting '\", var_name,\n        \"' from\\n\", attr->DebugString(), \"\\ninto \", target->DebugString());\n\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    int tsize = attr_list.type_size();\n    if (tsize == 0) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"unsupported list attribute type\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    AttrValue replacement;\n    attrs[var_name] = &replacement;\n    for (int i = 0; i < tsize; i++) {\n      replacement.set_type(attr_list.type(i));\n      FullTypeDef* target = result.add_args();\n      *target = tmpl;\n      TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *target),\n                                      \"while substituting '\", var_name,\n                                      \"' from\\n\", attr->DebugString(), \"\\n[\", i,\n                                      \"] into\\n\", target->DebugString());\n    }\n    // In case of error, it's ok for the attributes map to remain in an invalid\n    // state.\n    attrs[var_name] = attr;\n\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type\\n\",\n                               attr->DebugString(), \"\\nfor name \", var_name));\n  }\n  t = result;\n  return OkStatus();\n}\n\nStatus SubstituteGeneric(AttrMap& attrs, FullTypeDef& t) {\n  int nargs = t.args_size();\n  for (int j = 0; j < nargs; j++) {\n    FullTypeDef* arg_t = t.mutable_args(j);\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *arg_t),\n                                    \"while substituting arg \", j, \": \",\n                                    arg_t->DebugString());\n\n    // Special case for DT_VARIANT tensors. We leave those unset to avoid even\n    // more special casing downstream.\n    if (arg_t->type_id() == TFT_TENSOR && arg_t->args_size() &&\n        arg_t->args(0).type_id() == TFT_LEGACY_VARIANT) {\n      t.clear_args();\n      break;\n    }\n  }\n  return OkStatus();\n}\n\ninline Status SubstituteFromAttrs(AttrMap& attrs, FullTypeDef& t) {\n  // Resolve dependent types. The convention for op registrations is to use\n  // attributes as type variables.\n  // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n  // Once the op signature can be defined entirely in FullType, this\n  // convention can be deprecated.\n  //\n  // Note: While this code performs some basic verifications, it generally\n  // assumes consistent op defs and attributes. If more complete\n  // verifications are needed, they should be done by separately, and in a\n  // way that can be reused for type inference.\n  switch (t.type_id()) {\n    case TFT_VAR:\n      return SubstituteVar(attrs, t);\n\n    case TFT_FOR_EACH:\n      return SubstituteForEach(attrs, t);\n\n    default:\n      return SubstituteGeneric(attrs, t);\n  }\n  return OkStatus();\n}\n\n}  // namespace\n\nStatus SpecializeType(const AttrSlice& attrs, const OpDef& op_def,\n                      FullTypeDef& target) {\n  target.Clear();\n  target.set_type_id(TFT_PRODUCT);\n\n  AttrMap map;\n  for (const auto& attr : attrs) {\n    map.emplace(attr.first, &attr.second);\n  }\n\n  int nargs = op_def.output_arg_size();\n  for (int i = 0; i < nargs; i++) {\n    auto& t = *(target.add_args());\n    t = op_def.output_arg(i).experimental_full_type();\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(map, t), \"while expanding vars of\\n\",\n        t.DebugString(), \"\\nfrom\\n\", attrs.SummarizeNode());\n  }\n\n  return OkStatus();\n}\n\nconst FullTypeDef& GetArgDefaultUnset(const FullTypeDef& t, int i) {\n  static FullTypeDef* unset_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    return t.args(i);\n  }\n  return *unset_type;\n}\n\nconst FullTypeDef& GetArgDefaultAny(const FullTypeDef& t, int i) {\n  static FullTypeDef* any_type = []() {\n    FullTypeDef* t = new FullTypeDef();\n    t->set_type_id(TFT_ANY);\n    return t;\n  }();\n\n  if (i < t.args_size()) {\n    const FullTypeDef& f_val = t.args(i);\n    if (f_val.type_id() == TFT_UNSET) {\n      return *any_type;\n    }\n    return f_val;\n  }\n  return *any_type;\n}\n\nbool IsEqual(const FullTypeDef& lhs, const FullTypeDef& rhs) {\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n  const auto& lhs_s = lhs.s();\n  const auto& rhs_s = rhs.s();\n  if (lhs_s.empty()) {\n    if (!rhs_s.empty()) {\n      return false;\n    }\n  } else if (rhs_s != lhs_s) {\n    return false;\n  }\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (!IsEqual(lhs_arg, rhs_arg)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nuint64_t Hash(const FullTypeDef& arg) {\n  // Following style of IsEqual above and walking across FullTypeDef.\n  uint64_t val = Hash64Combine(arg.type_id(), 0);\n\n  const auto& arg_s = arg.s();\n  val = Hash64Combine(val, Hash64(arg_s));\n  for (int i = 0, e = arg.args_size(); i < e; ++i) {\n    const FullTypeDef& arg_arg = GetArgDefaultAny(arg, i);\n    val = Hash64Combine(val, Hash(arg_arg));\n  }\n\n  return val;\n}\n\nbool IsSubtype(const FullTypeDef& lhs, const FullTypeDef& rhs, bool covariant) {\n  // Rule: ANY is a supertype of all types.\n  if (rhs.type_id() == TFT_ANY) {\n    return true;\n  }\n  // Compatibility rule: UNSET is treated as ANY for the purpose of subtyping.\n  if (rhs.type_id() == TFT_UNSET) {\n    return true;\n  }\n  // Compatibility rule: TENSOR[LEGACY_VARIANT] is treated as ANY for the\n  // purpose of subtyping.\n  if ((rhs.type_id() == TFT_TENSOR) &&\n      (GetArgDefaultUnset(rhs, 0).type_id() == TFT_LEGACY_VARIANT)) {\n    return true;\n  }\n  // Rule: encodings are subtypes of the encoding type.\n  if (lhs.type_id() == TFT_ENCODED) {\n    return IsSubtype(GetArgDefaultAny(lhs, 1), rhs, true);\n  }\n\n  // Default rule: type IDs must match.\n  if (lhs.type_id() != rhs.type_id()) {\n    return false;\n  }\n\n  // Arguments must be subtypes of one another.\n  for (int i = 0; i < std::max(lhs.args_size(), rhs.args_size()); i++) {\n    const FullTypeDef& lhs_arg = GetArgDefaultAny(lhs, i);\n    const FullTypeDef& rhs_arg = GetArgDefaultAny(rhs, i);\n\n    if (covariant) {\n      if (!IsSubtype(lhs_arg, rhs_arg)) {\n        return false;\n      }\n    } else {\n      if (!IsSubtype(rhs_arg, lhs_arg)) {\n        return false;\n      }\n    }\n  }\n\n  // Invariant: type IDs are equal, and all args are subtype of one another.\n  return true;\n}\n\n}  // namespace full_type\n\n}  // namespace tensorflow"