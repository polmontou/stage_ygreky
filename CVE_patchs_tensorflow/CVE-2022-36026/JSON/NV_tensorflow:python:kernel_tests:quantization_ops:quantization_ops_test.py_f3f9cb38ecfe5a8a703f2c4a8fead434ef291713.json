"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for tf.quantize ops.\"\"\"\nimport numpy as np\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.platform import googletest\n\n\nclass FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars(\n              inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))\n\n\nclass FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[[0.0]], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[1.0], max=[[1.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Dimensions must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel(\n              inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n\n\nclass FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    gradients = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be equal rank|must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_gradient(\n              gradients=gradients,\n              inputs=inputs,\n              min=0.0,\n              max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_gradient(\n              gradients=gradients,\n              inputs=inputs,\n              min=[[1.0], [2.0], [4.0]],\n              max=[[1.0], [2.0], [4.0]]))\n\n\nclass FakeQuantWithMinMaxVarsPerChannelGradientOpTest(\n    test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    gradients = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n    inputs = constant_op.constant(\n        value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Shapes must be equal rank|must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n              gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))\n\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError),\n        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n              gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"Shapes must be equal rank|must be rank 1\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n              gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))\n\n    with self.assertRaisesRegex(\n        (ValueError, errors.InvalidArgumentError),\n        \"Dimension 0 in both shapes must be equal|incorrect size\"):\n      self.evaluate(\n          array_ops.fake_quant_with_min_max_vars_per_channel_gradient(\n              gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))\n\n\nclass QuantizedBiasedAddTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)\n    bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=[],\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=[],\n              min_bias=0.0,\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=[],\n              max_bias=1.0,\n              out_type=dtypes.qint32))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_bias_add(\n              input=inputs,\n              bias=bias,\n              min_input=0.0,\n              max_input=1.0,\n              min_bias=0.0,\n              max_bias=[],\n              out_type=dtypes.qint32))\n\n\nclass QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          array_ops.quantized_instance_norm(\n              x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))\n\n\nclass QuantizedAvgPoolingOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n    ksize = [1, 1, 1, 1]\n    strides = [1, 1, 1, 1]\n    padding = \"SAME\"\n\n    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                \"must be.* rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_avg_pool(\n              input=inputs,\n              min_input=[],\n              max_input=1.0,\n              ksize=ksize,\n              strides=strides,\n              padding=padding))\n\n    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                \"must be.* rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_avg_pool(\n              input=inputs,\n              min_input=0.0,\n              max_input=[],\n              ksize=ksize,\n              strides=strides,\n              padding=padding))\n\n\nclass QuantizedMaxPoolingOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n    ksize = [1, 1, 1, 1]\n    strides = [1, 1, 1, 1]\n    padding = \"SAME\"\n\n    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                \"must be.* rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_max_pool(\n              input=inputs,\n              min_input=[],\n              max_input=1.0,\n              ksize=ksize,\n              strides=strides,\n              padding=padding))\n\n    with self.assertRaisesRegex((errors.InvalidArgumentError, ValueError),\n                                \"must be.* rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_max_pool(\n              input=inputs,\n              min_input=0.0,\n              max_input=[],\n              ksize=ksize,\n              strides=strides,\n              padding=padding))\n\n\nclass RequantizeOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=[],\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=[],\n              requested_output_min=0.0,\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=[],\n              requested_output_max=1.0,\n              out_type=dtypes.qint8))\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.requantize(\n              input=inputs,\n              input_min=0.0,\n              input_max=1.0,\n              requested_output_min=0.0,\n              requested_output_max=[],\n              out_type=dtypes.qint8))\n\n\nclass QuantizedAddOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    x = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.quantized_add(\n              x=x,\n              y=y,\n              min_x=[],\n              max_x=1.0,\n              min_y=0.0,\n              max_y=1.0,\n              Toutput=dtypes.qint32))\n\n\nclass QuantizedReluOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          nn_ops.quantized_relu6(\n              features=inputs,\n              min_features=[],\n              max_features=127.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    inputs = constant_op.constant(\n        np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)\n\n    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n                                \"must be rank 0\"):\n      self.evaluate(\n          math_ops.quantize_down_and_shrink_range(\n              input=inputs, input_min=[], input_max=4.0,\n              out_type=dtypes.quint8))\n\n\nclass QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_valid(self):\n    with ops.Graph().as_default(), context.eager_mode():\n      input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n                                         shape=(6,),\n                                         dtype=dtypes.float32),\n      input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n      input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n      num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)\n\n      quantized = array_ops.quantize_and_dequantize_v3(\n          input_value,\n          input_min,\n          input_max,\n          num_bits,\n          signed_input=True,\n          range_given=False)\n      self.assertSequenceAlmostEqual(\n          input_value[0].numpy(), quantized.numpy()[0], delta=0.05)\n\n  @test_util.run_in_graph_and_eager_modes\n  def test_invalid_inputs(self):\n    input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],\n                                       shape=(6,),\n                                       dtype=dtypes.float32),\n    input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)\n    input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)\n    # Tensor with invalid shape and invalid number of elements.\n    num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)\n\n    # Test that running the op raises error. It raises different errors\n    # depending on whether the shape inference is run first or the op's\n    # Compute() is run first.\n    try:\n      array_ops.quantize_and_dequantize_v3(\n          input_value, input_min, input_max, num_bits, signed_input=True)\n    except Exception as ex:  # pylint: disable=broad-except\n      if isinstance(ex, errors.InvalidArgumentError):\n        self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")\n      elif isinstance(ex, ValueError):\n        self.assertRegex(str(ex), \"Shape must be rank 0\")\n      else:\n        self.fail(\n            \"Raised exception other than expected: %s. \"\n            \"Expected exceptions are errors.InvalidArgumentError or ValueError\",\n            ex.__name__)\n    else:\n      self.fail(\n          \"Did not raise an exception where it is expected to raise either \"\n          \"a ValueError or errors.InvalidArgumentError.\")\n\n\nif __name__ == \"__main__\":\n  googletest.main()"