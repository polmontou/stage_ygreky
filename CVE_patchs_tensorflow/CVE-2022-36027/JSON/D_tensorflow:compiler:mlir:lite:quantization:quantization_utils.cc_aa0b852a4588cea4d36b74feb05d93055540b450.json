"diff --git a/tensorflow/compiler/mlir/lite/quantization/quantization_utils.cc b/tensorflow/compiler/mlir/lite/quantization/quantization_utils.cc\nindex 0bee61e913f..d9a7534a214 100644\n--- a/tensorflow/compiler/mlir/lite/quantization/quantization_utils.cc\n+++ b/tensorflow/compiler/mlir/lite/quantization/quantization_utils.cc\n@@ -168,12 +168,10 @@ quant::UniformQuantizedPerAxisType ResetAxisAndBroadcast(\n         BroadcastVector<int64_t>(shaped.getDimSize(quant_dim), zero_points)) {\n       return {};\n     }\n-  } else if ((new_shape.size() == shape.size() + 1) && new_shape.back() == 1) {\n-    // This is a trivial shift left, then we shift the quant_dim as well.\n-    if (std::equal(shape.begin(), shape.end(), new_shape.begin()) &&\n-        quant_dim == -1) {\n-      quant_dim = shape.size() + quant_dim;\n-    } else {\n+  } else if ((new_shape.size() == shape.size() + 1) && new_shape.front() == 1) {\n+    // Handle the [A, B, C] -> [1, A, B, C] reshape case.\n+    if (!(std::equal(shape.begin(), shape.end(), new_shape.begin() + 1) &&\n+          quant_dim == new_shape.size() - 1)) {\n       return {};\n     }\n   } else {\n@@ -343,6 +341,10 @@ TypeAttr CastQuantizedTypeAttrFromExpressedType(Builder builder,\n   // Reset the quantization dimensions if it is per-axis.\n   if (auto per_axis =\n           qtype.dyn_cast_or_null<quant::UniformQuantizedPerAxisType>()) {\n+    // For the pass-through ops, we don't know which the dimension will be the\n+    // new quantization dimension. Only if the new quantization dimension can\n+    // be inferred, it is safe to reset the per-axis quantized type.\n+    if (axis == -1) return {};\n     qtype =\n         ResetAxisAndBroadcast(source_type.getShape(), per_axis, target, axis);\n   }"