"# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Unit tests for TensorFlow \"Eager\" Mode's Tensor class.\"\"\"\n\nimport copy\nimport re\nimport sys\n\nimport numpy as np\n\nfrom tensorflow.python import pywrap_tfe\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.eager import core\nfrom tensorflow.python.eager import test\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import io_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.ops import resource_variable_ops\nfrom tensorflow.python.ops import variables\n\n\ndef _create_tensor(value, device=None, dtype=None):\n  context.ensure_initialized()\n  ctx = context.context()\n  if device is None:\n    device = ctx.device_name\n  if dtype is not None:\n    dtype = dtype.as_datatype_enum\n  try:\n    return ops.EagerTensor(value, device=device, dtype=dtype)\n  except core._NotOkStatusException as e:  # pylint: disable=protected-access\n    raise core._status_to_exception(e)\n\n\nclass TFETensorTest(test_util.TensorFlowTestCase):\n\n  def testScalarTensor(self):\n    t = _create_tensor(3, dtype=dtypes.int32)\n    self.assertAllEqual(t, _create_tensor(np.array(3)))\n    self.assertEqual(dtypes.int32, t.dtype)\n    self.assertEqual(0, t.shape.ndims)\n    self.assertAllEqual([], t.shape.as_list())\n    self.assertIn(\"tf.Tensor\", str(t))\n    self.assertIn(\"tf.Tensor\", repr(t))\n\n  def testBadConstructorArgs(self):\n    context.ensure_initialized()\n    ctx = context.context()\n    device = ctx.device_name\n    # Missing device.\n    with self.assertRaisesRegex(TypeError, r\".*argument 'device' \\(pos 2\\).*\"):\n      ops.EagerTensor(1)\n    # Bad dtype type.\n    with self.assertRaisesRegex(TypeError,\n                                \"Expecting a DataType value for dtype. Got\"):\n      ops.EagerTensor(1, device=device, dtype=\"1\")\n\n    # Following errors happen when trying to copy to GPU.\n    if not test_util.is_gpu_available():\n      self.skipTest(\"No GPUs found\")\n\n    with ops.device(\"/device:GPU:0\"):\n      # Bad device.\n      with self.assertRaisesRegex(TypeError, \"Error parsing device argument\"):\n        ops.EagerTensor(1.0, device=1)\n\n  def testNumpyValue(self):\n    values = np.array([3.0])\n    t = _create_tensor(values)\n    self.assertAllEqual(values, t)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testNumpyDtypeSurvivesThroughTensorConversion(self):\n    scalar_creators = [np.int32, np.int64, np.float32, np.float64]\n    conversion_functions = [ops.convert_to_tensor, constant_op.constant]\n\n    for scalar_creator in scalar_creators:\n      for conversion_function in conversion_functions:\n        np_val = scalar_creator(3)\n        tensor_val = conversion_function(np_val)\n        self.assertEqual(tensor_val.numpy().dtype, np_val.dtype)\n        self.assertEqual(tensor_val.numpy(), np_val)\n\n  def testNumpyValueWithCast(self):\n    values = np.array([3.0], dtype=np.float32)\n    t = _create_tensor(values, dtype=dtypes.float64)\n    self.assertAllEqual(values, t)\n    ctx = context.context()\n    # Bad dtype value.\n    with self.assertRaisesRegex(TypeError, \"Invalid dtype argument value\"):\n      ops.EagerTensor(values, device=ctx.device_name, dtype=12345)\n\n  def testNumpyOrderHandling(self):\n    n = np.array([[1, 2], [3, 4]], order=\"F\")\n    t = _create_tensor(n)\n    self.assertAllEqual([[1, 2], [3, 4]], t)\n\n  def testNumpyArrayDtype(self):\n    tensor = constant_op.constant([1.0, 2.0, 3.0])\n    numpy_tensor = np.asarray(tensor, dtype=np.int32)\n    self.assertAllEqual(numpy_tensor, [1, 2, 3])\n\n  def testNdimsAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(numpy_tensor.ndim, tensor.ndim)\n\n  def testLenAgreesWithNumpy(self):\n    numpy_tensor = np.asarray(1.0)\n    tensor = constant_op.constant(numpy_tensor)\n    with self.assertRaises(TypeError):\n      len(numpy_tensor)\n    with self.assertRaisesRegex(TypeError, r\"Scalar tensor has no `len[(][)]`\"):\n      len(tensor)\n\n    numpy_tensor = np.asarray([1.0, 2.0, 3.0])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n    numpy_tensor = np.asarray([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n    tensor = constant_op.constant(numpy_tensor)\n    self.assertAllEqual(len(numpy_tensor), len(tensor))\n\n  def testCopy(self):\n    t = constant_op.constant(1.0)\n    tt = copy.copy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    tt = copy.deepcopy(t)\n    self.assertAllEqual(tt, 1.0)\n    del tt\n    self.assertAllEqual(t, 1.0)\n\n  def testConstantDtype(self):\n    self.assertEqual(\n        constant_op.constant(1, dtype=np.int64).dtype, dtypes.int64)\n\n  def testTensorAndNumpyMatrix(self):\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    actual = _create_tensor([[1.0, 2.0], [3.0, 4.0]])\n    self.assertAllEqual(expected, actual)\n    self.assertEqual(np.float32, actual.dtype)\n    self.assertEqual(dtypes.float32, actual.dtype)\n    self.assertAllEqual([2, 2], actual.shape.as_list())\n\n  def testNumpyArrayInterface(self):\n\n    class ArrayAsArrayInterface:\n      \"\"\"Simple class that wraps an np.array as an __array_interface__.\"\"\"\n\n      def __init__(self, array):\n        self.array = array\n\n      @property\n      def __array_interface__(self):\n        return self.array.__array_interface__\n\n    expected = np.array([[1.0, 2.0], [3.0, 4.0]], np.float32)\n    array_interface = ArrayAsArrayInterface(expected)\n    actual = _create_tensor(array_interface)\n    self.assertAllEqual(expected, actual)\n\n  def testFloatDowncast(self):\n    # Unless explicitly specified, float64->float32\n    t = _create_tensor(3.0)\n    self.assertEqual(dtypes.float32, t.dtype)\n    t = _create_tensor(3.0, dtype=dtypes.float64)\n    self.assertEqual(dtypes.float64, t.dtype)\n\n  def testBool(self):\n    self.assertFalse(bool(_create_tensor(False)))\n    self.assertFalse(bool(_create_tensor([False])))\n    self.assertFalse(bool(_create_tensor([[False]])))\n    self.assertFalse(bool(_create_tensor([0])))\n    self.assertFalse(bool(_create_tensor([0.])))\n    self.assertTrue(bool(_create_tensor([1])))\n    self.assertTrue(bool(_create_tensor([1.])))\n\n  def testIndex(self):\n    self.assertEqual([42][_create_tensor(0)], 42)\n\n    with self.assertRaises(TypeError):\n      _ = [42][_create_tensor([0])]\n\n  def testIntDowncast(self):\n    t = _create_tensor(3)\n    self.assertEqual(dtypes.int32, t.dtype)\n    t = _create_tensor(3, dtype=dtypes.int64)\n    self.assertEqual(dtypes.int64, t.dtype)\n    t = _create_tensor(2**33)\n    self.assertEqual(dtypes.int64, t.dtype)\n\n  def testTensorCreationFailure(self):\n    with self.assertRaises(ValueError):\n      # Should fail because the each row of the Python object has a different\n      # number of columns.\n      self.assertEqual(None, _create_tensor([[1], [1, 2]]))\n\n  def testMultiLineTensorStr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_str = str(t)\n    self.assertIn(\"shape=%s, dtype=%s\" % (t.shape, t.dtype.name), tensor_str)\n    self.assertIn(str(t), tensor_str)\n\n  def testMultiLineTensorRepr(self):\n    t = _create_tensor(np.eye(3))\n    tensor_repr = repr(t)\n    self.assertTrue(tensor_repr.startswith(\"<\"))\n    self.assertTrue(tensor_repr.endswith(\">\"))\n    self.assertIn(\n        \"shape=%s, dtype=%s, numpy=\\n%r\" % (t.shape, t.dtype.name, t.numpy()),\n        tensor_repr)\n\n  def testTensorStrReprObeyNumpyPrintOptions(self):\n    orig_threshold = np.get_printoptions()[\"threshold\"]\n    orig_edgeitems = np.get_printoptions()[\"edgeitems\"]\n    np.set_printoptions(threshold=2, edgeitems=1)\n\n    t = _create_tensor(np.arange(10, dtype=np.int32))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", str(t)))\n    self.assertTrue(re.match(r\".*\\[.*0.*\\.\\.\\..*9.*\\]\", repr(t)))\n\n    # Clean up: reset to previous printoptions.\n    np.set_printoptions(threshold=orig_threshold, edgeitems=orig_edgeitems)\n\n  def testZeroDimTensorStr(self):\n    t = _create_tensor(42)\n    self.assertIn(\"42, shape=(), dtype=int32\", str(t))\n\n  def testZeroDimTensorRepr(self):\n    t = _create_tensor(42)\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(), dtype=int32, numpy=42\", repr(t))\n\n  def testZeroSizeTensorStr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertIn(\"[], shape=(0,), dtype=float32\", str(t))\n\n  def testZeroSizeTensorRepr(self):\n    t = _create_tensor(np.zeros(0, dtype=np.float32))\n    self.assertTrue(repr(t).startswith(\"<\"))\n    self.assertTrue(repr(t).endswith(\">\"))\n    self.assertIn(\"shape=(0,), dtype=float32, numpy=%r\" % t.numpy(), repr(t))\n\n  def testStringTensor(self):\n    t_np_orig = np.array([[b\"a\", b\"ab\"], [b\"abc\", b\"abcd\"]])\n    t = _create_tensor(t_np_orig)\n    t_np = t.numpy()\n    self.assertTrue(np.all(t_np == t_np_orig), \"%s vs %s\" % (t_np, t_np_orig))\n\n  def testIterateOverTensor(self):\n    l = [[1, 2], [3, 4]]\n    t = _create_tensor(l)\n    for list_element, tensor_element in zip(l, t):\n      self.assertAllEqual(list_element, tensor_element.numpy())\n\n  def testIterateOverScalarTensorRaises(self):\n    t = _create_tensor(1)\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot iterate over a scalar tensor\"):\n      iter(t)\n\n  @test_util.run_gpu_only\n  def testStringTensorOnGPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = _create_tensor(\"test string\")\n      self.assertIn(\"GPU\", t.device)\n\n  def testInvalidUTF8ProducesReasonableError(self):\n    if sys.version_info[0] < 3:\n      self.skipTest(\"Test is only valid in python3.\")\n    with self.assertRaises(UnicodeDecodeError):\n      io_ops.read_file(b\"\\xff\")\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorPreferredDtypeIsRespected(self):\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.int32).dtype,\n        dtypes.float32)\n    self.assertEqual(\n        ops.convert_to_tensor(0.5, preferred_dtype=dtypes.float64).dtype,\n        dtypes.float64)\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCompatibility(self):\n    integer_types = [\n        dtypes.int8, dtypes.int16, dtypes.int32, dtypes.int64, dtypes.uint8,\n        dtypes.uint16, dtypes.uint32, dtypes.uint64\n    ]\n\n    # Floats are not compatible with ints\n    for t in integer_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # Ints compatible with floats\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float16)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float32)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.float64)), 5.0)\n    self.assertEqual(\n        self.evaluate(constant_op.constant(5, dtype=dtypes.bfloat16)), 5.0)\n\n    # Ints and floats are compatible with complex types\n    self.assertEqual(\n        constant_op.constant([[1.0]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n    self.assertEqual(\n        constant_op.constant([[1]], dtype=dtypes.complex128).dtype,\n        dtypes.complex128)\n\n    # Quantized types are not compatible with floats\n    quantized_types = [\n        dtypes.qint16, dtypes.qint32, dtypes.qint8, dtypes.quint16,\n        dtypes.quint8\n    ]\n\n    for t in quantized_types:\n      with self.assertRaises(TypeError):\n        constant_op.constant(0.5, dtype=t)\n\n    # TODO(b/118402529): quantized types are broken in eager.\n\n  @test_util.run_in_graph_and_eager_modes\n  def testCConvertToTensor(self):\n    with self.assertRaises(TypeError):\n      _ = constant_op.constant(0) < 0.5\n\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorAllowsOverflow(self):\n    _ = ops.convert_to_tensor(123456789, dtype=dtypes.uint8)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyZeroDim(self):\n    for np_type, dtype in [(np.int32, dtypes.int32), (np.half, dtypes.half),\n                           (np.float32, dtypes.float32)]:\n      x = ops.convert_to_tensor(\n          [np.array(65, dtype=np_type),\n           np.array(16, dtype=np_type)])\n      self.assertEqual(x.dtype, dtype)\n      self.assertAllEqual(x, [65, 16])\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  @test_util.run_in_graph_and_eager_modes\n  def testConvertToTensorNumpyScalar(self):\n    x = ops.convert_to_tensor([\n        np.array(321, dtype=np.int64).item(),\n        np.array(16, dtype=np.int64).item()\n    ])\n    self.assertAllEqual(x, [321, 16])\n\n  def testEagerTensorError(self):\n    with self.assertRaisesRegex(TypeError,\n                                \"Cannot convert .* to EagerTensor of dtype .*\"):\n      _ = ops.convert_to_tensor(1., dtype=dtypes.int32)\n\n  def testEagerLargeConstant(self):\n    for t in [dtypes.uint64, dtypes.uint32, dtypes.int32, dtypes.int64]:\n      self.assertEqual(constant_op.constant(t.max, dtype=t).numpy(), t.max)\n      self.assertEqual(constant_op.constant(t.min, dtype=t).numpy(), t.min)\n\n  def test_numpyIsView(self):\n    with ops.device(\"CPU\"):\n      t = constant_op.constant([0.0])\n      t._numpy()[0] = 42.0\n      self.assertAllClose(t, constant_op.constant([42.0]))\n\n  def test_numpyFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ resource\"):\n      v._handle._numpy()\n\n  def test_numpyFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Cannot convert .+ variant\"):\n      variant_t._numpy()\n\n  def testMemoryviewFailsForResource(self):\n    v = variables.Variable(42)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ resource\"):\n      np.asarray(memoryview(v._handle))\n\n  def testMemoryviewFailsForVariant(self):\n    variant_t = list_ops.tensor_list_reserve(\n        element_shape=[], num_elements=1, element_dtype=dtypes.float32)\n    with self.assertRaisesRegex(BufferError, \"Cannot convert .+ variant\"):\n      np.asarray(memoryview(variant_t))\n\n  def testMemoryviewIsReadonly(self):\n    t = constant_op.constant([0.0])\n    self.assertTrue(memoryview(t).readonly)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewScalar(self):\n    t = constant_op.constant(42.0)\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array(42.0, dtype=np.float32))\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewEmpty(self):\n    t = constant_op.constant([], dtype=np.float32)\n    self.assertAllEqual(np.array(memoryview(t)), np.array([]))\n\n  @test_util.run_gpu_only\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testMemoryviewCopyToCPU(self):\n    with ops.device(\"/device:GPU:0\"):\n      t = constant_op.constant([0.0])\n    self.assertAllEqual(\n        np.array(memoryview(t)), np.array([0.0], dtype=np.float32))\n\n  @test_util.disable_tfrt(\"b/169877776: ResourceVariable is not initialized \"\n                          \"properly in TFRT\")\n  def testResourceTensorCopy(self):\n    if not test_util.is_gpu_available():\n      self.skipTest(\"GPU only\")\n\n    with ops.device(\"GPU:0\"):\n      v = resource_variable_ops.ResourceVariable(1.)\n\n    read_handle_on_gpu = resource_variable_ops.read_variable_op(\n        v.handle, dtypes.float32)\n    handle_on_cpu = v.handle.cpu()\n    read_handle_on_cpu = resource_variable_ops.read_variable_op(\n        handle_on_cpu, dtypes.float32)\n\n    self.assertAllEqual(read_handle_on_cpu, read_handle_on_gpu)\n\n  def testEagerTensorFormat(self):\n    t = array_ops.constant(1)\n    self.assertEqual(f\"{t}\", \"1\")\n    self.assertEqual(str(t), \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(f\"{t!s}\", \"tf.Tensor(1, shape=(), dtype=int32)\")\n    self.assertEqual(repr(t), \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n    self.assertEqual(f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=int32, numpy=1>\")\n\n  def testEagerTensorFormatForResource(self):\n    t = resource_variable_ops.VarHandleOp(shape=[], dtype=dtypes.float32)\n\n    # type is compiler-depdendent, as it comes from demangling.\n    handle_str = (f\"<ResourceHandle(\"\n                  f\"name=\\\"\\\", \"\n                  f\"device=\\\"{t.device}\\\", \"\n                  f\"container=\\\"localhost\\\", \"\n                  f\"type=\\\"@@tensorflow@@Var@@\\\")>\")\n\n    def make_regex(s):\n      return re.escape(s).replace(\"@@\", \".*\")\n\n    self.assertRegex(f\"{t}\", make_regex(handle_str))\n    self.assertRegex(\n        str(t),\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        f\"{t!s}\",\n        make_regex(f\"tf.Tensor({handle_str}, shape=(), dtype=resource)\"))\n    self.assertRegex(\n        repr(t),\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n    self.assertRegex(\n        f\"{t!r}\",\n        make_regex(\n            f\"<tf.Tensor: shape=(), dtype=resource, value={handle_str}>\"))\n\n  def testEagerTensorFormatForVariant(self):\n    t = list_ops.tensor_list_reserve(\n        element_shape=[1], num_elements=1, element_dtype=dtypes.float32)\n    self.assertEqual(f\"{t}\", \"<TensorList>\")\n    self.assertEqual(str(t), \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(f\"{t!s}\",\n                     \"tf.Tensor(<TensorList>, shape=(), dtype=variant)\")\n    self.assertEqual(\n        repr(t), \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n    self.assertEqual(\n        f\"{t!r}\", \"<tf.Tensor: shape=(), dtype=variant, value=<TensorList>>\")\n\n  def testNumpyTooManyDimensions(self):\n    t = constant_op.constant(1., shape=[1] * 33)\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        \"Cannot convert tensor with 33 dimensions to NumPy array. NumPy arrays \"\n        \"can have at most 32 dimensions\"):\n      t.numpy()\n\n  def testNumpyDimsTooBig(self):\n    # Creating a Numpy array fails in some cases if the product of non-zero\n    # dimensions is very big, even if the shape also has a zero in it.\n    t = array_ops.ones((0, 2**31, 2**31))\n    with self.assertRaisesRegex(\n        errors.InvalidArgumentError,\n        r\"Failed to create numpy array from tensor of shape \"\n        r\"\\[0, 2147483648, 2147483648\\]. Numpy error.*array is too big\"):\n      t.numpy()\n\n\nclass TFETensorUtilTest(test_util.TensorFlowTestCase):\n\n  def setUp(self):\n    super(TFETensorUtilTest, self).setUp()\n    context.ensure_initialized()\n\n  def testListOfThree(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([[1, 2, 5], [3, 4, 5]], dtype=dtypes.int32)\n    t3 = _create_tensor([[1], [3], [5], [6]], dtype=dtypes.int32)\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 0)\n    self.assertAllEqual(np.array([3, 2, 4]), r.numpy())\n\n    r = pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2, t3], 1)\n    self.assertAllEqual(np.array([2, 3, 1]), r.numpy())\n\n  def testEmptyTensorList(self):\n    a = pywrap_tfe.TFE_Py_TensorShapeSlice([], 0)\n    self.assertTrue(isinstance(a, ops.EagerTensor))\n    self.assertEqual(0, a.numpy().size)\n\n  def testTensorListContainsNonTensors(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 1 has type \\\"str\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, \"abc\"], 0)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"Expected a list of EagerTensors but element 0 has type \\\"int\\\"\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([2, t1], 0)\n\n  def testTensorListNotList(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        TypeError,\n        r\"tensors argument must be a list or a tuple. Got.*EagerTensor\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice(t1, -2)\n\n  def testNegativeSliceDim(self):\n    t1 = _create_tensor([1, 2], dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        ValueError, r\"Slice dimension must be non-negative. Got -2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], -2)\n\n  def testUnicode(self):\n    self.assertEqual(constant_op.constant(u\"asdf\").numpy(), b\"asdf\")\n\n  def testFloatTensor(self):\n    self.assertEqual(dtypes.float64, _create_tensor(np.float64()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(np.float32()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float16, _create_tensor(np.float16()).dtype)  # pylint: disable=no-value-for-parameter\n    self.assertEqual(dtypes.float32, _create_tensor(0.0).dtype)\n\n  def testSliceDimOutOfRange(self):\n    t1 = _create_tensor([[1, 2], [3, 4], [5, 6]], dtype=dtypes.int32)\n    t2 = _create_tensor([1, 2], dtype=dtypes.int32)\n    t3 = _create_tensor(2, dtype=dtypes.int32)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(2\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 2\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1], 2)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(1\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 1 has rank 1\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t1, t2], 1)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 0 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t3], 0)\n\n    with self.assertRaisesRegex(\n        IndexError,\n        r\"Slice dimension \\(0\\) must be smaller than rank of all tensors, \"\n        \"but tensor at index 2 has rank 0\"):\n      pywrap_tfe.TFE_Py_TensorShapeSlice([t2, t1, t3], 0)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testTensorDir(self):\n    t = array_ops.ones(1)\n    t.test_attr = \"Test\"\n\n    instance_dir = dir(t)\n    type_dir = dir(ops.EagerTensor)\n\n    # Monkey patched attributes should show up in dir(t)\n    self.assertIn(\"test_attr\", instance_dir)\n    instance_dir.remove(\"test_attr\")\n    self.assertEqual(instance_dir, type_dir)\n\n  def testNonRectangularPackAsConstant(self):\n    l = [array_ops.zeros((10, 1)).numpy(), array_ops.zeros(1).numpy()]\n\n    with self.assertRaisesRegex(ValueError, \"non-rectangular Python sequence\"):\n      constant_op.constant(l)\n\n  @test_util.assert_no_new_pyobjects_executing_eagerly\n  def testFloatAndIntAreConvertibleToComplex(self):\n    a = [[1., 1], [1j, 2j]]\n    np_value = np.array(a, dtype=np.complex128)\n    tf_value = ops.convert_to_tensor(a, dtype=dtypes.complex128)\n    self.assertAllEqual(tf_value.numpy(), np_value)\n\n\nif __name__ == \"__main__\":\n  test.main()"