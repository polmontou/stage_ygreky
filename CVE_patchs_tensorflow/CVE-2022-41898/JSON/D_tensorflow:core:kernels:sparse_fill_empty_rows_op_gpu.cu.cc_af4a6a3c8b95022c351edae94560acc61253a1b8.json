"diff --git a/tensorflow/core/kernels/sparse_fill_empty_rows_op_gpu.cu.cc b/tensorflow/core/kernels/sparse_fill_empty_rows_op_gpu.cu.cc\nindex 37ce6c88e36..62e9cea0f23 100644\n--- a/tensorflow/core/kernels/sparse_fill_empty_rows_op_gpu.cu.cc\n+++ b/tensorflow/core/kernels/sparse_fill_empty_rows_op_gpu.cu.cc\n@@ -297,9 +297,12 @@ struct SparseFillEmptyRows<GPUDevice, T, Tindex> {\n       empty_row_indicator = empty_row_indicator_t.vec<bool>().data();\n     }\n \n-    TF_RETURN_IF_ERROR(wrap_kernel_call(ComputeEmptyRowIndicatorKernel<Tindex>,\n-                                        /*device=*/device, /*size=*/dense_rows,\n-                                        elements_per_row, empty_row_indicator));\n+    if (dense_rows > 0) {\n+      TF_RETURN_IF_ERROR(\n+          wrap_kernel_call(ComputeEmptyRowIndicatorKernel<Tindex>,\n+                           /*device=*/device, /*size=*/dense_rows,\n+                           elements_per_row, empty_row_indicator));\n+    }\n \n     // For each row, the number of empty rows up to and including that row.\n     Tensor num_empty_rows_through_t;\n@@ -405,14 +408,16 @@ struct SparseFillEmptyRows<GPUDevice, T, Tindex> {\n             done);\n       }\n \n-      OP_REQUIRES_OK_ASYNC(\n-          context,\n-          wrap_kernel_call(ScatterNewElementsKernel<T, Tindex>,\n-                           /*device=*/device, /*size=*/dense_rows, rank,\n-                           default_value, num_empty_rows_through,\n-                           input_row_ends, empty_row_indicator, output_indices,\n-                           output_values),\n-          done);\n+      if (dense_rows > 0) {\n+        OP_REQUIRES_OK_ASYNC(\n+            context,\n+            wrap_kernel_call(ScatterNewElementsKernel<T, Tindex>,\n+                             /*device=*/device, /*size=*/dense_rows, rank,\n+                             default_value, num_empty_rows_through,\n+                             input_row_ends, empty_row_indicator,\n+                             output_indices, output_values),\n+            done);\n+      }\n \n       done();\n     };\n@@ -461,9 +466,11 @@ struct SparseFillEmptyRows<GPUDevice, T, Tindex> {\n     TF_RETURN_IF_ERROR(\n         context->allocate_temp(index_type, TensorShape({N}), &row_indices_t));\n     auto row_indices = row_indices_t.flat<Tindex>();\n-    TF_RETURN_IF_ERROR(wrap_kernel_call(CopyRowIndicesKernel<Tindex>,\n-                                        /*device=*/device, /*size=*/N, rank,\n-                                        indices, row_indices));\n+    if (N > 0) {\n+      TF_RETURN_IF_ERROR(wrap_kernel_call(CopyRowIndicesKernel<Tindex>,\n+                                          /*device=*/device, /*size=*/N, rank,\n+                                          indices, row_indices));\n+    }\n     // Allocate input_index_map.\n     TF_RETURN_IF_ERROR(context->allocate_temp(index_type, TensorShape({N}),\n                                               input_index_map_t));\n@@ -528,9 +535,11 @@ struct SparseFillEmptyRowsGrad<GPUDevice, T, Tindex> {\n     auto visited = visited_t.vec<bool>();\n     visited.device(device) = visited.constant(false);\n \n-    TF_RETURN_IF_ERROR(wrap_kernel_call(\n-        GatherOriginalGradValuesKernel<T, Tindex>, /*device=*/device,\n-        /*size=*/N, reverse_index_map, grad_values, d_values, visited));\n+    if (N > 0) {\n+      TF_RETURN_IF_ERROR(wrap_kernel_call(\n+          GatherOriginalGradValuesKernel<T, Tindex>, /*device=*/device,\n+          /*size=*/N, reverse_index_map, grad_values, d_values, visited));\n+    }\n \n     // Now we mask out the visited values and sum the remaining ones (which\n     // correspond to the empty rows in the forward input) to compute"