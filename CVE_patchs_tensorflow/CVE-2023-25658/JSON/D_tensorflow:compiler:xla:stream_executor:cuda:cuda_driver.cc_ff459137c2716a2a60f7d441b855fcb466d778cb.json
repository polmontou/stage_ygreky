"diff --git a/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc b/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc\nindex a61a6b1a067..9c0f6c22e87 100644\n--- a/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc\n+++ b/tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc\n@@ -35,10 +35,10 @@ limitations under the License.\n #include \"absl/synchronization/notification.h\"\n #include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"\n #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.h\"\n-#include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"\n #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"\n #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"\n #include \"tensorflow/tsl/platform/env.h\"\n+#include \"tensorflow/tsl/platform/errors.h\"\n #include \"tensorflow/tsl/platform/stacktrace.h\"\n #include \"tensorflow/tsl/platform/static_threadlocal.h\"\n #include \"tensorflow/tsl/platform/threadpool.h\"\n@@ -267,7 +267,7 @@ static tsl::Status InternalInit() {\n   }\n \n   Diagnostician::LogDiagnosticInformation();\n-  return tsl::Status(port::error::ABORTED,\n+  return tsl::Status(tsl::error::ABORTED,\n                      absl::StrCat(\"failed call to cuInit: \", ToString(res)));\n }\n \n@@ -400,7 +400,7 @@ bool DeviceOptionsToContextFlags(const DeviceOptions& device_options,\n     }\n   }\n \n-  return tsl::Status(port::error::INTERNAL, message);\n+  return tsl::Status(tsl::error::INTERNAL, message);\n }\n \n /* static */ void GpuDriver::DestroyContext(GpuContext* context) {\n@@ -673,7 +673,7 @@ bool DeviceOptionsToContextFlags(const DeviceOptions& device_options,\n   }\n \n   return tsl::Status(\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       absl::StrCat(\"failed to get device for context: \", ToString(result)));\n }\n \n@@ -972,7 +972,7 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n /* static */ tsl::Status GpuDriver::DestroyEvent(GpuContext* context,\n                                                  CUevent* event) {\n   if (*event == nullptr) {\n-    return tsl::Status(port::error::INVALID_ARGUMENT,\n+    return tsl::Status(tsl::error::INVALID_ARGUMENT,\n                        \"input event cannot be null\");\n   }\n \n@@ -997,7 +997,7 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n   CUresult res = cuEventQuery(event);\n   if (res != CUDA_SUCCESS && res != CUDA_ERROR_NOT_READY) {\n     return tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\"failed to query event: %s\", ToString(res)));\n   }\n \n@@ -1263,11 +1263,11 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n   if (res == CUDA_SUCCESS) {\n     return ::tsl::OkStatus();\n   } else if (res == CUDA_ERROR_OUT_OF_MEMORY) {\n-    return tsl::Status(port::error::RESOURCE_EXHAUSTED,\n+    return tsl::Status(tsl::error::RESOURCE_EXHAUSTED,\n                        \"could not create CUDA event: out of device memory\");\n   } else {\n     return tsl::Status(\n-        port::error::FAILED_PRECONDITION,\n+        tsl::error::FAILED_PRECONDITION,\n         absl::StrCat(\"could not create CUDA event: \", ToString(res)));\n   }\n }\n@@ -1299,14 +1299,14 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n     // error then the original one.\n     if (context == nullptr) {\n       return tsl::Status(\n-          port::error::UNAVAILABLE,\n+          tsl::error::UNAVAILABLE,\n           \"Empty context returned while querying context for device pointer\");\n     }\n     return context;\n   }\n \n   return tsl::Status(\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       absl::StrCat(\"failed to query context for device pointer: \",\n                    ToString(result)));\n }\n@@ -1324,13 +1324,13 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n         return MemorySpace::kHost;\n       default:\n         return tsl::Status(\n-            port::error::INTERNAL,\n+            tsl::error::INTERNAL,\n             absl::StrCat(\"unknown memory space provided by CUDA API: \", value));\n     }\n   }\n \n   return tsl::Status(\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       absl::StrCat(\"failed to query device pointer for memory space: \",\n                    ToString(result)));\n }\n@@ -1346,13 +1346,13 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n     // \"there was an internal error while performing this operation\" (return\n     // below).\n     return tsl::Status(\n-        port::error::NOT_FOUND,\n+        tsl::error::NOT_FOUND,\n         absl::StrFormat(\"not a device pointer %p; %s\",\n                         reinterpret_cast<void*>(dptr), ToString(result)));\n   }\n \n   return tsl::Status(\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       absl::StrFormat(\"failed to get pointer into for device pointer %p; %s\",\n                       reinterpret_cast<void*>(dptr), ToString(result)));\n }\n@@ -1377,7 +1377,7 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n       cc_major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);\n   if (res != CUDA_SUCCESS) {\n     return tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\n             \"failed to get compute capability major for device: %s; %d\",\n             ToString(res), device));\n@@ -1387,7 +1387,7 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n       cc_minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);\n   if (res != CUDA_SUCCESS) {\n     return tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\n             \"failed to get compute capability minor for device: %s; %d\",\n             ToString(res), device));\n@@ -1399,13 +1399,13 @@ GpuDriver::CreateMemoryHandle(GpuContext* context, uint64_t bytes) {\n /* static */ tsl::Status GpuDriver::GetGpuISAVersion(int* version,\n                                                      CUdevice device) {\n   return tsl::Status{\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       \"Feature not supported on CUDA platform (GetGpuISAVersion)\"};\n }\n \n /* static */ tsl::Status GpuDriver::GetGpuGCNArchName(CUdevice, std::string*) {\n   return tsl::Status{\n-      port::error::INTERNAL,\n+      tsl::error::INTERNAL,\n       \"Feature not supported on CUDA platform (GetGpuGCNArchName)\"};\n }\n \n@@ -1519,7 +1519,7 @@ static tsl::StatusOr<T> GetSimpleAttribute(CUdevice device,\n   CUresult res = cuDeviceGetAttribute(&val, attribute, device);\n   if (res != CUDA_SUCCESS) {\n     return tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\"failed to get device attribute %d for device %d: %s\",\n                         attribute, device, ToString(res)));\n   }\n@@ -1628,7 +1628,7 @@ static tsl::StatusOr<T> GetSimpleAttribute(CUdevice device,\n   if (result != CUDA_SUCCESS &&\n       result != CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED) {\n     return tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\"failed to enable peer access from %p to %p: %s\", from,\n                         to, ToString(result)));\n   }"