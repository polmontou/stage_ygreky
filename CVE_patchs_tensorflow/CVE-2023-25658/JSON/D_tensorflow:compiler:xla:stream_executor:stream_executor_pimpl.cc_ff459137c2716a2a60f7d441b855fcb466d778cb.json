"diff --git a/tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc b/tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc\nindex c6babbe4919..8dc30fd966e 100644\n--- a/tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc\n+++ b/tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc\n@@ -32,11 +32,11 @@ limitations under the License.\n #include \"absl/synchronization/notification.h\"\n #include \"tensorflow/compiler/xla/stream_executor/blas.h\"\n #include \"tensorflow/compiler/xla/stream_executor/fft.h\"\n-#include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"\n #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"\n #include \"tensorflow/compiler/xla/stream_executor/rng.h\"\n #include \"tensorflow/compiler/xla/stream_executor/stream.h\"\n #include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"\n+#include \"tensorflow/tsl/platform/errors.h\"\n #include \"tensorflow/tsl/platform/stacktrace.h\"\n #include \"tensorflow/tsl/platform/statusor.h\"\n #include \"tensorflow/tsl/platform/threadpool.h\"\n@@ -405,7 +405,7 @@ StreamExecutor::createRnnDescriptor(\n     bool use_padded_io) {\n   dnn::DnnSupport* dnn_support = AsDnn();\n   if (!dnn_support) {\n-    return tsl::Status(port::error::UNKNOWN,\n+    return tsl::Status(tsl::error::UNKNOWN,\n                        \"Fail to find the dnn implementation.\");\n   }\n   return dnn_support->createRnnDescriptor(\n@@ -420,7 +420,7 @@ StreamExecutor::createRnnSequenceTensorDescriptor(int max_seq_length,\n                                                   dnn::DataType data_type) {\n   dnn::DnnSupport* dnn_support = AsDnn();\n   if (!dnn_support) {\n-    return tsl::Status(port::error::UNKNOWN,\n+    return tsl::Status(tsl::error::UNKNOWN,\n                        \"Fail to find the dnn implementation.\");\n   }\n   return dnn_support->createRnnSequenceTensorDescriptor(\n@@ -434,7 +434,7 @@ StreamExecutor::createRnnSequenceTensorDescriptor(\n     dnn::DataType data_type) {\n   dnn::DnnSupport* dnn_support = AsDnn();\n   if (!dnn_support) {\n-    return tsl::Status(port::error::UNKNOWN,\n+    return tsl::Status(tsl::error::UNKNOWN,\n                        \"Fail to find the dnn implementation.\");\n   }\n   return dnn_support->createRnnSequenceTensorDescriptor(\n@@ -448,7 +448,7 @@ StreamExecutor::createRnnStateTensorDescriptor(int num_layer, int batch_size,\n                                                dnn::DataType data_type) {\n   dnn::DnnSupport* dnn_support = AsDnn();\n   if (!dnn_support) {\n-    return tsl::Status(port::error::UNKNOWN,\n+    return tsl::Status(tsl::error::UNKNOWN,\n                        \"Fail to find the dnn implementation.\");\n   }\n   return dnn_support->createRnnStateTensorDescriptor(num_layer, batch_size,\n@@ -546,7 +546,7 @@ tsl::StatusOr<DeviceMemoryBase> StreamExecutor::GetUntypedSymbol(\n   }\n \n   return tsl::Status(\n-      port::error::NOT_FOUND,\n+      tsl::error::NOT_FOUND,\n       absl::StrCat(\"Check if module containing symbol \", symbol_name,\n                    \" is loaded (module_handle = \",\n                    reinterpret_cast<uintptr_t>(module_handle.id()), \")\"));\n@@ -691,7 +691,7 @@ tsl::Status StreamExecutor::SynchronousMemcpyD2H(\n   result = implementation_->SynchronousMemcpy(host_dst, device_src, size);\n   if (!result.ok()) {\n     result = tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\"failed to synchronously memcpy device-to-host: device \"\n                         \"%p to host %p size %d: %s\",\n                         device_src.opaque(), host_dst, size,\n@@ -715,7 +715,7 @@ tsl::Status StreamExecutor::SynchronousMemcpyH2D(const void* host_src,\n   result = implementation_->SynchronousMemcpy(device_dst, host_src, size);\n   if (!result.ok()) {\n     result = tsl::Status(\n-        port::error::INTERNAL,\n+        tsl::error::INTERNAL,\n         absl::StrFormat(\"failed to synchronously memcpy host-to-device: host \"\n                         \"%p to device %p size %d: %s\",\n                         host_src, device_dst->opaque(), size,"