"# TensorFlow Bazel configuration file.\n# This file tries to group and simplify build options for TensorFlow\n#\n# ----CONFIG OPTIONS----\n# Android options:\n#    android:\n#    android_arm:\n#    android_arm64:\n#    android_x86:\n#    android_x86_64:\n#\n# iOS options:\n#     ios:\n#     ios_armv7:\n#     ios_arm64:\n#     ios_i386:\n#     ios_x86_64:\n#     ios_fat:\n#\n# Macosx options\n#     darwin_arm64:\n#\n# Compiler options:\n#     cuda_clang:             Use clang when building CUDA code.\n#     avx_linux:              Build with avx instruction set on linux.\n#     avx2_linux:             Build with avx2 instruction set on linux.\n#     native_arch_linux:      Build with instruction sets available to the host machine on linux\n#     avx_win:                Build with avx instruction set on windows\n#     avx2_win:               Build with avx2 instruction set on windows\n#\n# Other build options:\n#     short_logs:       Only log errors during build, skip warnings.\n#     verbose_logs:     Show all compiler warnings during build.\n#     monolithic:       Build all TF C++ code into a single shared object.\n#     dynamic_kernels:  Try to link all kernels dynamically (experimental).\n#     libc++:           Link against libc++ instead of stdlibc++\n#     asan:             Build with the clang address sanitizer\n#     msan:             Build with the clang memory sanitizer\n#     ubsan:            Build with the clang undefined behavior sanitizer\n#     dbg:              Build with debug info\n#\n#\n# TF version options;\n#     v1: Build TF V1 (without contrib)\n#     v2: Build TF v2\n#\n# Feature and Third party library support options:\n#     xla:          Build TF with XLA\n#     tpu:          Build TF with TPU support\n#     cuda:         Build with full cuda support.\n#     rocm:         Build with AMD GPU support (rocm).\n#     mkl:          Enable full mkl support.\n#     tensorrt:     Enable Tensorrt support.\n#     numa:         Enable numa using hwloc.\n#     noaws:        Disable AWS S3 storage support\n#     nogcp:        Disable GCS support.\n#     nohdfs:       Disable hadoop hdfs support.\n#     nonccl:       Disable nccl support.\n#\n#\n# Remote build execution options (only configured to work with TF team projects for now.)\n#     rbe:       General RBE options shared by all flavors.\n#     rbe_linux: General RBE options used on all linux builds.\n#     rbe_win:   General RBE options used on all windows builds.\n#\n#     rbe_cpu_linux:                  RBE options to build with only CPU support.\n#     rbe_linux_cuda_nvcc_py*:        RBE options to build with GPU support using nvcc.\n#\n#     rbe_linux_py3:        Linux Python 3 RBE config\n#\n#     rbe_win_py37: Windows Python 3.7 RBE config\n#     rbe_win_py38: Windows Python 3.8 RBE config\n#     rbe_win_py39: Windows Python 3.9 RBE config\n#     rbe_win_py310: Windows Python 3.10 RBE config\n#\n#     tensorflow_testing_rbe_linux: RBE options to use RBE with tensorflow-testing project on linux\n#     tensorflow_testing_rbe_win:   RBE options to use RBE with tensorflow-testing project on windows\n#\n#     rbe_lite_linux: RBE options to build TF Lite.\n#\n# Embedded Linux options (experimental and only tested with TFLite build yet)\n#     elinux:          General Embedded Linux options shared by all flavors.\n#     elinux_aarch64:  Embedded Linux options for aarch64 (ARM64) CPU support.\n#     elinux_armhf:    Embedded Linux options for armhf (ARMv7) CPU support.\n#\n# Release build options (for all operating systems)\n#     release_base:                    Common options for all builds on all operating systems.\n#     release_gpu_base:                Common options for GPU builds on Linux and Windows.\n#     release_cpu_linux:               Toolchain and CUDA options for Linux CPU builds.\n#     release_cpu_macos:               Toolchain and CUDA options for MacOS CPU builds.\n#     release_gpu_linux:               Toolchain and CUDA options for Linux GPU builds.\n#     release_cpu_windows:             Toolchain and CUDA options for Windows CPU builds.\n#     release_gpu_windows:             Toolchain and CUDA options for Windows GPU builds.\n\n# Default build options. These are applied first and unconditionally.\n\n# For projects which use TensorFlow as part of a Bazel build process, putting\n# nothing in a bazelrc will default to a monolithic build. The following line\n# opts in to modular op registration support by default.\nbuild --define framework_shared_object=true\nbuild --define tsl_protobuf_header_only=true\n\nbuild --define=use_fast_cpp_protos=true\nbuild --define=allow_oversize_protos=true\n\nbuild --spawn_strategy=standalone\nbuild -c opt\n\n# Make Bazel print out all options from rc files.\nbuild --announce_rc\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --define=grpc_no_ares=true\n\n# See https://github.com/bazelbuild/bazel/issues/7362 for information on what\n# --incompatible_remove_legacy_whole_archive flag does.\n# This flag is set to true in Bazel 1.0 and newer versions. We tried to migrate\n# Tensorflow to the default, however test coverage wasn't enough to catch the\n# errors.\n# There is ongoing work on Bazel team's side to provide support for transitive\n# shared libraries. As part of migrating to transitive shared libraries, we\n# hope to provide a better mechanism for control over symbol exporting, and\n# then tackle this issue again.\n#\n# TODO: Remove this line once TF doesn't depend on Bazel wrapping all library\n# archives in -whole_archive -no_whole_archive.\nbuild --noincompatible_remove_legacy_whole_archive\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --enable_platform_specific_config\n\n# Enable XLA support by default.\nbuild --define=with_xla_support=true\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=short_logs\n\n# TODO(mihaimaruseac): Document this option or remove if no longer needed\nbuild --config=v2\n\n# Disable AWS/HDFS support by default\nbuild --define=no_aws_support=true\nbuild --define=no_hdfs_support=true\n\n# TF now has `cc_shared_library` targets, so it needs the experimental flag\n# TODO(rostam): Remove when `cc_shared_library` is enabled by default\nbuild --experimental_cc_shared_library\n\n# cc_shared_library ensures no library is linked statically more than once.\nbuild --experimental_link_static_libraries_once=false\n\n# Prevent regressions on those two incompatible changes\n# TODO: remove those flags when they are flipped in the default Bazel version TF uses.\nbuild --incompatible_enforce_config_setting_visibility\n# TODO: also enable this flag after fixing the visbility violations\n# build --incompatible_config_setting_private_default_visibility\n\n# Default options should come above this line.\n\n# Allow builds using libc++ as a linker library\n# This is mostly for OSSFuzz, so we also pass in the flags from environment to clean build file\nbuild:libc++ --action_env=CC\nbuild:libc++ --action_env=CXX\nbuild:libc++ --action_env=CXXFLAGS=-stdlib=libc++\nbuild:libc++ --action_env=PATH\nbuild:libc++ --define force_libcpp=enabled\nbuild:libc++ --linkopt -fuse-ld=lld\n\n# Android configs. Bazel needs to have --cpu and --fat_apk_cpu both set to the\n# target CPU to build transient dependencies correctly. See\n# https://docs.bazel.build/versions/master/user-manual.html#flag--fat_apk_cpu\nbuild:android --crosstool_top=//external:android/crosstool\nbuild:android --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:android_arm --config=android\nbuild:android_arm --cpu=armeabi-v7a\nbuild:android_arm --fat_apk_cpu=armeabi-v7a\nbuild:android_arm64 --config=android\nbuild:android_arm64 --cpu=arm64-v8a\nbuild:android_arm64 --fat_apk_cpu=arm64-v8a\nbuild:android_x86 --config=android\nbuild:android_x86 --cpu=x86\nbuild:android_x86 --fat_apk_cpu=x86\nbuild:android_x86_64 --config=android\nbuild:android_x86_64 --cpu=x86_64\nbuild:android_x86_64 --fat_apk_cpu=x86_64\n\n# Sets the default Apple platform to macOS.\nbuild:macos --apple_platform_type=macos\n\n# gRPC on MacOS requires this #define\nbuild:macos --copt=-DGRPC_BAZEL_BUILD\n\n# Settings for MacOS on ARM CPUs.\nbuild:macos_arm64 --cpu=darwin_arm64\nbuild:macos_arm64 --macos_minimum_os=11.0\n\n# iOS configs for each architecture and the fat binary builds.\nbuild:ios --apple_platform_type=ios\nbuild:ios --apple_bitcode=embedded --copt=-fembed-bitcode\nbuild:ios --copt=-Wno-c++11-narrowing\nbuild:ios_armv7 --config=ios\nbuild:ios_armv7 --cpu=ios_armv7\nbuild:ios_arm64 --config=ios\nbuild:ios_arm64 --cpu=ios_arm64\nbuild:ios_sim_arm64 --config=ios\nbuild:ios_sim_arm64 --cpu=ios_sim_arm64\nbuild:ios_i386 --config=ios\nbuild:ios_i386 --cpu=ios_i386\nbuild:ios_x86_64 --config=ios\nbuild:ios_x86_64 --cpu=ios_x86_64\nbuild:ios_fat --config=ios\nbuild:ios_fat --ios_multi_cpus=armv7,arm64,i386,x86_64\n\n# Config to use a mostly-static build and disable modular op registration\n# support (this will revert to loading TensorFlow with RTLD_GLOBAL in Python).\n# By default, TensorFlow will build with a dependence on\n# //tensorflow:libtensorflow_framework.so.\nbuild:monolithic --define framework_shared_object=false\nbuild:monolithic --define tsl_protobuf_header_only=false\nbuild:monolithic --experimental_link_static_libraries_once=false  # b/229868128\n\n# Please note that MKL on MacOS or windows is still not supported.\n# If you would like to use a local MKL instead of downloading, please set the\n# environment variable \"TF_MKL_ROOT\" every time before build.\nbuild:mkl --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl --define=build_with_openmp=true\nbuild:mkl -c opt\n\n# config to build OneDNN backend with a user specified threadpool.\nbuild:mkl_threadpool --define=build_with_mkl=true --define=enable_mkl=true\nbuild:mkl_threadpool --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:mkl_threadpool --define=build_with_mkl_opensource=true\nbuild:mkl_threadpool -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\nbuild:mkl_aarch64 --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64 --define=build_with_openmp=true\nbuild:mkl_aarch64 --define=build_with_acl=true\nbuild:mkl_aarch64 -c opt\n\n# Config setting to build oneDNN with Compute Library for the Arm Architecture (ACL).\n# with Eigen threadpool support\nbuild:mkl_aarch64_threadpool --define=build_with_mkl_aarch64=true\nbuild:mkl_aarch64_threadpool -c opt\n\n# This config refers to building CUDA op kernels with nvcc.\nbuild:cuda --repo_env TF_NEED_CUDA=1\nbuild:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain\nbuild:cuda --@local_config_cuda//:enable_cuda\n\n# This config refers to building CUDA op kernels with clang.\nbuild:cuda_clang --config=cuda\nbuild:cuda_clang --repo_env TF_CUDA_CLANG=1\nbuild:cuda_clang --@local_config_cuda//:cuda_compiler=clang\n\n# Debug config\nbuild:dbg -c dbg\n# Only include debug info for files under tensorflow/, excluding kernels, to\n# reduce the size of the debug info in the binary. This is because if the debug\n# sections in the ELF binary are too large, errors can occur. See\n# https://github.com/tensorflow/tensorflow/issues/48919.\n# Users can still include debug info for a specific kernel, e.g. with:\n#     --config=dbg --per_file_copt=+tensorflow/core/kernels/identity_op.*@-g\nbuild:dbg --per_file_copt=+.*,-tensorflow.*@-g0\nbuild:dbg --per_file_copt=+tensorflow/core/kernels.*@-g0\n# for now, disable arm_neon. see: https://github.com/tensorflow/tensorflow/issues/33360\nbuild:dbg --cxxopt -DTF_LITE_DISABLE_X86_NEON\n# AWS SDK must be compiled in release mode. see: https://github.com/tensorflow/tensorflow/issues/37498\nbuild:dbg --copt -DDEBUG_BUILD\n\n# Config to build TPU backend\nbuild:tpu --define=with_tpu_support=true\n\nbuild:tensorrt --repo_env TF_NEED_TENSORRT=1\n\nbuild:rocm --crosstool_top=@local_config_rocm//crosstool:toolchain\nbuild:rocm --define=using_rocm_hipcc=true\nbuild:rocm --define=tensorflow_mkldnn_contraction_kernel=0\nbuild:rocm --repo_env TF_NEED_ROCM=1\n\n# Options extracted from configure script\nbuild:numa --define=with_numa_support=true\n\n# Options to disable default on features\nbuild:noaws --define=no_aws_support=true\nbuild:nogcp --define=no_gcp_support=true\nbuild:nohdfs --define=no_hdfs_support=true\nbuild:nonccl --define=no_nccl_support=true\n\nbuild:stackdriver_support --define=stackdriver_support=true\n\n# Modular TF build options\nbuild:dynamic_kernels --define=dynamic_loaded_kernels=true\nbuild:dynamic_kernels --copt=-DAUTOLOAD_DYNAMIC_KERNELS\n\n# Don't trigger --config=<host platform> when cross-compiling.\nbuild:android --noenable_platform_specific_config\nbuild:ios --noenable_platform_specific_config\n\n# Suppress all C++ compiler warnings, otherwise build logs become 10s of MBs.\nbuild:android --copt=-w\nbuild:ios --copt=-w\nbuild:linux --host_copt=-w\nbuild:macos --copt=-w\nbuild:windows --copt=/W0\nbuild:windows --host_copt=/W0\n\n# Suppress most C++ complier warnings to reduce log size but allow\n# for specific warnings to still be present.\nbuild:linux --copt=\"-Wno-all\"\nbuild:linux --copt=\"-Wno-extra\"\nbuild:linux --copt=\"-Wno-deprecated\"\nbuild:linux --copt=\"-Wno-deprecated-declarations\"\nbuild:linux --copt=\"-Wno-ignored-attributes\"\nbuild:linux --copt=\"-Wno-array-bounds\"\n\n# Add unused-result as an error on Linux.\nbuild:linux --copt=\"-Wunused-result\"\nbuild:linux --copt=\"-Werror=unused-result\"\n# Add switch as an error on Linux.\nbuild:linux --copt=\"-Wswitch\"\nbuild:linux --copt=\"-Werror=switch\"\n# Required for building with clang\nbuild:linux --copt=\"-Wno-error=unused-but-set-variable\"\n\n# On Windows, `__cplusplus` is wrongly defined without this switch\n# See https://devblogs.microsoft.com/cppblog/msvc-now-correctly-reports-__cplusplus/\nbuild:windows --copt=/Zc:__cplusplus\nbuild:windows --host_copt=/Zc:__cplusplus\n\n# Tensorflow uses M_* math constants that only get defined by MSVC headers if\n# _USE_MATH_DEFINES is defined.\nbuild:windows --copt=/D_USE_MATH_DEFINES\nbuild:windows --host_copt=/D_USE_MATH_DEFINES\n\n# Windows has a relatively short command line limit, which TF has begun to hit.\n# See https://docs.bazel.build/versions/main/windows.html\nbuild:windows --features=compiler_param_file\n\n# Speed Windows compile times. Available in VS 16.4 (we are on 16.11). See\n# https://groups.google.com/a/tensorflow.org/d/topic/build/SsW98Eo7l3o/discussion\nbuild:windows --copt=/d2ReducedOptimizeHugeFunctions\nbuild:windows --host_copt=/d2ReducedOptimizeHugeFunctions\n\n# Default paths for TF_SYSTEM_LIBS\nbuild:linux --define=PREFIX=/usr\nbuild:linux --define=LIBDIR=$(PREFIX)/lib\nbuild:linux --define=INCLUDEDIR=$(PREFIX)/include\nbuild:linux --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\nbuild:macos --define=PREFIX=/usr\nbuild:macos --define=LIBDIR=$(PREFIX)/lib\nbuild:macos --define=INCLUDEDIR=$(PREFIX)/include\nbuild:macos --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include\n# TF_SYSTEM_LIBS do not work on windows.\n\n# By default, build TF in C++ 17 mode.\nbuild:android --cxxopt=-std=c++17\nbuild:android --host_cxxopt=-std=c++17\nbuild:ios --cxxopt=-std=c++17\nbuild:ios --host_cxxopt=-std=c++17\nbuild:linux --cxxopt=-std=c++17\nbuild:linux --host_cxxopt=-std=c++17\nbuild:macos --cxxopt=-std=c++17\nbuild:macos --host_cxxopt=-std=c++17\nbuild:windows --cxxopt=/std:c++17\nbuild:windows --host_cxxopt=/std:c++17\n\n# On windows, we still link everything into a single DLL.\nbuild:windows --config=monolithic\n\n# On linux, we dynamically link small amount of kernels\nbuild:linux --config=dynamic_kernels\n\n# Make sure to include as little of windows.h as possible\nbuild:windows --copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --host_copt=-DWIN32_LEAN_AND_MEAN\nbuild:windows --copt=-DNOGDI\nbuild:windows --host_copt=-DNOGDI\n\n# MSVC (Windows): Standards-conformant preprocessor mode\n# See https://docs.microsoft.com/en-us/cpp/preprocessor/preprocessor-experimental-overview\nbuild:windows --copt=/Zc:preprocessor\nbuild:windows --host_copt=/Zc:preprocessor\n\n# Misc build options we need for windows.\nbuild:windows --linkopt=/DEBUG\nbuild:windows --host_linkopt=/DEBUG\nbuild:windows --linkopt=/OPT:REF\nbuild:windows --host_linkopt=/OPT:REF\nbuild:windows --linkopt=/OPT:ICF\nbuild:windows --host_linkopt=/OPT:ICF\n\n# Verbose failure logs when something goes wrong\nbuild:windows --verbose_failures\n\n# Work around potential issues with large command lines on windows.\n# See: https://github.com/bazelbuild/bazel/issues/5163\nbuild:windows --features=compiler_param_file\n\n# On windows, we never cross compile\nbuild:windows --distinct_host_configuration=false\n# On linux, don't cross compile by default\nbuild:linux --distinct_host_configuration=false\n\n# Do not risk cache corruption. See:\n# https://github.com/bazelbuild/bazel/issues/3360\nbuild:linux --experimental_guard_against_concurrent_changes\n\n# Configure short or long logs\nbuild:short_logs --output_filter=DONT_MATCH_ANYTHING\nbuild:verbose_logs --output_filter=\n\n# Instruction set optimizations\n# TODO(gunan): Create a feature in toolchains for avx/avx2 to\n#   avoid having to define linux/win separately.\nbuild:avx_linux --copt=-mavx\nbuild:avx_linux --host_copt=-mavx\nbuild:avx2_linux --copt=-mavx2\nbuild:native_arch_linux --copt=-march=native\nbuild:avx_win --copt=/arch=AVX\nbuild:avx2_win --copt=/arch=AVX2\n\n# Options to build TensorFlow 1.x or 2.x.\nbuild:v1 --define=tf_api_version=1 --action_env=TF2_BEHAVIOR=0\nbuild:v2 --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\n\n# Disable XLA on mobile.\nbuild:xla     --define=with_xla_support=true # TODO: remove, it's on by default.\nbuild:android --define=with_xla_support=false\nbuild:ios     --define=with_xla_support=false\n\n# BEGIN TF REMOTE BUILD EXECUTION OPTIONS\n# Options when using remote execution\n# WARNING: THESE OPTIONS WONT WORK IF YOU DO NOT HAVE PROPER AUTHENTICATION AND PERMISSIONS\n\n# Flag to enable remote config\ncommon --experimental_repo_remote_exec\n\nbuild:rbe --repo_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1\nbuild:rbe --google_default_credentials\nbuild:rbe --bes_backend=buildeventservice.googleapis.com\nbuild:rbe --bes_results_url=\"https://source.cloud.google.com/results/invocations\"\nbuild:rbe --bes_timeout=600s\nbuild:rbe --define=EXECUTOR=remote\nbuild:rbe --distinct_host_configuration=false\nbuild:rbe --flaky_test_attempts=3\nbuild:rbe --jobs=800\nbuild:rbe --remote_executor=grpcs://remotebuildexecution.googleapis.com\nbuild:rbe --remote_timeout=3600\nbuild:rbe --spawn_strategy=remote,worker,standalone,local\ntest:rbe --test_env=USER=anon\n# Attempt to minimize the amount of data transfer between bazel and the remote\n# workers:\nbuild:rbe --remote_download_toplevel\n\nbuild:rbe_linux_base --config=rbe\nbuild:rbe_linux_base --action_env=PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin\"\n\nbuild:rbe_linux --config=rbe_linux_base\n# Non-rbe settings we should include because we do not run configure\nbuild:rbe_linux --config=avx_linux\n# TODO(gunan): Check why we need this specified in rbe, but not in other builds.\nbuild:rbe_linux --linkopt=-lrt\nbuild:rbe_linux --host_linkopt=-lrt\nbuild:rbe_linux --linkopt=-lm\nbuild:rbe_linux --host_linkopt=-lm\n\n# Use the GPU toolchain until the CPU one is ready.\n# https://github.com/bazelbuild/bazel/issues/13623\nbuild:rbe_cpu_linux_base --host_crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_cpu_linux_base --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_cpu_linux_base --extra_toolchains=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_cpu_linux_base --extra_execution_platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_cpu_linux_base --host_platform=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_cpu_linux_base --platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\n\nbuild:rbe_cpu_linux --config=rbe_linux\nbuild:rbe_cpu_linux --config=rbe_cpu_linux_base\n\nbuild:rbe_lite_linux --config=rbe_linux_base\nbuild:rbe_lite_linux --config=rbe_cpu_linux_base\nbuild:rbe_lite_linux --config=rbe_linux_py3_base\nbuild:rbe_lite_linux --noexperimental_check_desugar_deps\n\nbuild:rbe_linux_cuda_base --config=rbe_linux\nbuild:rbe_linux_cuda_base --config=cuda\nbuild:rbe_linux_cuda_base --config=tensorrt\nbuild:rbe_linux_cuda_base --action_env=TF_CUDA_VERSION=11\nbuild:rbe_linux_cuda_base --action_env=TF_CUDNN_VERSION=8\nbuild:rbe_linux_cuda_base --repo_env=REMOTE_GPU_TESTING=1\n# TensorRT 7 for CUDA 11.1 is compatible with CUDA 11.2, but requires\n# libnvrtc.so.11.1. See https://github.com/NVIDIA/TensorRT/issues/1064.\n# TODO(b/187962120): Remove when upgrading to TensorRT 8.\ntest:rbe_linux_cuda_base --test_env=LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-11.1/lib64\"\n\nbuild:rbe_linux_cuda11.2_nvcc_base --config=rbe_linux_cuda_base\nbuild:rbe_linux_cuda11.2_nvcc_base --host_crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cuda11.2_nvcc_base --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cuda11.2_nvcc_base --extra_toolchains=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cuda11.2_nvcc_base --extra_execution_platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda11.2_nvcc_base --host_platform=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda11.2_nvcc_base --platforms=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda11.2_nvcc_base --repo_env=TF_CUDA_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda\"\nbuild:rbe_linux_cuda11.2_nvcc_base --repo_env=TF_TENSORRT_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_tensorrt\"\nbuild:rbe_linux_cuda11.2_nvcc_base --repo_env=TF_NCCL_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_nccl\"\nbuild:rbe_linux_cuda11.2_nvcc_py3.7 --config=rbe_linux_cuda11.2_nvcc_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.7\"\nbuild:rbe_linux_cuda11.2_nvcc_py3.8 --config=rbe_linux_cuda11.2_nvcc_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.8\"\nbuild:rbe_linux_cuda11.2_nvcc_py3.9 --config=rbe_linux_cuda11.2_nvcc_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.9\"\nbuild:rbe_linux_cuda11.2_nvcc_py3.10 --config=rbe_linux_cuda11.2_nvcc_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.10\"\n\n# Map default to CUDA 11.2.\nbuild:rbe_linux_cuda_nvcc_py37 --config=rbe_linux_cuda11.2_nvcc_py3.7\nbuild:rbe_linux_cuda_nvcc_py38 --config=rbe_linux_cuda11.2_nvcc_py3.8\nbuild:rbe_linux_cuda_nvcc_py39 --config=rbe_linux_cuda11.2_nvcc_py3.9\nbuild:rbe_linux_cuda_nvcc_py310 --config=rbe_linux_cuda11.2_nvcc_py3.10\n\n# Deprecated configs that people might still use.\nbuild:rbe_linux_cuda_nvcc --config=rbe_linux_cuda_nvcc_py39\nbuild:rbe_gpu_linux       --config=rbe_linux_cuda_nvcc\n\nbuild:rbe_linux_cuda_clang_base --config=rbe_linux_cuda_base\nbuild:rbe_linux_cuda_clang_base --repo_env TF_CUDA_CLANG=1\nbuild:rbe_linux_cuda_clang_base --@local_config_cuda//:cuda_compiler=clang\nbuild:rbe_linux_cuda_clang_base --crosstool_top=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\nbuild:rbe_linux_cuda_clang_base --extra_toolchains=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_cuda_clang_base --extra_execution_platforms=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda_clang_base --host_platform=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda_clang_base --platforms=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform\"\nbuild:rbe_linux_cuda_clang_base --repo_env=TF_CUDA_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda\"\nbuild:rbe_linux_cuda_clang_base --repo_env=TF_TENSORRT_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_tensorrt\"\nbuild:rbe_linux_cuda_clang_base --repo_env=TF_NCCL_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_nccl\"\nbuild:rbe_linux_cuda_clang_py37 --config=rbe_linux_cuda_clang_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.7\"\nbuild:rbe_linux_cuda_clang_py38 --config=rbe_linux_cuda_clang_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.8\"\nbuild:rbe_linux_cuda_clang_py39 --config=rbe_linux_cuda_clang_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.9\"\nbuild:rbe_linux_cuda_clang_py310 --config=rbe_linux_cuda_clang_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-clang_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.10\"\n\n# ROCm\nbuild:rbe_linux_rocm_base --config=rocm\nbuild:rbe_linux_rocm_base --config=rbe_linux\nbuild:rbe_linux_rocm_base --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_rocm//crosstool:toolchain\"\nbuild:rbe_linux_rocm_base --extra_toolchains=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_rocm//crosstool:toolchain-linux-x86_64\"\nbuild:rbe_linux_rocm_base --extra_execution_platforms=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_platform//:platform\"\nbuild:rbe_linux_rocm_base --host_platform=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_platform//:platform\"\nbuild:rbe_linux_rocm_base --platforms=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_platform//:platform\"\nbuild:rbe_linux_rocm_base --action_env=TF_ROCM_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_rocm\"\nbuild:rbe_linux_rocm_py3.7 --config=rbe_linux_rocm_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_python3.7\"\nbuild:rbe_linux_rocm_py3.8 --config=rbe_linux_rocm_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_python3.8\"\nbuild:rbe_linux_rocm_py3.9 --config=rbe_linux_rocm_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_python3.9\"\nbuild:rbe_linux_rocm_py3.10 --config=rbe_linux_rocm_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-rocm_config_python3.10\"\n\n# Linux CPU\n\nbuild:rbe_linux_py3 --config=rbe_linux\nbuild:rbe_linux_py3 --config=rbe_linux_py3_base\nbuild:rbe_linux_py3_base --python_path=\"/usr/local/bin/python3.9\"\nbuild:rbe_linux_py3_base --repo_env=TF_PYTHON_CONFIG_REPO=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_python3.9\"\n\nbuild:rbe_win --config=rbe\nbuild:rbe_win --crosstool_top=\"//tensorflow/tools/toolchains/win/tf_win_01112023:toolchain\"\nbuild:rbe_win --extra_toolchains=\"//tensorflow/tools/toolchains/win/tf_win_01112023:cc-toolchain-x64_windows\"\nbuild:rbe_win --extra_execution_platforms=\"//tensorflow/tools/toolchains/win:rbe_windows_ltsc2019\"\nbuild:rbe_win --host_platform=\"//tensorflow/tools/toolchains/win:rbe_windows_ltsc2019\"\nbuild:rbe_win --platforms=\"//tensorflow/tools/toolchains/win:rbe_windows_ltsc2019\"\nbuild:rbe_win --shell_executable=C:\\\\tools\\\\msys64\\\\usr\\\\bin\\\\bash.exe\nbuild:rbe_win --experimental_strict_action_env=true\n\n# TODO(gunan): Remove once we use MSVC 2019 with latest patches.\nbuild:rbe_win --define=override_eigen_strong_inline=true\n\n# Don't build the python zip archive in the RBE build.\nbuild:rbe_win --remote_download_minimal\nbuild:rbe_win --enable_runfiles\nbuild:rbe_win --nobuild_python_zip\n\nbuild:rbe_win_py37 --config=rbe\nbuild:rbe_win_py37 --repo_env=TF_PYTHON_CONFIG_REPO=\"@windows_py37_config_python\"\nbuild:rbe_win_py37 --python_path=C:\\\\Python37\\\\python.exe\n\nbuild:rbe_win_py38 --config=rbe\nbuild:rbe_win_py38 --repo_env=PYTHON_BIN_PATH=C:\\\\Python38\\\\python.exe\nbuild:rbe_win_py38 --repo_env=PYTHON_LIB_PATH=C:\\\\Python38\\\\lib\\\\site-packages\nbuild:rbe_win_py38 --repo_env=TF_PYTHON_CONFIG_REPO=//tensorflow/tools/toolchains/win_1803/py38\nbuild:rbe_win_py38 --python_path=C:\\\\Python38\\\\python.exe\n\nbuild:rbe_win_py39 --config=rbe\nbuild:rbe_win_py39 --repo_env=PYTHON_BIN_PATH=C:\\\\Python39\\\\python.exe\nbuild:rbe_win_py39 --repo_env=PYTHON_LIB_PATH=C:\\\\Python39\\\\lib\\\\site-packages\nbuild:rbe_win_py39 --repo_env=TF_PYTHON_CONFIG_REPO=//tensorflow/tools/toolchains/win_1803/py39\nbuild:rbe_win_py39 --python_path=C:\\\\Python39\\\\python.exe\n\nbuild:rbe_win_py310 --config=rbe\nbuild:rbe_win_py310 --repo_env=PYTHON_BIN_PATH=C:\\\\Python310\\\\python.exe\nbuild:rbe_win_py310 --repo_env=PYTHON_LIB_PATH=C:\\\\Python310\\\\lib\\\\site-packages\nbuild:rbe_win_py310 --repo_env=TF_PYTHON_CONFIG_REPO=//tensorflow/tools/toolchains/win_1803/py310\nbuild:rbe_win_py310 --python_path=C:\\\\Python310\\\\python.exe\n\n# These you may need to change for your own GCP project.\nbuild:tensorflow_testing_rbe --project_id=tensorflow-testing\ncommon:tensorflow_testing_rbe_linux --remote_instance_name=projects/tensorflow-testing/instances/default_instance\nbuild:tensorflow_testing_rbe_linux --config=tensorflow_testing_rbe\n# Build GPU binaries for the RBE test machines (Tesla T4s).\nbuild:tensorflow_testing_rbe_linux --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=sm_75\n\ncommon:tensorflow_testing_rbe_win --remote_instance_name=projects/tensorflow-testing/instances/windows\nbuild:tensorflow_testing_rbe_win --config=tensorflow_testing_rbe\n\n# TFLite build configs for generic embedded Linux\nbuild:elinux --crosstool_top=@local_config_embedded_arm//:toolchain\nbuild:elinux --host_crosstool_top=@bazel_tools//tools/cpp:toolchain\nbuild:elinux_aarch64 --config=elinux\nbuild:elinux_aarch64 --cpu=aarch64\nbuild:elinux_aarch64 --distinct_host_configuration=true\nbuild:elinux_armhf --config=elinux\nbuild:elinux_armhf --cpu=armhf\nbuild:elinux_armhf --distinct_host_configuration=true\nbuild:elinux_armhf --copt -mfp16-format=ieee\n# END TF REMOTE BUILD EXECUTION OPTIONS\n\n# Config-specific options should come above this line.\n\n# Load rc file written by ./configure.\ntry-import %workspace%/.tf_configure.bazelrc\n\n# Load rc file with user-specific options.\ntry-import %workspace%/.bazelrc.user\n\n# Here are bazelrc configs for release builds\nbuild:release_base --config=v2\nbuild:release_base --distinct_host_configuration=false\ntest:release_base --flaky_test_attempts=3\ntest:release_base --test_size_filters=small,medium\n\nbuild:release_cpu_linux --config=release_base\nbuild:release_cpu_linux --config=avx_linux\nbuild:release_cpu_linux --crosstool_top=\"@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\"\ntest:release_cpu_linux --test_env=LD_LIBRARY_PATH\n\nbuild:release_cpu_macos --config=release_base\nbuild:release_cpu_macos --config=avx_linux\n\nbuild:release_gpu_base --config=cuda\nbuild:release_gpu_base --action_env=TF_CUDA_VERSION=\"11\"\nbuild:release_gpu_base --action_env=TF_CUDNN_VERSION=\"8\"\nbuild:release_gpu_base --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=\"sm_35,sm_50,sm_60,sm_70,sm_75,compute_80\"\n\nbuild:release_gpu_linux --config=release_cpu_linux\nbuild:release_gpu_linux --config=release_gpu_base\nbuild:release_gpu_linux --config=tensorrt\nbuild:release_gpu_linux --action_env=CUDA_TOOLKIT_PATH=\"/usr/local/cuda-11.2\"\nbuild:release_gpu_linux --action_env=LD_LIBRARY_PATH=\"/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda-11.1/lib64:/usr/local/tensorrt/lib\"\nbuild:release_gpu_linux --action_env=GCC_HOST_COMPILER_PATH=\"/dt9/usr/bin/gcc\"\nbuild:release_gpu_linux --crosstool_top=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain\n\nbuild:release_cpu_windows --config=release_base\nbuild:release_cpu_windows --config=avx_win\nbuild:release_cpu_windows --define=no_tensorflow_py_deps=true\n\nbuild:release_gpu_windows --config=release_cpu_windows\nbuild:release_gpu_windows --config=release_gpu_base\n\n# Address sanitizer\n# CC=clang bazel build --config asan\nbuild:asan --strip=never\nbuild:asan --copt -fsanitize=address\nbuild:asan --copt -DADDRESS_SANITIZER\nbuild:asan --copt -g\nbuild:asan --copt -O3\nbuild:asan --copt -fno-omit-frame-pointer\nbuild:asan --linkopt -fsanitize=address\nbuild:asan --@libjpeg_turbo//:noasm=yes\n\n# Memory sanitizer\n# CC=clang bazel build --config msan\nbuild:msan --strip=never\nbuild:msan --copt -fsanitize=memory\nbuild:msan --copt -DMEMORY_SANITIZER\nbuild:msan --copt -g\nbuild:msan --copt -O3\nbuild:msan --copt -fno-omit-frame-pointer\nbuild:msan --linkopt -fsanitize=memory\n\n# Undefined Behavior Sanitizer\n# CC=clang bazel build --config ubsan\nbuild:ubsan --strip=never\nbuild:ubsan --copt -fsanitize=undefined\nbuild:ubsan --copt -DUNDEFINED_BEHAVIOR_SANITIZER\nbuild:ubsan --copt -g\nbuild:ubsan --copt -O3\nbuild:ubsan --copt -fno-omit-frame-pointer\nbuild:ubsan --linkopt -fsanitize=undefined\nbuild:ubsan --linkopt -lubsan\n\n# Disable TFRT integration for now unless --config=tfrt is specified.\nbuild      --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\n# TODO(b/240450920): We are in the process of migrating JitRt backend to XLA\n# and while we are doing this we can't keep it buildable/testable in OSS.\nbuild:tfrt --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\n\n# TF Fuzztest config\ntry-import fuzztest.bazelrc\nrun:tf_fuzztest --config=fuzztest\n# Should aim to remove these\nbuild:tf_fuzztest --action_env=CC=clang\nbuild:tf_fuzztest --action_env=CXX=clang++\nbuild:tf_fuzztest --spawn_strategy=sandboxed\nbuild:tf_fuzztest --config=monolithic\nbuild:tf_fuzztest --@libjpeg_turbo//:noasm=yes"