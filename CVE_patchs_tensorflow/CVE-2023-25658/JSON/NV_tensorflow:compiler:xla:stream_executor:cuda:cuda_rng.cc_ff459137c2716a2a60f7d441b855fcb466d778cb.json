"/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.h\"\n\n#include <cstdint>\n\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_activation.h\"\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.h\"\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_helpers.h\"\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"\n#include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"\n#include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"\n#include \"tensorflow/compiler/xla/stream_executor/rng.h\"\n#include \"tensorflow/tsl/platform/status.h\"\n// clang-format off\n#include \"third_party/gpus/cuda/include/curand.h\"\n// clang-format on\n\n// Formats curandStatus_t to output prettified values into a log stream.\nstd::ostream &operator<<(std::ostream &in, const curandStatus_t &status) {\n#define OSTREAM_CURAND_STATUS(__name) \\\n  case CURAND_STATUS_##__name:        \\\n    in << \"CURAND_STATUS_\" #__name;   \\\n    return in;\n\n  switch (status) {\n    OSTREAM_CURAND_STATUS(SUCCESS)\n    OSTREAM_CURAND_STATUS(VERSION_MISMATCH)\n    OSTREAM_CURAND_STATUS(NOT_INITIALIZED)\n    OSTREAM_CURAND_STATUS(ALLOCATION_FAILED)\n    OSTREAM_CURAND_STATUS(TYPE_ERROR)\n    OSTREAM_CURAND_STATUS(OUT_OF_RANGE)\n    OSTREAM_CURAND_STATUS(LENGTH_NOT_MULTIPLE)\n    OSTREAM_CURAND_STATUS(LAUNCH_FAILURE)\n    OSTREAM_CURAND_STATUS(PREEXISTING_FAILURE)\n    OSTREAM_CURAND_STATUS(INITIALIZATION_FAILED)\n    OSTREAM_CURAND_STATUS(ARCH_MISMATCH)\n    OSTREAM_CURAND_STATUS(INTERNAL_ERROR)\n    default:\n      in << \"curandStatus_t(\" << static_cast<int>(status) << \")\";\n      return in;\n  }\n}\n\nnamespace stream_executor {\nnamespace gpu {\n\nPLUGIN_REGISTRY_DEFINE_PLUGIN_ID(kGpuRandPlugin);\n\nGpuRng::GpuRng(GpuExecutor* parent) : parent_(parent), rng_(nullptr) {}\n\nGpuRng::~GpuRng() {\n  if (rng_ != nullptr) {\n    cuda::ScopedActivateExecutorContext sac(parent_);\n    curandDestroyGenerator(rng_);\n  }\n}\n\nbool GpuRng::Init() {\n  absl::MutexLock lock(&mu_);\n  CHECK(rng_ == nullptr);\n\n  cuda::ScopedActivateExecutorContext sac(parent_);\n  curandStatus_t ret = curandCreateGenerator(&rng_, CURAND_RNG_PSEUDO_DEFAULT);\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to create random number generator: \" << ret;\n    return false;\n  }\n\n  CHECK(rng_ != nullptr);\n  return true;\n}\n\nbool GpuRng::SetStream(Stream* stream) {\n  cuda::ScopedActivateExecutorContext sac(parent_);\n  curandStatus_t ret = curandSetStream(rng_, AsGpuStreamValue(stream));\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to set stream for random generation: \" << ret;\n    return false;\n  }\n\n  return true;\n}\n\n// Returns true if std::complex stores its contents as two consecutive\n// elements. Tests int, float and double, as the last two are independent\n// specializations.\nconstexpr bool ComplexIsConsecutiveFloats() {\n  return sizeof(std::complex<int>) == 8 && sizeof(std::complex<float>) == 8 &&\n      sizeof(std::complex<double>) == 16;\n}\n\ntemplate <typename T>\nbool GpuRng::DoPopulateRandUniformInternal(Stream* stream, DeviceMemory<T>* v) {\n  absl::MutexLock lock(&mu_);\n  static_assert(ComplexIsConsecutiveFloats(),\n                \"std::complex values are not stored as consecutive values\");\n\n  if (!SetStream(stream)) {\n    return false;\n  }\n\n  // std::complex<T> is currently implemented as two consecutive T variables.\n  uint64_t element_count = v->ElementCount();\n  if (std::is_same<T, std::complex<float>>::value ||\n      std::is_same<T, std::complex<double>>::value) {\n    element_count *= 2;\n  }\n\n  cuda::ScopedActivateExecutorContext sac(parent_);\n  curandStatus_t ret;\n  if (std::is_same<T, float>::value ||\n      std::is_same<T, std::complex<float>>::value) {\n    ret = curandGenerateUniform(\n        rng_, reinterpret_cast<float*>(GpuMemoryMutable(v)), element_count);\n  } else {\n    ret = curandGenerateUniformDouble(\n        rng_, reinterpret_cast<double*>(GpuMemoryMutable(v)), element_count);\n  }\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to do uniform generation of \" << v->ElementCount()\n               << \" \" << TypeString<T>() << \"s at \" << v->opaque() << \": \"\n               << ret;\n    return false;\n  }\n\n  return true;\n}\n\nbool GpuRng::DoPopulateRandUniform(Stream* stream, DeviceMemory<float>* v) {\n  return DoPopulateRandUniformInternal(stream, v);\n}\n\nbool GpuRng::DoPopulateRandUniform(Stream* stream, DeviceMemory<double>* v) {\n  return DoPopulateRandUniformInternal(stream, v);\n}\n\nbool GpuRng::DoPopulateRandUniform(Stream* stream,\n                                   DeviceMemory<std::complex<float>>* v) {\n  return DoPopulateRandUniformInternal(stream, v);\n}\n\nbool GpuRng::DoPopulateRandUniform(Stream* stream,\n                                   DeviceMemory<std::complex<double>>* v) {\n  return DoPopulateRandUniformInternal(stream, v);\n}\n\ntemplate <typename ElemT, typename FuncT>\nbool GpuRng::DoPopulateRandGaussianInternal(Stream* stream, ElemT mean,\n                                            ElemT stddev,\n                                            DeviceMemory<ElemT>* v,\n                                            FuncT func) {\n  absl::MutexLock lock(&mu_);\n\n  if (!SetStream(stream)) {\n    return false;\n  }\n\n  cuda::ScopedActivateExecutorContext sac(parent_);\n  uint64_t element_count = v->ElementCount();\n  curandStatus_t ret =\n      func(rng_, GpuMemoryMutable(v), element_count, mean, stddev);\n\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to do gaussian generation of \" << v->ElementCount()\n               << \" floats at \" << v->opaque() << \": \" << ret;\n    return false;\n  }\n\n  return true;\n}\n\nbool GpuRng::DoPopulateRandGaussian(Stream* stream, float mean, float stddev,\n                                    DeviceMemory<float>* v) {\n  return DoPopulateRandGaussianInternal(stream, mean, stddev, v,\n                                        curandGenerateNormal);\n}\n\nbool GpuRng::DoPopulateRandGaussian(Stream* stream, double mean, double stddev,\n                                    DeviceMemory<double>* v) {\n  return DoPopulateRandGaussianInternal(stream, mean, stddev, v,\n                                        curandGenerateNormalDouble);\n}\n\nbool GpuRng::SetSeed(Stream* stream, const uint8_t* seed, uint64_t seed_bytes) {\n  absl::MutexLock lock(&mu_);\n  CHECK(rng_ != nullptr);\n\n  if (!CheckSeed(seed, seed_bytes)) {\n    return false;\n  }\n\n  if (!SetStream(stream)) {\n    return false;\n  }\n\n  cuda::ScopedActivateExecutorContext sac(parent_);\n  // Requires 8 bytes of seed data; checked in RngSupport::CheckSeed (above)\n  // (which itself requires 16 for API consistency with host RNG fallbacks).\n  curandStatus_t ret = curandSetPseudoRandomGeneratorSeed(\n      rng_, *(reinterpret_cast<const uint64_t*>(seed)));\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to set rng seed: \" << ret;\n    return false;\n  }\n\n  ret = curandSetGeneratorOffset(rng_, 0);\n  if (ret != CURAND_STATUS_SUCCESS) {\n    LOG(ERROR) << \"failed to reset rng position: \" << ret;\n    return false;\n  }\n  return true;\n}\n\n}  // namespace gpu\n\nvoid initialize_curand() {\n  tsl::Status status =\n      PluginRegistry::Instance()->RegisterFactory<PluginRegistry::RngFactory>(\n          cuda::kCudaPlatformId, gpu::kGpuRandPlugin, \"cuRAND\",\n          [](internal::StreamExecutorInterface* parent) -> rng::RngSupport* {\n            gpu::GpuExecutor* cuda_executor =\n                dynamic_cast<gpu::GpuExecutor*>(parent);\n            if (cuda_executor == nullptr) {\n              LOG(ERROR)\n                  << \"Attempting to initialize an instance of the cuRAND \"\n                  << \"support library with a non-CUDA StreamExecutor\";\n              return nullptr;\n            }\n\n            gpu::GpuRng* rng = new gpu::GpuRng(cuda_executor);\n            if (!rng->Init()) {\n              // Note: Init() will log a more specific error.\n              delete rng;\n              return nullptr;\n            }\n            return rng;\n          });\n\n  if (!status.ok()) {\n    LOG(ERROR) << \"Unable to register cuRAND factory: \"\n               << status.error_message();\n  }\n\n  PluginRegistry::Instance()->SetDefaultFactory(\n      cuda::kCudaPlatformId, PluginKind::kRng, gpu::kGpuRandPlugin);\n}\n\n}  // namespace stream_executor\n\nREGISTER_MODULE_INITIALIZER(register_curand,\n                            { stream_executor::initialize_curand(); });"