"/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_CORE_DATA_SERVICE_SERVER_LIB_H_\n#define TENSORFLOW_CORE_DATA_SERVICE_SERVER_LIB_H_\n\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"grpcpp/server.h\"\n#include \"grpcpp/server_builder.h\"\n#include \"tensorflow/core/data/service/data_transfer.h\"\n#include \"tensorflow/core/data/service/export.pb.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/profiler/rpc/profiler_service_impl.h\"\n#include \"tensorflow/core/protobuf/service_config.pb.h\"\n\nnamespace tensorflow {\nnamespace data {\n\n// Forward declared because transitively depending on .grpc.pb.h files causes\n// issues in the pywrap build.\nclass GrpcDispatcherImpl;\nclass GrpcWorkerImpl;\n\n// A grpc server for the tf.data service.\nclass GrpcDataServerBase {\n public:\n  // Constructs a tf.data server with the specified port. If the port is 0, the\n  // server will find an available port in `Start()`. The chosen port can be\n  // found by calling `BoundPort()`.\n  GrpcDataServerBase(\n      int requested_port, const std::string& protocol,\n      const std::string& server_type,\n      std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options = {});\n  virtual ~GrpcDataServerBase() = default;\n\n  // Starts the server running asynchronously.\n  Status Start();\n\n  // Stops the server. This will block until all outstanding requests complete.\n  void Stop();\n\n  // Blocks until the server stops.\n  void Join();\n\n  // Returns the port bound by the server. Only valid after calling Start().\n  int BoundPort();\n\n  // Exports the server state to improve debuggability.\n  virtual ServerStateExport ExportState() const = 0;\n\n protected:\n  virtual void AddDataServiceToBuilder(::grpc::ServerBuilder& builder) = 0;\n  void AddProfilerServiceToBuilder(::grpc::ServerBuilder& builder);\n  // Starts the service. This will be called after building the service, so\n  // bound_port() will return the actual bound port.\n  virtual Status StartServiceInternal() = 0;\n  virtual void StopServiceInternal() {}\n\n  int bound_port() { return bound_port_; }\n\n  const int requested_port_;\n  const std::string protocol_;\n  const std::string server_type_;\n\n private:\n  int bound_port_;\n  bool started_ = false;\n  bool stopped_ = false;\n\n  std::unique_ptr<::grpc::Server> server_;\n  // TensorFlow profiler service implementation.\n  std::unique_ptr<grpc::ProfilerService::Service> profiler_service_ = nullptr;\n  std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> server_options_;\n};\n\nclass DispatchGrpcDataServer : public GrpcDataServerBase {\n public:\n  explicit DispatchGrpcDataServer(\n      const experimental::DispatcherConfig& config,\n      std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options = {});\n  ~DispatchGrpcDataServer() override;\n\n  // Returns the number of workers registered with the dispatcher.\n  Status NumWorkers(int* num_workers);\n  // Returns the number of active (non-finished) iterations running on the\n  // dispatcher.\n  size_t NumActiveIterations();\n\n  ServerStateExport ExportState() const override;\n\n protected:\n  void AddDataServiceToBuilder(::grpc::ServerBuilder& builder) override;\n  Status StartServiceInternal() override;\n\n private:\n  const experimental::DispatcherConfig config_;\n  // Owned. We use a raw pointer because GrpcDispatcherImpl is forward-declared.\n  GrpcDispatcherImpl* service_;\n};\n\nclass WorkerGrpcDataServer : public GrpcDataServerBase {\n public:\n  explicit WorkerGrpcDataServer(\n      const experimental::WorkerConfig& config,\n      std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options = {});\n  ~WorkerGrpcDataServer() override;\n\n  // Returns the number of tasks currently being executed by the worker.\n  Status NumTasks(int* num_tasks);\n\n  ServerStateExport ExportState() const override;\n\n protected:\n  void AddDataServiceToBuilder(::grpc::ServerBuilder& builder) override;\n  Status StartServiceInternal() override;\n  void StopServiceInternal() override;\n\n private:\n  const experimental::WorkerConfig config_;\n  // Owned. We use a raw pointer because GrpcWorkerImpl is forward-declared.\n  GrpcWorkerImpl* service_;\n  std::shared_ptr<DataTransferServer> transfer_server_;\n};\n\n// Creates a dispatch tf.data server and stores it in `out_server`.\nStatus NewDispatchServer(const experimental::DispatcherConfig& config,\n                         std::unique_ptr<DispatchGrpcDataServer>& out_server);\n\n// Creates a worker tf.data server and stores it in `out_server`.\nStatus NewWorkerServer(const experimental::WorkerConfig& config,\n                       std::unique_ptr<WorkerGrpcDataServer>& out_server);\n\n}  // namespace data\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_DATA_SERVICE_SERVER_LIB_H_"