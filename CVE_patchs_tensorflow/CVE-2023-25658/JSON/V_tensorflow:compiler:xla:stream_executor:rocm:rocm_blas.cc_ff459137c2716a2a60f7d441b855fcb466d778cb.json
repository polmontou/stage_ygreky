"/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.h\"\n\n#include \"tensorflow/compiler/xla/stream_executor/rocm/rocblas_wrapper.h\"\n\n#define EIGEN_USE_GPU\n#include <assert.h>\n\n#include <complex>\n\n#include \"absl/strings/str_cat.h\"\n#include \"absl/strings/str_format.h\"\n#include \"absl/types/span.h\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_activation.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"\n#include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"\n#include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"\n#include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"\n#include \"tensorflow/compiler/xla/stream_executor/scratch_allocator.h\"\n#include \"tensorflow/compiler/xla/stream_executor/stream_executor.h\"\n#include \"tensorflow/tsl/util/determinism.h\"\nusing tsl::OpDeterminismRequired;\n\nnamespace stream_executor {\nnamespace gpu {\n\nPLUGIN_REGISTRY_DEFINE_PLUGIN_ID(kRocBlasPlugin);\n\ntemplate <class T>\nconst typename RocBlasTypeConversionHelper<T>::mapped_type *complex_cast(\n    const DeviceMemory<T> &a) {\n  return reinterpret_cast<\n      const typename RocBlasTypeConversionHelper<T>::mapped_type *>(\n      GpuMemory(a));\n}\n\ntemplate <class T>\nconst typename RocBlasTypeConversionHelper<T>::mapped_type *complex_cast(\n    const T &a) {\n  return reinterpret_cast<\n      const typename RocBlasTypeConversionHelper<T>::mapped_type *>(&a);\n}\ntemplate <class T>\ntypename RocBlasTypeConversionHelper<T>::mapped_type *complex_cast(\n    DeviceMemory<T> *a) {\n  return reinterpret_cast<\n      typename RocBlasTypeConversionHelper<T>::mapped_type *>(\n      GpuMemoryMutable(a));\n}\n\nstatic void blas_log(const char *c) {}\n\nstatic string ToString(rocblas_status status) {\n  switch (status) {\n    case rocblas_status_success:\n      return \"rocblas_status_success\";\n    case rocblas_status_invalid_handle:\n      return \"rocblas_status_invalid_handle\";\n    case rocblas_status_not_implemented:\n      return \"rocblas_status_not_implemented\";\n    case rocblas_status_invalid_pointer:\n      return \"rocblas_status_invalid_pointer\";\n    case rocblas_status_invalid_size:\n      return \"rocblas_status_invalid_size\";\n    case rocblas_status_memory_error:\n      return \"rocblas_status_memory_error\";\n    case rocblas_status_internal_error:\n      return \"rocblas_status_internal_error\";\n    default:\n      return absl::StrCat(\"<invalid rocBLAS status: \", status, \">\");\n  }\n}\n\nbool ROCMBlas::Init() {\n  gpu::ScopedActivateExecutorContext sac{parent_};\n  rocblas_status ret = wrap::rocblas_create_handle(&blas_);\n  if (ret != rocblas_status_success) {\n    LOG(ERROR) << \"failed to create rocBLAS handle: \" << ToString(ret);\n    return false;\n  }\n\n  return true;\n}\n\nROCMBlas::ROCMBlas(gpu::GpuExecutor *parent)\n    : parent_(CHECK_NOTNULL(parent)), blas_(nullptr) {}\n\nROCMBlas::~ROCMBlas() {\n  if (blas_ != nullptr) {\n    gpu::ScopedActivateExecutorContext sac{parent_};\n    wrap::rocblas_destroy_handle(blas_);\n  }\n}\n\nbool ROCMBlas::SetStream(Stream *stream) {\n  CHECK(stream != nullptr);\n  CHECK(AsGpuStreamValue(stream) != nullptr);\n  CHECK(blas_ != nullptr);\n  gpu::ScopedActivateExecutorContext sac{parent_};\n  rocblas_status ret =\n      wrap::rocblas_set_stream(blas_, AsGpuStreamValue(stream));\n  if (ret != rocblas_status_success) {\n    LOG(ERROR) << \"failed to set stream for rocBLAS calls: \" << ToString(ret);\n    return false;\n  }\n\n  return true;\n}\n\nnamespace {\n\n// Helper functions transforming blas arguments into rocBLAS arguments.\n\nrocblas_operation ROCMBlasTranspose(blas::Transpose trans) {\n  switch (trans) {\n    case blas::Transpose::kNoTranspose:\n      return rocblas_operation_none;\n    case blas::Transpose::kTranspose:\n      return rocblas_operation_transpose;\n    case blas::Transpose::kConjugateTranspose:\n      return rocblas_operation_conjugate_transpose;\n    default:\n      LOG(FATAL) << \"Invalid value of blas::Transpose.\";\n  }\n}\n\nrocblas_fill ROCMBlasUpperLower(blas::UpperLower uplo) {\n  switch (uplo) {\n    case blas::UpperLower::kUpper:\n      return rocblas_fill_upper;\n    case blas::UpperLower::kLower:\n      return rocblas_fill_lower;\n    default:\n      LOG(FATAL) << \"Invalid value of blas::UpperLower.\";\n  }\n}\n\nrocblas_diagonal ROCMBlasDiagonal(blas::Diagonal diag) {\n  switch (diag) {\n    case blas::Diagonal::kUnit:\n      return rocblas_diagonal_unit;\n    case blas::Diagonal::kNonUnit:\n      return rocblas_diagonal_non_unit;\n    default:\n      LOG(FATAL) << \"Invalid value of blas::Diagonal.\";\n  }\n}\n\nrocblas_side ROCMBlasSide(blas::Side side) {\n  switch (side) {\n    case blas::Side::kLeft:\n      return rocblas_side_left;\n    case blas::Side::kRight:\n      return rocblas_side_right;\n    default:\n      LOG(FATAL) << \"Invalid value of blas::Side.\";\n  }\n}\n\n}  // namespace\n\ntemplate <typename FuncT, typename... Args>\nbool ROCMBlas::DoBlasInternalImpl(FuncT rocblas_func, Stream *stream,\n                                  bool pointer_mode_host, bool err_on_failure,\n                                  Args... args) {\n  absl::MutexLock lock{&mu_};\n\n  CHECK(blas_ != nullptr);\n  if (!SetStream(stream)) {\n    return false;\n  }\n\n  gpu::ScopedActivateExecutorContext sac{parent_};\n\n  // set the atomics mode, leaving default to library\n  bool allow_atomics = !OpDeterminismRequired();\n  rocblas_status ret;\n  if (!allow_atomics) {\n    ret = wrap::rocblas_set_atomics_mode(blas_, rocblas_atomics_not_allowed);\n    if (err_on_failure && ret != rocblas_status_success) {\n      LOG(ERROR) << \"failed to to set atomics mode before \"\n                 << rocblas_func.kName << \": \" << ToString(ret);\n    }\n  }\n\n  ret = rocblas_func(blas_, args...);\n  if (err_on_failure && ret != rocblas_status_success) {\n    LOG(ERROR) << \"failed to run ROCBLAS routine \" << rocblas_func.kName << \": \"\n               << ToString(ret);\n  }\n  return ret == rocblas_status_success;\n}\n\nbool ROCMBlas::DoBlasAxpy(Stream *stream, uint64_t elem_count, float alpha,\n                          const DeviceMemory<float> &x, int incx,\n                          DeviceMemory<float> *y, int incy) {\n  blas_log(\"DoBlasAxpy\");\n  return DoBlasInternal(wrap::rocblas_saxpy, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        GpuMemory(x), incx, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasAxpy(Stream *stream, uint64_t elem_count, double alpha,\n                          const DeviceMemory<double> &x, int incx,\n                          DeviceMemory<double> *y, int incy) {\n  blas_log(\"DoBlasAxpy\");\n  return DoBlasInternal(wrap::rocblas_daxpy, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        GpuMemory(x), incx, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasAxpy(Stream *stream, uint64_t elem_count,\n                          std::complex<float> alpha,\n                          const DeviceMemory<std::complex<float>> &x, int incx,\n                          DeviceMemory<std::complex<float>> *y, int incy) {\n  return DoBlasInternal(\n      wrap::rocblas_caxpy, stream, /* pointer_mode_host = */ true, elem_count,\n      complex_cast(alpha), complex_cast(x), incx, complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasAxpy(Stream *stream, uint64_t elem_count,\n                          std::complex<double> alpha,\n                          const DeviceMemory<std::complex<double>> &x, int incx,\n                          DeviceMemory<std::complex<double>> *y, int incy) {\n  return DoBlasInternal(\n      wrap::rocblas_zaxpy, stream, /* pointer_mode_host = */ true, elem_count,\n      complex_cast(alpha), complex_cast(x), incx, complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasCopy(Stream *stream, uint64_t elem_count,\n                          const DeviceMemory<float> &x, int incx,\n                          DeviceMemory<float> *y, int incy) {\n  return DoBlasInternal(wrap::rocblas_scopy, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        GpuMemory(x), incx, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasCopy(Stream *stream, uint64_t elem_count,\n                          const DeviceMemory<double> &x, int incx,\n                          DeviceMemory<double> *y, int incy) {\n  return DoBlasInternal(wrap::rocblas_dcopy, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        GpuMemory(x), incx, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasCopy(Stream *stream, uint64_t elem_count,\n                          const DeviceMemory<std::complex<float>> &x, int incx,\n                          DeviceMemory<std::complex<float>> *y, int incy) {\n  return DoBlasInternal(wrap::rocblas_ccopy, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        complex_cast(x), incx, complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasCopy(Stream *stream, uint64_t elem_count,\n                          const DeviceMemory<std::complex<double>> &x, int incx,\n                          DeviceMemory<std::complex<double>> *y, int incy) {\n  return DoBlasInternal(wrap::rocblas_zcopy, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        complex_cast(x), incx, complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count, float alpha,\n                          DeviceMemory<float> *x, int incx) {\n  blas_log(\"DoBlasScal<float>\");\n  return DoBlasInternal(wrap::rocblas_sscal, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        GpuMemoryMutable(x), incx);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count, double alpha,\n                          DeviceMemory<double> *x, int incx) {\n  return DoBlasInternal(wrap::rocblas_dscal, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        GpuMemoryMutable(x), incx);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count, float alpha,\n                          DeviceMemory<std::complex<float>> *x, int incx) {\n  return DoBlasInternal(wrap::rocblas_csscal, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        complex_cast(x), incx);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count, double alpha,\n                          DeviceMemory<std::complex<double>> *x, int incx) {\n  return DoBlasInternal(wrap::rocblas_zdscal, stream,\n                        /* pointer_mode_host = */ true, elem_count, &alpha,\n                        complex_cast(x), incx);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count,\n                          std::complex<float> alpha,\n                          DeviceMemory<std::complex<float>> *x, int incx) {\n  return DoBlasInternal(wrap::rocblas_cscal, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        complex_cast(alpha), complex_cast(x), incx);\n}\n\nbool ROCMBlas::DoBlasScal(Stream *stream, uint64_t elem_count,\n                          std::complex<double> alpha,\n                          DeviceMemory<std::complex<double>> *x, int incx) {\n  return DoBlasInternal(wrap::rocblas_zscal, stream,\n                        /* pointer_mode_host = */ true, elem_count,\n                        complex_cast(alpha), complex_cast(x), incx);\n}\n\nbool ROCMBlas::DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,\n                          uint64_t n, float alpha, const DeviceMemory<float> &a,\n                          int lda, const DeviceMemory<float> &x, int incx,\n                          float beta, DeviceMemory<float> *y, int incy) {\n  blas_log(\"DoBlasGemv\");\n  return DoBlasInternal(\n      wrap::rocblas_sgemv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasTranspose(trans), m, n, &alpha, GpuMemory(a), lda, GpuMemory(x),\n      incx, &beta, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,\n                          uint64_t n, double alpha,\n                          const DeviceMemory<double> &a, int lda,\n                          const DeviceMemory<double> &x, int incx, double beta,\n                          DeviceMemory<double> *y, int incy) {\n  blas_log(\"DoBlasGemv\");\n  return DoBlasInternal(\n      wrap::rocblas_dgemv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasTranspose(trans), m, n, &alpha, GpuMemory(a), lda, GpuMemory(x),\n      incx, &beta, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,\n                          uint64_t n, std::complex<float> alpha,\n                          const DeviceMemory<std::complex<float>> &a, int lda,\n                          const DeviceMemory<std::complex<float>> &x, int incx,\n                          std::complex<float> beta,\n                          DeviceMemory<std::complex<float>> *y, int incy) {\n  blas_log(\"DoBlasGemv\");\n  return DoBlasInternal(\n      wrap::rocblas_cgemv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasTranspose(trans), m, n, complex_cast(alpha), complex_cast(a), lda,\n      complex_cast(x), incx, complex_cast(beta), complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasGemv(Stream *stream, blas::Transpose trans, uint64_t m,\n                          uint64_t n, std::complex<double> alpha,\n                          const DeviceMemory<std::complex<double>> &a, int lda,\n                          const DeviceMemory<std::complex<double>> &x, int incx,\n                          std::complex<double> beta,\n                          DeviceMemory<std::complex<double>> *y, int incy) {\n  blas_log(\"DoBlasGemv\\n\");\n  return DoBlasInternal(\n      wrap::rocblas_zgemv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasTranspose(trans), m, n, complex_cast(alpha), complex_cast(a), lda,\n      complex_cast(x), incx, complex_cast(beta), complex_cast(y), incy);\n}\n\nbool ROCMBlas::DoBlasSbmv(Stream *stream, blas::UpperLower uplo, uint64_t n,\n                          uint64_t k, float alpha, const DeviceMemory<float> &a,\n                          int lda, const DeviceMemory<float> &x, int incx,\n                          float beta, DeviceMemory<float> *y, int incy) {\n  return DoBlasInternal(\n      wrap::rocblas_ssbmv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasUpperLower(uplo), n, k, &alpha, GpuMemory(a), lda, GpuMemory(x),\n      incx, &beta, GpuMemoryMutable(y), incy);\n}\n\nbool ROCMBlas::DoBlasSbmv(Stream *stream, blas::UpperLower uplo, uint64_t n,\n                          uint64_t k, double alpha,\n                          const DeviceMemory<double> &a, int lda,\n                          const DeviceMemory<double> &x, int incx, double beta,\n                          DeviceMemory<double> *y, int incy) {\n  return DoBlasInternal(\n      wrap::rocblas_dsbmv, stream, /* pointer_mode_host = */ true,\n      ROCMBlasUpperLower(uplo), n, k, &alpha, GpuMemory(a), lda, GpuMemory(x),\n      incx, &beta, GpuMemoryMutable(y), incy);\n}\n\ntsl::Status ROCMBlas::DoBlasGemm(Stream *stream, blas::Transpose transa,\n                                 blas::Transpose transb, uint64_t m, uint64 n,\n                                 uint64_t k, blas::DataType dtype,\n                                 const void *alpha, const DeviceMemoryBase &a,\n                                 int lda, const DeviceMemoryBase &b, int ldb,\n                                 const void *beta, DeviceMemoryBase *c, int ldc,\n                                 blas::ComputePrecision precision) {\n  blas_log(\"DoBlasGemm\");\n  VLOG(1) << absl::StreamFormat(\n      \"doing rocBLAS GEMM: at=%d bt=%d m=%u n=%u \"\n      \"k=%llu alpha=%p a=%p lda=%d b=%p ldb=%d beta=%p \"\n      \"c=%p ldc=%d\",\n      static_cast<int>(transa), static_cast<int>(transb), m, n, k, alpha,\n      a.opaque(), lda, b.opaque(), ldb, beta, c->opaque(), ldc);\n  if (dtype == blas::DataType::kHalf || dtype == blas::DataType::kFloat) {\n    if (transa == blas::Transpose::kNoTranspose) {\n      if (lda < static_cast<int64_t>(m)) {\n        LOG(WARNING) << \"GEMM lda was smaller than m (no transpose case); \"\n                        \"precondition violation\";\n      }\n    } else {\n      if (lda < static_cast<int64_t>(k)) {\n        LOG(WARNING) << \"GEMM lda (\" << lda << \") was smaller than k (\" << k\n                     << \") (transpose case); precondition violation\";\n      }\n    }\n    if (transb == blas::Transpose::kNoTranspose) {\n      if (ldb < static_cast<int64_t>(k)) {\n        LOG(WARNING) << \"GEMM ldb (\" << ldb << \") was smaller than k (\" << k\n                     << \") (no transpose case); precondition violation\";\n      }\n    } else {\n      if (ldb < static_cast<int64_t>(n)) {\n        LOG(WARNING) << \"GEMM ldb was smaller than n (transpose case); \"\n                        \"precondition violation\";\n      }\n    }\n  }\n\n  switch (dtype) {\n    case blas::DataType::kHalf: {\n      tsl::StatusOr<bool> maybe_hasXDLOPS = GpuDriver::GetMFMASupport();\n      if (maybe_hasXDLOPS.ok() && maybe_hasXDLOPS.value()) {\n        VLOG(1) << \"Using rocblas_gemm_ex\";\n        return DoBlasInternalStatus(\n            wrap::rocblas_gemm_ex, stream, /* pointer_mode_host = */ true,\n            ROCMBlasTranspose(transa), ROCMBlasTranspose(transb),\n            (rocblas_int)m, (rocblas_int)n, (rocblas_int)k, alpha, a.opaque(),\n            rocblas_datatype_f16_r, lda, b.opaque(), rocblas_datatype_f16_r,\n            ldb, beta, c->opaque(), rocblas_datatype_f16_r, ldc, c->opaque(),\n            rocblas_datatype_f16_r, ldc, rocblas_datatype_f32_r,\n            rocblas_gemm_algo_standard, 0, 0);\n      } else {\n        VLOG(1) << \"Using rocblas_hgemm\";\n        const Eigen::half alpha_half(*static_cast<const float *>(alpha));\n        const Eigen::half beta_half(*static_cast<const float *>(beta));\n        return DoBlasInternalStatus(\n            wrap::rocblas_hgemm, stream, /* pointer_mode_host = */ true,\n            ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n            reinterpret_cast<const rocblas_half *>(&alpha_half),\n            reinterpret_cast<const rocblas_half *>(a.opaque()), lda,\n            reinterpret_cast<const rocblas_half *>(b.opaque()), ldb,\n            reinterpret_cast<const rocblas_half *>(&beta_half),\n            reinterpret_cast<rocblas_half *>(c->opaque()), ldc);\n      }\n    }\n    case blas::DataType::kBF16:\n      return DoBlasInternalStatus(\n          wrap::rocblas_gemm_ex, stream, /* pointer_mode_host = */ true,\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), (rocblas_int)m,\n          (rocblas_int)n, (rocblas_int)k, alpha, a.opaque(),\n          rocblas_datatype_bf16_r, lda, b.opaque(), rocblas_datatype_bf16_r,\n          ldb, beta, c->opaque(), rocblas_datatype_bf16_r, ldc, c->opaque(),\n          rocblas_datatype_bf16_r, ldc, rocblas_datatype_f32_r,\n          rocblas_gemm_algo_standard, 0, 0);\n    case blas::DataType::kFloat:\n      return DoBlasInternalStatus(\n          wrap::rocblas_sgemm, stream, /* pointer_mode_host = */ true,\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          static_cast<const float *>(alpha),\n          static_cast<const float *>(a.opaque()), lda,\n          static_cast<const float *>(b.opaque()), ldb,\n          static_cast<const float *>(beta), static_cast<float *>(c->opaque()),\n          ldc);\n    case blas::DataType::kDouble:\n      return DoBlasInternalStatus(\n          wrap::rocblas_dgemm, stream, /* pointer_mode_host = */ true,\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          static_cast<const double *>(alpha),\n          static_cast<const double *>(a.opaque()), lda,\n          static_cast<const double *>(b.opaque()), ldb,\n          static_cast<const double *>(beta), static_cast<double *>(c->opaque()),\n          ldc);\n    case blas::DataType::kComplexFloat: {\n      auto cb_alpha =\n          complex_cast(*static_cast<const std::complex<float> *>(alpha));\n      auto cb_beta =\n          complex_cast(*static_cast<const std::complex<float> *>(beta));\n      return DoBlasInternalStatus(\n          wrap::rocblas_cgemm, stream, /* pointer_mode_host = */ true,\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          cb_alpha, static_cast<const rocblas_float_complex *>(a.opaque()), lda,\n          static_cast<const rocblas_float_complex *>(b.opaque()), ldb, cb_beta,\n          static_cast<rocblas_float_complex *>(c->opaque()), ldc);\n    }\n    case blas::DataType::kComplexDouble: {\n      auto cb_alpha =\n          complex_cast(*static_cast<const std::complex<double> *>(alpha));\n      auto cb_beta =\n          complex_cast(*static_cast<const std::complex<double> *>(beta));\n      return DoBlasInternalStatus(\n          wrap::rocblas_zgemm, stream, /* pointer_mode_host = */ true,\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          cb_alpha, static_cast<const rocblas_double_complex *>(a.opaque()),\n          lda, static_cast<const rocblas_double_complex *>(b.opaque()), ldb,\n          cb_beta, static_cast<rocblas_double_complex *>(c->opaque()), ldc);\n    }\n    default:\n      return tsl::errors::Internal(\"Unsupported datatype for GEMM: \",\n                                   blas::DataTypeString(dtype));\n  }\n}\n\nbool ROCMBlas::DoBlasGemvWithProfiling(\n    Stream *stream, blas::Transpose trans, uint64_t m, uint64 n, float alpha,\n    const DeviceMemory<float> &a, int lda, const DeviceMemory<float> &x,\n    int incx, float beta, DeviceMemory<float> *y, int incy,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemvWithProfilingImpl(stream, trans, m, n, alpha, a, lda, x,\n                                     incx, beta, y, incy,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemvWithProfiling(\n    Stream *stream, blas::Transpose trans, uint64_t m, uint64 n, double alpha,\n    const DeviceMemory<double> &a, int lda, const DeviceMemory<double> &x,\n    int incx, double beta, DeviceMemory<double> *y, int incy,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemvWithProfilingImpl(stream, trans, m, n, alpha, a, lda, x,\n                                     incx, beta, y, incy,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemvWithProfiling(\n    Stream *stream, blas::Transpose trans, uint64_t m, uint64 n,\n    std::complex<float> alpha, const DeviceMemory<std::complex<float>> &a,\n    int lda, const DeviceMemory<std::complex<float>> &x, int incx,\n    std::complex<float> beta, DeviceMemory<std::complex<float>> *y, int incy,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemvWithProfilingImpl(stream, trans, m, n, alpha, a, lda, x,\n                                     incx, beta, y, incy,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemvWithProfiling(\n    Stream *stream, blas::Transpose trans, uint64_t m, uint64 n,\n    std::complex<double> alpha, const DeviceMemory<std::complex<double>> &a,\n    int lda, const DeviceMemory<std::complex<double>> &x, int incx,\n    std::complex<double> beta, DeviceMemory<std::complex<double>> *y, int incy,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemvWithProfilingImpl(stream, trans, m, n, alpha, a, lda, x,\n                                     incx, beta, y, incy,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemmWithProfiling(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, float alpha, const DeviceMemory<Eigen::half> &a,\n    int lda, const DeviceMemory<Eigen::half> &b, int ldb, float beta,\n    DeviceMemory<Eigen::half> *c, int ldc,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemmWithProfilingImpl(stream, transa, transb, m, n, k, alpha, a,\n                                     lda, b, ldb, beta, c, ldc,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemmWithProfiling(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, float alpha, const DeviceMemory<float> &a, int lda,\n    const DeviceMemory<float> &b, int ldb, float beta, DeviceMemory<float> *c,\n    int ldc, blas::ProfileResult *output_profile_result) {\n  return DoBlasGemmWithProfilingImpl(stream, transa, transb, m, n, k, alpha, a,\n                                     lda, b, ldb, beta, c, ldc,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemmWithProfiling(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, double alpha, const DeviceMemory<double> &a, int lda,\n    const DeviceMemory<double> &b, int ldb, double beta,\n    DeviceMemory<double> *c, int ldc,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemmWithProfilingImpl(stream, transa, transb, m, n, k, alpha, a,\n                                     lda, b, ldb, beta, c, ldc,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemmWithProfiling(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, std::complex<float> alpha,\n    const DeviceMemory<std::complex<float>> &a, int lda,\n    const DeviceMemory<std::complex<float>> &b, int ldb,\n    std::complex<float> beta, DeviceMemory<std::complex<float>> *c, int ldc,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemmWithProfilingImpl(stream, transa, transb, m, n, k, alpha, a,\n                                     lda, b, ldb, beta, c, ldc,\n                                     output_profile_result);\n}\n\nbool ROCMBlas::DoBlasGemmWithProfiling(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, std::complex<double> alpha,\n    const DeviceMemory<std::complex<double>> &a, int lda,\n    const DeviceMemory<std::complex<double>> &b, int ldb,\n    std::complex<double> beta, DeviceMemory<std::complex<double>> *c, int ldc,\n    blas::ProfileResult *output_profile_result) {\n  return DoBlasGemmWithProfilingImpl(stream, transa, transb, m, n, k, alpha, a,\n                                     lda, b, ldb, beta, c, ldc,\n                                     output_profile_result);\n}\n\ntemplate <typename T>\nbool ROCMBlas::DoBlasGemvWithProfilingImpl(\n    Stream *stream, blas::Transpose trans, uint64_t m, uint64 n, const T &alpha,\n    const DeviceMemory<T> &a, int lda, const DeviceMemory<T> &x, int incx,\n    const T &beta, DeviceMemory<T> *y, int incy,\n    blas::ProfileResult *output_profile_result) {\n  // ROCM TODO: properly implement the interface\n  return false;\n}\n\ntemplate <typename T, typename ParamType>\nbool ROCMBlas::DoBlasGemmWithProfilingImpl(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, const ParamType &alpha, const DeviceMemory<T> &a,\n    int lda, const DeviceMemory<T> &b, int ldb, const ParamType &beta,\n    DeviceMemory<T> *c, int ldc, blas::ProfileResult *output_profile_result) {\n  // ROCM TODO: properly implement the interface\n  return false;\n}\ntsl::Status ROCMBlas::DoBlasGemmWithAlgorithm(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, const void *alpha, const DeviceMemoryBase &a,\n    blas::DataType type_a, int lda, const DeviceMemoryBase &b,\n    blas::DataType type_b, int ldb, const void *beta, DeviceMemoryBase *c,\n    blas::DataType type_c, int ldc, blas::ComputationType computation_type,\n    blas::AlgorithmType algorithm, blas::ComputePrecision precision,\n    blas::ProfileResult *output_profile_result) {\n  // ROCM TODO: properly implement the interface\n  return tsl::errors::Internal(\"Not implemented on ROCm\");\n}\n\ntsl::Status ROCMBlas::DoBlasGemmStridedBatchedWithAlgorithm(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, const void *alpha, const DeviceMemoryBase &a,\n    blas::DataType type_a, int lda, int64_t stride_a, const DeviceMemoryBase &b,\n    blas::DataType type_b, int ldb, int64_t stride_b, const void *beta,\n    DeviceMemoryBase *c, blas::DataType type_c, int ldc, int64_t stride_c,\n    int batch_count, blas::ComputationType computation_type,\n    blas::AlgorithmType algorithm, blas::ComputePrecision precision,\n    blas::ProfileResult *output_profile_result) {\n  // ROCM TODO: properly implement the interface\n  return tsl::errors::Internal(\"Not implemented on ROCm\");\n}\n\nbool ROCMBlas::GetBlasGemmAlgorithms(\n    Stream *stream, std::vector<blas::AlgorithmType> *out_algorithms) {\n  // ROCM TODO: properly implement the interface\n  return true;\n}\n\n// This copies from source memory: raw_ptrs[i] to target memory:\n// device_memory_ptr at the interval of matrix_byte_size, or vice versa.\n// The below algorithm tries to minimize the number of memcpy by consolidating\n// neighboring memcpy into a single request\ntemplate <typename MAPPED_T>\ntsl::Status ReorganizeMemory(Stream *stream,\n                             DeviceMemory<MAPPED_T> *device_memory,\n                             const std::vector<MAPPED_T *> &raw_ptrs,\n                             int batch_count, uint64_t batch_stride,\n                             bool gather) {\n  assert(batch_count > 0);\n  char *device_memory_ptr = static_cast<char *>(device_memory->opaque());\n  char *src_ptr = reinterpret_cast<char *>(raw_ptrs[0]);\n  char *dst_ptr = device_memory_ptr;\n  size_t matrix_byte_size = batch_stride * sizeof(MAPPED_T);\n  uint64_t cur_stride_size = matrix_byte_size;\n\n  for (int i = 1; i < batch_count; ++i) {\n    if (reinterpret_cast<char *>(raw_ptrs[i]) == src_ptr + cur_stride_size) {\n      cur_stride_size += matrix_byte_size;\n    } else {\n      DeviceMemoryBase src_mem = DeviceMemoryBase(src_ptr, cur_stride_size);\n      DeviceMemoryBase target_mem = DeviceMemoryBase(dst_ptr, cur_stride_size);\n      bool a_status =\n          gather\n              ? stream->ThenMemcpy(&target_mem, src_mem, cur_stride_size).ok()\n              : stream->ThenMemcpy(&src_mem, target_mem, cur_stride_size).ok();\n      if (!a_status) {\n        return tsl::Status(\n            tsl::error::INTERNAL,\n            \"failed to copy device memory in ROCMBlas::DoBlasGemmBatched\");\n      }\n      src_ptr = reinterpret_cast<char *>(raw_ptrs[i]);\n      dst_ptr = device_memory_ptr + i * matrix_byte_size;\n      cur_stride_size = matrix_byte_size;\n    }\n  }\n\n  DeviceMemoryBase src_mem = DeviceMemoryBase(src_ptr, cur_stride_size);\n  DeviceMemoryBase target_mem = DeviceMemoryBase(dst_ptr, cur_stride_size);\n  bool a_status =\n      gather ? stream->ThenMemcpy(&target_mem, src_mem, cur_stride_size).ok()\n             : stream->ThenMemcpy(&src_mem, target_mem, cur_stride_size).ok();\n  if (!a_status)\n    return tsl::Status(\n        tsl::error::INTERNAL,\n        \"failed to copy device memory in ROCMBlas::DoBlasGemmBatched\");\n  return tsl::OkStatus();\n}\n\ntemplate <typename T>\ntsl::Status ROCMBlas::AllocateStridedBuffer(\n    const std::vector<typename RocBlasTypeConversionHelper<T>::mapped_type *>\n        &raw_ptrs,\n    int batch_count, uint64_t batch_stride, ScratchAllocator *scratch_allocator,\n    Stream *stream,\n    std::unique_ptr<TemporaryDeviceMemory<\n        typename RocBlasTypeConversionHelper<T>::mapped_type>> *temp_memory,\n    DeviceMemory<typename RocBlasTypeConversionHelper<T>::mapped_type>\n        *device_memory,\n    bool copy_data, bool &reallocated) {\n  assert(device_memory != nullptr);\n\n  using MAPPED_T = typename RocBlasTypeConversionHelper<T>::mapped_type;\n\n  bool needs_allocate_strided = false;\n  for (int i = 1; i < batch_count; ++i) {\n    uint64_t tmp_batch_stride = raw_ptrs[i] - raw_ptrs[i - 1];\n    if (tmp_batch_stride != batch_stride) {\n      needs_allocate_strided = true;\n      break;\n    }\n  }\n\n  size_t matrix_byte_size = batch_stride * sizeof(MAPPED_T);\n  size_t matrix_batch_byte_size = matrix_byte_size * batch_count;\n\n  // No need to do re-allocation, take the short cut and return\n  if (!needs_allocate_strided) {\n    *device_memory = DeviceMemory<MAPPED_T>(\n        DeviceMemoryBase(raw_ptrs[0], matrix_batch_byte_size));\n    reallocated = false;\n    return tsl::OkStatus();\n  }\n\n  if (scratch_allocator != nullptr) {\n    TF_ASSIGN_OR_RETURN(\n        DeviceMemory<uint8> batch_matrix_bytes,\n        scratch_allocator->AllocateBytes(matrix_batch_byte_size));\n    *device_memory = DeviceMemory<MAPPED_T>(batch_matrix_bytes);\n  } else {\n    assert(temp_memory != nullptr);\n    TF_ASSIGN_OR_RETURN(*temp_memory, stream->AllocateTemporaryArray<MAPPED_T>(\n                                          matrix_batch_byte_size));\n    *device_memory =\n        DeviceMemory<MAPPED_T>(*(*temp_memory)->mutable_device_memory());\n  }\n\n  reallocated = true;\n\n  if (copy_data)\n    return ReorganizeMemory(stream, device_memory, raw_ptrs, batch_count,\n                            batch_stride, true);\n  return tsl::OkStatus();\n}\n\ntemplate <typename T, typename FuncT>\ntsl::Status ROCMBlas::DoBlasGemmBatchedInternal(\n    FuncT rocblas_func, Stream *stream, blas::Transpose transa,\n    blas::Transpose transb, uint64_t m, uint64 n, uint64 k, T alpha,\n    DeviceMemorySlice<T> a_ptrs_to_wrappers, int lda,\n    DeviceMemorySlice<T> b_ptrs_to_wrappers, int ldb, T beta,\n    DeviceMemorySlice<T> c_ptrs_to_wrappers, int ldc, int batch_count,\n    ScratchAllocator *scratch_allocator) {\n  using MAPPED_T = typename RocBlasTypeConversionHelper<T>::mapped_type;\n\n  // Sanity checks before making any further progress\n  uint64_t batch_stride_a = 0;\n  uint64_t batch_stride_b = 0;\n  uint64_t batch_stride_c = 0;\n\n  assert(ldc >= m);\n  batch_stride_c = ldc * n;\n\n  if (ROCMBlasTranspose(transa) == rocblas_operation_none) {\n    assert(lda >= m);\n    batch_stride_a = lda * k;\n  } else {\n    assert(lda >= k);\n    batch_stride_a = lda * m;\n  }\n\n  if (ROCMBlasTranspose(transb) == rocblas_operation_none) {\n    assert(ldb >= k);\n    batch_stride_b = ldb * n;\n  } else {\n    assert(ldb >= n);\n    batch_stride_b = ldb * k;\n  }\n\n  // Allocate local vectors to hold device pointers to matrices\n  std::vector<MAPPED_T *> a_raw_ptrs, b_raw_ptrs, c_raw_ptrs;\n  for (int i = 0; i < batch_count; ++i) {\n    // static_cast does work when converting Eigen::half* to rocblas_half*,\n    // hence the use of reinterpret_cast\n    a_raw_ptrs.push_back(\n        reinterpret_cast<MAPPED_T *>(a_ptrs_to_wrappers[i]->opaque()));\n    b_raw_ptrs.push_back(\n        reinterpret_cast<MAPPED_T *>(b_ptrs_to_wrappers[i]->opaque()));\n    c_raw_ptrs.push_back(\n        reinterpret_cast<MAPPED_T *>(c_ptrs_to_wrappers[i]->opaque()));\n  }\n\n  DeviceMemory<MAPPED_T> a;\n  // Make sure the temporary memory are in-scope before the function returns\n  std::unique_ptr<TemporaryDeviceMemory<MAPPED_T>> a_temp;\n  bool reallocated_a, reallocated_b, reallocated_c;\n  tsl::Status a_allocation_status = AllocateStridedBuffer<T>(\n      a_raw_ptrs, batch_count, batch_stride_a, scratch_allocator, stream,\n      &a_temp, &a, true, reallocated_a);\n  if (a_allocation_status != tsl::OkStatus()) {\n    return a_allocation_status;\n  }\n\n  DeviceMemory<MAPPED_T> b;\n  std::unique_ptr<TemporaryDeviceMemory<MAPPED_T>> b_temp;\n  tsl::Status b_allocation_status = AllocateStridedBuffer<T>(\n      b_raw_ptrs, batch_count, batch_stride_b, scratch_allocator, stream,\n      &b_temp, &b, true, reallocated_b);\n  if (b_allocation_status != tsl::OkStatus()) {\n    return b_allocation_status;\n  }\n\n  DeviceMemory<MAPPED_T> c;\n  std::unique_ptr<TemporaryDeviceMemory<MAPPED_T>> c_temp;\n  tsl::Status c_allocation_status = AllocateStridedBuffer<T>(\n      c_raw_ptrs, batch_count, batch_stride_c, scratch_allocator, stream,\n      &c_temp, &c, true, reallocated_c);  // can disable copy if beta=0\n  if (c_allocation_status != tsl::OkStatus()) {\n    return c_allocation_status;\n  }\n\n  bool ok;\n  if constexpr (std::is_same_v<T, Eigen::bfloat16>) {\n    float alpha_ = static_cast<float>(alpha);\n    float beta_ = static_cast<float>(beta);\n    const void *alpha_ptr = reinterpret_cast<const void *>(&alpha_);\n    const void *beta_ptr = reinterpret_cast<const void *>(&beta_);\n\n    ok = DoBlasInternal(\n        rocblas_func, stream, /* pointer_mode_host = */ true,\n        ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n        alpha_ptr, a.opaque(), rocblas_datatype_bf16_r, lda, batch_stride_a,\n        b.opaque(), rocblas_datatype_bf16_r, ldb, batch_stride_b, beta_ptr,\n        c.opaque(), rocblas_datatype_bf16_r, ldc, batch_stride_c, c.opaque(),\n        rocblas_datatype_bf16_r, ldc, batch_stride_c, batch_count,\n        rocblas_datatype_f32_r, rocblas_gemm_algo_standard, 0, 0);\n  } else {\n    MAPPED_T *alpha_ptr = reinterpret_cast<MAPPED_T *>(&alpha);\n    MAPPED_T *beta_ptr = reinterpret_cast<MAPPED_T *>(&beta);\n    ok = DoBlasInternal(rocblas_func, stream, /* pointer_mode_host = */ true,\n                        ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m,\n                        n, k, GpuComplex(alpha_ptr), GpuMemory(a), lda,\n                        batch_stride_a, GpuMemory(b), ldb, batch_stride_b,\n                        GpuComplex(beta_ptr), GpuMemoryMutable(&c), ldc,\n                        batch_stride_c, batch_count);\n  }\n  if (!ok)\n    return tsl::Status(tsl::error::INTERNAL,\n                       \"failed BLAS call, see log for details\");\n  if (reallocated_c)\n    return ReorganizeMemory(stream, &c, c_raw_ptrs, batch_count, batch_stride_c,\n                            false);\n  return tsl::OkStatus();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(Stream *stream, blas::Transpose transa,\n                                 blas::Transpose transb, uint64_t m, uint64_t n,\n                                 uint64 k, float alpha,\n                                 DeviceMemorySlice<Eigen::half> a, int lda,\n                                 DeviceMemorySlice<Eigen::half> b, int ldb,\n                                 float beta, DeviceMemorySlice<Eigen::half> c,\n                                 int ldc, int batch_count,\n                                 ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  const Eigen::half alpha_half(alpha);\n  const Eigen::half beta_half(beta);\n\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_hgemm_strided_batched, stream, transa, transb, m, n, k,\n      alpha_half, a, lda, b, ldb, beta_half, c, ldc, batch_count,\n      scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, float alpha,\n    DeviceMemorySlice<Eigen::bfloat16> a_array, int lda,\n    DeviceMemorySlice<Eigen::bfloat16> b_array, int ldb, float beta,\n    DeviceMemorySlice<Eigen::bfloat16> c_array, int ldc, int batch_count,\n    ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  const Eigen::bfloat16 alpha_bf16(alpha);\n  const Eigen::bfloat16 beta_bf16(beta);\n\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_gemm_strided_batched_ex, stream, transa, transb, m, n, k,\n      alpha_bf16, a_array, lda, b_array, ldb, beta_bf16, c_array, ldc,\n      batch_count, scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(Stream *stream, blas::Transpose transa,\n                                 blas::Transpose transb, uint64_t m, uint64_t n,\n                                 uint64 k, float alpha,\n                                 DeviceMemorySlice<float> a_array, int lda,\n                                 DeviceMemorySlice<float> b_array, int ldb,\n                                 float beta, DeviceMemorySlice<float> c_array,\n                                 int ldc, int batch_count,\n                                 ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_sgemm_strided_batched, stream, transa, transb, m, n, k,\n      alpha, a_array, lda, b_array, ldb, beta, c_array, ldc, batch_count,\n      scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(Stream *stream, blas::Transpose transa,\n                                 blas::Transpose transb, uint64_t m, uint64_t n,\n                                 uint64 k, double alpha,\n                                 DeviceMemorySlice<double> a_array, int lda,\n                                 DeviceMemorySlice<double> b_array, int ldb,\n                                 double beta, DeviceMemorySlice<double> c_array,\n                                 int ldc, int batch_count,\n                                 ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_dgemm_strided_batched, stream, transa, transb, m, n, k,\n      alpha, a_array, lda, b_array, ldb, beta, c_array, ldc, batch_count,\n      scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, std::complex<float> alpha,\n    DeviceMemorySlice<std::complex<float>> a_array, int lda,\n    DeviceMemorySlice<std::complex<float>> b_array, int ldb,\n    std::complex<float> beta, DeviceMemorySlice<std::complex<float>> c_array,\n    int ldc, int batch_count, ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_cgemm_strided_batched, stream, transa, transb, m, n, k,\n      alpha, a_array, lda, b_array, ldb, beta, c_array, ldc, batch_count,\n      scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasGemmBatched(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, std::complex<double> alpha,\n    DeviceMemorySlice<std::complex<double>> a_array, int lda,\n    DeviceMemorySlice<std::complex<double>> b_array, int ldb,\n    std::complex<double> beta, DeviceMemorySlice<std::complex<double>> c_array,\n    int ldc, int batch_count, ScratchAllocator *scratch_allocator) {\n  blas_log(\"DoBlasGemmBatched\");\n  tsl::Status status = DoBlasGemmBatchedInternal(\n      wrap::rocblas_zgemm_strided_batched, stream, transa, transb, m, n, k,\n      alpha, a_array, lda, b_array, ldb, beta, c_array, ldc, batch_count,\n      scratch_allocator);\n  if (!status.ok()) {\n    LOG(ERROR) << status;\n  }\n  return status.ok();\n}\n\nbool ROCMBlas::DoBlasTrsm(Stream *stream, blas::Side side,\n                          blas::UpperLower uplo, blas::Transpose transa,\n                          blas::Diagonal diag, uint64_t m, uint64 n,\n                          float alpha, const DeviceMemory<float> &a, int lda,\n                          DeviceMemory<float> *b, int ldb) {\n  blas_log(\"DoBlasTrsm\");\n  return DoBlasInternal(wrap::rocblas_strsm, stream,\n                        /* pointer_mode_host = */ true, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, &alpha, GpuMemory(a), lda,\n                        GpuMemoryMutable(b), ldb);\n}\n\nbool ROCMBlas::DoBlasTrsm(Stream *stream, blas::Side side,\n                          blas::UpperLower uplo, blas::Transpose transa,\n                          blas::Diagonal diag, uint64_t m, uint64 n,\n                          double alpha, const DeviceMemory<double> &a, int lda,\n                          DeviceMemory<double> *b, int ldb) {\n  blas_log(\"DoBlasTrsm\");\n  return DoBlasInternal(wrap::rocblas_dtrsm, stream,\n                        /* pointer_mode_host = */ true, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, &alpha, GpuMemory(a), lda,\n                        GpuMemoryMutable(b), ldb);\n}\n\nbool ROCMBlas::DoBlasTrsm(Stream *stream, blas::Side side,\n                          blas::UpperLower uplo, blas::Transpose transa,\n                          blas::Diagonal diag, uint64_t m, uint64 n,\n                          std::complex<float> alpha,\n                          const DeviceMemory<std::complex<float>> &a, int lda,\n                          DeviceMemory<std::complex<float>> *b, int ldb) {\n  return DoBlasInternal(wrap::rocblas_ctrsm, stream,\n                        /* pointer_mode_host = */ true, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, complex_cast(alpha),\n                        complex_cast(a), lda, complex_cast(b), ldb);\n}\n\nbool ROCMBlas::DoBlasTrsm(Stream *stream, blas::Side side,\n                          blas::UpperLower uplo, blas::Transpose transa,\n                          blas::Diagonal diag, uint64_t m, uint64 n,\n                          std::complex<double> alpha,\n                          const DeviceMemory<std::complex<double>> &a, int lda,\n                          DeviceMemory<std::complex<double>> *b, int ldb) {\n  return DoBlasInternal(wrap::rocblas_ztrsm, stream,\n                        /* pointer_mode_host = */ true, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, complex_cast(alpha),\n                        complex_cast(a), lda, complex_cast(b), ldb);\n}\n\nbool ROCMBlas::DoBlasTrsmBatched(Stream *stream, blas::Side side,\n                                 blas::UpperLower uplo, blas::Transpose transa,\n                                 blas::Diagonal diag, uint64_t m, uint64 n,\n                                 float alpha, const DeviceMemory<float *> &as,\n                                 int lda, DeviceMemory<float *> *bs, int ldb,\n                                 int batch_count) {\n  return DoBlasInternal(wrap::rocblas_strsm_batched, stream,\n                        true /* = pointer_mode_host */, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, &alpha, GpuMemory(as),\n                        lda, GpuMemoryMutable(bs), ldb, batch_count);\n}\n\nbool ROCMBlas::DoBlasTrsmBatched(Stream *stream, blas::Side side,\n                                 blas::UpperLower uplo, blas::Transpose transa,\n                                 blas::Diagonal diag, uint64_t m, uint64 n,\n                                 double alpha, const DeviceMemory<double *> &as,\n                                 int lda, DeviceMemory<double *> *bs, int ldb,\n                                 int batch_count) {\n  return DoBlasInternal(wrap::rocblas_dtrsm_batched, stream,\n                        true /* = pointer_mode_host */, ROCMBlasSide(side),\n                        ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n                        ROCMBlasDiagonal(diag), m, n, &alpha, GpuMemory(as),\n                        lda, GpuMemoryMutable(bs), ldb, batch_count);\n}\n\nbool ROCMBlas::DoBlasTrsmBatched(Stream *stream, blas::Side side,\n                                 blas::UpperLower uplo, blas::Transpose transa,\n                                 blas::Diagonal diag, uint64_t m, uint64 n,\n                                 std::complex<float> alpha,\n                                 const DeviceMemory<std::complex<float> *> &as,\n                                 int lda,\n                                 DeviceMemory<std::complex<float> *> *bs,\n                                 int ldb, int batch_count) {\n  return DoBlasInternal(\n      wrap::rocblas_ctrsm_batched, stream, true /* = pointer_mode_host */,\n      ROCMBlasSide(side), ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n      ROCMBlasDiagonal(diag), m, n, complex_cast(alpha),\n      static_cast<const rocblas_float_complex *const *>(as.opaque()), lda,\n      static_cast<rocblas_float_complex *const *>(bs->opaque()), ldb,\n      batch_count);\n}\n\nbool ROCMBlas::DoBlasTrsmBatched(Stream *stream, blas::Side side,\n                                 blas::UpperLower uplo, blas::Transpose transa,\n                                 blas::Diagonal diag, uint64_t m, uint64 n,\n                                 std::complex<double> alpha,\n                                 const DeviceMemory<std::complex<double> *> &as,\n                                 int lda,\n                                 DeviceMemory<std::complex<double> *> *bs,\n                                 int ldb, int batch_count) {\n  return DoBlasInternal(\n      wrap::rocblas_ztrsm_batched, stream, true /* = pointer_mode_host */,\n      ROCMBlasSide(side), ROCMBlasUpperLower(uplo), ROCMBlasTranspose(transa),\n      ROCMBlasDiagonal(diag), m, n, complex_cast(alpha),\n      static_cast<const rocblas_double_complex *const *>(as.opaque()), lda,\n      static_cast<rocblas_double_complex *const *>(bs->opaque()), ldb,\n      batch_count);\n}\n\ntsl::Status ROCMBlas::DoBlasGemmStridedBatched(\n    Stream *stream, blas::Transpose transa, blas::Transpose transb, uint64_t m,\n    uint64_t n, uint64 k, blas::DataType dtype, const void *alpha,\n    const DeviceMemoryBase &a, int lda, int64_t stride_a,\n    const DeviceMemoryBase &b, int ldb, int64_t stride_b, const void *beta,\n    DeviceMemoryBase *c, int ldc, int64_t stride_c, int batch_count,\n    blas::ComputePrecision precision) {\n  VLOG(1) << absl::StreamFormat(\n      \"doing rocBLAS SGEMM Strided Batched<float>: at=%d bt=%d m=%u n=%u \"\n      \"k=%llu alpha=%p a=%p lda=%d b=%p ldb=%d beta=%p \"\n      \"c=%p ldc=%d\",\n      static_cast<int>(transa), static_cast<int>(transb), m, n, k, alpha,\n      a.opaque(), lda, b.opaque(), ldb, beta, c->opaque(), ldc);\n\n  switch (dtype) {\n    case blas::DataType::kHalf: {\n      const Eigen::half alpha_half(*static_cast<const float *>(alpha));\n      const Eigen::half beta_half(*static_cast<const float *>(beta));\n      return DoBlasInternalStatus(\n          wrap::rocblas_hgemm_strided_batched, stream,\n          false, /* pointer_mode_host */\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          reinterpret_cast<const rocblas_half *>(&alpha_half),\n          reinterpret_cast<const rocblas_half *>(a.opaque()), lda, stride_a,\n          reinterpret_cast<const rocblas_half *>(b.opaque()), ldb, stride_b,\n          reinterpret_cast<const rocblas_half *>(&beta_half),\n          reinterpret_cast<rocblas_half *>(c->opaque()), ldc, stride_c,\n          batch_count);\n    }\n    case blas::DataType::kBF16:\n      return DoBlasInternalStatus(\n          wrap::rocblas_gemm_strided_batched_ex, stream,\n          false, /* pointer_mode_host */\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k, alpha,\n          a.opaque(), rocblas_datatype_bf16_r, lda, stride_a, b.opaque(),\n          rocblas_datatype_bf16_r, ldb, stride_b, beta, c->opaque(),\n          rocblas_datatype_bf16_r, ldc, stride_c, c->opaque(),\n          rocblas_datatype_bf16_r, ldc, stride_c, batch_count,\n          rocblas_datatype_f32_r, rocblas_gemm_algo_standard, 0, 0);\n    case blas::DataType::kFloat:\n      return DoBlasInternalStatus(\n          wrap::rocblas_sgemm_strided_batched, stream,\n          false, /* pointer_mode_host */\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          reinterpret_cast<const float *>(alpha),\n          reinterpret_cast<const float *>(a.opaque()), lda, stride_a,\n          reinterpret_cast<const float *>(b.opaque()), ldb, stride_b,\n          reinterpret_cast<const float *>(beta),\n          reinterpret_cast<float *>(c->opaque()), ldc, stride_c, batch_count);\n    case blas::DataType::kDouble:\n      return DoBlasInternalStatus(\n          wrap::rocblas_dgemm_strided_batched, stream,\n          false, /* pointer_mode_host */\n          ROCMBlasTranspose(transa), ROCMBlasTranspose(transb), m, n, k,\n          reinterpret_cast<const double *>(alpha),\n          reinterpret_cast<const double *>(a.opaque()), lda, stride_a,\n          reinterpret_cast<const double *>(b.opaque()), ldb, stride_b,\n          reinterpret_cast<const double *>(beta),\n          reinterpret_cast<double *>(c->opaque()), ldc, stride_c, batch_count);\n    case blas::DataType::kComplexFloat: {\n      auto cb_alpha =\n          complex_cast(*static_cast<const std::complex<float> *>(alpha));\n      auto cb_beta =\n          complex_cast(*static_cast<const std::complex<float> *>(beta));\n      return DoBlasInternalStatus(\n          wrap::rocblas_cgemm_strided_batched, stream,\n          /* pointer_mode_host = */ true, ROCMBlasTranspose(transa),\n          ROCMBlasTranspose(transb), m, n, k, cb_alpha,\n          static_cast<const rocblas_float_complex *>(a.opaque()), lda, stride_a,\n          static_cast<const rocblas_float_complex *>(b.opaque()), ldb, stride_b,\n          cb_beta, static_cast<rocblas_float_complex *>(c->opaque()), ldc,\n          stride_c, batch_count);\n    }\n    case blas::DataType::kComplexDouble: {\n      auto cb_alpha =\n          complex_cast(*static_cast<const std::complex<double> *>(alpha));\n      auto cb_beta =\n          complex_cast(*static_cast<const std::complex<double> *>(beta));\n      return DoBlasInternalStatus(\n          wrap::rocblas_zgemm_strided_batched, stream,\n          /* pointer_mode_host = */ true, ROCMBlasTranspose(transa),\n          ROCMBlasTranspose(transb), m, n, k, cb_alpha,\n          static_cast<const rocblas_double_complex *>(a.opaque()), lda,\n          stride_a, static_cast<const rocblas_double_complex *>(b.opaque()),\n          ldb, stride_b, cb_beta,\n          static_cast<rocblas_double_complex *>(c->opaque()), ldc, stride_c,\n          batch_count);\n    }\n    default:\n      return tsl::errors::Internal(absl::StrCat(\n          \"Unsupported datatype for GEMM: \", blas::DataTypeString(dtype)));\n  }\n}\n\ntsl::Status ROCMBlas::GetVersion(string *version) {\n  return tsl::errors::Unimplemented(\"\");\n}\n\n}  // namespace gpu\n\nvoid initialize_rocblas() {\n  auto rocBlasAlreadyRegistered = PluginRegistry::Instance()->HasFactory(\n      rocm::kROCmPlatformId, PluginKind::kBlas, gpu::kRocBlasPlugin);\n\n  if (!rocBlasAlreadyRegistered) {\n    tsl::Status status =\n        PluginRegistry::Instance()\n            ->RegisterFactory<PluginRegistry::BlasFactory>(\n                rocm::kROCmPlatformId, gpu::kRocBlasPlugin, \"rocBLAS\",\n                [](internal::StreamExecutorInterface *parent)\n                    -> blas::BlasSupport * {\n                  gpu::GpuExecutor *rocm_executor =\n                      dynamic_cast<gpu::GpuExecutor *>(parent);\n                  if (rocm_executor == nullptr) {\n                    LOG(ERROR)\n                        << \"Attempting to initialize an instance of the \"\n                           \"rocBLAS \"\n                        << \"support library with a non-ROCM StreamExecutor\";\n                    return nullptr;\n                  }\n\n                  gpu::ROCMBlas *blas = new gpu::ROCMBlas(rocm_executor);\n                  if (!blas->Init()) {\n                    // Note: Init() will log a more specific error.\n                    delete blas;\n                    return nullptr;\n                  }\n                  return blas;\n                });\n\n    if (!status.ok()) {\n      LOG(ERROR) << \"Unable to register rocBLAS factory: \"\n                 << status.error_message();\n    }\n\n    PluginRegistry::Instance()->SetDefaultFactory(\n        rocm::kROCmPlatformId, PluginKind::kBlas, gpu::kRocBlasPlugin);\n  }\n}\n\n}  // namespace stream_executor\n\nREGISTER_MODULE_INITIALIZER(register_rocblas,\n                            { stream_executor::initialize_rocblas(); });"