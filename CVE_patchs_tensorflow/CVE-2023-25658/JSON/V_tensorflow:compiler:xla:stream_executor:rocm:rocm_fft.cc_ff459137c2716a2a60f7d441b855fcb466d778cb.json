"/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.h\"\n\n#include <complex>\n\n#include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_activation.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"\n#include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"\n#include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"\n#include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"\n#include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"\n#include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"\n#include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"\n#include \"tensorflow/tsl/platform/env.h\"\n\nnamespace stream_executor {\nnamespace gpu {\n\nPLUGIN_REGISTRY_DEFINE_PLUGIN_ID(kRocFftPlugin);\n\nnamespace wrap {\n\n#ifdef PLATFORM_GOOGLE\n// This macro wraps a global identifier, given by __name, in a callable\n// structure that loads the DLL symbol out of the DSO handle in a thread-safe\n// manner on first use. This dynamic loading technique is used to avoid DSO\n// dependencies on vendor libraries which may or may not be available in the\n// deployed binary environment.\n#define STREAM_EXECUTOR_ROCFFT_WRAP(__name)                      \\\n  struct WrapperShim__##__name {                                 \\\n    template <typename... Args>                                  \\\n    hipfftResult operator()(GpuExecutor *parent, Args... args) { \\\n      gpu::ScopedActivateExecutorContext sac{parent};            \\\n      return ::__name(args...);                                  \\\n    }                                                            \\\n  } __name;\n\n#else\n\n#define STREAM_EXECUTOR_ROCFFT_WRAP(__name)                              \\\n  struct DynLoadShim__##__name {                                         \\\n    static const char *kName;                                            \\\n    using FuncPtrT = std::add_pointer<decltype(::__name)>::type;         \\\n    static void *GetDsoHandle() {                                        \\\n      auto s = internal::CachedDsoLoader::GetHipfftDsoHandle();          \\\n      return s.value();                                                  \\\n    }                                                                    \\\n    static FuncPtrT LoadOrDie() {                                        \\\n      void *f;                                                           \\\n      auto s = tsl::Env::Default()->GetSymbolFromLibrary(GetDsoHandle(), \\\n                                                         kName, &f);     \\\n      CHECK(s.ok()) << \"could not find \" << kName                        \\\n                    << \" in rocfft DSO; dlerror: \" << s.error_message(); \\\n      return reinterpret_cast<FuncPtrT>(f);                              \\\n    }                                                                    \\\n    static FuncPtrT DynLoad() {                                          \\\n      static FuncPtrT f = LoadOrDie();                                   \\\n      return f;                                                          \\\n    }                                                                    \\\n    template <typename... Args>                                          \\\n    hipfftResult operator()(GpuExecutor *parent, Args... args) {         \\\n      gpu::ScopedActivateExecutorContext sac{parent};                    \\\n      return DynLoad()(args...);                                         \\\n    }                                                                    \\\n  } __name;                                                              \\\n  const char *DynLoadShim__##__name::kName = #__name;\n\n#endif\n\n// clang-format off\n#define ROCFFT_ROUTINE_EACH(__macro) \\\n  __macro(hipfftDestroy)             \\\n  __macro(hipfftSetStream)           \\\n  __macro(hipfftPlan1d)              \\\n  __macro(hipfftPlan2d)              \\\n  __macro(hipfftPlan3d)              \\\n  __macro(hipfftPlanMany)            \\\n  __macro(hipfftCreate)              \\\n  __macro(hipfftSetAutoAllocation)   \\\n  __macro(hipfftSetWorkArea)         \\\n  __macro(hipfftGetSize1d)           \\\n  __macro(hipfftMakePlan1d)          \\\n  __macro(hipfftGetSize2d)           \\\n  __macro(hipfftMakePlan2d)          \\\n  __macro(hipfftGetSize3d)           \\\n  __macro(hipfftMakePlan3d)          \\\n  __macro(hipfftGetSizeMany)         \\\n  __macro(hipfftMakePlanMany)        \\\n  __macro(hipfftExecD2Z)             \\\n  __macro(hipfftExecZ2D)             \\\n  __macro(hipfftExecC2C)             \\\n  __macro(hipfftExecC2R)             \\\n  __macro(hipfftExecZ2Z)             \\\n  __macro(hipfftExecR2C)\n\n// clang-format on\n\nROCFFT_ROUTINE_EACH(STREAM_EXECUTOR_ROCFFT_WRAP)\n\n}  // namespace wrap\n\nnamespace {\n\n// A helper function transforming gpu_fft arguments into rocFFT arguments.\nhipfftType ROCMFftType(fft::Type type) {\n  switch (type) {\n    case fft::Type::kC2CForward:\n    case fft::Type::kC2CInverse:\n      return HIPFFT_C2C;\n    case fft::Type::kC2R:\n      return HIPFFT_C2R;\n    case fft::Type::kR2C:\n      return HIPFFT_R2C;\n    case fft::Type::kZ2ZForward:\n    case fft::Type::kZ2ZInverse:\n      return HIPFFT_Z2Z;\n    case fft::Type::kZ2D:\n      return HIPFFT_Z2D;\n    case fft::Type::kD2Z:\n      return HIPFFT_D2Z;\n    default:\n      LOG(FATAL) << \"Invalid value of fft::Type.\";\n  }\n}\n\n// Associates the given stream with the given rocFFT plan.\nbool SetStream(GpuExecutor *parent, hipfftHandle plan, Stream *stream) {\n  auto ret = wrap::hipfftSetStream(parent, plan, AsGpuStreamValue(stream));\n  if (ret != HIPFFT_SUCCESS) {\n    LOG(ERROR) << \"failed to run rocFFT routine hipfftSetStream: \" << ret;\n    return false;\n  }\n  return true;\n}\n\n}  // namespace\n\ntsl::Status ROCMFftPlan::Initialize(\n    GpuExecutor *parent, Stream *stream, int rank, uint64_t *elem_count,\n    uint64_t *input_embed, uint64 input_stride, uint64 input_distance,\n    uint64_t *output_embed, uint64 output_stride, uint64 output_distance,\n    fft::Type type, int batch_count, ScratchAllocator *scratch_allocator) {\n  if (IsInitialized()) {\n    LOG(FATAL) << \"Try to repeatedly initialize.\";\n  }\n  is_initialized_ = true;\n  scratch_allocator_ = scratch_allocator;\n  int elem_count_[3], input_embed_[3], output_embed_[3];\n  for (int i = 0; i < rank; ++i) {\n    elem_count_[i] = elem_count[i];\n    if (input_embed) {\n      input_embed_[i] = input_embed[i];\n    }\n    if (output_embed) {\n      output_embed_[i] = output_embed[i];\n    }\n  }\n  parent_ = parent;\n  fft_type_ = type;\n  if (batch_count == 1 && input_embed == nullptr && output_embed == nullptr) {\n    hipfftResult_t ret;\n    if (scratch_allocator == nullptr) {\n      switch (rank) {\n        case 1:\n          // hipfftPlan1d\n          ret = wrap::hipfftPlan1d(parent, &plan_, elem_count_[0],\n                                   ROCMFftType(type), 1 /* = batch */);\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to create rocFFT 1d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to create rocFFT 1d plan.\"};\n          }\n          return tsl::OkStatus();\n        case 2:\n          // hipfftPlan2d\n          ret = wrap::hipfftPlan2d(parent, &plan_, elem_count_[0],\n                                   elem_count_[1], ROCMFftType(type));\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to create rocFFT 2d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to create rocFFT 2d plan.\"};\n          }\n          return tsl::OkStatus();\n        case 3:\n          // hipfftPlan3d\n          ret =\n              wrap::hipfftPlan3d(parent, &plan_, elem_count_[0], elem_count_[1],\n                                 elem_count_[2], ROCMFftType(type));\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to create rocFFT 3d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to create rocFFT 3d plan.\"};\n          }\n          return tsl::OkStatus();\n        default:\n          LOG(ERROR) << \"Invalid rank value for hipfftPlan. \"\n                        \"Requested 1, 2, or 3, given: \"\n                     << rank;\n          return tsl::Status{tsl::error::INVALID_ARGUMENT,\n                             \"hipfftPlan only takes rank 1, 2, or 3.\"};\n      }\n    } else {\n      ret = wrap::hipfftCreate(parent, &plan_);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to create rocFFT plan:\" << ret;\n        return tsl::Status{tsl::error::INTERNAL,\n                           \"Failed to create rocFFT plan.\"};\n      }\n      ret = wrap::hipfftSetAutoAllocation(parent, plan_, 0);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to set auto allocation for rocFFT plan:\" << ret;\n        return tsl::Status{tsl::error::INTERNAL,\n                           \"Failed to set auto allocation for rocFFT plan.\"};\n      }\n      switch (rank) {\n        case 1:\n          ret = wrap::hipfftMakePlan1d(parent, plan_, elem_count_[0],\n                                       ROCMFftType(type), /*batch=*/1,\n                                       &scratch_size_bytes_);\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to make rocFFT 1d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to make rocFFT 1d plan.\"};\n          }\n          break;\n        case 2:\n          ret = wrap::hipfftMakePlan2d(parent, plan_, elem_count_[0],\n                                       elem_count_[1], ROCMFftType(type),\n                                       &scratch_size_bytes_);\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to make rocFFT 2d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to make rocFFT 2d plan.\"};\n          }\n          break;\n        case 3:\n          ret = wrap::hipfftMakePlan3d(parent, plan_, elem_count_[0],\n                                       elem_count_[1], elem_count_[2],\n                                       ROCMFftType(type), &scratch_size_bytes_);\n          if (ret != HIPFFT_SUCCESS) {\n            LOG(ERROR) << \"failed to make rocFFT 3d plan:\" << ret;\n            return tsl::Status{tsl::error::INTERNAL,\n                               \"Failed to make rocFFT 3d plan.\"};\n          }\n          break;\n        default:\n          LOG(ERROR) << \"Invalid rank value for hipfftPlan. \"\n                        \"Requested 1, 2, or 3, given: \"\n                     << rank;\n          return tsl::Status{tsl::error::INVALID_ARGUMENT,\n                             \"hipfftPlan only takes rank 1, 2, or 3.\"};\n      }\n      return UpdateScratchAllocator(stream, scratch_allocator);\n    }\n  } else {\n    // For either multiple batches or rank higher than 3, use hipfftPlanMany().\n    if (scratch_allocator == nullptr) {\n      auto ret = wrap::hipfftPlanMany(\n          parent, &plan_, rank, elem_count_,\n          input_embed ? input_embed_ : nullptr, input_stride, input_distance,\n          output_embed ? output_embed_ : nullptr, output_stride,\n          output_distance, ROCMFftType(type), batch_count);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to create rocFFT batched plan:\" << ret;\n        return tsl::Status{tsl::error::INTERNAL,\n                           \"Failed to create rocFFT batched plan.\"};\n      }\n    } else {\n      auto ret = wrap::hipfftCreate(parent, &plan_);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to create rocFFT batched plan:\" << ret;\n        return tsl::Status{tsl::error::INTERNAL,\n                           \"Failed to create rocFFT batched plan.\"};\n      }\n      ret = wrap::hipfftSetAutoAllocation(parent, plan_, 0);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to set auto allocation for rocFFT batched plan:\"\n                   << ret;\n        return tsl::Status{\n            tsl::error::INTERNAL,\n            \"Failed to set auto allocation for rocFFT batched plan.\"};\n      }\n      ret = wrap::hipfftMakePlanMany(\n          parent, plan_, rank, elem_count_,\n          input_embed ? input_embed_ : nullptr, input_stride, input_distance,\n          output_embed ? output_embed_ : nullptr, output_stride,\n          output_distance, ROCMFftType(type), batch_count,\n          &scratch_size_bytes_);\n      if (ret != HIPFFT_SUCCESS) {\n        LOG(ERROR) << \"failed to make rocFFT batched plan:\" << ret;\n        return tsl::Status{tsl::error::INTERNAL,\n                           \"Failed to make rocFFT batched plan.\"};\n      }\n      return UpdateScratchAllocator(stream, scratch_allocator);\n    }\n  }\n  return tsl::OkStatus();\n}\n\ntsl::Status ROCMFftPlan::Initialize(GpuExecutor *parent, Stream *stream,\n                                    int rank, uint64_t *elem_count,\n                                    fft::Type type,\n                                    ScratchAllocator *scratch_allocator) {\n  return Initialize(parent_, stream, rank, elem_count,\n                    /*input_embed=*/nullptr, /*input_stride=*/0,\n                    /*input_distance=*/0,\n                    /*output_embed=*/nullptr, /*output_stride=*/0,\n                    /*output_distance=*/0, type, 1, scratch_allocator);\n}\n\ntsl::Status ROCMFftPlan::UpdateScratchAllocator(\n    Stream *stream, ScratchAllocator *scratch_allocator) {\n  scratch_allocator_ = scratch_allocator;\n  if (scratch_size_bytes_ != 0) {\n    auto allocated = scratch_allocator->AllocateBytes(scratch_size_bytes_);\n    if (!allocated.ok() || (scratch_ = allocated.value()) == nullptr) {\n      LOG(ERROR) << \"failed to allocate work area.\";\n      return allocated.status();\n    }\n  }\n  // Connect work area with allocated space.\n  auto ret = wrap::hipfftSetWorkArea(parent_, plan_, scratch_.opaque());\n  if (ret != HIPFFT_SUCCESS) {\n    LOG(ERROR) << \"failed to set work area for rocFFT plan:\" << ret;\n    return tsl::Status(tsl::error::INTERNAL,\n                       \"Failed to set work area for rocFFT plan.\");\n  }\n  return tsl::OkStatus();\n}\n\nROCMFftPlan::~ROCMFftPlan() { wrap::hipfftDestroy(parent_, plan_); }\n\nint ROCMFftPlan::GetFftDirection() const {\n  if (!IsInitialized()) {\n    LOG(FATAL) << \"Try to get fft direction before initialization.\";\n  } else {\n    switch (fft_type_) {\n      case fft::Type::kC2CForward:\n      case fft::Type::kZ2ZForward:\n      case fft::Type::kR2C:\n      case fft::Type::kD2Z:\n        return HIPFFT_FORWARD;\n      case fft::Type::kC2CInverse:\n      case fft::Type::kZ2ZInverse:\n      case fft::Type::kC2R:\n      case fft::Type::kZ2D:\n        return HIPFFT_BACKWARD;\n      default:\n        LOG(FATAL) << \"Invalid value of fft::Type.\";\n    }\n  }\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create1dPlan(Stream *stream, uint64_t num_x,\n                                                 fft::Type type,\n                                                 bool in_place_fft) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[1] = {num_x};\n  tsl::Status status =\n      fft_plan_ptr->Initialize(parent_, stream, 1, elem_count, type,\n                               /*scratch_allocator=*/nullptr);\n  // TODO(yangzihao): In the future, send error msg back to TensorFlow\n  // so it can fail gracefully,\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to initialize hipfft 1d plan: \"\n               << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create1dPlanWithScratchAllocator(\n    Stream *stream, uint64_t num_x, fft::Type type, bool in_place_fft,\n    ScratchAllocator *scratch_allocator) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[1] = {num_x};\n  tsl::Status status = fft_plan_ptr->Initialize(parent_, stream, 1, elem_count,\n                                                type, scratch_allocator);\n  if (!status.ok()) {\n    LOG(FATAL)\n        << \"failed to initialize hipfft 1d plan with customized allocator: \"\n        << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create2dPlan(Stream *stream, uint64_t num_x,\n                                                 uint64_t num_y, fft::Type type,\n                                                 bool in_place_fft) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[2] = {num_x, num_y};\n  tsl::Status status =\n      fft_plan_ptr->Initialize(parent_, stream, 1, elem_count, type,\n                               /*scratch_allocator=*/nullptr);\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to initialize hipfft 2d plan: \"\n               << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create2dPlanWithScratchAllocator(\n    Stream *stream, uint64_t num_x, uint64 num_y, fft::Type type,\n    bool in_place_fft, ScratchAllocator *scratch_allocator) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[2] = {num_x, num_y};\n  tsl::Status status = fft_plan_ptr->Initialize(parent_, stream, 2, elem_count,\n                                                type, scratch_allocator);\n  if (!status.ok()) {\n    LOG(FATAL)\n        << \"failed to initialize hipfft 2d plan with customized allocator: \"\n        << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create3dPlan(Stream *stream, uint64_t num_x,\n                                                 uint64_t num_y, uint64 num_z,\n                                                 fft::Type type,\n                                                 bool in_place_fft) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[3] = {num_x, num_y, num_z};\n  tsl::Status status =\n      fft_plan_ptr->Initialize(parent_, stream, 3, elem_count, type,\n                               /*scratch_allocator=*/nullptr);\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to initialize hipfft 3d plan: \"\n               << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::Create3dPlanWithScratchAllocator(\n    Stream *stream, uint64_t num_x, uint64 num_y, uint64 num_z, fft::Type type,\n    bool in_place_fft, ScratchAllocator *scratch_allocator) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  uint64_t elem_count[3] = {num_x, num_y, num_z};\n  tsl::Status status = fft_plan_ptr->Initialize(parent_, stream, 3, elem_count,\n                                                type, scratch_allocator);\n  if (!status.ok()) {\n    LOG(FATAL)\n        << \"failed to initialize hipfft 3d plan with customized allocator: \"\n        << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::CreateBatchedPlan(\n    Stream *stream, int rank, uint64_t *elem_count, uint64 *input_embed,\n    uint64_t input_stride, uint64 input_distance, uint64 *output_embed,\n    uint64_t output_stride, uint64 output_distance, fft::Type type,\n    bool in_place_fft, int batch_count) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  tsl::Status status = fft_plan_ptr->Initialize(\n      parent_, stream, rank, elem_count, input_embed, input_stride,\n      input_distance, output_embed, output_stride, output_distance, type,\n      batch_count, /*scratch_allocator=*/nullptr);\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to initialize batched hipfft plan: \"\n               << status.error_message();\n  }\n\n  return std::move(fft_plan_ptr);\n}\n\nstd::unique_ptr<fft::Plan> ROCMFft::CreateBatchedPlanWithScratchAllocator(\n    Stream *stream, int rank, uint64_t *elem_count, uint64 *input_embed,\n    uint64_t input_stride, uint64 input_distance, uint64 *output_embed,\n    uint64_t output_stride, uint64 output_distance, fft::Type type,\n    bool in_place_fft, int batch_count, ScratchAllocator *scratch_allocator) {\n  std::unique_ptr<ROCMFftPlan> fft_plan_ptr{new ROCMFftPlan()};\n  tsl::Status status = fft_plan_ptr->Initialize(\n      parent_, stream, rank, elem_count, input_embed, input_stride,\n      input_distance, output_embed, output_stride, output_distance, type,\n      batch_count, scratch_allocator);\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to initialize batched hipfft plan with customized \"\n                  \"allocator: \"\n               << status.error_message();\n  }\n  return std::move(fft_plan_ptr);\n}\n\nvoid ROCMFft::UpdatePlanWithScratchAllocator(\n    Stream *stream, fft::Plan *plan, ScratchAllocator *scratch_allocator) {\n  ROCMFftPlan *rocm_fft_plan = dynamic_cast<ROCMFftPlan *>(plan);\n  tsl::Status status =\n      rocm_fft_plan->UpdateScratchAllocator(stream, scratch_allocator);\n  if (!status.ok()) {\n    LOG(FATAL) << \"failed to update custom allocator for hipfft plan: \"\n               << status.error_message();\n  }\n}\n\ntemplate <typename FuncT, typename InputT, typename OutputT>\nbool ROCMFft::DoFftInternal(Stream *stream, fft::Plan *plan, FuncT hipfftExec,\n                            const DeviceMemory<InputT> &input,\n                            DeviceMemory<OutputT> *output) {\n  ROCMFftPlan *rocm_fft_plan = dynamic_cast<ROCMFftPlan *>(plan);\n  if (rocm_fft_plan == nullptr) {\n    LOG(ERROR) << \"the passed-in plan is not a ROCMFftPlan object.\";\n    return false;\n  }\n\n  if (!SetStream(parent_, rocm_fft_plan->GetPlan(), stream)) {\n    return false;\n  }\n\n  // As per rocFFT documentation, input buffers may be overwritten during\n  // execution of the C2R / D2Z transforms, even if the transform is not\n  // in-place.\n  // see rocFFT issue #298 for more info\n  //\n  // Same seems to apply for the R2C / Z2D transforms, as reported in\n  // see ROCm TF issue # 1150\n  //\n  // Hence for all those transforms, copy the input buffer\n  DeviceMemory<InputT> input_maybe_copy = input;\n  if (input.opaque() != output->opaque() && (input.size() > 0)) {\n    auto *allocator = rocm_fft_plan->GetScratchAllocator();\n    if (allocator) {\n      auto allocated = allocator->AllocateBytes(input.size());\n      if (allocated.ok()) {\n        if (stream->ThenMemcpy(&allocated.value(), input, input.size())\n                .ok()) {\n          input_maybe_copy = DeviceMemory<InputT>(allocated.value());\n        } else {\n          LOG(ERROR) << \"failed to copy input buffer for rocFFT.\";\n        }\n      }\n    }\n  }\n\n  InputT *ip = const_cast<InputT *>(GpuMemory(input_maybe_copy));\n  auto ret = hipfftExec(parent_, rocm_fft_plan->GetPlan(), GpuComplex(ip),\n                        GpuComplex(GpuMemoryMutable(output)));\n\n  if (ret != HIPFFT_SUCCESS) {\n    LOG(ERROR) << \"failed to run rocFFT routine: \" << ret;\n    return false;\n  }\n\n  return true;\n}\n\ntemplate <typename FuncT, typename InputT, typename OutputT>\nbool ROCMFft::DoFftWithDirectionInternal(Stream *stream, fft::Plan *plan,\n                                         FuncT hipfftExec,\n                                         const DeviceMemory<InputT> &input,\n                                         DeviceMemory<OutputT> *output) {\n  ROCMFftPlan *rocm_fft_plan = dynamic_cast<ROCMFftPlan *>(plan);\n  if (rocm_fft_plan == nullptr) {\n    LOG(ERROR) << \"the passed-in plan is not a ROCMFftPlan object.\";\n    return false;\n  }\n\n  if (!SetStream(parent_, rocm_fft_plan->GetPlan(), stream)) {\n    return false;\n  }\n\n  auto ret = hipfftExec(parent_, rocm_fft_plan->GetPlan(),\n                        GpuComplex(const_cast<InputT *>(GpuMemory(input))),\n                        GpuComplex(GpuMemoryMutable(output)),\n                        rocm_fft_plan->GetFftDirection());\n\n  if (ret != HIPFFT_SUCCESS) {\n    LOG(ERROR) << \"failed to run rocFFT routine: \" << ret;\n    return false;\n  }\n\n  return true;\n}\n\n#define STREAM_EXECUTOR_ROCM_DEFINE_FFT(__type, __fft_type1, __fft_type2,    \\\n                                        __fft_type3)                         \\\n  bool ROCMFft::DoFft(Stream *stream, fft::Plan *plan,                       \\\n                      const DeviceMemory<std::complex<__type>> &input,       \\\n                      DeviceMemory<std::complex<__type>> *output) {          \\\n    return DoFftWithDirectionInternal(                                       \\\n        stream, plan, wrap::hipfftExec##__fft_type1, input, output);         \\\n  }                                                                          \\\n  bool ROCMFft::DoFft(Stream *stream, fft::Plan *plan,                       \\\n                      const DeviceMemory<__type> &input,                     \\\n                      DeviceMemory<std::complex<__type>> *output) {          \\\n    return DoFftInternal(stream, plan, wrap::hipfftExec##__fft_type2, input, \\\n                         output);                                            \\\n  }                                                                          \\\n  bool ROCMFft::DoFft(Stream *stream, fft::Plan *plan,                       \\\n                      const DeviceMemory<std::complex<__type>> &input,       \\\n                      DeviceMemory<__type> *output) {                        \\\n    return DoFftInternal(stream, plan, wrap::hipfftExec##__fft_type3, input, \\\n                         output);                                            \\\n  }\n\nSTREAM_EXECUTOR_ROCM_DEFINE_FFT(float, C2C, R2C, C2R)\nSTREAM_EXECUTOR_ROCM_DEFINE_FFT(double, Z2Z, D2Z, Z2D)\n\n#undef STREAM_EXECUTOR_ROCM_DEFINE_FFT\n\n}  // namespace gpu\n\nvoid initialize_rocfft() {\n  auto rocFftAlreadyRegistered = PluginRegistry::Instance()->HasFactory(\n      rocm::kROCmPlatformId, PluginKind::kFft, gpu::kRocFftPlugin);\n\n  if (!rocFftAlreadyRegistered) {\n    tsl::Status status =\n        PluginRegistry::Instance()->RegisterFactory<PluginRegistry::FftFactory>(\n            rocm::kROCmPlatformId, gpu::kRocFftPlugin, \"rocFFT\",\n            [](internal::StreamExecutorInterface *parent) -> fft::FftSupport * {\n              gpu::GpuExecutor *rocm_executor =\n                  dynamic_cast<gpu::GpuExecutor *>(parent);\n              if (rocm_executor == nullptr) {\n                LOG(ERROR)\n                    << \"Attempting to initialize an instance of the rocFFT \"\n                    << \"support library with a non-ROCM StreamExecutor\";\n                return nullptr;\n              }\n\n              return new gpu::ROCMFft(rocm_executor);\n            });\n    if (!status.ok()) {\n      LOG(ERROR) << \"Unable to register rocFFT factory: \"\n                 << status.error_message();\n    }\n\n    PluginRegistry::Instance()->SetDefaultFactory(\n        rocm::kROCmPlatformId, PluginKind::kFft, gpu::kRocFftPlugin);\n  }\n}\n\n}  // namespace stream_executor\n\nREGISTER_MODULE_INITIALIZER(register_rocfft,\n                            { stream_executor::initialize_rocfft(); });"