"/* Copyright 2022 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/data/service/snapshot/snapshot_manager.h\"\n\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/data/service/common.pb.h\"\n#include \"tensorflow/core/data/service/dispatcher.pb.h\"\n#include \"tensorflow/core/data/service/snapshot/file_utils.h\"\n#include \"tensorflow/core/data/service/snapshot/path_utils.h\"\n#include \"tensorflow/core/data/service/split_provider.h\"\n#include \"tensorflow/core/data/snapshot_utils.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/tsl/platform/env.h\"\n#include \"tensorflow/tsl/platform/errors.h\"\n#include \"tensorflow/tsl/platform/statusor.h\"\n\nnamespace tensorflow {\nnamespace data {\n\nusing ::tsl::OkStatus;\nusing ::tsl::errors::InvalidArgument;\n\nStatusOr<std::unique_ptr<SnapshotManager>> SnapshotManager::Start(\n    const SnapshotRequest& request, Env* env) {\n  SnapshotManager* snapshot_manager = new SnapshotManager(request.path(), env);\n  TF_RETURN_IF_ERROR(snapshot_manager->Start(request));\n  return absl::WrapUnique(snapshot_manager);\n}\n\nStatus SnapshotManager::Start(const SnapshotRequest& request) {\n  if (env_->FileExists(request.path()).ok()) {\n    return InvalidArgument(request.path(), \" already exists\");\n  }\n  TF_RETURN_IF_ERROR(CreateSplitProviders(request.dataset(), split_providers_));\n  TF_RETURN_IF_ERROR(WriteOnDiskSkeleton());\n  TF_RETURN_IF_ERROR(WriteOnDiskMetadata(request));\n  metadata_ = request.metadata();\n  return OkStatus();\n}\n\nStatus SnapshotManager::WriteOnDiskSkeleton() {\n  TF_RETURN_IF_ERROR(\n      env_->RecursivelyCreateDir(CommittedChunksDirectory(path_)));\n  TF_RETURN_IF_ERROR(env_->RecursivelyCreateDir(StreamsDirectory(path_)));\n  return OkStatus();\n}\n\nStatus SnapshotManager::WriteOnDiskMetadata(const SnapshotRequest& request) {\n  TF_RETURN_IF_ERROR(WriteTextProto(env_, SnapshotMetadataFilePath(path_),\n                                    request.metadata()));\n  TF_RETURN_IF_ERROR(\n      WriteBinaryProto(env_, DatasetDefFilePath(path_), request.dataset()));\n  return OkStatus();\n}\n\nStatusOr<std::unique_ptr<SnapshotManager>> SnapshotManager::Resume(\n    absl::string_view path, Env* env) {\n  SnapshotManager* snapshot_manager = new SnapshotManager(path, env);\n  TF_RETURN_IF_ERROR(snapshot_manager->Resume());\n  return absl::WrapUnique(snapshot_manager);\n}\n\nStatus SnapshotManager::Resume() {\n  if (!env_->FileExists(path_).ok()) {\n    return InvalidArgument(\"failed to recover snapshot at \", path_,\n                           \": the snapshot path doesn't exist\");\n  }\n  TF_RETURN_IF_ERROR(ReadOnDiskMetadata());\n  TF_RETURN_IF_ERROR(ReadOnDiskStreams());\n  return OkStatus();\n}\n\nStatus SnapshotManager::ReadOnDiskMetadata() {\n  if (!env_->FileExists(SnapshotMetadataFilePath(path_)).ok()) {\n    return InvalidArgument(\"failed to recover snapshot at \", path_,\n                           \": snapshot has no snapshot.metadata\");\n  }\n  TF_RETURN_IF_ERROR(\n      ReadTextProto(env_, SnapshotMetadataFilePath(path_), &metadata_));\n\n  if (!env_->FileExists(DatasetDefFilePath(path_)).ok()) {\n    return InvalidArgument(\"failed to recovery snapshot at \", path_,\n                           \": snapshot has no dataset_def.proto\");\n  }\n  DatasetDef dataset_def;\n  TF_RETURN_IF_ERROR(\n      ReadBinaryProto(env_, DatasetDefFilePath(path_), &dataset_def));\n\n  TF_RETURN_IF_ERROR(CreateSplitProviders(dataset_def, split_providers_));\n  return OkStatus();\n}\n\nStatus SnapshotManager::ReadOnDiskStreams() {\n  std::string streams_path = StreamsDirectory(path_);\n\n  std::vector<std::string> stream_directories;\n  TF_RETURN_IF_ERROR(env_->GetChildren(streams_path, &stream_directories));\n  streams_.resize(stream_directories.size(), Stream(num_sources()));\n\n  absl::flat_hash_set<int64_t> global_split_indices;\n  for (const auto& stream_directory : stream_directories) {\n    std::string stream_path = io::JoinPath(streams_path, stream_directory);\n\n    // `stream_directory` must have this format: \"stream_<stream_index>\".\n    std::vector<std::string> tokens = absl::StrSplit(stream_directory, '_');\n    int64_t stream_index;\n    if (tokens.size() != 2 || !absl::SimpleAtoi(tokens[1], &stream_index) ||\n        stream_index < 0) {\n      return InvalidArgument(\n          \"can't parse the name of \", stream_path,\n          \": filename must have the format stream_<stream_index>\");\n    }\n\n    TF_RETURN_IF_ERROR(ReadOnDiskStream(stream_index, global_split_indices));\n  }\n\n  for (int64_t i = 0; i < global_split_indices.size(); ++i) {\n    if (!global_split_indices.contains(i)) {\n      return InvalidArgument(\"found missing global split index, \", i, \", in \",\n                             path_);\n    }\n  }\n  num_assigned_splits_ = global_split_indices.size();\n\n  return OkStatus();\n}\n\nStatus SnapshotManager::ReadOnDiskStream(\n    int64_t stream_index, absl::flat_hash_set<int64_t>& global_split_indices) {\n  std::string splits_path = SplitsDirectory(path_, stream_index);\n  std::vector<std::string> source_directories;\n  TF_RETURN_IF_ERROR(env_->GetChildren(splits_path, &source_directories));\n  for (const auto& source_directory : source_directories) {\n    std::string source_path = io::JoinPath(splits_path, source_directory);\n\n    // `source_directory` must have this format: \"source_<source_index>\".\n    std::vector<std::string> tokens = absl::StrSplit(source_directory, '_');\n    int64_t source_index;\n    if (tokens.size() != 2 || !absl::SimpleAtoi(tokens[1], &source_index) ||\n        source_index < 0) {\n      return InvalidArgument(\n          \"can't parse the name of \", source_path,\n          \": filename must have the format source_<source_index>\");\n    }\n    if (source_index >= num_sources()) {\n      return InvalidArgument(\"found conflict between the number of sources, \",\n                             num_sources(), \", and the filename of \",\n                             source_path);\n    }\n    TF_RETURN_IF_ERROR(\n        ReadOnDiskSource(stream_index, source_index, global_split_indices));\n  }\n\n  // TODO(mpcallanan): Handle unknowns.\n\n  return OkStatus();\n}\n\nStatus SnapshotManager::ReadOnDiskSource(\n    int64_t stream_index, int64_t source_index,\n    absl::flat_hash_set<int64_t>& global_split_indices) {\n  std::string source_path = SourceDirectory(path_, stream_index, source_index);\n\n  std::vector<std::string> split_filenames;\n  TF_RETURN_IF_ERROR(env_->GetChildren(source_path, &split_filenames));\n\n  Tensor unused_tensor;\n  bool unused_end_of_splits;\n  for (const auto& split_filename : split_filenames) {\n    std::string split_path = io::JoinPath(source_path, split_filename);\n\n    // `split_filename` must have this format:\n    // \"split_<local_split_index>_<global_split_index>\".\n    std::vector<std::string> tokens = absl::StrSplit(split_filename, '_');\n    int64_t local_split_index;\n    int64_t global_split_index;\n    if (tokens.size() != 3 ||\n        !absl::SimpleAtoi(tokens[1], &local_split_index) ||\n        local_split_index < 0 ||\n        !absl::SimpleAtoi(tokens[2], &global_split_index) ||\n        global_split_index < 0) {\n      return InvalidArgument(\"can't parse the name of \", split_path);\n    }\n    if (local_split_index > global_split_index) {\n      return InvalidArgument(\n          \"found conflict between local split index and global split index in \",\n          \"name of \", split_path);\n    }\n    if (local_split_index > split_filenames.size() - 1) {\n      return InvalidArgument(\n          \"found conflict between the number of splits and name of \",\n          split_path);\n    }\n    if (global_split_indices.contains(global_split_index)) {\n      return InvalidArgument(\"found duplicate global split index in name of \",\n                             split_path);\n    }\n\n    // To account for this split having been assigned, skip a split in the\n    // respective provider.\n    TF_RETURN_IF_ERROR(split_providers_[source_index]->GetNext(\n        &unused_tensor, &unused_end_of_splits));\n    global_split_indices.insert(global_split_index);\n  }\n\n  streams_[stream_index].num_assigned_splits[source_index] =\n      split_filenames.size();\n\n  return OkStatus();\n}\n\nStatusOr<int64_t> SnapshotManager::CreateNewStream(\n    const std::string& worker_address) {\n  int64_t new_stream_index = streams_.size();\n\n  for (int64_t source_index = 0; source_index < num_sources(); ++source_index) {\n    TF_RETURN_IF_ERROR(env_->RecursivelyCreateDir(\n        SourceDirectory(path_, new_stream_index, source_index)));\n  }\n\n  streams_.push_back(Stream(num_sources()));\n  assignments_.insert({worker_address, new_stream_index});\n  VLOG(1) << \"creating stream \" << new_stream_index\n          << \" and assigning it to worker \" << worker_address;\n\n  return new_stream_index;\n}\n\nStatus SnapshotManager::WorkerHeartbeat(const WorkerHeartbeatRequest& request,\n                                        WorkerHeartbeatResponse& response) {\n  SnapshotTaskDef* snapshot_task = response.add_snapshot_tasks();\n  snapshot_task->set_base_path(path_);\n  snapshot_task->set_num_sources(num_sources());\n  *snapshot_task->mutable_metadata() = metadata_;\n\n  if (auto it = assignments_.find(request.worker_address());\n      it != assignments_.end()) {\n    snapshot_task->set_stream_index(it->second);\n    return OkStatus();\n  }\n\n  // TODO(mpcallanan): Handle orphans.\n\n  TF_ASSIGN_OR_RETURN(int64_t new_stream_index,\n                      CreateNewStream(request.worker_address()));\n  snapshot_task->set_stream_index(new_stream_index);\n  return OkStatus();\n}\n\nStatus SnapshotManager::GetSnapshotSplit(const GetSnapshotSplitRequest& request,\n                                         GetSnapshotSplitResponse& response) {\n  // TODO(mpcallanan): Validate the request.\n\n  Tensor split;\n  bool end_of_splits;\n  TF_RETURN_IF_ERROR(split_providers_[request.source_index()]->GetNext(\n      &split, &end_of_splits));\n\n  Stream& stream = streams_[request.stream_index()];\n  if (end_of_splits) {\n    // TODO(mpcallanan): Handle doneness.\n    response.set_end_of_splits(true);\n    return OkStatus();\n  }\n\n  std::string split_path = SplitPath(\n      path_, request.stream_index(), request.source_index(),\n      stream.num_assigned_splits[request.source_index()], num_assigned_splits_);\n  TF_RETURN_IF_ERROR(AtomicallyWriteTFRecord(split_path, split, env_));\n\n  ++stream.num_assigned_splits[request.source_index()];\n  ++num_assigned_splits_;\n\n  split.AsProtoTensorContent(response.mutable_split());\n\n  return OkStatus();\n}\n\n}  // namespace data\n}  // namespace tensorflow"