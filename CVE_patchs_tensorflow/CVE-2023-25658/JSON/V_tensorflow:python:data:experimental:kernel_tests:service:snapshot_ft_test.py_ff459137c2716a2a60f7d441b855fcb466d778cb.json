"# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Fault tolerance tests for tf.data service snapshots.\"\"\"\nimport os\nimport tempfile\n\nfrom absl.testing import parameterized\n\nfrom tensorflow.python.data.experimental.kernel_tests.service import test_base as data_service_test_base\nfrom tensorflow.python.data.experimental.ops import distributed_save_op\nfrom tensorflow.python.data.kernel_tests import test_base\nfrom tensorflow.python.data.ops import dataset_ops\nfrom tensorflow.python.framework import combinations\nfrom tensorflow.python.platform import test\n\n\ndef write_file(path):\n  os.makedirs(os.path.dirname(path), exist_ok=True)\n  with open(path, \"w\") as _:\n    pass\n\n\nclass SnapshotFtTest(data_service_test_base.TestBase, parameterized.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    self._path = os.path.join(\n        tempfile.mkdtemp(dir=self.get_temp_dir()),\n        \"snapshot_ft_test\",\n    )\n\n  # This \"manual\" setup function is needed due to some bad interaction between\n  # `setUp` and `combinations` that causes the dataset to be out-of-scope.\n  def setup(self):\n    ds = dataset_ops.Dataset.range(10)\n    cluster = data_service_test_base.TestCluster(num_workers=1)\n    distributed_save_op.distributed_save(\n        ds, self._path, cluster.dispatcher_address()\n    )\n    return cluster, ds\n\n  def splits_dir(self, stream_idx=0):\n    return os.path.join(\n        self._path,\n        \"streams\",\n        f\"stream_{stream_idx}\",\n        \"splits\",\n    )\n\n  def source_dir(self, stream_idx=0, source_idx=0):\n    return os.path.join(\n        self.splits_dir(stream_idx),\n        f\"source_{source_idx}\",\n    )\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoverySucceeds(self):\n    cluster, _ = self.setup()\n    cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryBlocksOverwrite(self):\n    cluster, ds = self.setup()\n    cluster.restart_dispatcher()\n    with self.assertRaisesOpError(\"is already started or completed\"):\n      distributed_save_op.distributed_save(\n          ds, self._path, cluster.dispatcher_address()\n      )\n\n  @combinations.generate(\n      combinations.times(\n          test_base.eager_only_combinations(),\n          combinations.combine(\n              bad_stream_dir_name=[\"stream_\", \"stream_x\", \"stream_-1\"]\n          ),\n      )\n  )\n  def testSnapshotRecoveryFailsWithBadStreamName(self, bad_stream_dir_name):\n    cluster, _ = self.setup()\n    os.makedirs(os.path.join(self._path, \"streams\", bad_stream_dir_name))\n    with self.assertRaisesRegex(ValueError, \"can't parse\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(\n      combinations.times(\n          test_base.eager_only_combinations(),\n          combinations.combine(\n              bad_source_dir_name=[\"source_\", \"source_x\", \"source_-1\"]\n          ),\n      )\n  )\n  def testSnapshotRecoveryFailsWithBadSourceName(self, bad_source_dir_name):\n    cluster, _ = self.setup()\n    os.makedirs(os.path.join(self.splits_dir(), bad_source_dir_name))\n    with self.assertRaisesRegex(ValueError, \"can't parse\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryFailsWithOutOfBoundsSourceName(self):\n    cluster, _ = self.setup()\n    os.makedirs(os.path.join(self.splits_dir(), \"source_1\"))\n    with self.assertRaisesRegex(ValueError, \"found conflict\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(\n      combinations.times(\n          test_base.eager_only_combinations(),\n          combinations.combine(\n              bad_split_filename=[\n                  \"split_\",\n                  \"split_x_0\",\n                  \"split_-1_0\",\n                  \"split_0_x\",\n                  \"split_0_-1\",\n              ]\n          ),\n      )\n  )\n  def testSnapshotRecoveryFailsWithBadSplitNames(self, bad_split_filename):\n    cluster, _ = self.setup()\n    write_file(os.path.join(self.source_dir(), bad_split_filename))\n    with self.assertRaisesRegex(ValueError, \"can't parse\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryFailsWithOutOfOrderSplitName(self):\n    cluster, _ = self.setup()\n    write_file(os.path.join(self.source_dir(), \"split_1_0\"))\n    with self.assertRaisesRegex(ValueError, \"found conflict\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryFailsWithOutOfBoundsSplitName(self):\n    cluster, _ = self.setup()\n    write_file(os.path.join(self.source_dir(), \"split_1_1\"))\n    with self.assertRaisesRegex(ValueError, \"found conflict\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryFailsWithMissingGlobalIndexInSplitNames(self):\n    cluster, _ = self.setup()\n    write_file(os.path.join(self.source_dir(), \"split_0_1\"))\n    with self.assertRaisesRegex(ValueError, \"found missing global\"):\n      cluster.restart_dispatcher()\n\n  @combinations.generate(test_base.eager_only_combinations())\n  def testSnapshotRecoveryFailsWithDuplicateGlobalIndexInSplitName(self):\n    cluster, _ = self.setup()\n    write_file(os.path.join(self.source_dir(stream_idx=0), \"split_0_1\"))\n    write_file(os.path.join(self.source_dir(stream_idx=1), \"split_0_1\"))\n    with self.assertRaisesRegex(ValueError, \"found duplicate global\"):\n      cluster.restart_dispatcher()\n\n\nif __name__ == \"__main__\":\n  test.main()"