"# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for Python ops defined in sparse_ops.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.eager import def_function\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import sparse_tensor\nfrom tensorflow.python.framework import tensor_shape\nfrom tensorflow.python.framework import tensor_spec\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import nn_ops\nfrom tensorflow.python.ops import sparse_ops\nfrom tensorflow.python.ops import variables\nimport tensorflow.python.ops.sparse_grad  # pylint: disable=unused-import\nfrom tensorflow.python.platform import googletest\nfrom tensorflow.python.platform import test\n\n\n# TODO(zongheng): it'd be great to factor out this function and various random\n# SparseTensor gen funcs.\ndef _sparsify(x, thresh=0.5, index_dtype=np.int64):\n  x[x < thresh] = 0\n\n  non_zero = np.where(x)\n  x_indices = np.vstack(non_zero).astype(index_dtype).T\n  x_values = x[non_zero]\n  x_shape = x.shape\n\n  return sparse_tensor.SparseTensor(\n      indices=x_indices, values=x_values, dense_shape=x_shape), len(x_values)\n\n\nclass SparseToIndicatorTest(test_util.TensorFlowTestCase):\n\n  def _SparseTensor_5x6(self, dtype):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n    val = np.array([0, 10, 13, 14, 32, 33])\n    shape = np.array([5, 6])\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtype),\n        constant_op.constant(shape, dtypes.int64))\n\n  def _SparseTensor_2x3x4(self, dtype):\n    # Includes two entries with the form [1, 1, x] : 150.\n    ind = np.array([[0, 0, 1], [0, 1, 0], [0, 1, 2], [1, 0, 3], [1, 1, 0],\n                    [1, 1, 1], [1, 1, 2], [1, 2, 2]])\n    val = np.array([1, 10, 12, 103, 150, 149, 150, 122])\n    shape = np.array([2, 3, 4])\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtype),\n        constant_op.constant(shape, dtypes.int64))\n\n  def testInt32(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_5x6(dtypes.int32)\n      output = sparse_ops.sparse_to_indicator(sp_input, 50)\n\n      expected_output = np.zeros((5, 50), dtype=np.bool_)\n      expected_trues = ((0, 0), (1, 10), (1, 13), (1, 14), (3, 32), (3, 33))\n      for expected_true in expected_trues:\n        expected_output[expected_true] = True\n\n      self.assertAllEqual(output, expected_output)\n\n  def testInt64(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_5x6(dtypes.int64)\n      output = sparse_ops.sparse_to_indicator(sp_input, 50)\n\n      expected_output = np.zeros((5, 50), dtype=np.bool_)\n      expected_trues = [(0, 0), (1, 10), (1, 13), (1, 14), (3, 32), (3, 33)]\n      for expected_true in expected_trues:\n        expected_output[expected_true] = True\n\n      self.assertAllEqual(output, expected_output)\n\n  def testHigherRank(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_2x3x4(dtypes.int64)\n      output = sparse_ops.sparse_to_indicator(sp_input, 200)\n\n      expected_output = np.zeros((2, 3, 200), dtype=np.bool_)\n      expected_trues = [(0, 0, 1), (0, 1, 10), (0, 1, 12), (1, 0, 103),\n                        (1, 1, 149), (1, 1, 150), (1, 2, 122)]\n      for expected_true in expected_trues:\n        expected_output[expected_true] = True\n\n      self.assertAllEqual(output, expected_output)\n\n\nclass SparseMergeTest(test_util.TensorFlowTestCase):\n\n  def _SparseTensorValue_3x50(self, indices_dtype, values_dtype):\n    # NOTE: This input is intentionally not sorted to validate the\n    # already_sorted flag below.\n    ind = np.array([[0, 0], [1, 0], [1, 2], [2, 0], [2, 1], [1, 1]])\n    # NB: these are not sorted\n    indices = np.array([0, 13, 10, 33, 32, 14])\n    values = np.array([-3, 4, 1, 9, 5, 1])\n    shape = np.array([3, 3])\n    indices = sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(indices, indices_dtype), np.array(shape, np.int64))\n    values = sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(values, values_dtype), np.array(shape, np.int64))\n    return indices, values\n\n  def _SparseTensor_3x50(self, indices_dtype, values_dtype):\n    indices, values = self._SparseTensorValue_3x50(indices_dtype, values_dtype)\n    return (sparse_tensor.SparseTensor.from_value(indices),\n            sparse_tensor.SparseTensor.from_value(values))\n\n  def _AssertResultsSorted(self, output, vocab_size):\n    self.assertAllEqual(output.indices,\n                        [[0, 0], [1, 10], [1, 13], [1, 14], [2, 32], [2, 33]])\n    self.assertAllEqual(output.values, [-3, 1, 4, 1, 5, 9])\n    self.assertAllEqual(output.dense_shape, [3, vocab_size])\n\n  def _AssertResultsNotSorted(self, output, vocab_size):\n    self.assertAllEqual(output.indices,\n                        [[0, 0], [1, 13], [1, 10], [2, 33], [2, 32], [1, 14]])\n    self.assertAllEqual(output.values, [-3, 4, 1, 9, 5, 1])\n    self.assertAllEqual(output.dense_shape, [3, vocab_size])\n\n  def testInt32AndFloat32(self):\n    vocab_size = 50\n    indices_v, values_v = self._SparseTensorValue_3x50(np.int32, np.float32)\n    with test_util.force_cpu():\n      for indices in (indices_v,\n                      sparse_tensor.SparseTensor.from_value(indices_v)):\n        for values in (values_v,\n                       sparse_tensor.SparseTensor.from_value(values_v)):\n          sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n          output = self.evaluate(sp_output)\n          self._AssertResultsSorted(output, vocab_size)\n\n  def testInt64AndFloat32(self):\n    vocab_size = 50\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float32)\n      sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsSorted(output, vocab_size)\n\n  def testInt64AndFloat64(self):\n    vocab_size = 50\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float64)\n      sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsSorted(output, vocab_size)\n\n  def testInt32AndFloat32NonCanonicalOrder(self):\n    vocab_size = 50\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int32, np.float32)\n      sp_output = sparse_ops.sparse_merge(\n          indices, values, vocab_size, already_sorted=True)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsNotSorted(output, vocab_size)\n\n  def testInt64AndFloat32NonCanonicalOrder(self):\n    vocab_size = 50\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float32)\n      sp_output = sparse_ops.sparse_merge(\n          indices, values, vocab_size, already_sorted=True)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsNotSorted(output, vocab_size)\n\n  def testInt64AndFloat64NonCanonicalOrder(self):\n    vocab_size = 50\n    vocab_size_tensor = constant_op.constant(vocab_size, dtypes.int64)\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float64)\n      sp_output = sparse_ops.sparse_merge(\n          indices, values, vocab_size_tensor, already_sorted=True)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsNotSorted(output, vocab_size)\n\n  def testShouldSetLastDimensionInDynamicShape(self):\n    with ops.Graph().as_default():\n      shape = constant_op.constant([2, 2], dtype=dtypes.int64)\n      dynamic_shape = array_ops.placeholder_with_default(shape, shape=[2])\n      ids = sparse_tensor.SparseTensor(\n          indices=[[0, 0], [0, 1]],\n          values=[1, 3],\n          dense_shape=dynamic_shape)\n      values = sparse_tensor.SparseTensor(\n          indices=[[0, 0], [0, 1]],\n          values=[0.4, 0.7],\n          dense_shape=dynamic_shape)\n      merged = sparse_ops.sparse_merge(\n          sp_ids=ids, sp_values=values, vocab_size=5)\n      self.assertEqual(5, merged.get_shape()[1])\n\n\nclass SparseMergeHighDimTest(test_util.TensorFlowTestCase):\n\n  def _SparseTensor_3x50(self, indices_dtype, values_dtype):\n    # NOTE: This input is intentionally not sorted to validate the\n    # already_sorted flag below.\n    ind = np.array([[0, 0], [1, 0], [1, 2], [2, 0], [2, 1], [1, 1]])\n    # NB: these are not sorted\n    indices0 = np.array([0, 13, 10, 33, 32, 14])\n    indices1 = np.array([12, 4, 0, 0, 1, 30])\n    values = np.array([-3, 4, 1, 9, 5, 1])\n    shape = np.array([3, 3])\n    indices0 = sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(indices0, indices_dtype), np.array(shape, np.int64))\n    indices1 = sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(indices1, indices_dtype), np.array(shape, np.int64))\n    values = sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(values, values_dtype), np.array(shape, np.int64))\n    return ([sparse_tensor.SparseTensor.from_value(indices0),\n             sparse_tensor.SparseTensor.from_value(indices1)],\n            sparse_tensor.SparseTensor.from_value(values))\n\n  def _AssertResultsSorted(self, output, vocab_size):\n    self.assertAllEqual(\n        output.indices,\n        [[0, 0, 12], [1, 10, 0], [1, 13, 4], [1, 14, 30], [2, 32, 1],\n         [2, 33, 0]])\n    self.assertAllEqual(output.values, [-3, 1, 4, 1, 5, 9])\n    self.assertAllEqual(output.dense_shape, [3] + vocab_size)\n\n  def testInt64AndFloat32(self):\n    vocab_size = [50, 31]\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float32)\n      sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsSorted(output, vocab_size)\n\n  def testInt64AndFloat64(self):\n    vocab_size = [50, 31]\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float64)\n      sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsSorted(output, vocab_size)\n\n  def testInt64AndFloat64Shape(self):\n    vocab_size = [50, 30]\n    with test_util.force_cpu():\n      indices, values = self._SparseTensor_3x50(np.int64, np.float64)\n      sp_output = sparse_ops.sparse_merge(indices, values, vocab_size)\n\n      output = self.evaluate(sp_output)\n      self._AssertResultsSorted(output, vocab_size)\n\n\nclass SparseRetainTest(test_util.TensorFlowTestCase):\n\n  def _SparseTensorValue_5x6(self):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n    val = np.array([0, 10, 13, 14, 32, 33])\n    shape = np.array([5, 6])\n    return sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64),\n        np.array(val, np.int32), np.array(shape, np.int64))\n\n  def _SparseTensor_5x6(self):\n    return sparse_tensor.SparseTensor.from_value(self._SparseTensorValue_5x6())\n\n  def testBasic(self):\n    with test_util.force_cpu():\n      for sp_input in (self._SparseTensorValue_5x6(), self._SparseTensor_5x6()):\n        to_retain = np.array([1, 0, 0, 1, 1, 0], dtype=np.bool_)\n        sp_output = sparse_ops.sparse_retain(sp_input, to_retain)\n\n        output = self.evaluate(sp_output)\n\n        self.assertAllEqual(output.indices, [[0, 0], [1, 4], [3, 2]])\n        self.assertAllEqual(output.values, [0, 14, 32])\n        self.assertAllEqual(output.dense_shape, [5, 6])\n\n  def testRetainNone(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_5x6()\n      to_retain = np.zeros((6,), dtype=np.bool_)\n      sp_output = sparse_ops.sparse_retain(sp_input, to_retain)\n\n      output = self.evaluate(sp_output)\n\n      self.assertAllEqual(output.indices, np.array([]).reshape((0, 2)))\n      self.assertAllEqual(output.values, [])\n      self.assertAllEqual(output.dense_shape, [5, 6])\n\n  def testMismatchedRetainShape(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_5x6()\n      to_retain = np.array([1, 0, 0, 1, 0], dtype=np.bool_)\n      with self.assertRaises(ValueError):\n        sparse_ops.sparse_retain(sp_input, to_retain)\n\n\nclass SparseResetShapeTest(test_util.TensorFlowTestCase):\n\n  _IND_2_5_6 = np.array(\n      [[0, 0, 0], [0, 1, 0], [0, 1, 3], [1, 1, 4], [1, 3, 2], [1, 3, 3]],\n      dtype=np.int64)\n  _VAL_2_5_6 = np.array([0, 10, 13, 14, 32, 33], dtype=np.int32)\n  _SHP_2_5_6 = np.array([2, 5, 6], dtype=np.int64)\n\n  def _SparseTensor_2x5x6(self):\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(self._IND_2_5_6, dtypes.int64),\n        constant_op.constant(self._VAL_2_5_6, dtypes.int32),\n        constant_op.constant(self._SHP_2_5_6, dtypes.int64))\n\n  def _SparseTensor_2x5x6_Empty(self):\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(\n            np.empty(shape=[0, 3], dtype=np.int64), dtypes.int64),\n        constant_op.constant(np.empty(shape=[0], dtype=np.int32), dtypes.int32),\n        constant_op.constant(self._SHP_2_5_6, dtypes.int64))\n\n  def _SparseTensorValue_2x5x6(self):\n    return sparse_tensor.SparseTensorValue(self._IND_2_5_6, self._VAL_2_5_6,\n                                           self._SHP_2_5_6)\n\n  def testStaticShapeInfoPreservedWhenNewShapeIsProvidedAndStatic(self):\n    sp_input = self._SparseTensor_2x5x6()\n    new_shape = np.array([3, 6, 7], dtype=np.int64)\n    sp_output = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n    self.assertAllEqual([3, 6, 7], sp_output.get_shape())\n\n  def testBasic(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_2x5x6()\n      new_shape = np.array([3, 6, 7], dtype=np.int64)\n      sp_output = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      output = self.evaluate(sp_output)\n\n      self.assertAllEqual(output.indices, [[0, 0, 0], [0, 1, 0], [0, 1, 3],\n                                           [1, 1, 4], [1, 3, 2], [1, 3, 3]])\n      self.assertAllEqual(output.values, [0, 10, 13, 14, 32, 33])\n      self.assertAllEqual(output.dense_shape, [3, 6, 7])\n\n  def testInputUnavailableInGraphConstructionOk(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensorValue_2x5x6()\n      new_shape = np.array([3, 6, 7], dtype=np.int64)\n      sp_output = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      output = self.evaluate(sp_output)\n\n      self.assertAllEqual(output.indices, [[0, 0, 0], [0, 1, 0], [0, 1, 3],\n                                           [1, 1, 4], [1, 3, 2], [1, 3, 3]])\n      self.assertAllEqual(output.values, [0, 10, 13, 14, 32, 33])\n      self.assertAllEqual(output.dense_shape, [3, 6, 7])\n\n  @test_util.run_deprecated_v1\n  def testFeedInputUnavailableInGraphConstructionOk(self):\n    with self.session(use_gpu=False) as sess:\n      sp_input = array_ops.sparse_placeholder(dtype=dtypes.int32)\n      new_shape = np.array([3, 6, 7], dtype=np.int64)\n      sp_output = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      output = sess.run(sp_output,\n                        feed_dict={sp_input: self._SparseTensorValue_2x5x6()})\n\n      self.assertAllEqual(output.indices, [[0, 0, 0], [0, 1, 0], [0, 1, 3],\n                                           [1, 1, 4], [1, 3, 2], [1, 3, 3]])\n      self.assertAllEqual(output.values, [0, 10, 13, 14, 32, 33])\n      self.assertAllEqual(output.dense_shape, [3, 6, 7])\n\n  def testTightBoundingBox(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_2x5x6()\n      sp_output = sparse_ops.sparse_reset_shape(sp_input)\n\n      output = self.evaluate(sp_output)\n\n      self.assertAllEqual(output.indices, [[0, 0, 0], [0, 1, 0], [0, 1, 3],\n                                           [1, 1, 4], [1, 3, 2], [1, 3, 3]])\n      self.assertAllEqual(output.values, [0, 10, 13, 14, 32, 33])\n      self.assertAllEqual(output.dense_shape, [2, 4, 5])\n\n  def testTightBoundingBoxEmpty(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_2x5x6_Empty()\n      sp_output = sparse_ops.sparse_reset_shape(sp_input)\n\n      output = self.evaluate(sp_output)\n\n      self.assertAllEqual(output.indices.shape, [0, 3])\n      self.assertAllEqual(output.values.shape, [0])\n      self.assertAllEqual(output.dense_shape, [0, 0, 0])\n\n  def testInvalidRank(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_2x5x6()\n      new_shape = np.array([3, 7], dtype=np.int64)\n\n      with self.assertRaises(ValueError):\n        sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n  @test_util.run_deprecated_v1\n  def testInvalidRankNewShapeUnavailableInGraphConstruction(self):\n    with self.session(use_gpu=False) as sess:\n      new_shape = array_ops.placeholder(dtype=dtypes.int64)\n      sp_input = self._SparseTensor_2x5x6()\n      out = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      with self.assertRaisesOpError(\"x == y did not hold element-wise\"):\n        sess.run(out, feed_dict={new_shape: np.array([3, 7], dtype=np.int64)})\n\n  def testInvalidDimensionSizeStatic(self):\n    sp_input = self._SparseTensor_2x5x6()\n    new_shape = np.array([3, 7, 5], dtype=np.int64)\n\n    with self.assertRaisesRegex(ValueError, \"should have dimension sizes\"):\n      sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n  @test_util.run_deprecated_v1\n  def testInvalidDimensionSizeDynamic(self):\n    with self.session(use_gpu=False) as sess:\n      sp_input = self._SparseTensor_2x5x6()\n      new_shape = array_ops.placeholder(dtype=dtypes.int32)\n      out = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      with self.assertRaisesOpError(\"x <= y did not hold element-wise\"):\n        sess.run(out, feed_dict={new_shape: [3, 7, 5]})\n\n  @test_util.run_deprecated_v1\n  def testInvalidDimensionSizeInputUnavailableInGraphConstruction(self):\n    sp_input = array_ops.sparse_placeholder(dtype=dtypes.int32)\n    with self.session(use_gpu=False) as sess:\n      new_shape = np.array([3, 7, 5], dtype=np.int64)\n      out = sparse_ops.sparse_reset_shape(sp_input, new_shape)\n\n      with self.assertRaisesOpError(\"x <= y did not hold element-wise\"):\n        sess.run(out, feed_dict={sp_input: self._SparseTensorValue_2x5x6()})\n\n\nclass SparseSetShapeTest(test_util.TensorFlowTestCase):\n\n  def testSetShapeEagerValidates(self):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n    val = np.array([0, 10, 13, 14, 32, 33])\n    shape = np.array([5, 6])\n    sp = sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtypes.int64),\n        constant_op.constant(shape, dtypes.int64))\n\n    self.assertEqual(sp.shape, tensor_shape.TensorShape([5, 6]))\n\n    sp.set_shape(tensor_shape.TensorShape(None))\n    sp.set_shape(tensor_shape.TensorShape([None, None]))\n    sp.set_shape(tensor_shape.TensorShape([5, None]))\n    sp.set_shape(tensor_shape.TensorShape([None, 6]))\n    sp.set_shape(tensor_shape.TensorShape([5, 6]))\n\n    with self.assertRaises(ValueError):\n      sp.set_shape([None, None, None])\n\n    with self.assertRaises(ValueError):\n      sp.set_shape([3, None])\n\n    with self.assertRaises(ValueError):\n      sp.set_shape([None, 7])\n\n    with self.assertRaises(ValueError):\n      sp.set_shape([3, 6])\n\n  def testSetShapeFunctionMerges(self):\n\n    @def_function.function\n    def dynamic_shape_sparse(dense_shape):\n      ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n      val = np.array([0, 10, 13, 14, 32, 33])\n      sp = sparse_tensor.SparseTensor(\n          constant_op.constant(ind, dtypes.int64),\n          constant_op.constant(val, dtypes.int64),\n          dense_shape)\n\n      sp.set_shape(tensor_shape.TensorShape(None))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape(None))\n\n      sp.set_shape(tensor_shape.TensorShape([None, None]))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape([None, None]))\n\n      sp.set_shape(tensor_shape.TensorShape([5, None]))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape([5, None]))\n\n      sp.set_shape(tensor_shape.TensorShape([None, 6]))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape([5, 6]))\n\n      sp.set_shape(tensor_shape.TensorShape([None, None]))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape([5, 6]))\n\n      sp.set_shape(tensor_shape.TensorShape([5, 6]))\n      self.assertEqual(sp.shape, tensor_shape.TensorShape([5, 6]))\n\n      with self.assertRaises(ValueError):\n        sp.set_shape([None, None, None])\n\n      with self.assertRaises(ValueError):\n        sp.set_shape([3, None])\n\n      with self.assertRaises(ValueError):\n        sp.set_shape([None, 7])\n\n      with self.assertRaises(ValueError):\n        sp.set_shape([3, 6])\n\n    dense_shape_spec = tensor_spec.TensorSpec(None, dtypes.int64)\n    _ = dynamic_shape_sparse.get_concrete_function(dense_shape_spec)\n\n\nclass SparseFillEmptyRowsTest(test_util.TensorFlowTestCase):\n\n  def _SparseTensorValue_5x6(self, dtype=np.int32):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n    val = np.array([0, 10, 13, 14, 32, 33])\n    shape = np.array([5, 6])\n    return sparse_tensor.SparseTensorValue(\n        np.array(ind, np.int64), np.array(val, dtype), np.array(\n            shape, np.int64))\n\n  def _SparseTensor_5x6(self):\n    return sparse_tensor.SparseTensor.from_value(self._SparseTensorValue_5x6())\n\n  def _SparseTensor_String5x6(self):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]])\n    val = np.array([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n    shape = np.array([5, 6])\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtypes.string),\n        constant_op.constant(shape, dtypes.int64))\n\n  def _SparseTensor_2x6(self):\n    ind = np.array([[0, 0], [1, 0], [1, 3], [1, 4]])\n    val = np.array([0, 10, 13, 14])\n    shape = np.array([2, 6])\n    return sparse_tensor.SparseTensor(\n        constant_op.constant(ind, dtypes.int64),\n        constant_op.constant(val, dtypes.int32),\n        constant_op.constant(shape, dtypes.int64))\n\n  def testFillNumber(self):\n    with test_util.use_gpu():\n      for sp_input in (self._SparseTensorValue_5x6(), self._SparseTensor_5x6()):\n        sp_output, empty_row_indicator = (\n            sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n        output, empty_row_indicator_out = self.evaluate(\n            [sp_output, empty_row_indicator])\n\n        self.assertAllEqual(\n            output.indices,\n            [[0, 0], [1, 0], [1, 3], [1, 4], [2, 0], [3, 2], [3, 3], [4, 0]])\n        self.assertAllEqual(output.values, [0, 10, 13, 14, -1, 32, 33, -1])\n        self.assertAllEqual(output.dense_shape, [5, 6])\n        self.assertAllEqual(empty_row_indicator_out,\n                            np.array([0, 0, 1, 0, 1]).astype(np.bool_))\n\n  def testSparseFillEmptyRowsGradEmpty(self):\n    with test_util.use_gpu():\n      grad, _ = self.evaluate(\n          sparse_ops.sparse_fill_empty_rows_grad(\n              reverse_index_map=[], grad_values=[]))\n      self.assertAllEqual(grad, [])\n\n  @test_util.run_deprecated_v1\n  def testFillFloat(self):\n    with self.session():\n      values = constant_op.constant(\n          [0.0, 10.0, 13.0, 14.0, 32.0, 33.0], dtype=dtypes.float64)\n      default_value = constant_op.constant(-1.0, dtype=dtypes.float64)\n      sp_input = sparse_tensor.SparseTensorValue(\n          indices=np.array([[0, 0], [1, 0], [1, 3], [1, 4], [3, 2], [3, 3]]),\n          values=values,\n          dense_shape=np.array([5, 6]))\n      sp_output, empty_row_indicator = (sparse_ops.sparse_fill_empty_rows(\n          sp_input, default_value))\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices, [[0, 0], [1, 0], [1, 3], [1, 4],\n                                           [2, 0], [3, 2], [3, 3], [4, 0]])\n      self.assertAllClose(output.values, [0, 10, 13, 14, -1, 32, 33, -1])\n      self.assertAllEqual(output.dense_shape, [5, 6])\n      self.assertAllEqual(empty_row_indicator_out,\n                          np.array([0, 0, 1, 0, 1]).astype(np.bool_))\n\n      values_grad_err = gradient_checker.compute_gradient_error(\n          values, values.shape.as_list(), sp_output.values, [8], delta=1e-8)\n      self.assertGreater(values_grad_err, 0)\n      self.assertLess(values_grad_err, 1e-8)\n\n      default_value_grad_err = gradient_checker.compute_gradient_error(\n          default_value,\n          default_value.shape.as_list(),\n          sp_output.values, [8],\n          delta=1e-8)\n      self.assertGreater(default_value_grad_err, 0)\n      self.assertLess(default_value_grad_err, 1e-8)\n\n  def testFillString(self):\n    with test_util.force_cpu():\n      sp_input = self._SparseTensor_String5x6()\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, \"\"))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(\n          output.indices,\n          [[0, 0], [1, 0], [1, 3], [1, 4], [2, 0], [3, 2], [3, 3], [4, 0]])\n      self.assertAllEqual(output.values,\n                          [b\"a\", b\"b\", b\"c\", b\"d\", b\"\", b\"e\", b\"f\", b\"\"])\n      self.assertAllEqual(output.dense_shape, [5, 6])\n      self.assertAllEqual(empty_row_indicator_out,\n                          np.array([0, 0, 1, 0, 1]).astype(np.bool_))\n\n  def testNoEmptyRows(self):\n    with test_util.use_gpu():\n      sp_input = self._SparseTensor_2x6()\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices, [[0, 0], [1, 0], [1, 3], [1, 4]])\n      self.assertAllEqual(output.values, [0, 10, 13, 14])\n      self.assertAllEqual(output.dense_shape, [2, 6])\n      self.assertAllEqual(empty_row_indicator_out, np.zeros(2).astype(np.bool_))\n\n  def testNoEmptyRowsAndUnordered(self):\n    with test_util.use_gpu():\n      sp_input = sparse_tensor.SparseTensor(\n          indices=np.array([[1, 2], [1, 3], [0, 1], [0, 3]]),\n          values=np.array([1, 3, 2, 4]),\n          dense_shape=np.array([2, 5]))\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices, [[0, 1], [0, 3], [1, 2], [1, 3]])\n      self.assertAllEqual(output.values, [2, 4, 1, 3])\n      self.assertAllEqual(output.dense_shape, [2, 5])\n      self.assertAllEqual(empty_row_indicator_out, np.zeros(2).astype(np.bool_))\n\n  def testUnordered(self):\n    with test_util.use_gpu():\n      sp_input = sparse_tensor.SparseTensor(\n          indices=np.array([[2, 3], [2, 2], [0, 1], [0, 3]]),\n          values=np.array([1, 3, 2, 4]),\n          dense_shape=np.array([3, 5]))\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices,\n                          [[0, 1], [0, 3], [1, 0], [2, 3], [2, 2]])\n      self.assertAllEqual(output.values, [2, 4, -1, 1, 3])\n      self.assertAllEqual(output.dense_shape, [3, 5])\n      self.assertAllEqual(empty_row_indicator_out, [False, True, False])\n\n  def testEmptyIndicesTensor(self):\n    with test_util.use_gpu():\n      sp_input = sparse_tensor.SparseTensor(\n          indices=np.ones([0, 2]),\n          values=np.ones([0]),\n          dense_shape=np.array([2, 5]))\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices, [[0, 0], [1, 0]])\n      self.assertAllEqual(output.values, [-1, -1])\n      self.assertAllEqual(output.dense_shape, [2, 5])\n      self.assertAllEqual(empty_row_indicator_out, np.ones(2).astype(np.bool_))\n\n  def testEmptyOutput(self):\n    with test_util.use_gpu():\n      sp_input = sparse_tensor.SparseTensor(\n          indices=np.ones([0, 2]),\n          values=np.ones([0]),\n          dense_shape=np.array([0, 3]))\n      sp_output, empty_row_indicator = (\n          sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n      output, empty_row_indicator_out = self.evaluate(\n          [sp_output, empty_row_indicator])\n\n      self.assertAllEqual(output.indices, np.ones([0, 2]))\n      self.assertAllEqual(output.values, np.ones([0]))\n      self.assertAllEqual(output.dense_shape, [0, 3])\n      self.assertAllEqual(empty_row_indicator_out, [])\n\n  def testInvalidIndices(self):\n    with test_util.use_gpu():\n      sp_input = sparse_tensor.SparseTensor(\n          indices=np.array([[1, 2], [1, 3], [99, 1], [99, 3]]),\n          values=np.array([1, 3, 2, 4]),\n          dense_shape=np.array([2, 5]))\n\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  r\"indices\\(2, 0\\) is invalid\"):\n        self.evaluate(sparse_ops.sparse_fill_empty_rows(sp_input, -1))\n\n\nclass SparseAddTest(test_util.TensorFlowTestCase):\n\n  def testValuesInVariable(self):\n    indices = constant_op.constant([[0]], dtype=dtypes.int64)\n    values = variables.Variable([1], trainable=False, dtype=dtypes.float32)\n    shape = constant_op.constant([1], dtype=dtypes.int64)\n\n    sp_input = sparse_tensor.SparseTensor(indices, values, shape)\n    sp_output = sparse_ops.sparse_add(sp_input, sp_input)\n\n    with test_util.force_cpu():\n      self.evaluate(variables.global_variables_initializer())\n      output = self.evaluate(sp_output)\n      self.assertAllEqual(output.values, [2])\n\n\nclass SparseReduceTest(test_util.TensorFlowTestCase):\n\n  # [[1, ?, 2]\n  #  [?, 3, ?]]\n  # where ? is implicitly-zero.\n  ind = np.array([[0, 0], [0, 2], [1, 1]]).astype(np.int64)\n  vals = np.array([1, 1, 1]).astype(np.int32)\n  dense_shape = np.array([2, 3]).astype(np.int64)\n\n  def _compare(self, sp_t, reduction_axes, ndims, keep_dims, do_sum):\n    densified = self.evaluate(sparse_ops.sparse_tensor_to_dense(sp_t))\n\n    np_ans = densified\n    if reduction_axes is None:\n      if do_sum:\n        np_ans = np.sum(np_ans, keepdims=keep_dims)\n      else:\n        np_ans = np.max(np_ans, keepdims=keep_dims)\n    else:\n      if not isinstance(reduction_axes, list):  # Single scalar.\n        reduction_axes = [reduction_axes]\n      reduction_axes = np.array(reduction_axes).astype(np.int32)\n      # Handles negative axes.\n      reduction_axes = (reduction_axes + ndims) % ndims\n      # Loop below depends on sorted.\n      reduction_axes.sort()\n      for ra in reduction_axes.ravel()[::-1]:\n        if do_sum:\n          np_ans = np.sum(np_ans, axis=ra, keepdims=keep_dims)\n        else:\n          np_ans = np.max(np_ans, axis=ra, keepdims=keep_dims)\n\n    with self.cached_session():\n      if do_sum:\n        tf_dense_ans = sparse_ops.sparse_reduce_sum(sp_t, reduction_axes,\n                                                    keep_dims)\n      else:\n        tf_dense_ans = sparse_ops.sparse_reduce_max(sp_t, reduction_axes,\n                                                    keep_dims)\n      out_dense = self.evaluate(tf_dense_ans)\n\n      if do_sum:\n        tf_sparse_ans = sparse_ops.sparse_reduce_sum_sparse(sp_t,\n                                                            reduction_axes,\n                                                            keep_dims)\n      else:\n        tf_sparse_ans = sparse_ops.sparse_reduce_max_sparse(sp_t,\n                                                            reduction_axes,\n                                                            keep_dims)\n      # Convert to dense for comparison purposes.\n      out_sparse = sparse_ops.sparse_tensor_to_dense(tf_sparse_ans)\n\n    self.assertAllClose(np_ans, out_dense)\n    self.assertAllClose(np_ans, out_sparse)\n\n  def _compare_all(self, sp_t, reduction_axes, ndims):\n    self._compare(sp_t, reduction_axes, ndims, False, False)\n    self._compare(sp_t, reduction_axes, ndims, False, True)\n    self._compare(sp_t, reduction_axes, ndims, True, False)\n    self._compare(sp_t, reduction_axes, ndims, True, True)\n\n  # (TODO:b/133851381): Re-enable this test.\n  def disabledtestSimpleAndRandomInputs(self):\n    if np.__version__ == \"1.13.0\":\n      self.skipTest(\"numpy 1.13.0 bug\")\n\n    sp_t = sparse_tensor.SparseTensor(self.ind, self.vals, self.dense_shape)\n\n    with test_util.force_cpu():\n      self._compare_all(sp_t, None, ndims=2)\n      self._compare_all(sp_t, 0, ndims=2)\n      self._compare_all(sp_t, [1], ndims=2)\n      self._compare_all(sp_t, [0, 1], ndims=2)\n      self._compare_all(sp_t, [1, 0], ndims=2)\n      self._compare_all(sp_t, [-1], ndims=2)\n      self._compare_all(sp_t, [1, -2], ndims=2)\n\n    np.random.seed(1618)\n    test_dims = [(1618, 1, 11, 7, 1), (1,), (1, 1, 1)]\n    with test_util.force_cpu():\n      for dims in test_dims:\n        sp_t, unused_nnz = _sparsify(np.random.randn(*dims))\n        # reduce all using None\n        self._compare_all(sp_t, None, ndims=len(dims))\n        # reduce random axes from 1D to N-D\n        for d in range(1, len(dims) + 1):\n          axes = np.random.choice(len(dims), size=d, replace=False).tolist()\n          self._compare_all(sp_t, axes, ndims=len(dims))\n\n  def testInvalidAxes(self):\n    sp_t = sparse_tensor.SparseTensor(self.ind, self.vals, self.dense_shape)\n    with test_util.force_cpu():\n      with self.assertRaisesOpError(\"Invalid reduction dimension -3\"):\n        self.evaluate(sparse_ops.sparse_reduce_sum(sp_t, -3))\n      with self.assertRaisesOpError(\"Invalid reduction dimension 2\"):\n        self.evaluate(sparse_ops.sparse_reduce_sum(sp_t, 2))\n      with self.assertRaisesOpError(\"Invalid reduction dimension -3\"):\n        self.evaluate(sparse_ops.sparse_reduce_max(sp_t, -3))\n      with self.assertRaisesOpError(\"Invalid reduction dimension 2\"):\n        self.evaluate(sparse_ops.sparse_reduce_max(sp_t, 2))\n\n  @test_util.run_deprecated_v1\n  def testGradient(self):\n    np.random.seed(8161)\n    test_dims = [(11, 1, 5, 7, 1), (2, 2)]\n    with self.session(use_gpu=False):\n      for dims in test_dims:\n        sp_t, nnz = _sparsify(np.random.randn(*dims))\n        # reduce random axes from 1D to N-D\n        for d in range(1, len(dims) + 1):\n          axes = np.random.choice(len(dims), size=d, replace=False).tolist()\n          reduced = sparse_ops.sparse_reduce_sum(sp_t, axes)\n\n          err = gradient_checker.compute_gradient_error(\n              sp_t.values, (nnz,), reduced,\n              self.evaluate(reduced).shape)\n          self.assertLess(err, 1e-3)\n\n        # Tests for negative axes.\n        reduced = sparse_ops.sparse_reduce_sum(sp_t, -1)\n        err = gradient_checker.compute_gradient_error(\n            sp_t.values, (nnz,), reduced,\n            self.evaluate(reduced).shape)\n        self.assertLess(err, 1e-3)\n\n  def _testSparseReduceShape(self, sp_t, reduction_axes, ndims, keep_dims,\n                             do_sum):\n    densified = self.evaluate(sparse_ops.sparse_tensor_to_dense(sp_t))\n\n    np_op = np.sum\n    tf_op = sparse_ops.sparse_reduce_sum\n    if not do_sum:\n      np_op = np.max\n      tf_op = sparse_ops.sparse_reduce_max\n\n    np_ans = densified\n    if reduction_axes is None:\n      np_ans = np_op(np_ans, keepdims=keep_dims)\n    else:\n      if not isinstance(reduction_axes, list):  # Single scalar.\n        reduction_axes = [reduction_axes]\n      reduction_axes = np.array(reduction_axes).astype(np.int32)\n      # Handles negative axes.\n      reduction_axes = (reduction_axes + ndims) % ndims\n      # Loop below depends on sorted.\n      reduction_axes.sort()\n      for ra in reduction_axes.ravel()[::-1]:\n        np_ans = np_op(np_ans, axis=ra, keepdims=keep_dims)\n\n    tf_ans = tf_op(sp_t, reduction_axes, keep_dims)\n    self.assertAllEqual(np_ans.shape, tf_ans.get_shape().as_list())\n\n  # (TODO:b/133851381): Re-enable this test\n  def disabledtestSparseReduceSumOrMaxShape(self):\n    sp_t = sparse_tensor.SparseTensor(self.ind, self.vals, self.dense_shape)\n\n    with test_util.force_cpu():\n      for do_sum in [True, False]:\n        for keep_dims in [True, False]:\n          self._testSparseReduceShape(sp_t, None, 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, 0, 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, [1], 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, [0, 1], 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, [1, 0], 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, [-1], 2, keep_dims, do_sum)\n          self._testSparseReduceShape(sp_t, [1, -2], 2, keep_dims, do_sum)\n\n  def testIntegerOverflow(self):\n    with self.cached_session(use_gpu=False):\n      with self.assertRaises(errors.InvalidArgumentError):\n        res = sparse_ops.gen_sparse_ops.sparse_reduce_max(\n            input_indices=[[1, 2], [3, 4]],\n            input_shape=[2**32, 2**31],\n            input_values=[1, 3],\n            reduction_axes=[0],\n            keep_dims=False,\n            name=None)\n\n        self.evaluate(res)\n      with self.assertRaises(errors.InvalidArgumentError):\n        res = sparse_ops.gen_sparse_ops.sparse_reduce_max_sparse(\n            input_indices=[[1, 2], [3, 4]],\n            input_shape=[2**32, 2**31],\n            input_values=[1, 3],\n            reduction_axes=[0],\n            keep_dims=False,\n            name=None)\n\n        self.evaluate(res)\n      with self.assertRaises(errors.InvalidArgumentError):\n        res = sparse_ops.gen_sparse_ops.sparse_reduce_sum(\n            input_indices=[[1, 2], [3, 4]],\n            input_shape=[2**32, 2**31],\n            input_values=[1, 3],\n            reduction_axes=[0],\n            keep_dims=False,\n            name=None)\n\n        self.evaluate(res)\n\n\nclass SparseMathOpsTest(test_util.TensorFlowTestCase):\n\n  def _check(self, result_tensor, result_np, input_sp_t):\n    self.assertTrue(isinstance(result_tensor, sparse_tensor.SparseTensor))\n    self.assertTrue(isinstance(input_sp_t, sparse_tensor.SparseTensor))\n    self.assertAllCloseAccordingToType(input_sp_t.indices,\n                                       result_tensor.indices)\n    self.assertAllCloseAccordingToType(input_sp_t.dense_shape,\n                                       result_tensor.dense_shape)\n\n    res_densified = sparse_ops.sparse_to_dense(\n        result_tensor.indices, result_tensor.dense_shape, result_tensor.values)\n    self.assertAllCloseAccordingToType(result_np, res_densified)\n\n  @test_util.run_deprecated_v1\n  def testCwiseShapeValidation(self):\n    # Test case for GitHub 24072.\n    with test_util.force_cpu():\n      a = array_ops.ones([3, 4, 1], dtype=dtypes.int32)\n      b = sparse_tensor.SparseTensor([[0, 0, 1, 0], [0, 0, 3, 0]], [10, 20],\n                                     [1, 1, 4, 2])\n      c = a * b\n      with self.assertRaisesRegex(\n          errors.InvalidArgumentError,\n          \"broadcasts dense to sparse only; got incompatible shapes\"):\n        self.evaluate(c)\n\n  def testCwiseDivAndMul(self):\n    np.random.seed(1618)\n    sp_shapes = [(10, 10, 10), (5, 5), (1618,), (3, 3, 7)]\n    dense_shapes = [(10, 10, 1), (5, 5), (1,), (1, 7)]\n\n    with test_util.force_cpu():\n      for dtype in [np.float32, np.float64, np.int32, np.int64]:\n        for sp_shape, dense_shape in zip(sp_shapes, dense_shapes):\n          sp_vals_np = np.random.rand(*sp_shape).astype(dtype) + 1\n          dense_vals_np = np.random.rand(*dense_shape).astype(dtype) + 1\n          sp_t, unused_nnz = _sparsify(sp_vals_np, thresh=1.5)\n          sp_t_densified = sparse_ops.sparse_tensor_to_dense(sp_t)\n          dense_t = constant_op.constant(dense_vals_np)\n\n          self._check(sp_t / dense_t, sp_t_densified / dense_vals_np, sp_t)\n          # Check commutative.\n          self._check(sp_t * dense_t, sp_t_densified * dense_vals_np, sp_t)\n          self._check(dense_t * sp_t, sp_t_densified * dense_vals_np, sp_t)\n\n          if dtype in [np.int32, np.int64]:\n            res = sp_t / dense_t  # should invoke \"__truediv__\"\n            self.assertEqual(res.values.dtype, np.float64)\n\n  def testCwiseAdd(self):\n    with test_util.force_cpu():\n      # Identity(2) + AllOnes(2,2).  Should be equal to 2 * Identity(2).\n      indices = [[0, 0], [1, 1]]\n      vals = [1, 1]\n      shape = (2, 2)\n\n      sp_t = sparse_tensor.SparseTensor(indices, vals, shape)\n      dense_t = array_ops.ones(shape, dtype=dtypes.int32)\n      self._check(\n          sparse_ops.sparse_dense_cwise_add(sp_t, dense_t),\n          np.identity(2) * 2, sp_t)\n\n      # Variant of above, but broadcasts the dense side.\n      dense_t = array_ops.ones([1], dtype=dtypes.int32)\n      self._check(\n          sparse_ops.sparse_dense_cwise_add(sp_t, dense_t),\n          np.identity(2) * 2, sp_t)\n\n  @test_util.run_deprecated_v1\n  def testGradients(self):\n    np.random.seed(1618)\n    sp_shapes = [(10, 10, 10), (5, 5), (1618,), (3, 3, 7)]\n    dense_shapes = [(10, 10, 1), (5, 5), (1,), (1, 7)]\n\n    with self.session(use_gpu=False):\n      for dtype in [np.float32, np.float64]:\n        for sp_shape, dense_shape in zip(sp_shapes, dense_shapes):\n          sp_vals_np = np.random.rand(*sp_shape).astype(dtype) + 1\n          dense_vals_np = np.random.rand(*dense_shape).astype(dtype) + 1\n          sp_t, nnz = _sparsify(sp_vals_np, thresh=1.5)\n          dense_t = constant_op.constant(dense_vals_np)\n\n          cmul = sp_t * dense_t\n          err = gradient_checker.compute_gradient_error([sp_t.values, dense_t],\n                                                        [(nnz,), dense_shape],\n                                                        cmul.values, (nnz,))\n          self.assertLess(err, 1e-4)\n\n          cdiv = sp_t / dense_t\n          err = gradient_checker.compute_gradient_error(sp_t.values, (nnz,),\n                                                        cdiv.values, (nnz,))\n          self.assertLess(err, 1e-4)\n          err = gradient_checker.compute_gradient_error(\n              dense_t,\n              dense_shape,\n              cdiv.values, (nnz,),\n              x_init_value=dense_vals_np)\n          self.assertLess(err, 2e-4)\n\n\nclass SparseSoftmaxTest(test_util.TensorFlowTestCase):\n\n  @test_util.run_deprecated_v1\n  def testEquivalentToDensified(self):\n    np.random.seed(1618)\n    n, m = np.random.choice(20, size=2)\n\n    for dtype in [np.float16, np.float32, np.float64]:\n      sp_vals_np = np.random.rand(n, m).astype(dtype)\n\n      batched_sp_t, unused_nnz1 = _sparsify(\n          sp_vals_np.reshape((1, n, m)), thresh=0.)  # No masking.\n\n      with test_util.force_cpu():\n        densified = constant_op.constant(sp_vals_np)\n\n        sp_result = self.evaluate(\n            sparse_ops.sparse_softmax(batched_sp_t)).values.reshape((n, m))\n        dense_result = nn_ops.softmax(densified)\n\n        self.assertAllCloseAccordingToType(dense_result, sp_result)\n\n  def testHigherRanks(self):\n    # For the first shape:\n    # First batch:\n    # [?   e.]\n    # [1.  ? ]\n    # Second batch:\n    # [e   ? ]\n    # [e   e ]\n    #\n    # The softmax results should be:\n    # [?   1.]     [1    ?]\n    # [1.  ? ] and [.5  .5]\n    # where ? means implicitly zero.\n    #\n    # The second shape: same input data, but with a higher-rank shape.\n    shapes = [[2, 2, 2], [2, 1, 2, 2]]\n    for shape in shapes:\n      values = np.asarray(\n          [0., np.e, 1., 0., np.e, 0., np.e, np.e]).reshape(shape)\n      sp_t, unused_nnz = _sparsify(values, thresh=1e-2)\n      expected_values = [1., 1., 1., .5, .5]\n\n      with test_util.force_cpu():\n        result = sparse_ops.sparse_softmax(sp_t)\n\n        self.assertAllEqual(expected_values, result.values)\n        self.assertAllEqual(sp_t.indices, result.indices)\n        self.assertAllEqual(shape, result.dense_shape)\n\n  @test_util.run_deprecated_v1\n  def testGradient(self):\n    x_shape = [2, 5, 10]\n    with self.cached_session(use_gpu=False):\n      for dtype in [np.float32, np.float64]:\n        x_np = np.random.randn(*x_shape).astype(dtype)\n        x_tf, nnz = _sparsify(x_np)\n        y_tf = sparse_ops.sparse_softmax(x_tf)\n        err = gradient_checker.compute_gradient_error(x_tf.values, (nnz,),\n                                                      y_tf.values, (nnz,))\n        self.assertLess(err, 1e-4)\n\n  def testIntegerOverflow(self):\n    with self.cached_session(use_gpu=False):\n      with self.assertRaises(errors.InvalidArgumentError):\n        res = sparse_ops.gen_sparse_ops.sparse_softmax(\n            sp_indices=[[1, 1]],\n            sp_values=[2.0],\n            sp_shape=[2**32, 2**31],\n            name=None)\n\n        self.evaluate(res)\n\n  def testReshapeNegativeShape(self):\n    with self.cached_session(use_gpu=False):\n      with self.assertRaises(errors.InvalidArgumentError):\n        res = sparse_ops.gen_sparse_ops.sparse_softmax(\n            sp_indices=[[1, 1]], sp_values=[2.0], sp_shape=[-1, 1], name=None)\n\n        self.evaluate(res)\n\n\nclass SparseMinimumMaximumTest(test_util.TensorFlowTestCase):\n\n  def _assertSparseTensorValueEqual(self, a, b):\n    self.assertAllEqual(a.indices, b.indices)\n    self.assertAllEqual(a.values, b.values)\n    self.assertAllEqual(a.dense_shape, b.dense_shape)\n\n  def testBasic(self):\n    with test_util.force_cpu():\n      # 1-D, values at index 0.\n      sp_zero = sparse_tensor.SparseTensor([[0]], [0], [7])\n      sp_one = sparse_tensor.SparseTensor([[0]], [1], [7])\n      max_tf = sparse_ops.sparse_maximum(sp_zero, sp_one)\n      min_tf = sparse_ops.sparse_minimum(sp_zero, sp_one)\n      self._assertSparseTensorValueEqual(sp_one, max_tf)\n      self._assertSparseTensorValueEqual(sp_zero, min_tf)\n\n      # Values at different indices.\n      sp_zero = sparse_tensor.SparseTensor([[0]], [0], [7])\n      sp_zero_2 = sparse_tensor.SparseTensor([[1]], [0], [7])\n      expected = sparse_tensor.SparseTensor([[0], [1]], [0, 0], [7])\n      max_tf = sparse_ops.sparse_maximum(sp_zero, sp_zero_2)\n      min_tf = sparse_ops.sparse_minimum(sp_zero, sp_zero_2)\n      self._assertSparseTensorValueEqual(expected, max_tf)\n      self._assertSparseTensorValueEqual(expected, min_tf)\n\n  @test_util.run_deprecated_v1\n  def testRandom(self):\n    np.random.seed(1618)\n    shapes = [(13,), (6, 8), (1, 7, 1)]\n    for shape in shapes:\n      for dtype in [np.int32, np.int64, np.float16, np.float32, np.float64]:\n        a_np = np.random.randn(*shape).astype(dtype)\n        b_np = np.random.randn(*shape).astype(dtype)\n        sp_a, unused_a_nnz = _sparsify(a_np, thresh=-.5)\n        sp_b, unused_b_nnz = _sparsify(b_np, thresh=-.5)\n\n        with self.cached_session(use_gpu=False):\n          maximum_tf = sparse_ops.sparse_maximum(sp_a, sp_b)\n          maximum_tf_densified = sparse_ops.sparse_tensor_to_dense(\n              maximum_tf).eval()\n          minimum_tf = sparse_ops.sparse_minimum(sp_a, sp_b)\n          minimum_tf_densified = sparse_ops.sparse_tensor_to_dense(\n              minimum_tf).eval()\n\n          a_densified = sparse_ops.sparse_tensor_to_dense(sp_a).eval()\n          b_densified = sparse_ops.sparse_tensor_to_dense(sp_b).eval()\n\n        self.assertAllEqual(\n            np.maximum(a_densified, b_densified), maximum_tf_densified)\n        self.assertAllEqual(\n            np.minimum(a_densified, b_densified), minimum_tf_densified)\n\n  def testMismatchedShapes(self):\n    with test_util.force_cpu():\n      sp_zero = sparse_tensor.SparseTensor([[0, 0]], [0], [1, 1])\n      sp_one = sparse_tensor.SparseTensor([[0]], [1], [2])\n      with self.assertRaisesOpError(\"Operands do not have the same ranks\"):\n        self.evaluate(sparse_ops.sparse_maximum(sp_zero, sp_one))\n\n      sp_zero = sparse_tensor.SparseTensor([[0]], [0], [1])\n      sp_one = sparse_tensor.SparseTensor([[0]], [1], [2])\n      with self.assertRaisesOpError(\"Operands' shapes do not match\"):\n        self.evaluate(sparse_ops.sparse_maximum(sp_zero, sp_one))\n\n\nclass SparseTransposeTest(test.TestCase):\n\n  def testTranspose(self):\n    if np.__version__ == \"1.13.0\":\n      self.skipTest(\"numpy 1.13.0 bug\")\n\n    with test_util.force_cpu():\n      np.random.seed(1618)\n      shapes = [np.random.randint(1, 10, size=rank) for rank in range(1, 6)]\n      for shape in shapes:\n        for dtype in [np.int32, np.int64, np.float32, np.float64]:\n          dn_input = np.random.randn(*shape).astype(dtype)\n          rank = self.evaluate(array_ops.rank(dn_input))\n          perm = np.random.choice(rank, rank, False)\n          sp_input, unused_a_nnz = _sparsify(dn_input)\n          sp_trans = sparse_ops.sparse_transpose(sp_input, perm=perm)\n          dn_trans = sparse_ops.sparse_tensor_to_dense(sp_trans)\n          expected_trans = array_ops.transpose(dn_input, perm=perm)\n          self.assertAllEqual(expected_trans.shape, sp_trans.get_shape())\n          self.assertAllEqual(dn_trans, expected_trans)\n\n\nclass SparsePlaceholderTest(test.TestCase):\n\n  @test_util.run_deprecated_v1\n  def testPlaceholder(self):\n    foo = array_ops.sparse_placeholder(dtypes.float32, shape=(10, 47))\n    self.assertAllEqual([10, 47], foo.get_shape())\n    self.assertAllEqual([None, 2], foo.indices.get_shape().as_list())\n\n  @test_util.run_deprecated_v1\n  def testPartialShapePlaceholder(self):\n    foo = array_ops.sparse_placeholder(dtypes.float32, shape=(None, 47))\n    self.assertAllEqual([None, 47], foo.get_shape().as_list())\n    self.assertAllEqual([None, 2], foo.indices.get_shape().as_list())\n\n  @test_util.run_deprecated_v1\n  def testNoShapePlaceholder(self):\n    foo = array_ops.sparse_placeholder(dtypes.float32, shape=None)\n    self.assertAllEqual(None, foo.get_shape())\n    self.assertAllEqual([None, None], foo.indices.get_shape().as_list())\n\n\nif __name__ == \"__main__\":\n  googletest.main()"