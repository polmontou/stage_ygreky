"# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Tests for ops which manipulate lists of tensors via bridge.\"\"\"\n\n# pylint: disable=g-bad-name\nimport os\n\nfrom absl.testing import parameterized\nimport numpy as np\nfrom tensorflow.compiler.tests import xla_test\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import list_ops\nfrom tensorflow.python.platform import test\n\n\nclass ListOpsTest(parameterized.TestCase, xla_test.XLATestCase):\n\n  def testElementShape(self):\n    with self.session() as sess, self.test_scope():\n      dim = array_ops.placeholder(dtypes.int32)\n      l = list_ops.empty_tensor_list(\n          element_shape=(dim, 15),\n          element_dtype=dtypes.float32,\n          max_num_elements=20)\n      e32 = list_ops.tensor_list_element_shape(l, shape_type=dtypes.int32)\n      e64 = list_ops.tensor_list_element_shape(l, shape_type=dtypes.int64)\n      self.assertAllEqual(sess.run(e32, {dim: 10}), (10, 15))\n      self.assertAllEqual(sess.run(e64, {dim: 7}), (7, 15))\n\n  def testPushPop(self):\n    with self.session() as sess, self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_shape=(7, 15),\n          element_dtype=dtypes.float32,\n          max_num_elements=10)\n      l = list_ops.tensor_list_push_back(\n          l, constant_op.constant(1.0, shape=(7, 15)))\n      l = list_ops.tensor_list_push_back(\n          l, constant_op.constant(2.0, shape=(7, 15)))\n      l, e2 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      _, e1 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(sess.run(e2), 2.0 * np.ones((7, 15)))\n      self.assertAllEqual(sess.run(e1), 1.0 * np.ones((7, 15)))\n\n  def testDoNotConstantFoldVariants(self):\n    with self.session() as sess, self.test_scope():\n      val = array_ops.placeholder(dtype=dtypes.float32)\n      l = list_ops.empty_tensor_list(\n          element_shape=(7, 15),\n          element_dtype=dtypes.float32,\n          max_num_elements=10)\n      # Note: Pushing a Placeholder will force the constant folding code\n      # to build a Const node with a DT_VARIANT output. This tests that XLA\n      # passes a cf_consider_fn which prevent folding such nodes.\n      l = list_ops.tensor_list_push_back(\n          l, array_ops.fill(value=val, dims=(7, 15)))\n      l = list_ops.tensor_list_push_back(\n          l, constant_op.constant(2.0, shape=(7, 15)))\n      l, e2 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      _, e1 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(sess.run(e2, {val: 1.0}), 2.0 * np.ones((7, 15)))\n      self.assertAllEqual(sess.run(e1, {val: 1.0}), 1.0 * np.ones((7, 15)))\n\n  def testPushPopSeparateLists(self):\n    with self.session() as sess, self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_shape=[],\n          element_dtype=dtypes.float32,\n          max_num_elements=20)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n      l2 = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n      l3 = list_ops.tensor_list_push_back(l, constant_op.constant(3.0))\n      _, e11 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      l2, e21 = list_ops.tensor_list_pop_back(l2, element_dtype=dtypes.float32)\n      l2, e22 = list_ops.tensor_list_pop_back(l2, element_dtype=dtypes.float32)\n      l3, e31 = list_ops.tensor_list_pop_back(l3, element_dtype=dtypes.float32)\n      l3, e32 = list_ops.tensor_list_pop_back(l3, element_dtype=dtypes.float32)\n      result = sess.run([e11, [e21, e22], [e31, e32]])\n      self.assertEqual(result, [1.0, [2.0, 1.0], [3.0, 1.0]])\n\n  def testEmptyTensorListNoMax(self):\n    with self.session() as sess, self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_shape=(7, 15), element_dtype=dtypes.float32)\n      l = list_ops.tensor_list_push_back(\n          l, constant_op.constant(1.0, shape=(7, 15)))\n      _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                  \"Set the max number of elements\"):\n        self.assertAllEqual(sess.run(e), 1.0 * np.ones((7, 15)))\n\n  def testEmptyTensorListMax(self):\n    with self.session() as sess, self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_shape=(10, 15), element_dtype=dtypes.float32,\n          max_num_elements=2)\n      l = list_ops.tensor_list_push_back(\n          l, array_ops.fill(value=3.0, dims=(10, 15)))\n      _, e = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(sess.run(e), 3.0 * np.ones((10, 15)))\n\n  def testListFromTensor(self):\n    with self.session(), self.test_scope():\n      t = constant_op.constant([1.0, 2.0])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(e, 1.0)\n      l, e0 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(e0, 2.0)\n      l, e1 = list_ops.tensor_list_pop_back(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(e1, 1.0)\n      self.assertAllEqual(list_ops.tensor_list_length(l), 2)\n\n  def testGetSet(self):\n    with self.session(), self.test_scope():\n      t = constant_op.constant([1.0, 2.0])\n      l = list_ops.tensor_list_from_tensor(t, element_shape=[])\n      e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(e0, 1.0)\n      l = list_ops.tensor_list_set_item(l, 0, 3.0)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [3.0, 2.0])\n\n  def testSetDoesNotUpdatePushIndex(self):\n    with self.session(), self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_shape=[], element_dtype=dtypes.float32, max_num_elements=2)\n      # SetItem should not change the push index.\n      l = list_ops.tensor_list_set_item(l, 1, 3.)\n      l = list_ops.tensor_list_push_back(l, 5.)\n      l = list_ops.tensor_list_push_back(l, 7.)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [5., 7.])\n\n  def testGetSetReserved(self):\n    with self.session(), self.test_scope():\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32, element_shape=[], num_elements=2)\n      e0 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(e0, 0.0)\n      l = list_ops.tensor_list_set_item(l, 0, 3.0)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [3.0, 0.0])\n\n  def testSetStackReservedUnknownElementShape(self):\n    with self.session(), self.test_scope():\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32, element_shape=None, num_elements=2)\n      l = list_ops.tensor_list_set_item(l, 0, [3.0, 4.0])\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [[3.0, 4.0], [0., 0.]])\n\n  def testPushInEmptyListWithUnknownElementShape(self):\n    with self.session(), self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32, element_shape=None, max_num_elements=2)\n      l = list_ops.tensor_list_push_back(l, [3.0, 4.0])\n      # Pushing an element with a different shape should raise an error.\n      with self.assertRaisesRegex(errors.InternalError, \"shape\"):\n        l = list_ops.tensor_list_push_back(l, 5.)\n        self.evaluate(\n            list_ops.tensor_list_stack(l, element_dtype=dtypes.float32))\n\n  def testGetSetReservedNonScalar(self):\n    with self.session() as sess, self.test_scope():\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32,\n          element_shape=(7, 15),\n          num_elements=2)\n      l = list_ops.tensor_list_set_item(\n          l, 0, constant_op.constant(1.0, shape=(7, 15)))\n      e1 = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      e2 = list_ops.tensor_list_get_item(l, 1, element_dtype=dtypes.float32)\n      self.assertAllEqual(sess.run(e1), np.ones((7, 15)))\n      self.assertAllEqual(sess.run(e2), np.zeros((7, 15)))\n\n  def testStack(self):\n    with self.session(), self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[],\n          max_num_elements=2)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n      e = list_ops.tensor_list_get_item(l, 0, element_dtype=dtypes.float32)\n      self.assertAllEqual(e, 1.0)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(2.0))\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t.shape.as_list(), [None])\n      self.assertAllEqual(t, [1.0, 2.0])\n\n  @parameterized.named_parameters(\n      (\"FlatList\", [1.0, 2.0, 3.0], [], [0, 2], [1.0, 3.0]),\n      (\"NestedList\", [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]\n                     ], [2], [1], [[3.0, 4.0]]),\n      (\"EmptyIndices\", [1.0, 2.0, 3.0], [], [], []),\n  )\n  def testGather(self, input_list, element_shape, indices, output):\n    with self.session(), self.test_scope():\n      tensor_list = list_ops.tensor_list_from_tensor(\n          input_list, element_shape=element_shape)\n      gather_t = list_ops.tensor_list_gather(\n          tensor_list, indices, element_dtype=dtypes.float32)\n      self.assertAllEqual(gather_t, output)\n\n  def testStackWithUninitializedTensors(self):\n    with self.session(), self.test_scope():\n      l = list_ops.tensor_list_reserve(\n          element_dtype=dtypes.float32, element_shape=[], num_elements=3)\n      t = list_ops.tensor_list_stack(l, element_dtype=dtypes.float32)\n      self.assertAllEqual(t, [0., 0., 0.])\n\n  def testZerosLikeForTensorList(self):\n    with self.session(), self.test_scope():\n      l = list_ops.empty_tensor_list(\n          element_dtype=dtypes.float32,\n          element_shape=[],\n          max_num_elements=2)\n      l = list_ops.tensor_list_push_back(l, constant_op.constant(1.0))\n      z = array_ops.zeros_like(l)\n      z = list_ops.tensor_list_stack(z, element_dtype=dtypes.float32)\n      self.assertAllEqual(z.shape.as_list(), [None])\n      self.assertAllEqual(z, [0.0, 0.0])\n\n  def testInvalidSplitLength(self):\n    with self.session(), self.test_scope():\n      tensor_list_split = list_ops.tensor_list_split(\n          tensor=[1], element_shape=[-1], lengths=[0]\n      )\n      with self.assertRaisesRegex(\n          errors.UnimplementedError, \"All lengths must be positive\"\n      ):\n        self.evaluate(tensor_list_split)\n\n\nif __name__ == \"__main__\":\n  os.environ[\"TF_XLA_FLAGS\"] = (\"--tf_xla_min_cluster_size=2 \" +\n                                os.environ.get(\"TF_XLA_FLAGS\", \"\"))\n  test.main()"