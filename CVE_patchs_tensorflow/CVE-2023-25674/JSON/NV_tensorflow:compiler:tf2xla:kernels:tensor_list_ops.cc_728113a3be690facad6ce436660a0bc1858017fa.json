"/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// XLA TensorList operators.\n\n#include <limits>\n#include <utility>\n#include <vector>\n\n#include \"tensorflow/compiler/tf2xla/kernels/gather_op_helpers.h\"\n#include \"tensorflow/compiler/tf2xla/kernels/tensor_list_utils.h\"\n#include \"tensorflow/compiler/tf2xla/shape_util.h\"\n#include \"tensorflow/compiler/tf2xla/type_util.h\"\n#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n#include \"tensorflow/compiler/tf2xla/xla_op_registry.h\"\n#include \"tensorflow/compiler/xla/client/xla_builder.h\"\n#include \"tensorflow/compiler/xla/literal.h\"\n#include \"tensorflow/compiler/xla/status_macros.h\"\n#include \"tensorflow/compiler/xla/xla_data.pb.h\"\n#include \"tensorflow/core/framework/bounds_check.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/partial_tensor_shape.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\n\nnamespace {\n\n// GetTensorListDynamicDims collects the dynamic dimensions that a tensorlist\n// may carry and returns them in a 2D vector: XlaOp[ElementSize][DimSize]. If a\n// dimension is static, a constant dimension is returned. If a dim is dynamic, a\n// dynamic XlaOp representing the dynamic size is returned.\nStatusOr<std::vector<std::vector<xla::XlaOp>>> GetTensorListDynamicDims(\n    XlaOpKernelContext* ctx, const xla::Shape& element_shape,\n    const xla::Shape& list_shape, int64_t num_elements) {\n  std::vector<int64_t> dynamic_sizes;\n  // The multiplier can be a dynamic value.\n  TF_RETURN_IF_ERROR(ctx->ConstantInputAsIntVector(0, &dynamic_sizes));\n  std::vector<bool> dims_are_dynamic;\n  TF_RETURN_IF_ERROR(\n      ctx->ResolveInputDynamismIntoPredVector(0, &dims_are_dynamic));\n  bool leading_dim_is_dynamic;\n  TF_RETURN_IF_ERROR(\n      ctx->ResolveInputDynamismIntoPred(1, &leading_dim_is_dynamic));\n  std::vector<std::vector<xla::XlaOp>> list_dynamic_dims;\n  // Set dynamic dimension size to 0 for initialization value.\n  std::vector<xla::XlaOp> dynamic_dims;\n  dynamic_dims.reserve(1 + element_shape.dimensions_size());\n  if (leading_dim_is_dynamic) {\n    dynamic_dims.push_back(ctx->Input(1));\n  } else {\n    dynamic_dims.push_back(\n        xla::ConstantR0<int32>(ctx->builder(), num_elements));\n  }\n  for (int64_t dim = 0; dim < element_shape.dimensions_size(); ++dim) {\n    if (dims_are_dynamic[dim]) {\n      auto dynamic_dim_size = xla::Slice(ctx->Input(0), {dim}, {dim + 1}, {1});\n      dynamic_dim_size = xla::Reshape(dynamic_dim_size, {});\n      dynamic_dim_size = xla::ConvertElementType(dynamic_dim_size, xla::S32);\n      dynamic_dims.push_back(dynamic_dim_size);\n    } else {\n      dynamic_dims.push_back(\n          xla::ConstantR0<int32>(ctx->builder(), dynamic_sizes[dim]));\n    }\n  }\n  list_dynamic_dims.push_back(std::move(dynamic_dims));\n  return list_dynamic_dims;\n}\n\nclass TensorListLengthOp : public XlaOpKernel {\n public:\n  explicit TensorListLengthOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    int64_t leading_dim;\n    xla::XlaOp leading_dim_size;\n    bool leading_dim_is_dynamic;\n    OP_REQUIRES_OK(ctx, GetLeadingDimForTensorList(ctx->Input(0), &leading_dim,\n                                                   &leading_dim_is_dynamic,\n                                                   &leading_dim_size));\n    ctx->SetOutput(0, leading_dim_size);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListLengthOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListLength\").IsMetadataOp(), TensorListLengthOp);\n\n// \"input\" is the shape input for EmptyTensorList/TensorListReserve ops.\n// If \"input\" is a compile time constant and not \"unknown rank\" (-1), return\n// its value in \"*shape\".\nStatus TryGetElementShapeFromInput(XlaOpKernelContext* ctx, xla::XlaOp input,\n                                   xla::PrimitiveType dtype, bool* got_shape,\n                                   xla::Shape* shape) {\n  auto is_compile_time_constant_or = input.builder()->IsConstant(input);\n  TF_RETURN_IF_ERROR(is_compile_time_constant_or.status());\n\n  bool is_compile_time_constant = is_compile_time_constant_or.value();\n  if (!is_compile_time_constant) {\n    *got_shape = false;\n    return OkStatus();\n  }\n\n  PartialTensorShape partial_shape;\n  TF_RETURN_IF_ERROR(ctx->ConstantInputAsPartialShape(0, &partial_shape));\n  if (!partial_shape.IsFullyDefined()) {\n    *got_shape = false;\n    return OkStatus();\n  }\n\n  *shape = xla::ShapeUtil::MakeShape(dtype, partial_shape.dim_sizes());\n  *got_shape = true;\n  return OkStatus();\n}\n\nclass TensorListReserveOp : public XlaOpKernel {\n public:\n  explicit TensorListReserveOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));\n    // Only non-nested TensorList is supported for now.\n    OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    int64_t num_elements;\n    OP_REQUIRES_OK(ctx,\n                   ctx->ConstantInputAsIntScalar(\n                       1, &num_elements, xla::ValueInferenceMode::kUpperBound));\n    bool num_element_is_dynamic;\n    OP_REQUIRES_OK(\n        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic));\n    OP_REQUIRES(\n        ctx, num_elements >= 0,\n        errors::InvalidArgument(\n            \"XLA compilation requires a fixed tensor list size. Set the number \"\n            \"of elements. This could also happen if you're using a TensorArray \"\n            \"in a while loop that does not have its maximum_iteration set, you \"\n            \"can fix this by setting maximum_iteration to a suitable value.\"));\n\n    // If element shape is compile time constant and it's not \"unknown rank\"\n    // shape (-1), create an initialized TensorList. Otherwise create an\n    // uninitialized TensorList.\n    xla::XlaOp element_shape_handle = ctx->Input(0);\n    xla::PrimitiveType type;\n    OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));\n    bool got_shape;\n    xla::Shape element_shape;\n    OP_REQUIRES_OK(ctx,\n                   TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                               &got_shape, &element_shape));\n    if (got_shape) {\n      xla::Shape list_shape;\n      OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(\n                              element_shape, num_elements,\n                              num_element_is_dynamic, &list_shape));\n      // Set up dynamic dimension sizes to create the zero tensor.\n      auto list_dynamic_dims_or = GetTensorListDynamicDims(\n          ctx, element_shape, list_shape, num_elements);\n      OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());\n      xla::XlaOp new_list;\n      OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(\n                              ctx->builder(), list_shape,\n                              list_dynamic_dims_or.value(), &new_list));\n      xla::XlaOp result;\n      OP_REQUIRES_OK(\n          ctx,\n          SetTensorListPushIndex(\n              new_list, xla::ConstantR0<int32>(ctx->builder(), num_elements),\n              &result));\n      ctx->SetTensorListOutput(0, result);\n      return;\n    }\n\n    xla::XlaOp result = BuildUninitializedTensorList(\n        ctx->builder(), num_elements, num_element_is_dynamic, ctx->Input(1));\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListReserveOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListReserve\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"num_elements\"),\n                TensorListReserveOp);\n\nclass EmptyTensorListOp : public XlaOpKernel {\n public:\n  explicit EmptyTensorListOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    int64_t max_num_elements;\n    OP_REQUIRES_OK(\n        ctx, ctx->ConstantInputAsIntScalar(\n                 1, &max_num_elements, xla::ValueInferenceMode::kUpperBound));\n    bool num_element_is_dynamic;\n    OP_REQUIRES_OK(\n        ctx, ctx->ResolveInputDynamismIntoPred(1, &num_element_is_dynamic));\n    OP_REQUIRES(ctx, max_num_elements >= 0,\n                errors::InvalidArgument(\n                    \"XLA compilation requires a fixed tensor list size. Set \"\n                    \"the max number of elements. This could also happen if \"\n                    \"you're using a TensorArray in a while loop that does not \"\n                    \"have its maximum_iteration set, you can fix this by \"\n                    \"setting maximum_iteration to a suitable value.\"));\n\n    if (dtype_ != DT_VARIANT) {\n      // We are creating a non-nested TensorList.\n      // If element shape is compile time constant and it's not \"unknown\n      // rank\" shape (-1), create an initialized TensorList. Otherwise\n      // create an uninitialized TensorList.\n      xla::XlaOp element_shape_handle = ctx->Input(0);\n      xla::PrimitiveType type;\n      OP_REQUIRES_OK(ctx, DataTypeToPrimitiveType(dtype_, &type));\n      bool got_shape;\n      xla::Shape element_shape;\n      OP_REQUIRES_OK(\n          ctx, TryGetElementShapeFromInput(ctx, element_shape_handle, type,\n                                           &got_shape, &element_shape));\n      if (got_shape) {\n        xla::Shape list_shape;\n        OP_REQUIRES_OK(ctx, GetTensorListShapeFromElementShape(\n                                element_shape, max_num_elements,\n                                num_element_is_dynamic, &list_shape));\n        // Set up dynamic dimension sizes to create the zero tensor.\n        auto list_dynamic_dims_or = GetTensorListDynamicDims(\n            ctx, element_shape, list_shape, max_num_elements);\n        OP_REQUIRES_OK(ctx, list_dynamic_dims_or.status());\n\n        xla::XlaOp result;\n        OP_REQUIRES_OK(ctx, CreateZerosTensorListWithShape(\n                                ctx->builder(), list_shape,\n                                list_dynamic_dims_or.value(), &result));\n\n        ctx->SetTensorListOutput(0, result);\n        return;\n      }\n    }\n\n    // We are creating a nested TensorList or a non-nested TensorList with\n    // unknown shape. Just create an uninitialized TensorList.\n    xla::XlaOp result =\n        BuildUninitializedTensorList(ctx->builder(), max_num_elements,\n                                     num_element_is_dynamic, ctx->Input(1));\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(EmptyTensorListOp);\n};\n\nREGISTER_XLA_OP(Name(\"EmptyTensorList\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"max_num_elements\")\n                    .AllowVariantTypes(),\n                EmptyTensorListOp);\n\nclass TensorListElementShapeOp : public XlaOpKernel {\n public:\n  explicit TensorListElementShapeOp(OpKernelConstruction* ctx)\n      : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"shape_type\", &shape_type_));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListElementShape.\"));\n\n    // For non-nested TensorList, element shape is the buffer shape without\n    // the first dimension.\n    xla::XlaBuilder* b = ctx->builder();\n    xla::Shape list_shape;\n    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(ctx->Input(0), &list_shape));\n    list_shape.DeleteDimension(0);\n\n    switch (shape_type_) {\n      case DT_INT64:\n        ctx->SetOutput(0, xla::ConstantR1<int64_t>(b, list_shape.dimensions()));\n        break;\n      case DT_INT32: {\n        std::vector<int32> size;\n        const auto& dimensions = list_shape.dimensions();\n        size.reserve(dimensions.size());\n        for (int64_t s : dimensions) {\n          size.push_back(s);\n        }\n        ctx->SetOutput(0, xla::ConstantR1<int32>(b, size));\n        break;\n      }\n      default:\n        ctx->CtxFailure(\n            errors::InvalidArgument(\"Unsupported shape type requested\"));\n        return;\n    }\n  }\n\n private:\n  DataType shape_type_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListElementShapeOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListElementShape\").IsMetadataOp(),\n                TensorListElementShapeOp);\n\nclass TensorListGetItemOp : public XlaOpKernel {\n public:\n  explicit TensorListGetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"));\n\n    xla::XlaOp list = ctx->Input(0);\n    xla::XlaOp index = ctx->Input(1);\n\n    xla::XlaOp result;\n    OP_REQUIRES_OK(ctx, ExecuteTensorListGetItem(list, index, &result));\n\n    ctx->SetOutput(0, result);\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListGetItemOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListGetItem\"), TensorListGetItemOp);\n\nclass TensorListGatherOp : public XlaOpKernel {\n public:\n  explicit TensorListGatherOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGather.\"));\n\n    DataType indices_type = ctx->input_type(1);\n\n    const TensorShape indices_shape = ctx->InputShape(1);\n    OP_REQUIRES(ctx, indices_shape.dims() == 1,\n                errors::InvalidArgument(\"indices must be rank 1\"));\n\n    xla::XlaOp list = ctx->Input(0);\n    xla::XlaOp indices = ctx->Input(1);\n\n    xla::XlaOp buffer;\n    OP_REQUIRES_OK(ctx, GetTensorListBuffer(list, &buffer));\n    xla::Shape buffer_xla_shape;\n    OP_REQUIRES_OK(ctx, GetTensorListBufferShape(list, &buffer_xla_shape));\n    TensorShape buffer_shape;\n    OP_REQUIRES_OK(ctx, XLAShapeToTensorShape(buffer_xla_shape, &buffer_shape));\n\n    xla::XlaOp result;\n    OP_REQUIRES_OK(\n        ctx, XlaGather(buffer, buffer_shape, indices, indices_shape, /*axis=*/0,\n                       /*indices_are_nd=*/false, dtype_, indices_type,\n                       ctx->builder(), &result));\n    ctx->SetOutput(0, result);\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListGatherOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListGather\"), TensorListGatherOp);\n\nclass TensorListStackOp : public XlaOpKernel {\n public:\n  explicit TensorListStackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(ctx->Input(0), &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListGetItem.\"));\n\n    xla::XlaOp buffer;\n    OP_REQUIRES_OK(ctx, GetTensorListBuffer(ctx->Input(0), &buffer));\n    ctx->SetOutput(0, buffer);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListStackOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListStack\"), TensorListStackOp);\n\nclass TensorListConcatOp : public XlaOpKernel {\n public:\n  explicit TensorListConcatOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    xla::XlaOp input = ctx->Input(0);\n\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx, (IsTensorListInitialized(input, &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(input, &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListConcat.\"));\n\n    xla::XlaOp buffer;\n    OP_REQUIRES_OK(ctx, GetTensorListBuffer(input, &buffer));\n\n    xla::XlaBuilder* b = input.builder();\n    auto shape_or = b->GetShape(buffer);\n    OP_REQUIRES_OK(ctx, shape_or.status());\n    xla::Shape element_shape = std::move(shape_or).value();\n    std::vector<int64_t> element_dims =\n        xla::SpanToVector(element_shape.dimensions());\n    OP_REQUIRES(\n        ctx, element_dims.size() > 1,\n        errors::Unimplemented(\"TensorList of scalars is not supported\"));\n    int64_t num_elements = element_dims[0];\n    int64_t tensor_lengths = element_dims[1];\n\n    std::vector<int64_t> new_dims = {num_elements * tensor_lengths};\n\n    for (int i = 2; i < element_dims.size(); i++) {\n      new_dims.push_back(element_dims[i]);\n    }\n\n    xla::XlaOp out = xla::Reshape(buffer, new_dims);\n    ctx->SetOutput(0, out);\n\n    // Second output is a tensor of lengths of returned tensors.\n    xla::XlaOp lengths = xla::ConstantR1(b, num_elements, tensor_lengths);\n    ctx->SetOutput(1, lengths);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListConcatOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListConcatV2\"), TensorListConcatOp);\n\nclass TensorListSplitOp : public XlaOpKernel {\n public:\n  explicit TensorListSplitOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"element_dtype\", &dtype_));\n    // Only non-nested TensorList is supported for now.\n    OP_REQUIRES(\n        ctx, dtype_ != DT_VARIANT,\n        errors::Unimplemented(\n            \"Only non-nested TensorList is supported for TensorListReserve.\"));\n  }\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    xla::XlaOp input_tensor = ctx->Input(0);\n\n    xla::XlaBuilder* b = input_tensor.builder();\n    auto shape_or = b->GetShape(input_tensor);\n    OP_REQUIRES_OK(ctx, shape_or.status());\n    xla::Shape element_shape = std::move(shape_or).value();\n    std::vector<int64_t> element_dims =\n        xla::SpanToVector(element_shape.dimensions());\n    OP_REQUIRES(\n        ctx, !element_dims.empty(),\n        errors::Unimplemented(\"Element dimensions have to be non-empty\"));\n\n    std::vector<int64_t> lengths;\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntVector(2, &lengths));\n    OP_REQUIRES(ctx, !lengths.empty(),\n                errors::Unimplemented(\"Length has to be non-empty\"));\n    int64_t length = lengths[0];\n    for (int64_t len : lengths) {\n      OP_REQUIRES(ctx, len == length,\n                  errors::Unimplemented(\"All lengths have to be the same\"));\n    }\n    OP_REQUIRES(ctx, length,\n                errors::Unimplemented(\"All lengths must be positive\"));\n    OP_REQUIRES(\n        ctx, element_dims[0] % length == 0,\n        errors::Unimplemented(\"Buffer size has to be a multiple of length\"));\n    std::vector<int64_t> new_dims = {element_dims[0] / length, length};\n    for (int i = 1; i < element_dims.size(); i++) {\n      new_dims.push_back(element_dims[i]);\n    }\n\n    xla::XlaOp reshaped = xla::Reshape(input_tensor, new_dims);\n\n    xla::XlaOp result;\n    OP_REQUIRES_OK(ctx, ExecuteTensorListFromTensor(length, reshaped, &result));\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListSplitOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListSplit\")\n                    .CompileTimeConstantInput(\"element_shape\")\n                    .CompileTimeConstantInput(\"lengths\"),\n                TensorListSplitOp);\n\nclass TensorListFromTensorOp : public XlaOpKernel {\n public:\n  explicit TensorListFromTensorOp(OpKernelConstruction* ctx)\n      : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    const TensorShape& tensor_shape = ctx->InputShape(0);\n    int num_elements = tensor_shape.dim_size(0);\n    const xla::XlaOp tensor = ctx->Input(0);\n    xla::XlaOp result;\n    OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListFromTensor(num_elements, tensor, &result));\n    auto list_shape_or = ctx->builder()->GetShape(result);\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListFromTensorOp);\n};\n\nREGISTER_XLA_OP(\n    Name(\"TensorListFromTensor\").CompileTimeConstantInput(\"element_shape\"),\n    TensorListFromTensorOp);\n\nclass TensorListSetItemOp : public XlaOpKernel {\n public:\n  explicit TensorListSetItemOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    xla::XlaOp list = ctx->Input(0);\n    xla::XlaOp index = ctx->Input(1);\n    xla::XlaOp element = ctx->Input(2);\n    xla::XlaOp initialized_list;\n    OP_REQUIRES_OK(ctx, GetInitializedTensorListForElement(\n                            list, element, /*element_is_tensor_list=*/false,\n                            &initialized_list));\n\n    // Only non-nested TensorList is supported for now.\n    bool is_nested;\n    OP_REQUIRES_OK(ctx, IsNestedTensorList(initialized_list, &is_nested));\n    OP_REQUIRES(ctx, !is_nested,\n                errors::Unimplemented(\"Only non-nested TensorList is supported \"\n                                      \"for TensorListSetItem.\"));\n\n    xla::XlaOp result;\n    OP_REQUIRES_OK(ctx, ExecuteTensorListSetItem(initialized_list, index,\n                                                 element, &result));\n\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListSetItemOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListSetItem\"), TensorListSetItemOp);\n\nclass TensorListPushBackOp : public XlaOpKernel {\n public:\n  explicit TensorListPushBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    xla::XlaOp list = ctx->Input(0);\n    xla::XlaOp element = ctx->Input(1);\n    bool element_is_tensor_list = IsTensorListInput(ctx, 1);\n    xla::XlaOp initialized_list;\n    OP_REQUIRES_OK(\n        ctx, GetInitializedTensorListForElement(\n                 list, element, element_is_tensor_list, &initialized_list));\n\n    xla::XlaOp result;\n    OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPushBack(initialized_list, element,\n                                             element_is_tensor_list, &result));\n\n    ctx->SetTensorListOutput(0, result);\n  }\n\n private:\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListPushBackOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListPushBack\").AllowVariantTypes(),\n                TensorListPushBackOp);\n\nclass TensorListPopBackOp : public XlaOpKernel {\n public:\n  explicit TensorListPopBackOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {}\n\n  void Compile(XlaOpKernelContext* ctx) override {\n    // Check that the TensorList is initialized.\n    bool is_initialized;\n    OP_REQUIRES_OK(ctx,\n                   (IsTensorListInitialized(ctx->Input(0), &is_initialized)));\n    OP_REQUIRES(ctx, is_initialized,\n                errors::InvalidArgument(\"TensorList is not initialized\"));\n\n    xla::XlaOp list = ctx->Input(0);\n    xla::XlaOp list_result, element_result;\n    bool element_is_tensor_list;\n    OP_REQUIRES_OK(ctx,\n                   ExecuteTensorListPopBack(list, &list_result, &element_result,\n                                            &element_is_tensor_list));\n\n    ctx->SetTensorListOutput(0, list_result);\n    if (element_is_tensor_list) {\n      ctx->SetTensorListOutput(1, element_result);\n    } else {\n      ctx->SetOutput(1, element_result);\n    }\n  }\n\n private:\n  DataType dtype_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorListPopBackOp);\n};\n\nREGISTER_XLA_OP(Name(\"TensorListPopBack\").AllowVariantTypes(),\n                TensorListPopBackOp);\n\n}  // anonymous namespace\n}  // namespace tensorflow"